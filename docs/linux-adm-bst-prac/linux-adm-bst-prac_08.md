# 第五章：补丁管理策略

在 Linux 系统的日常操作中，平均系统管理员最常见的任务大概是补丁管理（即补丁更新）。与 Windows 和 macOS 世界不同，系统管理员通常负责处理各种操作系统和应用程序的补丁更新任务，涵盖了主系统和第三方生态系统。同时，系统中通常内置或通过第三方提供应用程序管理工具，以协助完成这项可能令人生畏的工作。

补丁管理，当然还有系统更新，是我们工作中的重要部分，虽然它可能感觉平凡，但确保它做得正确非常重要。而今天的生产 Linux 系统比十年前更加复杂和多样化。补丁管理也变得比以往任何时候都更为重要，我们预计这一趋势随着时间的推移只会越来越明显。

我们将首先了解补丁和更新是如何提供的，以及我们所说的不同安装方法的含义。

在本章中，我们将学习以下内容：

+   二进制、源代码和脚本软件部署

+   补丁理论与策略

+   管理员的编译工作

+   Linux 安装与重新部署策略

+   重启服务器

# 二进制、源代码和脚本软件部署

软件有各种形态和大小。因此，软件部署并不是一刀切的事。软件的标准部署方式有三种：直接作为二进制包、通过需要编译成二进制包的源代码，或者作为脚本。我们将深入探讨这些方式，因为理解每种方式的含义及其适用场景非常重要。

## 编译型和解释型软件

许多系统管理员从未作为开发人员工作过，通常也不了解软件的存在形式。编程语言主要有两种基本类型：编译型和解释型。

编译语言是用一种语言（源代码）编写的，通过编译器生成二进制可执行代码，这些代码可以直接在操作系统上运行。这可能是一个过于简化的说法，但我们不是开发人员，仅需要关注原始代码被编译成二进制格式即可。对于 Linux，这种格式被称为**ELF**，即**可执行与可链接格式**。编译后的二进制文件在操作系统上运行。

解释型语言有所不同。它们不像编译成二进制那样，而是保持原样，并由一个叫做解释器的程序实时处理，解释器本身是一个二进制可执行文件，它将代码作为输入文件来处理。因此，解释型软件要求操作系统上安装适当的解释器，以便该软件能正常工作。例如，如果你有一个 Python 程序，并希望在某个系统上运行，那么你需要确保该系统上安装了 Python 解释器来处理这个文件。

这两种软件方法完全正常且有效。作为系统管理员，我们将始终与这两种方法打交道。现代计算机（和解释器）速度非常快，因此两者之间的性能差异几乎没有什么关切，其他因素（主要是开发人员的考虑）通常在决定软件如何编写时更为重要。

软件并不完全如此简单，存在一些奇怪的概念，比如看似解释型的代码，实际上却在最后一刻被编译并像二进制文件一样运行。一些像基于.NET 和 Java 的语言，虽然是编译的，但并不是编译成二进制文件，因此本质上是结合了两种方法的一种混合体，兼具两者的优点。

然而，通常我们将所有软件视为二进制可执行文件（直接在操作系统上运行，无需帮助）或解释型软件（需要操作系统上的编程语言环境或*平台*来运行）。为了理解代码部署的目的，像.NET 和 Java 这样的语言，以及**JIT**（**即时编译**）的语言，如 Perl，由于其行为，通常被归类为解释型语言。

常见的预编译语言包括 C、C++、Rust 和 Go。常见的解释型语言，或者看起来像是解释型语言的，包括 Python、PHP、Perl 和 Ruby。更让人困惑的是，任何解释型语言都可以被编译。标准编译语言甚至可以被解释！更重要的不是*语言本身做了什么*，而是*在特定情况下它是怎么做的*？本质上，任何语言*都可以*根据我们在实践中的处理方式来选择编译或解释。然而，在现实世界中，没有人会解释 C++，也没有人会编译 Python。但如果你愿意，还是有可能的。

作为系统管理员，我们实际上对软件的构建没有发言权，我们只需要按给定的方式部署软件。我们最需要理解的是，我们可能对整个平台的控制和影响力有多少。如果我们运行一个二进制应用程序，那么我们的实际选项可能仅限于我们所运行的内核版本。但如果我们要安装一个 PHP 脚本，我们可能还需要决定如何安装 PHP，选择哪个版本，选择哪个 PHP 提供者，等等。在某些情况下，这可能变得相当复杂。

在几乎所有商业场景中，我们部署的大多数软件将是二进制格式。通常，我们甚至可能不知道（或不关心）特定的软件，因为整个过程通常会由其他人处理。盲目安装软件的情况非常常见。

系统管理员安装由脚本构成的软件的情况越来越常见，这些脚本是可以直接读取的代码。这些文件只是由解释器处理。因此，软件从未以二进制形式存在于磁盘上。由于现代计算机系统如此强大，尽管这一过程在效率上似乎存在问题，但通常并不成问题。现在，许多流行的软件包都是以这种方式编写和交付的，因此大多数系统管理员通常会与脚本安装打交道。

在许多情况下，脚本的安装与二进制软件包使用相同的自动化方法，这使得整个过程通常对管理员透明。作为系统管理员，你可能并不总是知道自己正在部署的是什么类型的软件包，除非你深入其底层组件。这种情况在非关键软件包中尤为明显，尤其是使用依赖解决系统部署的软件包（例如 PHP 或 Python），它们为你处理了平台的集成，或者这些依赖项已经为其他组件提前安装好了。

今天，我们预期脚本的安装将成为一项常见的任务，这可能不会代表部署到系统上的大多数软件包，但它很容易构成系统上主要的工作负载代码。我的意思是，操作系统、支持工具和大型系统库通常是二进制软件包。但最终的工作负载，系统之所以存在，往往有很大可能是脚本，而非编译后的二进制文件。

最后，最后一种类型是不能直接运行的源代码，必须先编译成二进制软件包才能运行。我们将在接下来的两个部分中深入讨论这个主题，因此这里只会简单提及。你可以争辩说，这种方法仍然是二进制安装，因为最终部署的软件包是二进制的，这完全正确。然而，为了获取和部署这个二进制文件，必须遵循的工作流程截然不同，因此这成为了一种有效的三级部署选项。一些系统会自动执行编译步骤，因此有可能出现一个部署包，它在编译并安装二进制文件的同时，系统管理员甚至都没有察觉。

## 误导性的源代码安装使用

由于我们稍后将在本章深入讨论的原因，从源代码安装软件通常会有不好的声誉。在某些方面，这是应得的，而在某些方面，又并非如此。

因为源代码安装在实际上是自由和开源软件世界的独特存在，它在 1990 年代和 2000 年代时遭到厂商和 IT 从业人员的猛烈攻击，目的是为了抹黑它，因为它严重影响了传统的闭源产品（以及那些只支持闭源软件的人的工作）。这当然是完全虚构的，但由于源代码授权复杂难懂，很容易让那些没有掌握该话题细微差别的人产生恐惧和怀疑。

然而，更重要的是，源代码安装被贴上了不专业且不必要的标签，原因是它被认为是由一些更像爱好者的系统管理员推动的，他们在没有真正考虑业务需求的情况下以这种方式安装。它有趣，或者看起来很有印象，或者是他们的朋友这么做，所以他们也这么做。我很遗憾地说，这种说法在很大程度上是准确的。曾经有一段时期，许多软件以不必要的复杂和繁琐方式安装，而不考虑这一过程对业务的有效性。并不是说源代码编译没有其存在的价值，它确实有。但即使在二十年前或更久，这种方式也只是局限在一个小众的场景中，而不是大多数的部署情况。因此，从很多方面来看，这个坏名声是实至名归的，但并非完全如此。

然而，今天，源代码编译几乎被遗忘，几乎没有人知道如何使用标准流程来进行编译，并且相关工具的安装通常被禁止，或者这些工具并不容易获得，使得编译变得非常困难，甚至不可能。只有那些需要编译的强烈需求的软件才会以这种方式分发。因此，市场实际上几乎消除了这种做法。

但是，那些曾经进行编译的人仍然面临着恐惧和羞辱。说某人正在进行源代码安装，依然是一种贬低的说法。遗憾的是，为了进一步抹黑现今的软件，现在已经普遍将这个术语用于指代那些不需要通过源代码编译成二进制的脚本类软件。术语“源代码”暗示代码必须从源代码转化为二进制，而脚本在这个上下文中并不被认为是源代码。然而，从技术上来说，它们确实是原始代码、源代码，但不再有那个令人不悦的步骤。可是很少有人会进一步探讨这个问题，而这一小小的语言技巧很容易误导他人。所以，这成为了一种简单的手段，能够让一个仅仅寻求借口来做情绪决策的经理，被误导。这听起来很合理，而很少有人会真的去深思。

这个窍门实际上来自于语义简写，这是一个总是危险的东西，尤其是在 IT 领域。自编译软件的问题与源代码的可用性无关，而是与在使用之前需要编译它有关。如果没有这个步骤，源代码的存在对我们来说完全是积极的。人们随后错误地将编译过程称为源代码安装。这种语义错误为某些人打开了大门，他们将某个技术上确实是源代码安装的软件（没有编译）误解为安装源代码，而由于这个术语长时间被错误使用，它变成了一种负面的含义，应用到错误的事物上，最终没有人理解为什么这些东西是错的或反向的。

Linux 为我们提供了许多标准的企业级软件部署方法。尽管这些选项功能强大，但也使得标准化和长期支持的规划变得更加困难。

在所有生产环境中的 Linux 系统中，无论供应商如何，默认都会存在一个软件包管理系统。多年来，这些软件包管理系统已成为区分不同 Linux 操作系统的关键因素。存在多种软件打包格式，但其中两种，即 DEB 和 RPM，已经成为主流，其他格式则保持在非常小众的地位。

现在越来越多的 Linux 发行版要么有多个软件打包系统，要么在单一的软件包管理系统下使用多种格式。这种多样性是好的，因为它给我们提供了更多的选择来维护系统中的特定包，但也意味着更多的复杂性。

与所有软件部署一样，我们有一些对所有操作系统普遍适用的标准关注点。首先是软件是否自包含，或者是否需要访问其他包或库。传统上，大多数软件，尤其是在 Linux 和其他类 UNIX 操作系统上，都是通过利用扩展的系统和第三方库（统称为依赖关系）来减少其安装大小以及操作系统本身的大小。这意味着我们可以拥有尽可能小的软件，并且使用相同资源的其他软件可以共享它们在磁盘上的存储，从而最小化（有时显著地）我们需要存储和维护的内容。更新一个软件包或库时，所有使用该包的程序都会同步更新。另一种方式是让每个独立的软件包都携带自己的所有依赖项，并且这些依赖项仅在该软件包内可用。这会导致软件安装变得更大，并且可能会在系统中存在多次相同的数据。可能是很多次。这导致了臃肿，但也使得单个软件包更容易维护，因为不同软件组件之间的互动较少。

举个例子，数十个或更多的软件包可能都需要使用 OpenSSL 库。如果每二十个包中都有 OpenSSL，我们将把相同的代码存储在磁盘上二十次。此外，如果 OpenSSL 发布了更新，或者更重要的是，如果发现了漏洞需要修补，我们就必须修补二十次，而不是一次。相比之下，如果我们使用一个共享的 OpenSSL 库，无论我们有一个应用依赖它还是一百个应用，我们只需修补这个库，确保所有的漏洞或更新都已解决。

这两种方法都是完全有效的。过去，由于系统存储空间较小，共享库是一种“必要的恶魔”，因为共享资源不仅能减少磁盘使用，还能更好地优化内存，因为共享库有可能被加载到内存中，并且能被多个软件共享。如今，我们通常拥有更多的存储和内存，远超实际需求，这种小规模的效率优化已经不再必要，尽管它可能仍然有些许好处。非共享方法则将这种效率转化为每个软件包拥有自己的依赖项，从而避免了依赖冲突或共享资源不可用时带来的问题。

共享资源方法的最大优势可能在于，修补已知漏洞可能会更简单。举个例子，如果我们假设 OpenSSL（一个广泛共享的库）发现了一个关键漏洞并发布了更新。如果我们的系统使用共享资源，我们只需要找到安装了 OpenSSL 的系统并更新该包。所有依赖该包的系统都会自动一起修补。如果 OpenSSL 被单独打包并与数十个不同的应用程序一起使用，我们就需要找到这些应用程序中的每一个，确认它们都在使用 OpenSSL，并且要单独修补它们。这将是一个可能令人生畏的任务。我们依赖每个软件的包维护者进行适当的审查，快速修补依赖项，并立即提供更新的包给我们，但这并不是常有的事。

系统通常会使用一种包管理和软件仓库系统，如 DEB，当存在共享系统组件和需要处理许多依赖项时。它们会在将所有依赖项包含在最终包中时使用另一种包管理系统，如 SNAP。但这远比听起来复杂，例如，制作一个包含所有依赖项的 DEB 包，或者一个期望依赖项由外部提供并共享的包。DEB 通常作为软件包的共享库只是一种约定。在 Linux 中，我们还面临着一组完全不同的关注点，如果你来自 Windows 或 macOS 背景，可能并不习惯：一个与操作系统本身紧密相连的软件生态系统。在 Linux 中，我们期望操作系统（例如 RHEL、Ubuntu、Fedora、SUSE Tumbleweed 等）不仅包含基本的操作系统功能和一些极为基础的实用工具，还包括几乎所有可能描述的软件，包括核心库、编程语言、数据库、Web 服务器、终端用户应用程序等等。在很多情况下，你可能永远不会使用任何没有与你的 Linux 发行版一起打包的软件，当你添加第三方软件时，它通常是一个关键应用程序，代表着战略性业务应用，或者显而易见，是内部定制开发的软件。

因此，在 Linux 上处理软件时，我们必须考虑是使用内置操作系统的软件，独立获取并安装的软件（这包括定制软件），还是两者的混合，其中软件的许多组件来自操作系统，但一些组件由其他方式提供。

深入了解不同打包系统的具体细节没有太大意义，特别是因为它们在一般使用上往往有很大的重叠，但在实际使用中又非常独特。现在我们已经知道了它们存在的选择。软件包管理系统在 Linux 中比在其他操作系统中更为重要，如 Windows 或 macOS，因为在 Linux 运行的大型服务器系统中，通常存在更多的复杂性，而安装的软件通常使用更广泛的依赖集，从许多不同项目中拉取组件或支持库。Linux 打包系统维护在线软件、库、组件等的仓库，使这一切成为可能。

大型 Linux 软件包管理系统及其相关软件仓库最重要的方面可能是它们允许分发商在其精确的内核和组件选择与配置下，组装并测试大量的组合软件，从而提供一个庞大、可靠的平台来部署解决方案。

在这里，最佳实践是困难的。事实上，我们只能依赖经验法则，但这些法则非常强大。经验法则是尽可能使用供应商的仓库进行软件部署。这个方法看似简单和显而易见，但出乎意料的是，仍然有很多人会通过手动方式获取软件并安装，而没有供应商的测试和依赖管理的支持。

真正的最佳实践，正如你可能预期的那样，是深入了解你所选发行版的包管理生态系统，以便你能够充分利用其特性。这些特性通常包括日志记录、版本控制、回滚、补丁和系统更新自动化、校验和、自动配置等。

软件组件越常见和基础，越有可能由供应商作为分发的一部分提供。越是小众且接近业务核心，越有可能通过手动安装或非标准过程来安装它，因为最终用户产品不太可能被包含在供应商的软件仓库中，更有可能需要仔细管理版本和更新计划，而不仅仅是关注与系统其他部分的稳定性和测试。

软件供应商通常会为那些不包含在分发仓库中的产品创建和维护自己的仓库，允许你配置其仓库，仍然通过标准工具管理所有安装和补丁任务。

软件部署包含了许多特殊情况。人们很容易想要提供标准、明确的*总是这样做*的指导，但软件的工作方式并非如此。学习你系统的工具，能用时使用它们，为每个需要部署的工作负载准备做一些独特的工作或学习某些东西。有些，比如 WordPress，可能会变得非常标准，以至于你只需要使用发行版自带的软件包即可。其他软件可能会非常独特，你可能只需要部署一个基本的操作系统，下载供应商的安装程序，它会安装所需的所有软件，甚至可能会编译它！这一切都取决于情况，最重要的是，它取决于软件供应商如何构建和打包软件，以及你的发行版是否决定将该软件包包含在操作系统中，或是否需要单独安装。

现在我们已经了解了软件安装过程和相关注意事项，我们可以深入探讨关于补丁和更新的核心问题。

# 补丁理论和策略

有人可能认为打补丁是非常直接的事情，不会有太多可讨论的内容。但实际上并非如此。如果你与几个系统管理员交谈，你肯定会得到一些相当不同的看法。有些人每天打补丁，有些人每周打补丁，有些人会尽量等到最后才打补丁，还有些人则是随机进行补丁操作，甚至有些人认为根本不应该打补丁（嘿，如果它没坏，为什么要修呢！）

我们应该首先明确为什么要给软件打补丁。打补丁不同于更新或升级，它意味着我们对软件进行小范围的修复，以解决已知问题或漏洞，而不是实施新功能或特性。添加新功能通常被视为一次更新。

大多数软件供应商和操作系统供应商遵循这一系统，并维持仅在版本之间解决安全性或稳定性问题的补丁系统。在 Linux 生态系统中，这主要与操作系统的发布版本相关。例如，如果你使用的是 Ubuntu 22.04，并且通过其自身的补丁机制来修补随发行版一起提供的软件，那么你将仅获得现有软件版本的安全性和稳定性修复，而不会得到新版本、特性或功能。其逻辑在于，升级到新版本可能会导致软件出现问题、改变可用性，或使依赖该软件的其他产品失败。

升级到新版本通常只在操作系统本身发布新版本时发生，这时操作系统和所有其中的包可以同时升级。这样，操作系统供应商理论上可以将软件作为一个整体进行测试，以便让客户（你）确信，即使在将所有软件升级到新版本之后，所有的软件组件仍然能够协同工作。

因此，我们假设如果补丁已经提供给我们，这意味着供应商（很可能与我们的分发供应商合作）已经发现了需要修复的问题，已经创建了修复方案，进行了测试，现在正在分发补丁。然而，即使经过测试，众多目光监督错误，并且目标只是修复已知漏洞，事情仍然可能出错。补丁本身可能有问题，打补丁的过程也可能遇到意外的麻烦。这意味着，无论提供补丁的人有多么良好的意图，我们都必须对打补丁保持谨慎。

在打补丁时，我们面临着两个相互对立的担忧。一方面，如果系统当前对我们来说是正常工作的，为什么在没有必要的情况下还要引入补丁过程的风险（和工作量）呢？另一方面，既然补丁已经提供给我们，为什么还要继续运行一个存在已知漏洞的系统？我们必须权衡这些问题，选择一个合理的行动方案。

风险规避并不是这里的关键问题，我们并不是在权衡成本与风险，而是在面对两种几乎相等的行动方案（从努力和成本的角度来看），但它们会带来截然不同的结果。我们需要选择一个能够最大限度降低业务风险的方案，仅此而已。最重要的不是我们有多么规避风险，而是我们的风险特征是什么。如果我们的业务非常容易受到小规模停机事件的影响，那么可能会优先考虑推迟修补。如果我们公司拥有高度敏感的数据，这些数据可能成为攻击目标，或者我们非常关注在发生数据泄露时的公关危机，那么我们可能会采取非常积极的修补策略。为了做出明智的决定，我们必须了解每种方案是如何产生和缓解不同风险的，以及这些风险如何影响我们特定的组织。

## 推迟修补的风险

单纯推迟修补并不能消除某些类型的风险。虽然这可能带来一定的好处，但也可能根据情况引入更多的风险。通常情况下，新的修补程序会频繁发布，可能一天发布多次，至少也会每月发布几次。

如果我们经常修补，比如每周一次，那么理论上我们通常只需处理极少的修补程序，在任何给定时刻，任何故障或不兼容问题都相对容易识别和回滚，因为需要处理的修补程序很少。

如果我们在一段时间内积累修补程序，并且只在比如说一年一次时修补，那么我们会面临一些问题。首先，修补过程可能需要相当长的时间，因为可能需要许多修补程序。其次，如果出现故障，可能很难找出导致问题的修补程序，因为它可能会被一大堆需要部署的修补程序所掩盖。第三，一次性进行的大量更改以及与任何经过测试的场景的*偏离*（几乎没有供应商会针对像你这样具体过时的系统进行测试，并与大量突如其来的更改进行对比）意味着修补过程引发故障的几率更大。

因此，推迟修补在许多情况下会成为一种自我实现的预言，那些因为*修补会破坏东西*而避免修补的人，往往会看到这一点发生，因为他们创造了一个更容易发生的局面。

没有一刀切的方案。每个组织都必须根据自身需求定制修补流程。有些组织会通过构建无状态系统并简单地部署已经修补过的新系统，销毁旧的未修补实例，从而完全避免修补问题。但并不是每个工作负载都可以采用这种方式，也不是每个组织都有能力进行这种基础设施的跃迁，以支持这种流程。

一些组织会进行持续的补丁测试，查看补丁在其环境中的表现。一些组织完全避免打补丁，抱着侥幸心理，期望最好。一些则盲目地打补丁。我们将讨论这些不同的选择。

## 因为 Windows 而避免打补丁

最近几年，系统管理员中出现了一种*避免打补丁*的文化。考虑到打补丁在一般情况下的重要性，以及它对我们职业生涯的核心作用，这似乎有些反直觉。没有人比系统管理员更支持快速、定期打补丁。

在 Windows 世界中，打补丁的过程与 Linux 或其他操作系统截然不同。它通常是延迟的、保密的、缓慢的、不可靠的，最糟糕的是，常常存在漏洞和错误。Windows 的打补丁问题一直存在，但在 2010 年代变得如此严重，以至于它不再是确定性的，远远比直接部署新系统要花更长时间，而且经常失败。

Windows 打补丁失败可能意味着几乎任何情况，从补丁安装失败，需要投入资源使其正常运行，到导致软件故障，无法再继续使用。一些补丁可能需要耗费数小时来运行，但最终失败，然后又需要花费数小时回滚！

正因为如此，Windows 领域的系统管理员通常对补丁保持谨慎态度，甚至完全避免打补丁，几乎成为了一种普遍现象。这种现象不仅限于补丁，还扩展到系统版本更新。因此，现在发现许多 Windows 系统已经多年甚至十年未更新，已成为常态，导致整个生态系统中越来越多的安全漏洞。

微软的回应不是修复打补丁的问题，而是试图强行进行未经授权的打补丁，并且通过模糊补丁过程，制造了更多的可靠性问题，甚至在许多情况下，打补丁管理系统发生了严重故障，以至于即使是那些希望保持完全更新的管理员，常常也不确定如何操作，或者根本无法做到这一点。

这些问题今天是微软特有的，并且大多数是现代时代微软所独有的。我们不能让对这种独特糟糕情况的情绪反应影响我们在 Linux 或其他领域的实践，这些领域并未受到微软的影响。在微软孤立的行业领域之外，没有其他生态系统经历过类似的问题。无论是在 Ubuntu、Red Hat、Fedora、SUSE、IBM AIX、Oracle Solaris、FreeBSD、NetBSD、DragonFly BSD、macOS、Apple iOS、Android、Chromebook 等，都没有出现过这种情况。打补丁总是存在风险，我们应该意识到这一点，但微软的问题是独一无二的，与我们在其他行业的实践无关。

补丁可以是自动化的，也可以是手动的。两种方法都完全可以接受。自动化需要更少的努力，并且可以防止忘记补丁或降低其优先级。在大组织中，要求手动干预的正式补丁程序可能很简单，以确保一致性，但在只有几个服务器的小型组织中，补丁可能很容易被忽视，甚至几个月都没有进行。当考虑手动与自动化补丁时，只需要考虑流程的潜在可靠性和涉及的人力成本（通常是时间）。

手动补丁的好处在于，你可以让人类在每个补丁安装时*检查*每个包，并在补丁进行时实时测试系统。如果出现问题，补丁过程中的每个细节都会历历在目，因为他们刚刚执行过，而且他们知道在出现问题时应该测试什么，回滚或处理什么。

自动化的好处在于它可以自动发生，可能在非常可预测的时间内，并且即使没有人类在场工作，它也能发生。将自动化补丁安排在晚上、过夜、周末或节假日进行，可以最大限度地减少对人类的影响，同时加速补丁过程。自动化补丁不太可能被遗漏，而且在补丁发生时或出现问题时，容易发送警报。

在大多数情况下，自动化补丁比手动补丁更受欢迎，因为它成本更低，几乎所有手动的好处都可以以某种形式自动化，比如通过让人类待命，以便在出现问题时接收警报。

## 测试补丁很少是可行的

每个人都在谈论测试补丁的重要性。系统管理员常常要求这样做，并且尝试拒绝应用补丁，直到能够完成测试（这是避免完全补丁系统的一个方便方式）。如果补丁出现问题，管理层几乎总是要求了解为什么之前没有进行补丁测试。

这里有一个残酷的现实：没有任何实际可行的手段可以在任何规模上测试补丁。说到这，我说出来了。大声说出来，去告诉你的老板们。测试补丁的成本，无论是时间还是金钱，都远远大于任何人所认为的。为了彻底测试补丁，我们需要一个复制的环境，这样才能给我们提供一个与生产环境相同的镜像，以便我们能够对要部署的补丁进行测试，涉及的软件、硬件和配置。如果试图简化这一过程，是行不通的，因为正是所有这些部分的相互作用使得测试变得重要。如果你改变了任何东西，可能会完全抵消这一非常昂贵过程的好处（或者更糟糕的是，产生一种虚假的安全感）。

在真实的环境中，每个系统基本上都是独一无二的。虽然有例外，但通常情况下，这是真的。有许多可能的变量，包括硬件制造日期、不同的零部件、固件版本，以及更高层次的基础设施堆栈（即，接近最终应用的代码和组件）。今天的计算机系统如此复杂，可能有数百万种变量，导致补丁中的某个 bug 被触发。

这就是虚拟化如此重要的原因之一，它创造了一个标准化的中间层，使得系统中一些更复杂的部分能够标准化。这样，至少有一部分，涉及许多驱动程序的复杂部分，可以简化复杂性。

很少有组织会进行真正的补丁测试。这样做的成本很高。通常，这涉及到仔细复制整个生产环境，包括匹配硬件版本、固件修订、补丁历史等。每个可能的方面都应该是相同的。补丁必须通过一系列快速的测试，以测试公司范围内的各种场景中的给定补丁。

在实际操作中，这意味着要复制所有硬件和软件，并且需要有一个专门的团队进行补丁测试。很少有公司能承担这样的费用，能证明这种做法带来的一点点潜在保护的公司就更少了。

## 补丁的及时性

补丁工作是一项通常需要非常迅速完成的活动，随着行业的成熟，快速补丁的重要性持续增加。我们这些在 1990 年代及之前接受过训练的人，通常记得那个时候补丁几乎没有时间敏感性，因为大多数计算机都是离线的，补丁几乎完全是为了稳定性问题，如果你没有遇到过问题，那就不太可能遇到。所以，等待几个月或几年再给系统打补丁（如果你做了的话），通常并不是一件大事。

哦，时代变化多么迅速。今天，软件变得更加庞大和动态，层级之间的相互关联也更多，而且除了最罕见的计算机系统，几乎所有系统都连接到互联网，并且始终可能面临活跃的安全威胁和动态变化的环境。关于补丁的所有事宜，在过去二十年中发生了翻天覆地的变化，尽管大部分重大变化在 2001 年左右就已经发生了。

今天，修补工作往往主要集中在弥补最近发现的安全漏洞，每一步都在急忙将补丁推向市场，以防坏人发现漏洞并加以利用。恶意行为者知道，对于任何漏洞，补丁都会很快发布，因此漏洞利用完全是关于速度。在某些情况下，正是补丁的发布本身提醒了更广泛的社区漏洞的存在，因此发布补丁的行为触发了每个人都必须应用该补丁的紧迫需求，而这在几个小时前是完全不必要的。

因此，快速修补漏洞极为重要。基于漏洞修补的攻击很可能已经在发生，并且会在即将消失的漏洞最后一刻加剧，或者会在一个之前未知的漏洞成为公开知识后迅速开始。对许多人来说，这意味着我们希望将修补工作以小时而非天数来考虑。我们仍然需要考虑在生产时间内可能发生的潜在稳定性风险或影响，因此立即修补通常不是一种选择，但在合理的情况下，当然是可能的。

在 Linux 中，由于修补一般既快速又简便，且几乎总是可靠的，因此在某些情况下，可以考虑在生产日内进行修补，在大多数其他情况下进行每日修补。可能的智能方法包括使用内置的随机生成器，每四到八小时随机修补（为了减轻系统负载），或者每天晚上十点或其他合适的时间进行计划性修补。

在极端环境下，按周进行修补是可行的，这在一到二十年前的企业中很流行。如今，等待长达六天来修补已知漏洞几乎是鲁莽的，应该小心进行。六天在暴露系统漏洞的世界里是非常长的一段时间。

时间框架的选择通常基于工作负载模式。一些工作负载，如电子邮件或库存控制系统，可能对短暂的中断不太敏感，可以快速回滚或切换。因此，在一天中午间进行修补可能是合理的。大多数公司都有一天内周期性的工作负载模式，可以预测某个应用程序在凌晨一到两点使用非常少，或者也许到晚上七点每个用户都已注销，甚至十小时的停机也不会被人察觉。

无论是否存在日内模式，我们几乎总是会看到按周计算的日间模式。某些工作负载可能在周末较轻，而在工作日较重，反之亦然。有时，尤其是在金融应用程序中，模式更加偏向月度，通常月初的负载较重，而月中较轻。

每个工作负载通常需要评估，以了解何时进行补丁是合理且可行的。有时我们必须在时间安排上富有创意，以便在工作负载允许时进行补丁。如果工作负载无法中断进行补丁，那么它们也不能经历其他更不计划的停机事件，我们应该有一个连续性计划，允许我们在发生任何问题时进行补丁、修复或故障切换。在大多数情况下，我们可以通过这些方法进行零影响的补丁操作。

过去那种认为补丁可以作为一个特殊的每月活动来保存，或者只有在识别到组织的特定需求时才进行补丁的想法，已经不再现实。等待这么长时间会使系统处于危险暴露之中，任何声称每月只有一次补丁机会的工作负载都应该质疑，怎么会有既重要又无法进行补丁的工作负载。从概念上讲，这两者是无法并存的。工作负载越重要，及时进行补丁就越重要。

一个常见的缓慢补丁流程的借口是，补丁发布前需要进行测试。表面上看，这有道理，听起来也合情合理。你可能能将这个想法卖给非技术管理层。想要测试补丁本身没有问题。但我们必须考虑到，我们已经在支付（或免费获得）分发供应商来测试补丁，等我们收到补丁时。那些企业级操作系统供应商（如 Canonical、IBM、SUSE 等）拥有比任何但最大规模的组织更多的技能、经验和资源来测试补丁。如果我们的测试没有为我们已经依赖的广泛测试增加什么重要的内容，那么我们自己的内部测试过程应该避免，以免浪费资源并让组织面临不必要的风险，延误可能至关重要的补丁部署。

如果保持足够轻量并且绝不作为推迟及时补丁更新的借口，快速而轻量的测试是合理的。一种常见的有用补丁测试方法是，选取几个代表你组织中典型工作负载环境的系统，运行演示工作负载，在补丁发布之前先对每个补丁进行测试，以便观察安装成功并在最高级别进行测试。这可以在小型组织中仅仅是一台虚拟机。考虑是否有任何测试是有价值的，如果有的话，尽量保持测试轻量化，以确保生产环境中的补丁更新尽可能迅速地完成，前提是满足工作负载的需求。

标准的补丁策略通常会建议你先从高风险的工作负载开始，或者从低优先级的工作负载开始，专注于修复漏洞，或者使用低优先级工作负载作为测试对象，为更关键的工作负载做准备。如果你的环境中有一百台虚拟机需要补丁，你大概可以安排一个时间表，首先补丁那些不那么关键的系统，随着对补丁流程信心的逐步建立，慢慢接触更多关键或脆弱的工作负载。

把补丁管理看作是系统管理员最重要且简单的任务之一。不要让情绪或那些不了解补丁管理（或受 Windows 管理员影响）的企业或系统管理员的非理性建议将你引偏。补丁管理是至关重要的，任何不支持补丁管理流程的组织管理层都不了解该过程的风险与回报，我们需要准备好向他们解释这一点。

找到一个满足你所在组织需求的补丁管理流程。你不需要按照固定的时间表进行补丁更新，也不需要按照其他组织的方式进行补丁管理。找到适合你的测试方法以及手动或自动补丁流程，以确保你的系统在不对组织造成过度影响的情况下保持更新。

到现在为止，我们应该对补丁的概念有一个相当扎实的理解，你可能甚至已经感到一种紧迫感，想去检查一下你当前的服务器，看看它们最近是否有更新。这是可以理解的，如果你现在想查看一下它们，在继续之前，我愿意等你。安全总比后悔好。等你回来后，我们将讨论软件编译，并将该过程与补丁管理联系起来。

# 管理员的编译工作

还不久前，主要的系统管理员指南中包括了一项要求，即任何中级或高级管理员都必须熟悉标准软件编译过程的细节。当然，所有的知识都是有价值的，我们绝不会说不应该学习这些内容。然而，即使在当时，这也显得像是一种奇怪的*幕后*开发知识以及关于单个软件解决方案打包的知识，居然被期望由一个非开发角色的人来掌握。

这就像是从你最喜欢的汽车公司订购一辆新车时，要求它以零件的形式交付，并且每个潜在的新车主都需要在驾驶之前自己组装汽车一样。值得注意的是，这一过程仅在开源世界中才可能实现，而且除了 Linux 领域，大多数软件甚至 Linux 领域中的一部分软件根本无法由系统管理员进行编译。因此，整个这一要求的概念几乎只适用于一种非常特定的情况，并且在系统管理的广泛意义上并不适用，仅这一点就应当成为那些将其作为教育和认证标准的组织的一个严重警示。

作为系统管理员，要求我们从开发者那里获取源代码并进行定制编译，使用我们提供的编译器在我们自己的环境中进行编译，这几乎是荒谬的。在 Windows 环境中，这几乎是不可能的，谁会有权限访问合适的编译器或任何必要的工具呢？在 Linux 和 BSD 系统中，这通常是可行的，因为编译器或多个编译器可能已经包含在基础操作系统中。

曾经，目标系统上的编译有其价值。通常，通用编译的软件由于需要支持几乎任何潜在的硬件，效率往往较低，而通过在目标上编译，我们可以充分发挥非常特定硬件组合的每一点性能。然而，这也是一个由于 CPU 性能有限而导致编译时间很长的时代，这意味着系统的安装可能需要几天，而不是几分钟。软件部署是一个漫长、复杂且容易出错的任务。在现代世界，浪费时间和资源来编译大部分软件几乎是不可想象的。当我们可以在短短几分钟内部署整个服务器群，并且使用极少的系统资源时，仅仅为了完成相同任务而占用大量 CPU 周期并花费几个小时，从资源角度来看，这完全没有意义。

然而，编译带来的风险远不止浪费时间和系统资源。它还意味着，我们可能会在不同的系统上得到略有不同的结果，或者在不同的部署时间、我们测试过的系统上，甚至更重要的是，在供应商已经测试过的系统上。正如之前所讨论的，面对补丁测试场景的挑战时，编译使得测试变得更加困难。同样，补丁也变得更加难以应用。

一些软件今天需要进行编译以便部署，通常是那些依赖特定硬件驱动的桌面软件。这类软件通常出现在桌面端，而不是服务器上。并不意味着我们永远不会遇到它，但它应该是相当罕见的。从技术上讲，自行编译软件并不错误，但只有在绝对必要并且具有非常必要的目的时才应该这么做。它不应当是随意进行的，今天的系统管理员没有必要了解编译过程。

现在有一些新的额外因素出现，使得将编译作为一个标准过程变得不太可能。二十年前，Linux 生态系统中只有一个主要的编译器，大家都假设所有以代码形式部署的软件都会用 C 语言编写，并且由开发团队针对那个编译器进行测试。当时有一个非常标准的工具链，大家普遍认为它就是所需的工具链，而且几乎总是正确的。如今，不仅有多个标准编译器在不同的项目中使用，且各项目为了测试使用不同的编译器，还有一些常用的编译语言，它们也有自己独立的编译器和工具链。

编译从来都不是一个单一的标准过程，尽管曾经有这种暗示。然而，传统上它几乎就是一个标准过程。如今，正如之前提到的原因，编译已经变成了一个分散的过程。除此之外，许多需要最终用户进行编译的项目现在已经内建了一个编译过程，使得它更像是一个独立的部署工具，而不需要系统管理员了解编译过程，甚至不需要意识到所部署的软件正在进行编译！这个世界几乎在每个方面都发生了变化。

在现实世界中，我曾在成千上万台服务器上工作，跨越数千个客户，并且已经有超过十七年没有见过任何组织使用假定的*标准*编译过程了。即使在十七年前，编译过程也极为罕见，可以忽略不计，而且通常在系统管理员将业务视为个人爱好而非严肃事业时，才会在可疑的情况下使用。

## 编译时代

在 Linux 的早期，能够自己编译软件通常是一个重要特性，相比于封闭源代码系统，如 Windows 和 Netware，这些系统的编译器并不是免费的，且操作系统代码也无法获取。这意味着可以在不同的架构之间轻松迁移，而当时系统资源是宝贵的，因此通过定制编译获得的微小性能优势，有时意味着软件性能的真正差异。系统管理员曾经非常热衷于编译器标志和版本。

这种趋势非常显著，以至于整个操作系统的发布都围绕这一概念进行。最著名的例子是 Gentoo Linux，它每次部署时都要重新定制编译整个操作系统。这常常导致人们讨论安装完整操作系统需要多少天。初始安装的投资非常庞大。

在 1990 年代，操作系统的安装常常需要花费多天时间。我们很少使用虚拟化技术，因此安装通常是从物理介质到独特硬件的安装，即使一切顺利，这个过程也非常耗时，而且经常会遇到安装故障，导致需要多次尝试安装。在那个环境下，花时间编译软件，甚至是整个操作系统，也不像今天这样疯狂。但是放心，这样做也并不是完全理智的。

与由于资源限制而使编译有意义的那个时代相重合的，是互联网前的办公室世界和初步的互联网世界，那时环境威胁，特别是试图利用未打补丁的计算机的威胁，还是比较罕见的。当然，计算机病毒是存在的，且广为人知，但通过不在系统之间共享物理介质来避免它们，能在良好管理的情况下大大减少感染的可能性。因此，大多数时候，定制编译软件的打补丁问题并不构成困扰。这是*设置并忘记*软件的时代。编译过的软件更可能被遗忘，而不是被维护。安装过程的努力使得打补丁的潜在工作量巨大且风险极高。当你自己编译代码时，很多事情可能出错，最终导致你没有一个可用的系统。

过去，CPU 和 RAM 资源在大多数系统上都非常紧张，通常情况下，能够多等几天才能将系统投入生产是值得的，即使只是为了获得额外的百分之一的性能提升。往往被忽视的是，若编译初始安装需要消耗那么多时间和资源，那么未来编译补丁或更新时，可能需要相同甚至更多的资源。这带来了巨大的风险，通常会导致完全没有补丁更新，因为一旦系统部署完成，几乎没有办法停机几个小时或几天进行编译步骤，希望能更新系统。

在信息技术领域，常常有一种强烈的愿望，想要建立一座纸牌屋，并希望当它倒塌时，足够远的时间可以让它变成别人的问题。遗憾的是，这种做法逐渐成为一种可行的策略，因为公司很少将失败与造成失败的人联系起来，而是常常随机地责怪身边的任何人。正因为如此，创造风险情况通常是有利的，因为任何收益都会归功于实施者，而任何灾难则会在稍后随机归咎于某人。

现代的系统管理员仍然应该学习传统的软件编译方法，哪怕只是为了理解历史背景，并为可能出现的任何异常情况做好准备。但今天（以及多年来），将编译自己的软件作为标准流程应当避免，作为经验法则，这根本不是一种资源的好利用方式，而且会引入太多风险而没有实际的好处。

现在进行编译时，不能再像过去那样盲目地遵循通用过程了。过去那种保护了许多仅仅凭运气的管理员的惯例，如今已经不再适用。今天要进行软件编译，我们需要开发者的指导和指引，才能有任何希望了解需要哪些工具、配置、库、语言和外部包，以及如何使编译过程正常工作。这里有太多潜在的可变因素，所有这些知识都是开发者的知识，而不是 IT 知识，更不用说系统管理员的知识了。系统管理员需要掌握并深入理解的信息非常庞大，是技术领域中最广泛、最具挑战性的领域之一。让系统管理员深入学习一个完全不同领域的知识和技能，从来没有任何意义。如果所有的系统管理员都能同时完成这些工作，那开发者为什么还要存在呢？软件工程是一个庞大的领域，需要深厚的知识才能做得好；暗示一个完全不同的学科能轻松地担任开发者角色，而不需要同样的多年训练和全职投入，这不仅荒谬，而且对开发者极为侮辱。

## 工程部门编译

我们应该提到一个中间方法，它是合理的。那就是有一个工程小组，从开发者（通常是内部定制团队或开源项目）那里获取源代码，并进行内部编译，可能是为了额外的安全步骤，或者极端的性能调优，亦或是因为该软件需要特殊的编译方式，比如与内核版本或驱动程序相关联时。

通过设立一个中心小组，负责将源代码内部编译并打包成最终的二进制文件供系统管理员团队使用，可以让系统管理过程专注于标准化、可重复且快速部署的二进制机制，同时组织还可以享受定制化编译的优势。

这种方法通常只适用于能够维持快速软件打包工作流的大型组织，以便补丁、测试和定制化几乎能像由软件供应商直接完成一样迅速。在大规模环境下，这种方法可以带来好处。

这一过程之所以有效，是因为它避免将软件编译和打包交给管理员处理，而管理员在这方面会遇到很多麻烦和问题。

最佳实践是在需要时才编译软件，而不是随意进行编译，除非你有一个能够快速可靠地处理已编译软件打包的部门，且其速度足以满足适当的补丁管理需求，同时执行这项工作所产生的开销能通过规模效益得到弥补。

编译是有用的知识，但仅仅因为你*能*编译软件，并不意味着你*应该*。将这个技能保留在你的后备知识中，只有在真正需要时，或者当软件供应商指示你这么做时再使用。接下来，我们将讨论如何部署我们的 Linux 发行版本身，甚至更重要的是，在灾难发生后，如何*重新部署*一个发行版。

# Linux 部署和重新部署

如今，我们有许多潜在的方法来部署，甚至更重要的是，重新部署我们的服务器（或者工作站）。在我看来，这个话题在过去相对不重要，因为大多数公司依赖于*缓慢的部署*方法，它们的灾难恢复模型依赖于恢复，而不是重新部署系统。但今天有了更多现代化的灾难恢复方法，这些方法依赖于能够快速部署服务器，因此我们必须以全新的眼光来看待这个话题。

借助现代部署技术和方法，能够在几秒钟内部署一个新的基础操作系统已不再罕见，而过去，即使是高度自动化的系统，往往也需要花费许多分钟甚至小时（更不用说定制编译系统可能带来的复杂性了！）。当然，今天的计算机速度更快，这在加速部署过程中起了作用。供应商也改进了安装程序。这不仅仅是 Linux 的特色，几乎所有操作系统都如此。

即便是做最传统的*基于 ISO 的安装*，我们通过 DVD 镜像进行安装，或者从 USB 媒体或虚拟媒体中安装，通常也能在几分钟内从头开始手动完成操作系统的完整安装。在正常硬件上，可能需要十到十五分钟。这与近二十年前的安装方式相比，已经算是非常快速了。

在较大的环境中，传统上会使用类似响应文件的方式来加速这些安装过程，使其更加高效且可重复。这个过程通常意味着将你的安装 ISO 文件存储在网络的某个地方，存储一套安装指令文件，并在其他地方定义系统，通常会列出 MAC 地址来分配适当的配置文件。基本上就是在执行传统安装时自动化人类的响应。有效，但略显笨重。

如今，任何形式的 ISO 或类似介质的安装通常仅用于真正的手动安装，这些安装一般由非常小的公司进行（这些公司通常只构建几个服务器，而且每个服务器可能都是独一无二的）或特殊情况。旧的响应自动化方法没有错，但如今有这么多更新的选项，它已逐渐被淘汰，并继续失去作为流行安装方法的吸引力。在虚拟化之前，它在安装自动化选项很少的时代确实最为有效，且安装通常是每个物理设备一个操作系统，这使得基于 MAC 地址的管理非常有效。今天，这种方法对于平台（虚拟化管理程序）安装仍然有效，但对于操作系统安装就不那么适用了。

虚拟化的出现意味着两个大变化。首先，安装到物理服务器裸机上的虚拟化管理程序很少会进行定制，除了最基本的选项，这减少了对自动化的需求（整个安装过程也变得更小）。其次，操作系统安装现在是在非物理空间中进行的，这为更多以前无法获得的特殊安装技术打开了大门。

在虚拟空间中，我们可以继续手动安装系统，许多人仍然这样做。我们可以继续使用响应文件，尽管我知道现在没有人继续这样做，但我相信这仍然是广泛实践的，特别是因为已经有许多大规模半自动化部署系统可供使用。然而，现在我们可以轻松地使用预构建的系统镜像，从库中调用它们来实现更快的安装。采用这种方法，已经构建好的系统只是被复制或克隆来创建新系统。初始镜像可以预先配置最新的补丁和自定义包，通常可以在一分钟内完成安装；有时甚至只需要几秒钟。如果使用某些类型的存储，它的执行速度可以快到几乎瞬间完成。通过容器，我们有时可以看到新系统被初始化得如此迅速，以至于几乎察觉不到有构建过程的存在（因为从实际操作来看，根本没有）。

你选择用于部署服务器的方法并不是最重要的因素。所有这些部署方法，包括更多的选项，都有其适用的地方。我们需要考虑的是，通过你选择的过程，如何更快速且可靠地构建新的系统。当需要新的工作负载时，知道我们可以在一定的时间内构建一个新的服务器，并对其最终配置充满信心，是一件很好的事情。如果一个文档齐全的手动过程能够达到可接受的结果，那也没问题。

对于许多企业来说，快速部署的能力并不是非常重要。真正重要的是重新部署的能力。当然，对于某些类型的应用程序，例如那些非常适合云计算的应用程序，快速的初始部署是至关重要的，但这仍然是一个小众的做法，而不是常态，并且在可预见的未来仍将如此。但重新部署通常意味着某种程度的灾难已经发生，系统需要恢复功能，而在这种情况下，我们几乎总是面临着尽快将系统恢复到生产环境的压力。

因此，在我们的环境中，通常是重新部署速度，而非部署速度，才是更为重要的。然而，由于灾难恢复很少以这种方式来考虑，这一点在唯一能够现实地影响的时刻——也就是说，我们只能在初始设计和实施阶段真正解决这个问题，但通常直到为时已晚才会注意到——往往被忽视。此外，重新部署需要有信心地进行，以确保我们快速构建的内容按预期构建并按预期运行。在这些匆忙和压力下，很容易遗漏步骤、忽视过程、走捷径并犯错。

我们的系统越快、越自动化，我们就越有可能在高压环境下反复交付相同的系统。在我们制定初始部署计划时，我们应该为这种情况做准备。能够重新创建系统，而无需依赖备份和恢复机制，对于许多公司来说可能是一个游戏规则改变者，尤其是当他们常常感到被迫依赖单一方法来将系统重新上线时，而在许多情况下，可能存在更优的替代方案。我们将在未来章节中深入讨论备份时详细讲解这一点。

允许我们快速恢复的过程还可以为我们的工作流带来更大的灵活性。测试补丁、部署、配置、构建临时系统等的能力，灵活性关乎于应对未知的风险。

最佳部署实践是评估时间，以设计最适合你环境的可靠部署方法，并根据实际情况简化这个过程，以便能够在适合你环境的时间内恢复基准操作系统。

一些环境能够如此快速地构建新服务器，并为其必要的工作负载进行配置，以至于它们实际上选择在执行诸如修补、更新，甚至可能是重启等活动时，直接选择这样做！相反，它们会迅速构建并部署一个全新的虚拟机或容器，并销毁旧的虚拟机。这是一个非常有效的做法，前提是你能让这个过程为你服务。

在接下来的部分，我们将讨论在常规、频繁和计划性的条件下重启和测试环境的重要性。

# 重启服务器

向普通的系统管理员，甚至是对技术感兴趣的非技术人员询问，他们会告诉你服务器长时间正常运行的重要性，以及他们希望看到这些超高的*重启后的时间*。这似乎很自然，几乎每个人都会为此自豪。*我的服务器三年都不需要重启！*

然而，这背后有两个关键问题。

第一个问题是，*重启后的时间*本身没有商业价值，而商业价值决定了 IT 价值。那么，为什么我们要在乎，甚至吹嘘某件没有价值的事情呢？知道一个系统在线多久或许很有趣，但投资者并不会因为计算机系统在长时间内没有重启而获得回报。我们为的是业务的好处，如果我们开始关注除了最终业务价值之外的事情，那我们就迷失了方向。这种情况发生在我们关注手段而非目的时，服务器的正常运行时间容易携带情感价值，*看起来好像*它可能带来好结果，因此，我们作为人类，常常喜欢在心中设置代理来简化评估结果，而正常运行时间常常被视为稳定性的代理，而稳定性又被视为商业价值的代理。所有这一切都是错误的，这些代理并不准确，甚至更糟，它们可能被颠倒了。

第二个问题是最大的——高正常运行时间本身代表了一种风险。这是未知的风险。随着时间的推移，我们的系统会发生变化，从硬件的磨损到补丁、更新以及软件的常规变动。可能会出现数据损坏或无法恢复的读取错误。也许会有配置更改不按预期工作。无论是否有人做出过系统更改，都会有许多不可预知的事情发生。而且，距离上次重启越久，我们对系统的反应就越没有信心。

我们必须在合理的范围内始终对重启的效果充满信心。我们并不总是能控制重启的时机。我们可以尝试使用冗余电源和冗余组件，但每个系统都有可能重新启动，当它们重启时，我们希望能够高度自信地确保它们能顺利重启。

重启过程会给服务器带来许多风险。它需要重新加载大量从磁盘或其他存储位置读取的数据，这些数据可能自上次重启以来没有被完全读取，因此潜在的损坏或其他存储问题的风险会增加。它对物理系统造成压力，尤其是当物理重启与软件重启结合时。此时你可能会发现某个文件丢失、文件损坏，或者内存条终于开始出现故障。

乍一看，我们可能会认为故意重启系统似乎很疯狂，为什么要故意促成故障的发生呢？但这正是我们想要的。我们故意诱发潜在的故障，以期在其他时候避免它的发生。

这里的逻辑是我们在一个方便或安全的时间进行重启，即一个*绿色区间*。如果在我们重启的时刻发生了硬件故障，或者发现了一个未知的软件问题，那时我们知道是什么触发了问题（计划重启），上次重启是什么时候（希望不是很久前），中间发生了什么变化（如果是软件或配置问题），或者重启就是硬件故障暴露的时机。这应该发生在我们为修复潜在问题而预定的时间段。

## 找到你的绿色区间

你的维护窗口或绿色区间是一个特定的时间段，在这个时间段内，工作负载被认为是不可用的，以便进行常规管理任务。典型的任务可能包括重启、软件安装、打补丁、数据库重新索引、磁盘碎片整理或其他需要高负载的任务。每个行业、公司，甚至每个单独的工作负载都会有不同的时间段适合分配绿色区间。不要期望一个公司正确的绿色区间能适用于另一个公司，甚至是同一公司内部的不同业务单元。

一个常见的绿色区间是周末。对于许多公司来说，一些甚至所有的工作负载可以安全地在从周五晚上到周一早上期间不可用，而不会对业务产生任何影响。通常，除非是 IT 部门，否则其他人甚至不会知道这个情况。如果情况确实如此，一个好的策略是，在周五晚上绿色区间开始时几乎立即进行任何打补丁或类似任务，接着立刻进行重启。如果重启导致任何故障，你将有超过两天半的时间来恢复系统，直到有人进来抱怨系统崩溃。两天的无影响时间可以让你进行更好的修复，而不是在压力巨大、资金损失、业务急需答案的情况下强行修复系统，而这时你还要集中精力解决问题。

根据我个人的经验，我曾管理过一个应用程序，在这个程序中，我们测量了数据库记录，发现这些记录每周至少有一分钟的时间内不会被使用，这个规律在所有系统客户中都存在。这使得我们可以有效利用仅仅 60 秒的时间窗口，但如果我们进行仔细规划，就能够在这个时间内进行系统重启、软件更新、打补丁等操作。虽然这样做并不特别方便，但相比于要求客户提供一个通用的维护窗口，或者为这一分钟运行额外的系统来进行覆盖，这种方式是非常具备成本效益的。

绿色区间可能具有创意性，且可能在你意想不到的时候出现。它们可能像长周末那样简单，或者可能发生在每周例行的周二午餐会议期间。与工作负载的客户合作，了解何时工作负载未被使用或不面临风险。

这实际上完全是关于规划的。只有在我们实际可以恢复系统时才触发问题。这样，我们就不太可能在我们无法提供支持或工作负载正在重度使用时，遇到相同的问题。绝不让任何业务说工作负载太重要而不能有计划的停机时间，这种说法是自相矛盾的。我们之所以有计划的停机时间，正是因为工作负载至关重要。如果某个工作负载不重要，那么直到出现故障才进行维护并不成问题。工作负载越关键，计划停机时间就越重要。事实上，任何没有停机时间（至少在系统层面上）的工作负载，都可以被认为是不关键的或非生产级别的，仅仅因为没有计划的维护。

相比汽车，你越重视一辆车，就越可能将其停用进行定期维护，比如换油和检查刹车。你这么做是因为计划性维护是微不足道的，而非计划性故障的发动机则不然。我们自然知道，维护汽车总比让它们发生故障要好。我们的服务器也不例外。

## 避免计划停机时间就等于为非计划停机时间做准备。

如果某个工作负载没有合理的停机时间容忍度，那么就需要采取额外的策略。例如，如果你是亚马逊经营全球在线商店，即使是一分钟的停机时间，也可能导致大量销售损失。如果你是一家投资银行，停机一分钟可能意味着订单未能正确完成，从而造成数百万美元的损失。如果你是一家医院，停机一分钟可能意味着危急生命支持系统失效，导致死亡。如果你是军队，停机一分钟可能意味着失去一场战争，因此有些类型的工作负载中断我们真的希望避免，这是毫无争议的。显然，在某些时候，我们需要采取极端措施，确保停机时间不会发生。

在这些情况下，我们需要一个高可用性水平，允许我们将基础设施中的任意组件下线。这可能是存储、网络，或任何数量的平台和计算资源。这意味着在应用层面也需要一定的高可用性，以便我们能够适当修补从硬盘固件到应用库的所有内容，甚至包括其中的每一环节。

关键工作负载需要平稳运行且高度安全的基础设施来确保其持续运行。一个良好的维护计划是确保工作负载可靠性的核心所在。

关于重启频率没有硬性规定。但一个好的起点是每周重启，并从中评估什么是适合你环境的。我们往往选择每周或每月重启，因为我们通常知道重启是必要的，但我们仍然认为应该避免重启。但在少数情况下，这种想法并不成立。我们真正想要做的是在被认为安全和明智的情况下，尽可能频繁地重启。

在当前的补丁管理制度下，每月重启大约是你可以考虑等待标准计划的最长时间。记住，任何计划都需要考虑到系统被错过的情况，必须等待额外的周期。所以，如果你计划每月重启，你需要接受有些系统偶尔会因为技术或物流问题而两个月没有维护。

每周重启通常是最实用的计划。大多数工作负载都有每周的使用模式，这使得分配维护窗口变得容易，或者至少是可行的。每周重启计划对用户也很有利，因为它们很容易记住。例如，如果一个系统每周六早上九点重启，用户就会习惯于此，即使他们当时想工作，也不会在此时使用系统。这会变成一种习惯。每周重启足够频繁，这样重启过程增加的风险很可能会暴露出即将在接下来的六天内发生的硬件或软件故障。这通常是方便性与可靠性之间的最佳平衡。

我们应该始终评估更频繁重启的机会。如果我们的工作负载安排允许，举例来说，每天重启是非常合适的。这也是我们通常处理终端用户工作负载的方式，鼓励系统在一天结束时重启，这样员工到达工作地点时（无论是虚拟的还是实际的都无所谓），系统已经焕然一新，准备好迎接新的一天。对服务器做同样的处理可能也是有意义的。

你的重启计划应该考虑到你的应用程序更新计划。如果你运行的软件更新很少，那么每月重启可能更为合理。如果你有几乎每天都在更新的工作负载，那么将系统重启与应用程序更新结合起来可能更有意义。

系统重启在软件更新和主要工作负载（通常假设不由操作系统供应商管理）之后尤为重要，因为有很多可能性会导致服务无法按预期启动，需要额外的配置，或者仅仅是在重启时遇到故障。如果你在进行软件更新时不重启，你就无法完全确认安装时重启是否成功。如果稍后出现问题，知道在上次系统更改时重启是成功的，这有助于加快恢复过程。

如果定期重启系统的遗忘是一个常见问题，那么忘记进行重启监控几乎是无处不在的。即便是那些认真对待重启计划的 IT 部门，通常也从未想到将*正常运行时间监控*添加到环境中的监控传感器列表中。重启监控通常非常简单，并且一般可以相对宽松地执行。例如，在我管理的许多环境中，我们希望服务器每周重启一次，我们会添加一个监控项，监测*正常运行时间超过九天*。如果我们的监控系统发现服务器的正常运行时间超过九天，它将发送警报邮件。错过一次重启事件并不是一个大问题，这样就有足够的时间避免误报，并有足够的时间规划手动干预，查找导致计划重启失败的原因，并在下次计划重启之前将问题修复。

这里的最佳实践是尽可能频繁地重启系统，除了有充分的业务需求外，不要避免重启，*系统无法宕机*的错误需求不能作为理由。争取每周重启，甚至是每日重启，如果只能做到每月重启，也要接受，并确保添加监控，因为没有重启的系统是难以通过日常检查发现的。

# 总结

系统的修补、更新和重启可能会让人觉得非常教条。在某些方面，我想它们确实是。但是，有时候真的很重要的事情也可能有些枯燥。实际上，修补和基本的系统维护应该是枯燥的，它应该是可预测的、可靠的和按计划进行的。如果可能的话，它应该是自动化的。

修补不应成为一个挑战或可怕的提议。通过适当的规划、备份、测试等，通常很容易拥有一个可靠的修补甚至更新流程，这样的流程极少会遇到任何重大问题。如果我们未能让我们的修补和更新变得定期和可靠，我们将开始害怕这一过程，而这几乎肯定会导致我们避免修补和更新，进而加剧问题。

在现代计算世界中，总有人试图利用我们的系统，虽然没有任何东西可以防御所有可能的攻击，但我们可以通过快速、定期和可靠的修补大大减少我们的暴露面。

现在，你应该能够自信地评估你的工作负载，确保它们都更新到最新，并开始在你的服务器群体中实施一个正式的修补、更新和重启计划。

在我们的下一章中，我们将讨论数据库以及它们应如何从系统管理的角度进行管理。
