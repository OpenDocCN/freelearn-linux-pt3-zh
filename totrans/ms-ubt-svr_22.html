<html><head></head><body>
<div id="sbo-rt-content"><div class="Basic-Text-Frame" id="_idContainer301">
<h1 class="chapterNumber">22</h1>
<h1 class="chapterTitle" id="_idParaDest-293">Troubleshooting Ubuntu Servers</h1>
<p class="normal">So far, we’ve covered many topics surrounding Ubuntu Server and worked on some really fun projects. We’ve set up web servers, built automation, and even created infrastructure in the cloud. As the applications and services you’ve implemented age, your organization may depend on them more and more. But what happens if something your organization relies on suddenly becomes unavailable? What do you do when things don’t quite go according to plan?</p>
<p class="normal">While it’s impossible for us to account for every possible problem that may come up, there are some common places to look for clues when you run into a problem. In this chapter, we’ll take a look at some common starting points and techniques that you can utilize when it comes to troubleshooting issues with your servers. Building solid troubleshooting skills is an important focus, and with the concepts explored here, you’ll be well on your way.</p>
<p class="normal">In this chapter, we will cover:</p>
<ul>
<li class="bulletList">Evaluating the scope</li>
<li class="bulletList">Conducting a root cause analysis</li>
<li class="bulletList">Viewing system logs</li>
<li class="bulletList">Tracing network issues</li>
<li class="bulletList">Troubleshooting resource issues</li>
<li class="bulletList">Diagnosing defective RAM</li>
</ul>
<p class="normal">The first step with regards to troubleshooting is to analyze the problem and determine how critical a problem it may be. In the next section, we’ll explore how to do just that.</p>
<h1 class="heading-1" id="_idParaDest-294">Evaluating the scope</h1>
<p class="normal">When a problem<a id="_idIndexMarker1291"/> occurs within your servers or network, your systems will exhibit one or more symptoms. Perhaps an application is much slower than normal, maybe users are unable to access the network, or a server suffers from total failure. There are many problems that can come up at any time, and it can be challenging to keep up.</p>
<p class="normal">Once you’ve identified the symptoms of the problem, the next goal is to identify the overall scope. Essentially, this means determining (as best you can) where the problem is most likely to reside, and how many systems and services are affected. Sometimes the root cause is obvious. For example, if none of your computers are receiving an IP address from your DHCP server, then you’ll know straight away to start investigating the logs on that particular server concerning its ability (or inability) to do the job designated for it. In other cases, the cause may not be so obvious. Perhaps you have an application that exhibits problems every now and then but isn’t something you can reliably reproduce. In that case, it may take some digging before you know just how large the scope of the problem might be. Sometimes, the culprit is the last thing you expect.</p>
<p class="normal">Each component on your network works together with other components, or at least that’s how it should be. A network of Linux servers, just as with any other network, is a collection of services (daemons) that complement and often depend upon one another. For example, DHCP assigns IP addresses to all of your hosts, but it also assigns their default DNS servers as well. If your DNS server has encountered an issue, then your DHCP server would essentially be assigning a non-working DNS server to your clients. Identifying the problem space means that after you identify the symptoms, you’ll also work toward reaching an understanding of how each component within your network contributes to (or is affected by) the problem.</p>
<p class="normal">With regards to the scope, we identify how far the problem reaches, as well as how many users or systems are affected by the issue. Perhaps just one user is affected, or an entire subnet. This will help you determine the priority of the issue and decide whether this is something essential that you need to fix now, or something that can wait until later. Often, prioritizing is half the battle; sometimes a user will even be under the impression that their issues are more important than others. Use your best judgment.</p>
<p class="normal">When identifying the scope, you’ll want to answer the following questions as best as you can:</p>
<ul>
<li class="bulletList">What are the symptoms of the issue?</li>
<li class="bulletList">When did this problem first occur?</li>
<li class="bulletList">Were there any changes made within the network around that time?</li>
<li class="bulletList">Has this problem happened before? If so, what was done to fix it last time?</li>
<li class="bulletList">Which servers or nodes are impacted by this issue?</li>
<li class="bulletList">How many users are impacted?</li>
</ul>
<p class="normal">If the problem is limited to a single machine, then a few really good places to start poking around is to check who is logged in to the server and which commands have recently been entered. Quite often, I’ve found the culprit just by checking the Bash history for logged-on users (or users that have recently logged in). With each user account, there should be a .bash_history file in their home directory. Within this file is a list of commands that were recently entered. Check this file and see if anyone modified anything recently. I can’t tell you how many times this alone has led directly to the answer. And what’s even better, sometimes the Bash history leads to the solution. If a problem has occurred before and someone has already fixed it at some point in the past, chances are their efforts were recorded in the Bash history, so you can see what the previous person did to solve the problem just by looking at it. </p>
<p class="normal">To view the Bash history, you can either view the contents of the .bash_history file in a user’s home directory, or you can simply execute the history command as that user.</p>
<p class="normal">Additionally, if <a id="_idIndexMarker1292"/>you check who is currently logged into the server, you may be able to pinpoint if someone is working on an issue already, or perhaps something they’re doing caused the issue in the first place. If you enter the <code class="inlineCode">w</code> command, you can see who is logged in to the server currently. In addition, you’ll also see the IP address of the user that’s logged in when you run this command. Therefore, if you don’t know who corresponds to a user account listed when you run the <code class="inlineCode">w</code> command, you can check the IP address in your DHCP server to find out who the IP address belongs to, so you can ask that person directly. In a perfect world, other administrators will send out a departmental email when they work on something to make sure everyone is aware. Unfortunately, many don’t do this. By checking the logged-in users as well as their Bash history, you’re well on your way to determining where the problem originated.</p>
<p class="normal">After identifying the problem space and the scope, you can begin narrowing down the issue to help find a cause. Sometimes, the culprit will be obvious. If a website stopped working and you noticed that the Apache configuration on your web server was changed recently, you can attack the problem by investigating the change and who made it.</p>
<p class="normal">If the problem is a network issue, such as users not being able to visit websites, the potential problem space is much larger. Your internet gateway may be malfunctioning, your DNS or DHCP server may be down, your internet provider could be having issues, or perhaps your accounting department simply forgot to pay the internet bill. As long as you are able to determine a potential list of targets to focus your troubleshooting on, you’re well on your way to finding the issue. As we go through this chapter, I’ll talk about some common issues that can come up and how to deal with them.</p>
<p class="normal">Understanding the scope of the problem helps us understand just how severe it may be and the number of systems and users impacted, and sometimes, investigating the scope can lead you to <a id="_idIndexMarker1293"/>the root cause of the problem. If you don’t already know the underlying cause, you can conduct a root cause analysis to attempt to find the source of the problem. That’s what we’ll explore next.</p>
<h1 class="heading-1" id="_idParaDest-295">Conducting a root cause analysis</h1>
<p class="normal">Once you<a id="_idIndexMarker1294"/> resolve a problem on your server or network, you’ll immediately revel in the awesomeness of your troubleshooting skills. It’s a wonderful feeling to have fixed an issue, becoming the hero within your technology department. But you’re not done yet. The next step is looking toward preventing this problem from happening again. It’s important to look at how the problem started as well as steps you can take in order to help stop the problem from occurring again. This is known as a <strong class="keyWord">root cause analysis</strong>. A root cause analysis may be a report you file with your manager or within your knowledge-base system, or it could just be a memo you document for yourself. Either way, it’s an important learning opportunity.</p>
<p class="normal">A good root cause analysis has several sides to the equation. First, it will demonstrate the events that led to the problem occurring in the first place. Then, it will contain a list of steps that you’ve completed to correct the problem. If the problem is something that could potentially recur, you would want to include information about how to prevent it from happening again in the future.</p>
<p class="normal">The problem with a root cause analysis is that it’s rare that you can be 100 percent accurate. Sometimes, the root cause may be obvious. For example, suppose a user named <code class="inlineCode">Bob</code> deleted an entire directory that contained files important to your company. If you log into the server and check the logs, you can see that <code class="inlineCode">Bob</code> not only logged into the server near the time of the incident, but his Bash history literally shows him running the <code class="inlineCode">rm -rf /work/important-files</code> command. At this point, the case is closed. You figured out how the problem happened and who did it, and you can restore the files from your most recent backup. But a root cause is usually not that cut and dry.</p>
<p class="normal">One example I’ve personally encountered was a <a id="_idIndexMarker1295"/>pair of <strong class="keyWord">Virtual Machine</strong> (<strong class="keyWord">VM</strong>) servers that were “fencing.” At a company I once worked for, our Citrix-based VM servers (which were part of a cluster) both went down at the same time, taking every Linux VM down with them. When I attached a monitor to them, I could see them both rebooting over and over. After I got the servers to settle down, I started to investigate deeper. I read in the documentation for Citrix XenServer that you should never install a cluster of anything less than three machines because it can create a situation exactly like the one I experienced. We only had two servers in that cluster, so I concluded that the servers were set up improperly and the company would need a third server if they wanted to cluster them.</p>
<p class="normal">The problem though is that this root cause analysis wasn’t 100 percent perfect. Were the servers having issues because they needed a third server? The documentation did mention that three servers were a minimum, but there’s no way to know for sure that was the reason the problem started. However, not only was I not watching the servers when it happened, but<a id="_idIndexMarker1296"/> I also wasn’t the individual who set them up; that person had already left the company. There was no way I could reach an absolute conclusion, but my root cause analysis was sound in the sense that it was the most likely explanation (that we weren’t using best practices). Someone could counter my root cause analysis with “but the servers were running fine that way for several years.” True, but nothing is absolute when dealing with technology. Sometimes, you never really know. The only thing you can do is make sure everything is set up properly according to the guidelines set forth by the manufacturer.</p>
<p class="normal">A good root cause analysis is as sound in logic as it can be, though not necessarily bulletproof. Correlating system events to symptoms is often a good first step but is not necessarily perfect. After investigating the symptoms, solving the issue, and documenting what you’ve done to rectify it, sometimes the root cause analysis writes itself. Other times, you’ll need to read the documentation and ensure that the configuration of the server or daemon that failed was implemented along with best practices. In a worst-case scenario, you won’t really know how the problem happened or how to prevent it, but it should still be documented in case other details come to light later. And without documentation, you’ll never gain anything from the situation.</p>
<p class="normal">A root cause analysis should include details such as the following:</p>
<ul>
<li class="bulletList">A description of the issue</li>
<li class="bulletList">Which application or piece of hardware encountered a fault</li>
<li class="bulletList">The date and time the issue was first noticed</li>
<li class="bulletList">What you found while investigating the issue</li>
<li class="bulletList">What you’ve done to resolve the issue</li>
<li class="bulletList">What events, configurations, or faults caused the issue to happen</li>
</ul>
<p class="normal">A root cause analysis should be used as a learning experience. Depending on what the issue was, it may serve as an example of what not to do, or what to do better. In the case of my VM server fiasco, the moral of the story was to follow best practices from Citrix and use three servers for the cluster instead of two. Other times, the end result may be another technician not following proper directives or making a mistake, which is unfortunate. In the future, if the issue were to happen again, you’ll be able to look back and remember exactly what happened last time and what you did to fix it. This is valuable, if only because we’re all human and prone to forgetting important details after a time. In an organization, a root cause analysis is valuable to show stakeholders that you’re able to not only address a problem but are reasonably able to prevent it from happening again.</p>
<p class="normal">Often, log files <a id="_idIndexMarker1297"/>are a great place to find clues, as quite a bit of information surrounding system and application events are stored there. In the next section, we’ll explore log files in more detail.</p>
<h1 class="heading-1" id="_idParaDest-296">Viewing system logs</h1>
<p class="normal">If you’re having<a id="_idIndexMarker1298"/> trouble finding the root cause, or you just want more information regarding a problem that occurred, consider looking through log files. Linux has great logging capabilities, and many of the applications you may be running are writing log files as events happen. If there’s an issue, you may be able to find information about it within an application’s logs.</p>
<p class="normal">There are two primary methods of viewing logs. Historically, for most of Ubuntu’s life, you could simply inspect the log files that are stored within the <code class="inlineCode">/var/log</code> directory. The files contained within that directory are standard files and directories, so you can use commands you’ve used in the past to view the contents of text files to view the contents of the log files within the <code class="inlineCode">/var/log</code> directory as well. This method of viewing log files is slowly being aged out; however, the majority of applications still store their log files within that directory, even today.</p>
<p class="normal">The newer method of viewing logging information for an application is to use the <code class="inlineCode">journalctl</code> command. This command is part of <code class="inlineCode">systemd</code>, and it’s dedicated to the purpose of viewing logs. To use the <code class="inlineCode">journalctl</code> command to check the status of a running service, you provide it the <code class="inlineCode">-u</code> option, along with the name of a service you’d like to check:</p>
<pre class="programlisting con"><code class="hljs-con">journalctl -u ssh
</code></pre>
<p class="normal">With that example, we’re attempting to view logging information for the <code class="inlineCode">ssh</code> service:</p>
<figure class="mediaobject"><img alt="" height="539" src="../Images/B18425_22_01.png" width="872"/></figure>
<p class="packt_figref">Figure 22.1: Viewing logging information via the <code class="inlineCode">journalctl</code> command</p>
<p class="normal">The <code class="inlineCode">-u</code> option is <a id="_idIndexMarker1299"/>required and tells the <code class="inlineCode">journalctl</code> command that you’d like to check on a service. So in the previous example, we provided <code class="inlineCode">ssh</code> as an argument for what we wanted to find logging information on. The name of the unit (or service) will be the same as it is when you’re starting, stopping, or restarting a service with the <code class="inlineCode">systemctl</code> command. I recommend making the <code class="inlineCode">journalctl</code> command your first consideration when checking logging information on a Linux system.</p>
<div class="note">
<p class="normal">If you also add the <code class="inlineCode">-f</code> option in addition to the <code class="inlineCode">-u</code> option, the output will continue to scroll as new information is added to the logs for the particular service you’re checking. This is very useful if you want to follow along with what’s going on with a service as new events occur.</p>
</div>
<p class="normal">However, not all services log information via <code class="inlineCode">journalctl</code>, so understanding the legacy approach to viewing log files is also important. Inside the <code class="inlineCode">/var/log</code> directory, you’ll see a handful of logs you can view, which differs from server to server depending on which applications are installed. In quite a few cases, an installed application will create its own log file somewhere within <code class="inlineCode">/var/log</code>, either in a log file or a log file within a subdirectory of <code class="inlineCode">/var/log</code>. For example, once you install Apache, it will create log files in the <code class="inlineCode">/var/log/apache2</code> directory, and looking through those logs may give you a hint as to what may be going on if the problem is related to your web server. These are known as <strong class="keyWord">Application Logs</strong>, which<a id="_idIndexMarker1300"/> are basically log files created by an application and not the distribution. There are also <strong class="keyWord">System Logs</strong>, which are the log files created by the distribution and allow you to view system events.</p>
<p class="normal">Viewing a log <a id="_idIndexMarker1301"/>file stored within the <code class="inlineCode">/var/log</code> directory can be done in several ways. One way is to use the <code class="inlineCode">cat</code> command along with the path and filename of a log file. For example, the Apache access log can be viewed with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">cat /var/log/apache2/access.log
</code></pre>
<p class="normal">Some log files are restricted and need <code class="inlineCode">root</code> privileges in order to access them. If you get a permission denied error when attempting to view a log, use <code class="inlineCode">sudo</code> in front of any of the commands in this section to view the file.</p>
<p class="normal">One problem with the <code class="inlineCode">cat</code> command is that it will print out the entire file, no matter how big it is. It will scroll by your terminal and if the file is large, you won’t be able to see all of it. In addition, if your server is already taxed when it comes to performance, using <code class="inlineCode">cat</code> can actually tie up the server for a bit in a case where the log file is massive. This will cause you to lose control of your shell until the file stops printing. You can press <em class="keystroke">Ctrl + c</em> to stop printing the log file, but the server may end up being too busy to respond to <em class="keystroke">Ctrl + c</em> and show the entire file anyway.</p>
<p class="normal">Another method is to use the <code class="inlineCode">tail</code> command. By default, the <code class="inlineCode">tail</code> command shows you the last ten lines of a file:</p>
<pre class="programlisting con"><code class="hljs-con">tail /var/log/apache2/access.log
</code></pre>
<p class="normal">If you wish to see more than the last ten lines, you can use the <code class="inlineCode">-n</code> option to specify a different amount. To view the last <code class="inlineCode">100</code> lines, we would use the following:</p>
<pre class="programlisting con"><code class="hljs-con">tail -n 100 /var/log/apache2/access.log
</code></pre>
<p class="normal">Perhaps one of the most useful features of the <code class="inlineCode">tail</code> command is the <code class="inlineCode">-f</code> option, which allows you to follow a log file. Basically, this means that as entries are written to the log file, it will scroll by in front of you. It’s close to watching the log file in real time:</p>
<pre class="programlisting con"><code class="hljs-con">tail -f /var/log/apache2/access.log
</code></pre>
<p class="normal">Once you start using the <code class="inlineCode">follow</code> option, you’ll wonder how you ever lived without it. If you’re having a specific problem that you are able to reproduce, you can watch the log file for that application and see the log entries as they appear while you’re reproducing the issue. In the case of a DHCP server not providing IP addresses to clients, you can view the output of the <code class="inlineCode">/var/log/syslog</code> file (the <code class="inlineCode">isc-dhcp-server</code> daemon doesn’t have its own log file), and you can see any errors that come up as your clients try to re-establish their DHCP lease, allowing you to see the problem as it is happening.</p>
<p class="normal">Another useful <a id="_idIndexMarker1302"/>command for viewing logs is <code class="inlineCode">less</code>. The <code class="inlineCode">less</code> command allows you to scroll through a log file with the page up and page down keys on your keyboard, which makes it more useful for viewing log files than the <code class="inlineCode">cat</code> command. You can press <em class="keystroke">q </em>to exit the file:</p>
<pre class="programlisting con"><code class="hljs-con">less /var/log/apache2/access.log
</code></pre>
<p class="normal">So now that you know a few ways in which you can view these files, which files should you inspect? Unfortunately, there’s no one rule, as each application handles its logging differently. Some daemons have their own log file stored somewhere in <code class="inlineCode">/var/log</code>. </p>
<p class="normal">Therefore, a good place to check is in that directory, to see if there is a log file with the name of the daemon. Some daemons don’t even have their own log file and will use <code class="inlineCode">/var/log/syslog</code> instead. You may try viewing the contents of the file while using <code class="inlineCode">grep</code> to find messages related to the daemon you’re troubleshooting. In regard to the <code class="inlineCode">isc-dhcp-server</code> daemon, the following would narrow down the <code class="inlineCode">syslog</code> to messages from that specific daemon:</p>
<pre class="programlisting con"><code class="hljs-con">cat /var/log/syslog | grep dhcp
</code></pre>
<p class="normal">While troubleshooting security issues, the log file you’ll definitely want to look at is the <strong class="keyWord">Authorization Log</strong>, located at <code class="inlineCode">/var/log/auth.log</code>. You’ll need to use the <code class="inlineCode">root</code> account or <code class="inlineCode">sudo</code> to view this file. The authorization log includes information regarding authentication attempts to the server, including logins from the server itself, as well as logins over OpenSSH. This is useful for several reasons, among them the fact that if something really bad happens on your server, you can find out who logged in to the server around that time. In addition, if you or one of your users is having trouble accessing the server via OpenSSH, you may want to look at the authorization log for clues, as additional information for OpenSSH failures will be logged there. Often, the <code class="inlineCode">ssh</code> command may complain about permissions of key files not being correct, which would give you an answer as to why public key authentication stopped working, as OpenSSH expects specific permissions for its files. For example, the private key file (typically <code class="inlineCode">/home/&lt;user&gt;/.ssh/id_rsa</code>) should not be readable or writable by anyone other than its owning user. You’d see errors within <code class="inlineCode">/var/log/auth.log</code> mentioning such a thing if that were the case.</p>
<p class="normal">Another use case for checking <code class="inlineCode">/var/log/auth.log</code> is for security, as a high number of login attempts may indicate an intrusion attempt. (Hopefully, you have Fail2ban installed, which we went over in the last chapter.) An unusually high number of failed password attempts may indicate someone trying to log in to the server by brute force. That would<a id="_idIndexMarker1303"/> definitely be a cause for concern, and you’d want to block their IP address immediately.</p>
<p class="normal">The <strong class="keyWord">System Log</strong>, located in <code class="inlineCode">/var/log/syslog</code>, contains logging information for quite a few different things. It’s essentially the Swiss Army knife of Ubuntu’s logs. If a daemon doesn’t have its own log file, chances are its logs are being written to this file. In addition, information regarding cron jobs will be written here, which makes it a candidate to check when a cron job isn’t being executed properly. The <code class="inlineCode">dhclient</code> daemon, which is responsible for grabbing an IP address from a DHCP server, is also important.</p>
<p class="normal">You’ll be able to see from <code class="inlineCode">dhclient</code> events within the system log when an IP address is renewed, and you can also see messages relating to failures if it’s not able to obtain an IP address. Also, the <code class="inlineCode">systemd init</code> daemon itself logs here, which allows you to see messages related to server startup as well as applications it’s trying to run.</p>
<p class="normal">Another useful log is the <code class="inlineCode">/var/log/dpkg.log</code> file, which records log entries relating to installing and upgrading packages. If a server starts misbehaving after you roll out updates across your network, you can view this log to see which packages were recently updated. This log will not only give you a list of updated or installed packages, but also a timestamp from when the installation occurred. If a user installed an unauthorized application, you can correlate this log to the authentication log to determine who logged in around that time, and then you can check that user’s Bash history to confirm.</p>
<p class="normal">Often, log files will get rotated after some time by a utility known as <code class="inlineCode">logrotate</code>. Inside the <code class="inlineCode">/var/log</code> directory, you’ll see several log files with a <code class="inlineCode">.gz</code> extension, which means that the original log file was compressed and renamed, and a new log file was created in its place. For example, you’ll see the <code class="inlineCode">syslog</code> file for the system log in the <code class="inlineCode">/var/log</code> directory, but you’ll also see files named with a number and a <code class="inlineCode">.gz</code> extension as well, such as <code class="inlineCode">syslog.2.gz</code>. These are compressed logs. Normally, you’d view these logs by uncompressing them and then opening them via any of the methods mentioned in this section. An easier way to do so is with the <code class="inlineCode">zcat</code> command, which allows you to view compressed files immediately:</p>
<pre class="programlisting con"><code class="hljs-con">zcat /var/log/syslog.2.gz  
</code></pre>
<p class="normal">There’s also <code class="inlineCode">zless</code>, which serves a similar purpose as the <code class="inlineCode">less</code> command.</p>
<p class="normal">Another useful command for checking logging information is <code class="inlineCode">dmesg</code>. Unlike other log files, <code class="inlineCode">dmesg</code> is <a id="_idIndexMarker1304"/>literally its own command, and you can execute it from anywhere in the filesystem. The <code class="inlineCode">dmesg</code> command allows you to view log entries from the Linux kernel’s ring buffer, which can be very useful when troubleshooting hardware issues (such as seeing which disks were recognized by the kernel). When troubleshooting hardware, the system log is also helpful, but using the <code class="inlineCode">dmesg</code> command may be a good place to check as well.</p>
<p class="normal">As I mentioned earlier, on an Ubuntu system, there are two types of log files, system logs and application logs. System logs, such as <code class="inlineCode">auth.log</code> and <code class="inlineCode">dpkg.log</code>, detail important system events and aren’t specific to any one particular application. Application logs become installed when you install their parent packages, such as Apache or MariaDB. Application logs create log entries into their own log file.</p>
<p class="normal">Some daemons you install will not create their own application log, such as <code class="inlineCode">isc-dhcp-server</code>. Since there’s no general rule when it comes to which applications log is where, the first step in finding a log file is to see if the application you want log entries from creates its own log file. If not, it’s likely using a system log.</p>
<p class="normal">When faced with a problem, it’s important to practice viewing log files at the same time as you try and reproduce the problem. Using <code class="inlineCode">follow</code> mode with <code class="inlineCode">tail</code> (<code class="inlineCode">tail -f</code>) works very well for this, as you can watch the log file generate new entries as you try and reproduce the issue. This technique works very well in almost any situation where you’re dealing with a misbehaving daemon. This technique can also help narrow down hardware issues. For example, I once dealt with an Ubuntu system where when I plugged in a flash drive, nothing happened. When I followed the log as I inserted and removed the flash drive, I saw the system log update and recognize each insertion and removal. So clearly, the Linux kernel itself saw the hardware and was prepared to use it. This helped me narrow down the problem to being that the desktop environment I was using wasn’t updating to show the inserted flash drive, but my hardware and USB ports were operating perfectly fine. With one command, I was able to determine that the issue was a software problem and not related to hardware.</p>
<p class="normal">As you can see, Ubuntu contains very helpful log files that will aid you in troubleshooting your servers. Often, when you’re faced with a problem, viewing relevant log entries and then conducting a Google search regarding them will result in a useful answer, or at least bring you to a bug report to let you know the problem isn’t just limited to you or your configuration. </p>
<p class="normal">Hopefully, your search results will lead you right to the answer, or at least to a workaround. From there, you can continue to work through the problem until it is solved.</p>
<p class="normal">What about<a id="_idIndexMarker1305"/> network issues? Tracking down the root cause of an issue on the network can be especially challenging, but it’s not as difficult as it may seem. In the next section, we’ll take a look at a few ways you can trace network issues.</p>
<h1 class="heading-1" id="_idParaDest-297">Tracing network issues</h1>
<p class="normal">It’s amazing how<a id="_idIndexMarker1306"/> important TCP/IP networking is to the world today. Of all the protocols in use in modern computing, it’s by far the most widespread. But it’s also one of the most annoying situations to figure out when it’s not working well. Thankfully, Ubuntu features really handy utilities you can use in order to pinpoint what’s going on.</p>
<p class="normal">First, let’s look at connectivity. After all, if you can’t connect to a network, your server is essentially useless. In most cases, Ubuntu recognizes just about all network cards without fail, and it will automatically connect your server or workstation to your network if it is within reach of a DHCP server.</p>
<p class="normal">While troubleshooting, get the obvious stuff out of the way first. The following may seem like a no-brainer, but you’d be surprised how often one can miss something obvious. I’m going to assume you’ve already checked to make sure network cables are plugged in tight on both ends. Another aspect regarding cabling is that sometimes network cables themselves develop faults and need to be replaced. You should be able to use a cable tester and get a clean signal through the cable.</p>
<p class="normal">Routing issues can sometimes be tricky to troubleshoot, but by testing each destination point one by one, you can generally see where the problem lies. Typical symptoms of a routing issue may include being unable to access a device within another subnet, or perhaps not being able to get out to the internet, despite being able to reach internal devices. To investigate a potential routing issue, first, check your routing table. You can do so with the <code class="inlineCode">ip route</code> command. This command will print your current routing table information:</p>
<figure class="mediaobject"><img alt="" height="145" src="../Images/B18425_22_02.png" width="881"/></figure>
<p class="packt_figref">Figure 22.2: Viewing the routing table on an Ubuntu server</p>
<p class="normal">In this example, you<a id="_idIndexMarker1307"/> can see that the default gateway for all traffic is <code class="inlineCode">10.10.10.1</code>. This is the first entry on the table, which tells us that all traffic to the destination <code class="inlineCode">0.0.0.0</code> (which is everything) leaves via <code class="inlineCode">10.10.10.1</code>. As long as ICMP traffic isn’t disabled, you should be able to ping this default gateway, and you should be able to ping other nodes within your subnet as well.</p>
<p class="normal">To start troubleshooting a routing issue, you would use the information shown after printing your routing table to conduct several ping tests. First, try to ping your default gateway. If you cannot, then you’ve found the issue. If you can, try running the <code class="inlineCode">traceroute</code> command. </p>
<p class="normal">This command isn’t available by default, but all you’ll have to do is install the <code class="inlineCode">traceroute</code> package, so hopefully, you have it installed on the server. If you do, you can run <code class="inlineCode">traceroute</code> against a host, such as an external URL, to find out where the connection drops. The <code class="inlineCode">traceroute</code> command should show every hop between you and your target. Each “hop” is basically another default gateway. You traverse through one gateway after another until you ultimately reach your destination. With the <code class="inlineCode">traceroute</code> command, you can see where the chain stops. In all likelihood, you’ll find that perhaps the problem isn’t even on your network, but perhaps your internet service provider is where the connection drops.</p>
<p class="normal">DNS issues don’t happen very often, but by using a few tricks, you should be able to resolve them. Symptoms of DNS failures will usually result in a host being unable to access internal or external resources by name.</p>
<p class="normal">Knowing whether the problem is with internal or external hosts (or both) should help you determine whether it’s your DNS server that’s the problem, or perhaps the DNS server at your ISP.</p>
<p class="normal">The first step in pinpointing the source of DNS woes is to ping a known IP address on your network, preferably the default gateway. If you can ping it, but you can’t ping the gateway by name, then you probably have a DNS issue. You can confirm a potential DNS issue by using the <code class="inlineCode">nslookup</code> command against the domain, such as this:</p>
<pre class="programlisting con"><code class="hljs-con">nslookup myserver.local
</code></pre>
<p class="normal">In addition, make sure you try and ping external resources as well, such as a website. This will help you narrow down the scope of the issue.</p>
<p class="normal">You will also want<a id="_idIndexMarker1308"/> to know which DNS server your host is sending queries to. In the past, finding out which DNS server was assigned to your host was as simple as inspecting the contents of <code class="inlineCode">/etc/resolv.conf</code>. However, nowadays, this file will often refer to a local resolver instead and won’t reveal the actual server requests are being sent to. To find out the real DNS server that’s assigned to your host, the following command will do the trick:</p>
<pre class="programlisting con"><code class="hljs-con">resolvectl status
</code></pre>
<p class="normal">Are they what you expect? If not, you can temporarily fix this problem by removing the incorrect name server entries from this file and replacing them with the correct IP addresses. The reason I suggest this as a temporary fix and not a permanent one is because the next thing you’ll need to do is investigate how the invalid IP addresses got there in the first place. Normally, these are assigned by your DHCP server. As long as your DHCP server is sending out the appropriate name server list, you shouldn’t run into this problem. If you’re using a static IP address, then perhaps there’s an error in your Netplan config file.</p>
<p class="normal">A useful method of pinpointing DNS issues in regard to being unable to resolve external sites is to temporarily switch your DNS provider on your local machine. Normally, your machine is going to use your external DNS provider, such as the one that comes from your ISP. Your external DNS server is something we went through setting up in <em class="chapterRef">Chapter 11</em>, <em class="italic">Setting Up Network Services</em>, specifically the forwarders section of the configuration for the <code class="inlineCode">bind9</code> daemon. The forwarders used by the <code class="inlineCode">bind9</code> daemon are where it sends traffic if it isn’t able to resolve your request based on its internal list of hosts.</p>
<p class="normal">You could consider bypassing this by changing your local workstation’s DNS name servers to Google’s, which are <code class="inlineCode">8.8.8.8</code> and <code class="inlineCode">8.8.4.4</code>. If you’re able to reach the external resource after switching your name servers, you can be reasonably confident that your forwarders are the culprit.</p>
<p class="normal">I’ve actually seen <a id="_idIndexMarker1309"/>situations in which a website has changed its IP address but the ISP’s DNS servers didn’t get updated quickly enough, causing some clients to be unable to reach a site they need to perform their job. Switching everyone to alternate name servers (by adjusting the <code class="inlineCode">forwarders</code> option, as we did in <em class="chapterRef">Chapter 11</em>, <em class="italic">Setting Up Network Services</em>) was the easiest way they could work around the issue.</p>
<p class="normal">Some additional tools to consider while checking your server’s ability to resolve DNS entries are <code class="inlineCode">dig</code> and <code class="inlineCode">nslookup</code>. You should be able to use both commands to test your server’s DNS settings. Both commands are used with a hostname or domain name as an option. The <code class="inlineCode">dig</code> command will present you with information regarding the address (<code class="inlineCode">A</code>) record of the DNS zone file responsible for the IP address or domain. The <code class="inlineCode">host</code> command should return the IP address of the host you’re trying to reach. Here’s some example output:</p>
<figure class="mediaobject"><img alt="" height="571" src="../Images/B18425_22_03.png" width="876"/></figure>
<p class="packt_figref">Figure 22.3: Output of the dig and host commands</p>
<p class="normal">Hardware support<a id="_idIndexMarker1310"/> is also critical when it comes to networking. If the Linux kernel doesn’t support your network hardware, then you’ll likely run into a situation where the distribution doesn’t recognize or do anything when you insert a network cable, or in the case of wireless networking, doesn’t show any nearby networks despite there being one or more. Unlike the Windows platform, hardware support is generally baked right into the kernel when it comes to Linux. While there are exceptions to this, the Linux kernel shipped with a distribution typically supports hardware the same age as itself or older. </p>
<p class="normal">In the case of Ubuntu 22.04 LTS (which was released in April 2022), it’s able to support hardware released as of the beginning of 2022 and older. Future releases of Ubuntu Server will publish hardware enablement updates, which will allow Ubuntu Server 22.04 to support newer hardware and chip sets once they come out. Typically, Ubuntu will release several point releases during the life of a supported distribution, such as 22.04.1, 22.04.2, and so on. As long as you’re using the latest one, you’ll have access to the latest hardware support that Ubuntu has made available at the time.</p>
<p class="normal">In other cases, hardware support may depend on external kernel modules. In the case of a missing hardware driver, the first thing you should try when faced with network hardware that’s not recognized is to look up the hardware using a search engine. Typically the search term <code class="inlineCode">&lt;hardware name&gt; Ubuntu</code> will do the trick. But what do you search for? To find out the hardware string for your network device, try the <code class="inlineCode">lspci</code> command:</p>
<pre class="programlisting con"><code class="hljs-con">lspci | grep -i net
</code></pre>
<p class="normal">The <code class="inlineCode">lspci</code> command lists hardware connected to your server’s PCI bus. Here, we’re using the command with a case insensitive <code class="inlineCode">grep</code> search for the word <code class="inlineCode">net</code>:</p>
<pre class="programlisting con"><code class="hljs-con">lspci |grep -i net
</code></pre>
<p class="normal">This should return a list of networking components available on your server. On my machine, for example, I get the following output:</p>
<pre class="programlisting con"><code class="hljs-con">01:00.1 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller (rev 12)
02:00.0 Network controller: Intel Corporation Wireless 8260 (rev 3a)  
</code></pre>
<p class="normal">As you can see, I<a id="_idIndexMarker1311"/> have a wired and wireless network card on this machine. If one of them wasn’t working, I could search online for information by searching for the hardware string and the keyword <code class="inlineCode">Ubuntu</code>, which should give me results pertaining to my exact hardware. If a package is required to be installed, the search results will likely give me some clues as to what package I need to install.</p>
<p class="normal">Without having network access though, the worst-case scenario is that I may have to download the package from another computer and transfer it to the server via a flash drive. That’s certainly not a fun thing to need to do, but it does work if the latest Ubuntu installation media doesn’t yet offer full support for your hardware.</p>
<p class="normal">Another potential problem point is DHCP. When it works well, DHCP is a wonderfully magical thing. When it stops working, it can be frustrating. But generally, DHCP issues often end up being a lack of available IP addresses, the DHCP daemon (<code class="inlineCode">isc-dhcp-server</code>) not running, an invalid configuration, or hosts that have clocks that are out of sync (all servers should have the <code class="inlineCode">ntp</code> package installed).</p>
<p class="normal">If you have a server that is unable to obtain an IP address via DHCP and your network utilizes a Linux-based DHCP server, check the system log (<code class="inlineCode">/var/log/syslog</code>) for events related to <code class="inlineCode">dhcpd</code>. Unfortunately, there’s no command you can run that I’ve ever been able to find that will print how many IP address leases your DHCP server has remaining, but if you run out, chances are you’ll see log entries related to an exhausted pool in the system log. In addition, the system log will also show you attempts from your nodes to obtain an IP address as they attempt to do so. Feel free to use <code class="inlineCode">tail -f</code> against the system log to watch for any events related to DHCP leases.</p>
<p class="normal">In some cases, a lack of DHCP leases being available can come down to having a very generous lease time enabled. Some administrators will give their clients up to a week for the lease time, which is generally unnecessary. A lease time of one day is fine for most networks, but ultimately, the lease time you decide on is up to you. In <em class="chapterRef">Chapter 11</em>, <em class="italic">Setting Up Network Services</em>, we looked at configuring our DHCP server, so feel free to refer to that chapter if you need a refresher on how to configure the <code class="inlineCode">isc-dhcp-server</code> daemon.</p>
<p class="normal">Although it’s probably not the first thing you’ll think of while facing DHCP issues, hosts having out-of-sync clocks can actually contribute to the problem. DHCP requests are <code class="inlineCode">timestamped</code> on both the client and the server, so if the clock is off by a large degree on one, the timestamps will be off as well, causing the DHCP server to become confused. Surprisingly, I’ve seen this come up fairly often. I recommend standardizing NTP across your network as early on as you can. DHCP isn’t the only service that suffers when clocks are out of sync; file<a id="_idIndexMarker1312"/> synchronization utilities also require accurate time. If you ensure NTP is installed on all of your clients and it’s up to date and working, you should be in good shape. Using configuration management utilities such as Ansible to ensure NTP is not only configured but is running properly on all the machines in your network will only benefit you.</p>
<p class="normal">Of course, there are many things that can go wrong when it comes to networking, but the information here should cover the majority of issues. In summary, troubleshooting network issues generally revolves around ping tests. Trying to ping your default gateway, tracing failed endpoints with <code class="inlineCode">traceroute</code>, and troubleshooting DNS and DHCP will take care of a majority of issues. Then again, faulty hardware such as failed network cards and bad cabling will no doubt present themselves as well.</p>
<p class="normal">Our servers utilize storage, CPU, memory, and other resources to provide us with value and serve our clients. In the next section, we’ll take a closer look at how to check those resources.</p>
<h1 class="heading-1" id="_idParaDest-298">Troubleshooting resource issues</h1>
<p class="normal">I don’t know about <a id="_idIndexMarker1313"/>others, but it seems that a majority of my time troubleshooting servers is usually spent pinpointing resource issues. By resources, I’m referring to CPU, memory, disk, input/output, and so on. Generally, issues come down to a user storing too many large files, a process going haywire that consumes a large amount of CPU, or a server running out of memory. In this section, we’ll go through some of the common things you’re likely to run into while administering Ubuntu servers.</p>
<p class="normal">First, let’s revisit topics related to storage. In <em class="chapterRef">Chapter 9</em>, <em class="italic">Managing Storage Volumes</em>, we went over concepts related to this already, and many of those concepts also apply to troubleshooting as well. Therefore, I won’t spend too much time on those concepts here, but it’s worth a refresher in regard to troubleshooting storage issues. First, whenever you have users that are complaining about being unable to write new files to the server, the following two commands are the first you should run. You are probably already well aware of these, but they’re worth repeating:</p>
<pre class="programlisting con"><code class="hljs-con">df -h
df -i
</code></pre>
<p class="normal">The first <code class="inlineCode">df</code> command variation gives you information regarding how much space is used on a drive, in a human-readable format (the <code class="inlineCode">-h</code> option), which will print the information in terms of megabytes and gigabytes. </p>
<p class="normal">The <code class="inlineCode">-i</code> option in the second command gives you information regarding in-use and available inodes. The reason you should also run this is that on a Linux system, it can report storage as full even if there’s plenty of free space. But if there are no remaining inodes, it’s the same as being full, but the first command wouldn’t show the usage as 100 percent when no inodes are free. Usually, the number of inodes a storage medium has available is extremely generous, and the limit is hard to hit. However, if a service is creating new log files over and over every second, or a mail daemon grows out of control and generates a huge backlog of undelivered mail, you’d be surprised how quickly inodes can empty out.</p>
<p class="normal">Of course, once you figure out that you have an issue with full storage, the next logical question becomes, what is eating up all my free space? The <code class="inlineCode">df</code> commands will give you a list of storage volumes and their sizes, which will tell you at least which disk or partition to focus your attention on. My favorite command for pinpointing storage hogs, as I mentioned in <em class="chapterRef">Chapter 9</em>, <em class="italic">Managing Storage Volumes</em>, is the <code class="inlineCode">ncdu</code> command. While not installed by default, <code class="inlineCode">ncdu</code> is a wonderful utility for checking to see where your storage is being consumed the most. If run by itself, <code class="inlineCode">ncdu</code> will scan your server’s entire filesystem. Instead, I recommend running it with the <code class="inlineCode">-x</code> option, which will limit it to a specific folder as a starting point. For example, if the <code class="inlineCode">/home</code> partition is full on your server, you might want to run the following to find out which directory is using the most space:</p>
<pre class="programlisting con"><code class="hljs-con">sudo ncdu -x /home
</code></pre>
<p class="normal">The <code class="inlineCode">-x</code> option will cause <code class="inlineCode">ncdu</code> to not cross filesystems. This means if you have another disk mounted within the folder you’re scanning, it won’t touch it. With <code class="inlineCode">-x</code>, <code class="inlineCode">ncdu</code> is only concerned with the target you give it.</p>
<p class="normal">If you aren’t able to utilize <code class="inlineCode">ncdu</code>, there’s also the <code class="inlineCode">du</code> command, which takes some extra work. The <code class="inlineCode">du -h</code> command, for example, will give you the current usage of your current working directory, with human-readable numbers. It doesn’t traverse directory trees by default like <code class="inlineCode">ncdu</code> does, so you’d need to run it on each subdirectory until you manually find the directory that’s holding the most files. A very useful variation of the <code class="inlineCode">du</code> command, nicknamed <code class="inlineCode">ducks</code>, is the following. It will show you the top 15 largest directories in your current <a id="_idIndexMarker1314"/>working directory:</p>
<pre class="programlisting con"><code class="hljs-con">du -cksh * | sort -hr | head -n 15
</code></pre>
<p class="normal">Another issue with storage volumes that can arise is to do with filesystem integrity. Most of the time, these issues only seem to come up when there’s an issue with power, such as a server powering off unexpectedly. Depending on the server and the formatting you’ve used when setting up your storage volumes (and several other factors), power issues are handled differently from one installation to another. In most cases, a filesystem check (<code class="inlineCode">fsck</code>) will happen automatically during the next boot. If it doesn’t, and you’re having odd issues with storage that can’t be explained, a manual filesystem check is recommended. Scheduling a filesystem check is actually very easy:</p>
<pre class="programlisting con"><code class="hljs-con">sudo touch /forcefsck
</code></pre>
<p class="normal">The previous command will create an empty file, <code class="inlineCode">forcefsck</code>, at the root of the filesystem. When the server reboots and it sees this file, it will trigger a filesystem check on that volume and then remove the file. </p>
<p class="normal">If you’d like to check a filesystem other than the root volume, you can create the <code class="inlineCode">forcefsck</code> file elsewhere. For example, if your server has a separate <code class="inlineCode">/home</code> partition, you could create the file there instead to check that volume:</p>
<pre class="programlisting con"><code class="hljs-con">sudo touch /home/forcefsck
</code></pre>
<p class="normal">The filesystem check will usually complete fairly quickly unless there’s an issue it needs to fix. Depending on the nature of the problem, the issue could be repaired quickly, or perhaps it will take a while. I’ve seen some really bad integrity issues that have taken over four hours to fix, but I’ve seen others fixed in a matter of seconds. Sometimes it will finish so quickly that it will scroll by so fast during boot that you may miss seeing it. In case of a large volume, you may want to schedule the <code class="inlineCode">fsck</code> check to happen after-hours in case the scan takes a long time.</p>
<p class="normal">With regards to issues with memory, the <code class="inlineCode">free -m</code> command will give you an overview of how much memory and swap are available on your server. It won’t tell you what exactly is using up all your memory, but you’ll use it to see if you’re in jeopardy of running out. The <strong class="keyWord">free</strong> column from the output of the <code class="inlineCode">free</code> command will show you how much memory is <a id="_idIndexMarker1315"/>remaining, and allow you to make a decision on when to take action:</p>
<figure class="mediaobject"><img alt="" height="139" src="../Images/B18425_22_04.png" width="882"/></figure>
<p class="packt_figref">Figure 22.4: Checking the available memory on an Ubuntu server</p>
<p class="normal">In <em class="chapterRef">Chapter 8</em>, <em class="italic">Monitoring System Resources</em>, we took a look at the <code class="inlineCode">htop</code> command, which helps us answer the question of “what” is using up our resources. Using <code class="inlineCode">htop</code> (once installed), you can sort the list of processes by CPU or memory usage by pressing<em class="keystroke"> F6</em> and then selecting a new sort field, such as <code class="inlineCode">PERCENT_CPU</code> or <code class="inlineCode">PERCENT_MEM</code>. This will give you an idea of what is consuming resources on your server, allowing you to make a decision on what to do about it. The action you take will differ from one process to another, and your solution may range from adding more memory to the server to tuning the application to have a lower memory ceiling. But what do you do when the results from <code class="inlineCode">htop</code> don’t correlate to the usage you’re seeing? For example, what if your load average is high, but no process seems to be consuming a large portion of CPU?</p>
<p class="normal">One command I haven’t discussed so far in this book is <code class="inlineCode">iotop</code>. While not installed by default, the <code class="inlineCode">iotop</code> utility is definitely a must-have, so I recommend you install the <code class="inlineCode">iotop</code> package. The <code class="inlineCode">iotop</code> utility itself needs to be run as <code class="inlineCode">root</code> or with <code class="inlineCode">sudo</code>:</p>
<pre class="programlisting con"><code class="hljs-con">sudo iotop
</code></pre>
<p class="normal">The <code class="inlineCode">iotop</code> command will allow you to see how much data is being written to or read from your disks. <strong class="keyWord">Input/Output</strong> (<strong class="keyWord">IO</strong>) definitely <a id="_idIndexMarker1316"/>contributes to a system’s load, and not all resource monitoring utilities will show this usage. If you see a high load average but nothing in your resource monitor shows anything to account for it, check the IO. </p>
<p class="normal">The <code class="inlineCode">iotop</code> utility is a great way to do that as if data is bottle-necked while being written to disk, which can account for a serious overhead in IO that will slow other processes down. If nothing else, it will<a id="_idIndexMarker1317"/> give you an idea of which process is misbehaving, in case you need to kill it:</p>
<figure class="mediaobject"><img alt="" height="397" src="../Images/B18425_22_05.png" width="882"/></figure>
<p class="packt_figref">Figure 22.5: The iotop utility running on an Ubuntu server</p>
<p class="normal">The <code class="inlineCode">iotop</code> window will refresh on its own, sorting processes by the column that is highlighted. To change the highlight, you’ll only need to press the <em class="keystroke">left</em> and <em class="keystroke">right</em> arrows on your keyboard. You can sort processes by columns such as <code class="inlineCode">IO</code>, <code class="inlineCode">SWAPIN</code>, <code class="inlineCode">DISK WRITE</code>, <code class="inlineCode">DISK READ</code>, and others. When you’re finished with the application, press <em class="keystroke">q</em> to quit.</p>
<p class="normal">The utilities we looked at in this section are very useful when identifying issues with bottle-necked resources. What you do to correct the situation after you find the culprit will depend on the daemon. Perhaps there’s an invalid configuration, or the daemon has encountered a fault and needs to be restarted. Often, checking the logs may lead you to an answer as to why a daemon misbehaves. In the case of full storage, almost nothing beats <code class="inlineCode">ncdu</code>, which will almost always lead you directly to the problem. Tools such as <code class="inlineCode">htop</code> and <code class="inlineCode">iotop</code> allow you to view additional information regarding resource usage as well, and <code class="inlineCode">htop</code> even allows you to kill a misbehaving process right from within the application, by pressing <em class="keystroke">F9</em>.</p>
<p class="normal"> What do you do when system memory (RAM) becomes physically defective? It happens more often than <a id="_idIndexMarker1318"/>you’d think. In the next section, we’ll look at a way we can test our RAM to see if it’s defective or not.</p>
<h1 class="heading-1" id="_idParaDest-299">Diagnosing defective RAM</h1>
<p class="normal">All server and <a id="_idIndexMarker1319"/>computing components can and will fail eventually, but there are a few pieces of hardware that seem to fail more often than others. Fans, power supplies, and hard disks definitely make the list of common things administrators will end up replacing, but defective memory is also a situation I’m sure you’ll run into eventually.</p>
<p class="normal">Although memory sticks becoming defective is something that could happen, I made it the last section in this chapter because unfortunately, I can’t give you a definitive list of symptoms to look out for that indicate that memory is the source of an issue. RAM issues are very mysterious in nature, and each time I’ve run into one, I’ve always stumbled across memory being bad only after troubleshooting everything else. It’s for this reason that nowadays I’ll often test the memory on a server or workstation first since it’s very easy to do. Even if memory has nothing to do with an issue, it’s worth checking anyway since it could become a problem later.</p>
<p class="normal">Most distributions of Linux (Ubuntu included) feature <strong class="keyWord">Memtest86+</strong> right on the installation media. Whether you create a bootable CD <a id="_idIndexMarker1320"/>or flash drive, there’s a memory test option available from the Ubuntu Server media. When you first boot from the Ubuntu Server media, you’ll see an icon toward the bottom indicating that you can press a key to bring up a menu (if you don’t press a key, the installer will automatically start). Next, you’ll be asked to choose your language, and then you’ll be shown an installation menu. Among the choices there will be a <strong class="screenText">Test memory</strong> option:</p>
<figure class="mediaobject"><img alt="" height="520" src="../Images/B18425_22_06.png" width="786"/></figure>
<p class="packt_figref">Figure 22.6: The main menu of the Ubuntu installer, showing a Test memory option</p>
<p class="normal">Other editions of <a id="_idIndexMarker1321"/>Ubuntu, such as the Ubuntu desktop distribution or any of its derivatives, also feature an option to test memory. Even if you don’t have installation media handy for the server edition, you can use whichever version you have. </p>
<p class="normal">When you choose the <strong class="screenText">Test memory</strong> option from your installation media, the <strong class="keyWord">Memtest86+</strong> program<a id="_idIndexMarker1322"/> will immediately get to work and start testing your memory (press <em class="keystroke">Esc</em> to exit the test). The test may take a long time, depending on how much memory your workstation or server has installed. It can take minutes or even hours to complete. Generally speaking, when your machine has defective RAM, you’ll see a bunch of errors show up relatively quickly, usually within the first 5-10 minutes.</p>
<p class="normal">If you don’t see errors within 15 minutes, you’re most likely in good shape. In my experience, every time I’ve run into defective memory, I’ve seen errors in 15 minutes or less (usually within 5). Theoretically, though, you could very well have a small issue with your memory modules that may not show up until after 15 minutes, so you should let the test finish if you can spare the time for it.</p>
<p class="normal">The main question becomes when to <a id="_idIndexMarker1323"/>run <strong class="keyWord">Memtest86+</strong> on a machine. In my experience, symptoms of bad memory are almost never the same from one machine to another. Usually, you’ll run into a situation where a server doesn’t boot properly, applications close unexpectedly, applications don’t start at all, or perhaps an application is behaving irregularly. In my view, testing memory should be done whenever you experience a problem that doesn’t necessarily seem straightforward. In addition, you may want to consider testing the memory on your server before you roll it out into production. That way, you can ensure that it starts out as free of hardware issues as possible. If you install new memory modules, make sure to test the RAM right away.</p>
<p class="normal">If the test does report errors, you’ll next want to find out which memory module is faulty. This can be difficult, as some servers can have more than a dozen memory modules installed. To narrow it down, you’d want to test each memory module independently if you can, until you find out which one is defective. You should also continue to test the other modules, even after you discover the culprit. The reason for this is that having multiple memory modules going bad isn’t outside the realm of possibility, considering whatever situation led to the first module becoming defective may have affected others.</p>
<p class="normal">Another tip I’d like to pass along regarding memory is that when you do discover a bad stick of memory, it’s best to erase the hard disk and start over if you can. I understand that this isn’t always feasible, and you could have many hours logged into setting up a server. Some servers can take weeks to rebuild, depending on their workload. But at least keep in mind that<a id="_idIndexMarker1324"/> any data that passes through defective RAM can become corrupted.</p>
<p class="normal">This means that data at rest (data stored on your hard disk) may be corrupt if it was sitting in a defective area of RAM before it was written to disk. When a server or workstation encounters defective RAM, you really can’t trust it anymore. I’ll leave the decision on how to handle this situation up to you (hopefully you’ll never encounter it at all), but just keep this in mind as you plan your course of action. Personally, I don’t trust an installation of any operating system after its hardware has encountered such issues.</p>
<p class="normal">I also recommend that you check the capacitors on your server’s motherboard whenever you’re having odd issues. Although this isn’t necessarily related to memory, I mention it here because the symptoms are basically the same as bad memory when you have bad capacitors. I’m not asking you to get a voltage meter or do any kind of electrician work, but sometimes it may make sense to open the case of your server, shine a flashlight on the capacitors, and see if any of them appear to be leaking fluid or expanding. The reason I bring this up is that I’ve personally spent hours troubleshooting a machine (more than once) where I would test the memory and hard disk and look through system logs, without finding any obvious causes, only to later look at the hardware and discover that capacitors on the motherboard were leaking. It would have saved me a lot of time if I had simply looked at the capacitors. And that’s really all you have to do: just take a quick glance <a id="_idIndexMarker1325"/>around the motherboard and look for anything that doesn’t seem right.</p>
<h1 class="heading-1" id="_idParaDest-300">Summary</h1>
<p class="normal">While Ubuntu is generally a very stable and secure platform, it’s important to be prepared for problems occurring and to know how to deal with them. In this chapter, we discussed common troubleshooting we can perform when our servers stop behaving themselves. We started off by evaluating the scope, which gives us an understanding of how many users or servers are affected by the issue. Then, we looked into Ubuntu’s log files, which are a treasure trove of information that we can use to pinpoint issues and narrow down the problem. We also covered several networking issues that can come up, such as issues with DHCP, DNS, and routing. We certainly can’t predict problems before they occur, nor can we be prepared in advance for every type of problem that can possibly happen. However, applying sound logic and common sense to problems will go a long way in helping us figure out the root cause.</p>
<p class="normal">In the next chapter, we will take a look at preventing disasters in the first place and recovering from them if they happen anyway. See you there!</p>
<h1 class="heading-1" id="_idParaDest-301">Further reading</h1>
<ul>
<li class="bulletList">Reporting Bugs in Ubuntu Server: <a href="https://learnlinux.link/report-bugs"><span class="url">https://learnlinux.link/report-bugs</span></a></li>
</ul>
<h1 class="heading-1">Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the author and other readers: </p>
<p class="normal"><a href="https://packt.link/LWaZ0"><span class="url">https://packt.link/LWaZ0</span></a></p>
<p class="normal"><img alt="" height="177" src="../Images/QR_Code50046724-1955875156.png" width="177"/></p>
</div>
</div></body></html>