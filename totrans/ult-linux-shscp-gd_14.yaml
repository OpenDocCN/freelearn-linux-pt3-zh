- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Using awk – Part 1
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 awk – 第 1 部分
- en: In this chapter, I’ll show you a bit about `awk`. It’s a programming environment
    with a long and storied history that dates back to the 1970s, when it was invented
    by Alfred Aho, Peter Weinberger, and Brian Kernighan for use with the early Unix
    operating systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将向您展示一些关于 `awk` 的知识。它是一个具有悠久历史的编程环境，追溯到 1970 年代，当时由 Alfred Aho、Peter Weinberger
    和 Brian Kernighan 发明，用于早期的 Unix 操作系统。
- en: There are several ways in which you can use `awk`. It is a full-blown programming
    language, so you can use it to write very complex, stand-alone programs. You can
    also create simple `awk` commands that you can either run from the command-line
    or from within normal shell scripts. There’s a lot to `awk`, and entire books
    have been written about it. The goal for this chapter is to show you how to use
    `awk` in normal shell scripts.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过多种方式使用 `awk`。它是一个完整的编程语言，因此您可以用它编写非常复杂的独立程序。您还可以创建简单的 `awk` 命令，既可以从命令行运行，也可以在常规的
    shell 脚本中运行。`awk` 内容丰富，已有专门的书籍介绍它。本章的目标是向您展示如何在常规的 shell 脚本中使用 `awk`。
- en: 'Topics in this chapter include:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的主题包括：
- en: Introducing `awk`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 `awk`
- en: Understanding patterns and actions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解模式与操作
- en: Obtaining input from text files
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本文件获取输入
- en: Obtaining input from commands
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从命令获取输入
- en: If you’re ready to squawk with `awk`, let’s get started.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你准备好使用 `awk`，那我们就开始吧。
- en: Introducing awk
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 awk
- en: '`awk` is a pattern-scanning and text-processing utility that you can use to
    automate the process of creating reports and databases. With its built-in math
    functions, you can also use it to perform spreadsheet operations on text files
    of columnar, numerical data. The term `awk` comes from the names of its creators,
    Aho, Weinberger and Kernighan. The original version is now referred to as “old
    `awk`". Newer implementations, such as `nawk` and `gawk`, have more features and
    are somewhat easier to use.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`awk` 是一个模式扫描和文本处理工具，您可以使用它来自动化生成报告和数据库的过程。凭借其内置的数学功能，您还可以使用它对列状数字数据的文本文件执行电子表格操作。术语
    `awk` 来自其创造者的名字：Aho、Weinberger 和 Kernighan。原始版本现在被称为“旧版 `awk`”。更新的实现版本，如 `nawk`
    和 `gawk`，具有更多功能，且更易于使用。'
- en: 'The version of `awk` you have depends upon which operating system you’re running.
    Most Linux operating systems run `gawk`, which is the GNU implementation of `awk`.
    There’s most always an `awk` symbolic link that points to the `gawk` executable,
    as you see here on my Fedora workstation:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您使用的 `awk` 版本取决于您运行的操作系统。大多数 Linux 操作系统运行的是 `gawk`，它是 `awk` 的 GNU 实现。通常会有一个指向
    `gawk` 可执行文件的 `awk` 符号链接，就像我在 Fedora 工作站上看到的那样：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A notable exception is with Alpine Linux, which by default uses the lightweight
    `awk` implementation that’s built into the `busybox` executable. However, both
    `gawk` and `mawk`, another `awk` implementation, are available for installation
    from the Alpine repositories. (I couldn’t find a definitive answer for why `mawk`
    is called `mawk`. But, its author is Michael Brennan, so I’m guessing that it’s
    supposed to stand for “Michael’s `awk`".)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个显著的例外是 Alpine Linux，它默认使用内置在 `busybox` 可执行文件中的轻量级 `awk` 实现。不过，`gawk` 和另一种
    `awk` 实现 `mawk` 都可以从 Alpine 仓库安装。（我找不到 `mawk` 为什么被称为 `mawk` 的确切答案。不过，它的作者是 Michael
    Brennan，所以我猜它代表着“Michael 的 `awk`”。）
- en: Unix and Unix-like operating systems, such as macOS, OpenIndiana, and the various
    BSD distros, use `nawk`, which is short for “new `awk`". You’ll sometimes see
    this referred to as the “one true `awk`", partly because Brian Kernighan, one
    of the authors of the original `awk`, is one of its maintainers. However, `gawk`
    is available for installation for both FreeBSD and OpenIndiana, and `mawk` is
    available for FreeBSD.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Unix 和类 Unix 操作系统，如 macOS、OpenIndiana 和各种 BSD 发行版，使用的是 `nawk`，即“新 `awk`”的简称。您有时会看到它被称为“唯一真正的
    `awk`”，部分原因是 `awk` 原作者之一 Brian Kernighan 是它的维护者之一。不过，`gawk` 可在 FreeBSD 和 OpenIndiana
    上安装，而 `mawk` 则可在 FreeBSD 上安装。
- en: 'So, what are the differences between these different `awk` implementations?
    Well, here’s a quick run-down:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这些不同的 `awk` 实现之间有什么区别呢？这里有一个简要的概述：
- en: '`busybox`: The `awk` implementation that’s built into `busybox` is super lightweight,
    and is ideal for low-resource embedded systems. This is why it’s the default choice
    for Alpine Linux, which is also popular for embedded systems. Be aware though
    that it might not always have the features that you need for complex `awk` commands
    or scripts.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`busybox`：`busybox`中内置的`awk`实现非常轻量，非常适合低资源的嵌入式系统。这也是它成为Alpine Linux（一个也在嵌入式系统中非常流行的系统）默认选择的原因。然而要注意，它可能并不总是具备你在复杂`awk`命令或脚本中所需的功能。'
- en: '`nawk`: As I’ve already mentioned, `nawk` is the default choice for most Unix
    and Unix-like systems such as FreeBSD, OpenIndiana, and macOS. But, the executable
    file you’ll find on these systems is normally just `awk`, instead of `nawk`.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nawk`：正如我之前提到的，`nawk`是大多数Unix和类Unix系统（如FreeBSD、OpenIndiana和macOS）上的默认选择。但你在这些系统上找到的可执行文件通常是`awk`，而不是`nawk`。'
- en: '`mawk`: This is supposed to be a faster version of `awk`, which was created
    by Mike Brennan.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mawk`：这是`awk`的一个更快的版本，由Mike Brennan创建。'
- en: '`gawk`: This implementation has features that the other implementations don’t
    have. One major enhancement is the inclusion of **internationalization and localization**
    capabilities, which facilitates creating software for different languages and
    locales. It also includes TCP/IP networking capabilities and enhanced features
    for dealing with regular expressions.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gawk`：这个实现具有其他实现所没有的功能。一个重要的增强功能是**国际化和本地化**能力，这有助于为不同语言和地区创建软件。它还包括TCP/IP网络功能和改进的正则表达式处理功能。'
- en: Unless I state otherwise, I’ll be showing you coding techniques that work the
    same on both `nawk` and `gawk`. So, let’s get started.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除非我另有说明，否则我将向你展示在`nawk`和`gawk`上都能使用的编码技巧。现在，让我们开始吧。
- en: Understanding Patterns and Actions
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解模式和动作
- en: 'An `awk` **pattern** is simply the text or the regular expression upon which
    an **action** will operate. The source can be either a plain text file or the
    output of another program. To begin, let’s dump the entire contents of the `/etc/passwd`
    file to the screen, like so:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`awk`**模式**只是文本或正则表达式，用于执行**操作**的依据。数据源可以是普通文本文件，也可以是另一个程序的输出。首先，让我们将`/etc/passwd`文件的全部内容输出到屏幕上，如下所示：'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this command, the `{print $0}` part is the action, which must be surrounded
    by a pair of single quotes. The `$` designates which field to print. In this case,
    the `$0` causes every field to print. Specifying a pattern would cause only the
    lines with that pattern to print. By not specifying a pattern this time, I caused
    every line to print. Now, let’s say that I only want to show the line that contains
    a specific username. I’ll just add the pattern, like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个命令中，`{print $0}`部分是操作，它必须被一对单引号包围。`$`用于指定要打印的字段。在这个例子中，`$0`会打印出所有字段。指定模式将导致只有匹配该模式的行被打印。由于这次没有指定模式，所以我让每一行都被打印。现在，假设我只想显示包含特定用户名的行。我只需添加模式，如下所示：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The pattern needs to be enclosed within a pair of forward slashes, which in
    turn need to be within the pair of single quotes that also surround the action.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 模式需要被一对斜杠包围，而这对斜杠需要放在单引号中，这些单引号也同时包围着操作部分。
- en: '`awk` operates on groups of information known as `records`. By default, each
    line in a text file is one record. For now, that’s all we’re going to deal with.
    However, you can also have files with multi-line records, which require special
    techniques to process. I’ll show you that in the next chapter.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`awk`操作的是被称为`records`的信息组。默认情况下，文本文件中的每一行就是一个记录。现在，我们暂时只处理这个。不过，你也可以有多行记录的文件，这需要使用特殊技巧来处理。我将在下一章中展示如何操作。'
- en: 'Since `{print $0}` is the default action, I could just omit that part and get
    the same result, like so:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`{print $0}`是默认的操作，我可以直接省略这一部分，得到相同的结果，如下所示：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, let’s just print out the first field of this line. Do it like this:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们只打印出这一行的第一个字段。这样做：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `$1` designates that I want to print field number 1\. But wait though,
    this still isn’t right, because the command has actually printed fields 1 through
    5\. That’s because the default field delimiter for `awk` is a blank space. Field
    5, which contains my full name, has a blank space between the “Donald” and the
    “A.” So, as far as `awk` is concerned, this is the beginning of the second field.
    To fix that, I’ll use the `-F:` option to make `awk` recognize the colon as the
    field delimiter, like this:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`$1`表示我要打印第1个字段。但等等，这样还是不对，因为命令实际上打印了第1到第5个字段。那是因为`awk`的默认字段分隔符是空格。字段5包含我的全名，而“Donald”和“A.”之间有一个空格。所以，对`awk`来说，这是第二个字段的开始。为了修正这个问题，我会使用`-F:`选项，让`awk`将冒号识别为字段分隔符，像这样：'
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Finally, I have the output that I want.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我得到了我想要的输出。
- en: 'If you need to display more than one field, use a comma-separated list of field
    identifiers in the action, like this:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要显示多个字段，请在动作中使用逗号分隔的字段标识符列表，像这样：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: So here, I’m displaying fields 1 and 7\. (Note that the comma between the field
    numbers is what places a blank space between the fields in the output. Omitting
    the comma would cause the output to not have that blank space.)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在这里，我显示的是字段1和字段7。（请注意，字段编号之间的逗号是在输出中为字段之间添加空格的原因。如果省略逗号，输出将不会有这个空格。）
- en: 'You can also pipe the output of another program into `awk`, like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以将另一个程序的输出通过管道传递给`awk`，像这样：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Yeah, I know. It’s usually bad form to pipe `cat` output into another utility,
    when you could just directly use the other utility. But for now, this serves to
    demonstrate the concept.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我知道。通常来说，将`cat`的输出管道传递给另一个工具不是一种好形式，尤其是在你可以直接使用其他工具的情况下。但现在这样做是为了演示这个概念。
- en: All of the demos that I’ve shown you thus far could also have been done with
    `cat`, `grep`, `cut`, or combinations thereof. So, you could be forgiven for wondering
    what the point is in using `awk`. Well, hang on, because you’ll soon see that
    `awk` can do some awesome things that the other utilities can’t do, or can’t do
    as well. We’ll begin by taking a closer look at how `awk` can process input from
    plain text files.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我展示的所有示例也可以使用`cat`、`grep`、`cut`或它们的组合来完成。所以，你可能会疑惑，为什么要使用`awk`呢？好吧，稍等一下，你很快就会看到`awk`可以做一些其他工具做不到，或者做得不如它的精彩事情。我们将从更深入地了解`awk`如何处理来自普通文本文件的输入开始。
- en: Obtaining Input from Text Files
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从文本文件中获取输入
- en: As you might have already guessed, the default manner in which `awk` operates
    is to read a file line-by-line, searching for the specified pattern in each line.
    When it finds a line that contains the specified pattern, it will perform the
    specified action on that line. Let’s begin by building upon the `passwd` file
    example that I showed you in the previous section.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经猜到的那样，`awk`的默认操作方式是逐行读取文件，搜索每行中指定的模式。当它找到包含指定模式的行时，会对该行执行指定的操作。我们将从前一节中展示的`passwd`文件示例开始，继续构建。
- en: Looking for Human Users
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查找人类用户
- en: 'The `/etc/passwd` file contains a list of all users on the system. What I’ve
    always found curious is that system user accounts and normal human user accounts
    are all mixed together in the same file. But, let’s say that as part of your administrator
    duties, you need to maintain a list of normal human users on each machine. One
    way to do that is to use `awk` to search through the `passwd` file for the **User
    ID Numbers** (**UIDs**) that correspond to human users. To find out what the UID
    numbers for normal users are, you can look in the `/etc/login.defs` file that’s
    on most Linux systems. This file can be somewhat different on different Linux
    systems, so I’ll just show you how it is on my Fedora machine. On lines 142 through
    145, you see this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`/etc/passwd`文件包含了系统上所有用户的列表。我一直觉得很奇怪的是，系统用户账户和普通人类用户账户都混杂在同一个文件中。但是，假设作为管理员职责的一部分，你需要维护每台机器上的普通人类用户列表。做到这一点的一个方法是使用`awk`在`passwd`文件中搜索对应人类用户的**用户ID号码**（**UIDs**）。要查找普通用户的UID号码，你可以查看大多数Linux系统上的`/etc/login.defs`文件。这个文件在不同的Linux系统上可能会有所不同，所以我只会展示在我的Fedora机器上的情况。在第142到145行，你可以看到以下内容：'
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'So, to view all human user accounts on my system, I would search for all `passwd`
    file lines where field 3 (the UID field) contains a value that is greater than
    or equal to 1000 and less than or equal to 60000, like so:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，为了查看我系统上的所有人类用户账户，我会搜索所有`passwd`文件中字段3（即UID字段）包含大于或等于1000且小于或等于60000的行，如下所示：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You can also redirect the output into a text file, by placing the output redirector
    within the action construct, like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将输出重定向到一个文本文件中，只需在动作结构中放置输出重定向符号，如下所示：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In both examples, note how I’m using `&&` as the `and` operator in the pattern
    portion of the command.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个示例中，请注意我在命令的模式部分使用了`&&`作为`and`操作符。
- en: Tip
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: If you plan to use this command for your own use, be sure to verify what range
    of UID numbers that your operating system is using. Most Linux distros use the
    range of 1000 through 60000, as defined in the `/etc/login.defs` file. Non-Linux
    operating systems, such as OpenIndiana and FreeBSD, don’t use a `login.defs` file,
    and I’ve not been able to find any definitive answer about what UID ranges they
    use. The best I can tell you about them is to look in the `/etc/passwd` file to
    see what UID is assigned to the first human user account, and to consult your
    organization’s policy manual to see the exact range of UID numbers that your organization
    wants to use for human users.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划将此命令用于自己的用途，确保验证你的操作系统正在使用的UID号码范围。大多数Linux发行版使用1000到60000的范围，这个范围定义在`/etc/login.defs`文件中。非Linux操作系统，如OpenIndiana和FreeBSD，则不使用`login.defs`文件，我还没能找到关于它们使用的UID范围的明确答案。根据我所知道的，你可以查看`/etc/passwd`文件，看看第一个人类用户帐户分配的UID是什么，并查阅你所在组织的政策手册，看看组织希望为人类用户使用的UID号码范围。
- en: 'Of course, there’s no need to type this whole long command every time you want
    to use it. Instead, just put it into a normal shell script, which I’ll call `user_list.sh`.
    It will look something like this:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，每次想使用这个命令时，你不必每次都键入整个长命令。相反，只需将其放入一个普通的Shell脚本中，我将其命名为`user_list.sh`。它将类似于以下内容：
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'That’s good, but what if you need a comma-separated value (`.csv`) file that
    you can easily import into a spreadsheet? Well, I’ve got you covered. Just add
    a `BEGIN` section, where you would define the new field delimiter for the output,
    as well as the field delimiter for the input, like this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但如果你需要一个可以轻松导入到电子表格中的逗号分隔值（`.csv`）文件呢？好吧，我已经为你准备好了。只需添加一个`BEGIN`部分，在其中定义输出的新字段分隔符以及输入字段分隔符，如下所示：
- en: '[PRE12]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This might seem a bit strange, because when you define an input field delimiter
    in the `awk` action, you used the `-F` option. But, when you define an input field
    delimiter in the `BEGIN` section, you use the `FS` option. Likewise, you use `OFS`
    in the `BEGIN` section to define the output field delimiter. (In `awk`-speak,
    field delimiters are actually called **Field Separators**, which explains why
    these `BEGIN` options are called `FS` and `OFS`.)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来有点奇怪，因为当你在`awk`动作中定义输入字段分隔符时，你使用了`-F`选项。但当你在`BEGIN`部分定义输入字段分隔符时，你使用了`FS`选项。同样，在`BEGIN`部分，你使用`OFS`来定义输出字段分隔符。（在`awk`术语中，字段分隔符实际上被称为**字段分隔符**，这也解释了为什么这些`BEGIN`选项被称为`FS`和`OFS`。）
- en: The `BEGIN` section of an `awk` command or script is where you add any type
    of initialization code that you want to run before `awk` starts processing the
    input file. You can use it to define field separators, add a header to the output,
    or initialize global variables that you’ll use later.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`awk`命令或脚本的`BEGIN`部分是你可以添加任何初始化代码的地方，这些代码将在`awk`开始处理输入文件之前运行。你可以用它来定义字段分隔符，向输出添加标题，或初始化你稍后将使用的全局变量。'
- en: 'That’s good, but I’d also like to see the users’ UIDs. So, I’ll just add field
    3 to the mix, like this:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但我还想看到用户的UID。所以，我只需将第3列添加进去，如下所示：
- en: '[PRE13]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now that I have my `awk` command the way I want it, I’ll place it into the
    `user_list2.sh` shell script that will look like this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经将我的`awk`命令设置为我想要的样子，我将把它放入名为`user_list2.sh`的Shell脚本中，脚本如下所示：
- en: '[PRE14]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You could write a program that does this same thing in some other programming
    language, such as Python, C, or Java. But, the program code would be quite complex
    and more difficult to get right. With `awk`, all it takes is just a simple single-line
    command.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用其他编程语言编写一个程序来做同样的事情，比如Python、C或Java。但是，程序代码会相当复杂，且更难以正确实现。使用`awk`，只需一个简单的一行命令就可以完成。
- en: Next, let’s see how `awk` can help a busy webserver administrator.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看`awk`如何帮助忙碌的Web服务器管理员。
- en: Parsing Webserver Access Logs
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析Web服务器访问日志
- en: Webserver access logs contain a lot of information that can help a website owner,
    a webserver administrator, or a network security administrator. There are a lot
    of fancy log-parsing tools that can build fancy reports that tell you everything
    that’s going on, if that’s what you need. But, there may be times when you’ll
    want to quickly extract some specific data without taking the time to run some
    fancy tool. There are a few different ways to do that, and `awk` is one of the
    best.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Web 服务器访问日志包含大量信息，可以帮助网站所有者、web 服务器管理员或网络安全管理员。有很多先进的日志解析工具可以生成详细报告，告诉你发生了什么，如果你需要的话。但有时候，你可能想快速提取一些特定数据，而不花时间运行复杂的工具。有几种方法可以做到这一点，而
    `awk` 是其中最好的之一。
- en: 'To begin the scenario, you’ll need a virtual machine with an active webserver
    installed. To keep things simple, I’ll just install the Apache server and the
    PHP module on my Fedora Server virtual machine, like this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个场景，你需要一台安装了活动 web 服务器的虚拟机。为了简化操作，我将在我的 Fedora Server 虚拟机上安装 Apache 服务器和
    PHP 模块，方法如下：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, enable and start the Apache service, like this:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，启用并启动 Apache 服务，方法如下：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To access the server from different machines, you’ll need to open Port 80 on
    the firewall, like this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要从不同的机器访问服务器，你需要在防火墙上打开端口 80，方法如下：
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Finally, in the `/var/www/html/` directory, create the `test.php` file, with
    the following contents:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 `/var/www/html/` 目录下，创建 `test.php` 文件，并添加以下内容：
- en: '[PRE18]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Reminder**: To make this work, be sure to set your virtual machine up with
    Bridged Mode networking, so that other machines on your network can reach it.
    Also, be sure that the virtual machines that you use to access the webserver are
    also set up in Bridged Mode, so that each machine will have its own IP address
    in the access log file.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**提醒**：为了使其正常工作，请确保将你的虚拟机设置为桥接模式网络，这样网络中的其他机器就能访问它。还要确保用于访问 web 服务器的虚拟机也设置为桥接模式，以便每台机器在访问日志文件中都有自己的
    IP 地址。'
- en: 'Now, from as many other machines as possible, access both the Fedora Webserver
    Test Page and the `test.php` page. Then, try to access a non-existent page. Your
    URLs should look something like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，从尽可能多的其他机器上访问 Fedora Web 服务器测试页面和 `test.php` 页面。然后，尝试访问一个不存在的页面。你的 URL 应该像这样：
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'On the webserver virtual machine, open the `var/log/httpd/access_log` file
    in `less`, like this:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 web 服务器虚拟机上，使用 `less` 打开 `var/log/httpd/access_log` 文件，方法如下：
- en: '[PRE20]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Note the structure of the file, and how it uses blank spaces as field delimiters
    for some fields and double quotes as field delimiters for other fields. For example,
    here’s one entry from my own access file:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意文件的结构，以及它如何使用空格作为某些字段的分隔符，而使用双引号作为其他字段的分隔符。例如，以下是我自己访问文件中的一条记录：
- en: '[PRE21]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'So, you see here that some fields are surrounded by double quotes, and others
    aren’t. For now, let’s look at the IP addresses that have accessed this machine,
    like so:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你会看到这里有些字段被双引号包围，而有些则没有。现在，我们来看一下访问过这台机器的 IP 地址，方法如下：
- en: '[PRE22]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you see, I just piped the `awk` output into `sort -V`, which I then piped
    into `uniq`. Using the `-V` option for `sort` causes the IP addresses to be sorted
    in correct numerical order. You can’t use the `-n` switch for this, because by
    default, `sort` treats the dots in the IP addresses as decimal points. The `-V`
    option overrides that behavior by doing what is called a **natural sort**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我将 `awk` 输出管道传输到 `sort -V`，然后再管道传输到 `uniq`。使用 `sort` 的 `-V` 选项会按照正确的数字顺序对
    IP 地址进行排序。你不能使用 `-n` 选项，因为默认情况下，`sort` 会将 IP 地址中的点当作小数点处理。`-V` 选项会通过执行所谓的**自然排序**来覆盖这一行为。
- en: 'This is good, except that I still don’t know how many times the webserver was
    accessed from each IP address. I’ll use `uniq` with the `-c` option to see that,
    which will look like this:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做是不错的，但我仍然不知道每个 IP 地址访问 web 服务器的次数。我将使用带 `-c` 选项的 `uniq` 来查看，这将显示如下内容：
- en: '[PRE23]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'That’s good, but I really want to create a `.csv` file, as I did for my list
    of users. I can’t do that by defining the `OFS` parameter in the `BEGIN` section
    this time, because the count field isn’t created until I pipe the output into
    `uniq -c`. So, I’ll cheat a bit by installing the `miller` package, which is in
    the repositories for most Linux distros, as well as for FreeBSD. On a Mac, you
    should be able to install it with `homebrew`. Anyway, to create the `.csv` file,
    I’ll just pipe the output from this `awk` command into the `mlr` utility, which
    is part of the `miller` package. Here’s how that looks:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这样不错，但我真的想创建一个`.csv`文件，就像我为我的用户列表做的那样。因为计数字段直到我将输出管道到`uniq -c`之后才会创建，所以这次我不能通过在`BEGIN`部分定义`OFS`参数来做到这一点。所以，我稍微“作弊”一下，安装`miller`包，它包含在大多数Linux发行版以及FreeBSD的仓库中。在Mac上，你应该可以通过`homebrew`安装它。无论如何，为了创建`.csv`文件，我将把来自这个`awk`命令的输出管道到`mlr`工具，它是`miller`包的一部分。看起来是这样的：
- en: '[PRE24]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `--p2c` option for `mlr` is what converts the output to `.csv` format. After
    that is `cat`, which is the `mlr` verb. You see that this `cat` just dumps the
    output to either the screen or to a file, the same as its `bash` cousin does.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlr`的`--p2c`选项用于将输出转换为`.csv`格式。接下来是`cat`，这是`mlr`的动词。你会看到这个`cat`会像它的`bash`版本一样，将输出直接显示到屏幕或文件中。'
- en: 'I’m showing you how to create `.csv` files, because for historical reasons,
    `.csv` is the most popular format for plain-text data files, and your employer
    or clients might expect you to use them. However, as we’ll see in a bit, this
    isn’t always the best format. In certain circumstances, you might find that your
    best bet is to forget about `.csv` files, and instead save your data to **Tab
    Separated Value** (`.tsv`) files, which might look something like this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我正在向你展示如何创建`.csv`文件，因为出于历史原因，`.csv`是最流行的纯文本数据文件格式，而你的雇主或客户可能期望你使用这种格式。然而，正如我们稍后会看到的，这并不总是最佳格式。在某些情况下，你可能会发现最好的选择是忘记`.csv`文件，而是将数据保存为**制表符分隔值**（`.tsv`）文件，它们可能像这样：
- en: '[PRE25]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: You can also import them into your favorite spreadsheet program, and in certain
    circumstances, they’re much easier to deal with.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将它们导入你最喜欢的电子表格程序，在某些情况下，它们更容易处理。
- en: 'If you need a `.json` file instead of a `.csv` file, `mlr` can also do that
    for you. You’ll just replace the `--p2c` option with the `--ojson` option, like
    this:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要的是`.json`文件而不是`.csv`文件，`mlr`也能帮你做到。你只需将`--p2c`选项替换为`--ojson`选项，如下所示：
- en: '[PRE26]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: There’s a lot more that you can do with `mlr` than I can show you here. To learn
    more about it, consult either the `mlr` man page or the Miller Documentation web
    page. (You’ll find a link to the Miller page in the *Further Reading* section.)
    As good as `mlr` is though, it does have one flaw. That is, it can’t handle fields
    that contain blank spaces or commas. So, you won’t be able to use it for every
    field in the Apache access log.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用`mlr`做的事情远远超过我在这里展示的内容。要了解更多，查阅`mlr`的手册页或Miller文档网页。 （你可以在*进一步阅读*部分找到指向Miller网页的链接。）不过，尽管`mlr`非常优秀，它确实有一个缺点。也就是，它不能处理包含空格或逗号的字段。所以，你不能在Apache访问日志中的每个字段上使用它。
- en: 'Now, let’s say that we want to see which operating systems and browsers are
    accessing this server. The **User Agent** string that contains that information
    is in field 6, which is surrounded by a pair of double quotes. So, we’ll have
    to use the double quote as the field delimiter, like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们想查看哪些操作系统和浏览器正在访问这个服务器。包含这些信息的**用户代理**字符串位于第6个字段中，并且被一对双引号包围。所以，我们需要使用双引号作为字段分隔符，如下所示：
- en: '[PRE27]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: You can see here that I had to escape the double quote with a backslash, so
    that the shell won’t misinterpret it.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，我必须用反斜杠转义双引号，这样shell就不会错误地解析它。
- en: 'Next, let’s look for a specific User Agent. Let’s say that we want to know
    how many users are using a Mac. Just add the pattern, like this:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们查找特定的用户代理。假设我们想知道有多少用户使用的是Mac。只需添加模式，像这样：
- en: '[PRE28]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The entries for the Intel Mac are from my 2010-model Mac Pro, so they make sense.
    But, what’s with that PPC business in lines 3 and 4 of the output? Well, that’s
    also easily explained. Just for fun, I fired up my 21-year old eMac that’s equipped
    with an old-school Motorola PowerPC G4 processor, and used it to access the test
    webserver. (I’m guessing that you’ll never see any of those on your own network.)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 英特尔Mac的条目来自我2010年的Mac Pro，所以它们是合理的。但是，输出的第3和第4行中出现的PPC是怎么回事？这也很好解释。只是为了好玩，我启动了我的21年历史的eMac，它配备了老式的摩托罗拉PowerPC
    G4处理器，用它访问了测试Web服务器。（我猜测你在自己的网络上永远不会看到这些设备。）
- en: 'You can also obtain this information with nothing but pure `awk`, without having
    to pipe the output into other utilities. Do that by building an **associative
    array**, which looks like this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以仅使用纯 `awk` 获得这些信息，无需将输出传递给其他工具。通过构建一个**关联数组**，可以实现这一点，格式如下：
- en: '[PRE29]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Add a `BEGIN` section with an `OFS` definition, and you can create a `.csv`
    file. Here’s how that looks:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个 `BEGIN` 部分，并定义 `OFS`，你就可以创建一个 `.csv` 文件。它是这样的：
- en: '[PRE30]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Unlike the normal shell scripting arrays that you’ve seen previously, `awk`
    associative arrays use text strings, instead of numbers, as their indexes. Also,
    arrays in `awk` are defined on-the-fly, and don’t have to be declared before you
    can use them. So here you see the `count` array, with whatever the respective
    values of field 1 are for the index values. The `++` operator, which assumes an
    initial value of 0, adds together the number of times each index string is found
    in the file. The first portion of this command, which ends at the semi-colon,
    processes the file line-by-line as `awk` normally does. The `END` keyword designates
    code that will run after the line-by-line processing has completed. In this case,
    you see a `for` loop that prints out a summary of unique IP addresses, along with
    how many times each one was found. Unfortunately, there’s no easy way to sort
    the output with pure `awk`, but you can still pipe the output into `sort`, like
    this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 与你之前见过的普通 Shell 脚本数组不同，`awk` 的关联数组使用文本字符串，而不是数字，作为索引。此外，`awk` 中的数组是动态定义的，无需在使用前声明它们。所以在这里你会看到
    `count` 数组，它的索引值对应字段 1 的各个值。`++` 运算符假定初始值为 0，表示每个索引字符串在文件中出现的次数。这个命令的第一部分，以分号结尾，按行处理文件，正如
    `awk` 通常所做的那样。`END` 关键字标志着代码会在逐行处理完成后运行。在这种情况下，你会看到一个 `for` 循环，打印出唯一 IP 地址的摘要，并显示每个地址出现的次数。不幸的是，用纯
    `awk` 对输出进行排序并没有简单的方法，但你仍然可以将输出传递给 `sort`，像这样：
- en: '[PRE31]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: To make this work, I’m using sort with the `-t,` option to define the comma
    as the field delimiter. (Yeah, I know. It would be nice if all Linux and Unix
    utilities used the same option switch to define field delimiters, but that’s just
    not how the world works.)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其生效，我使用 `-t,` 选项对 `sort` 进行排序，将逗号定义为字段分隔符。（是的，我知道。如果所有 Linux 和 Unix 工具都使用相同的选项开关来定义字段分隔符，那就好了，但现实情况并非如此。）
- en: 'Another difference with using pure `awk` is that the number of occurrences
    for each IP address is in the second column, rather than in the first column as
    you saw before. That’s okay here, but it might not work so well for other fields.
    For example, let’s change the command to look at the User Agents in field 6:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用纯 `awk` 的另一个区别是，每个 IP 地址的出现次数位于第二列，而不是你之前看到的第一列。这里没问题，但对于其他字段可能不太适用。例如，让我们将命令更改为查看字段
    6 中的用户代理：
- en: '[PRE32]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Yeah, it works, but having the number of occurrences in the second column for
    this makes the output somewhat less readable.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，方法有效，但在第二列中显示出现次数使得输出的可读性稍差。
- en: As I mentioned before, the `.csv` format isn’t always your best choice for a
    plain-text data file. In fact, it’s impossible to turn the output from field 6
    into a proper `.csv` file that any spreadsheet program will properly display.
    That’s because this field contains blank spaces and commas that make a spreadsheet
    program think that there are more fields in the `.csv` file than there really
    are.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前提到的，`.csv` 格式并不总是最适合用作纯文本数据文件。事实上，将字段 6 的输出转化为任何电子表格程序能够正确显示的 `.csv` 文件几乎是不可能的。因为该字段包含空格和逗号，会导致电子表格程序误认为
    `.csv` 文件中有比实际更多的字段。
- en: 'So, the easiest solution is to surround the text in field 6 with a pair of
    double quotes and save the output to a `.tsv` file. Then, when you open the file
    in your spreadsheet, define the `"` as the field delimiter. Anyway, here’s the
    command to create the `.tsv` file, without using an associative array:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，最简单的解决方案是用一对双引号将字段 6 中的文本括起来，并将输出保存为 `.tsv` 文件。然后，当你在电子表格中打开该文件时，将 `"` 定义为字段分隔符。无论如何，以下是创建
    `.tsv` 文件的命令，未使用关联数组：
- en: '[PRE33]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'By default, `awk` strips out the double quotes that surround field 6 in the
    original log file. So, to make this work properly, I have to put them back into
    the final output file. In the action part, you see that I’m printing a double
    quote both before and after `$6`. By omitting the commas that you might normally
    place between the various `print` elements, I’ll ensure that there are no blank
    spaces between the quotes and the text. Then, I’m just piping the output into
    `sort`, `uniq`, and `sort` again as I’ve shown you before. Here’s how the file
    looks:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`awk` 会去掉原始日志文件中字段 6 周围的双引号。所以，为了使这个操作正常工作，我必须将双引号放回最终输出文件中。在操作部分，你会看到我在`$6`之前和之后都打印了一个双引号。通过省略你通常会在各个`print`元素之间放置的逗号，我确保双引号和文本之间没有空格。然后，我只是像之前所展示的那样，将输出通过管道传递给
    `sort`、`uniq`，然后再次传递给 `sort`。下面是文件的样子：
- en: '[PRE34]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'If you prefer to use an associative array, you can do it like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更喜欢使用关联数组，可以像这样操作：
- en: '[PRE35]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Note how I had to surround the `printf` parameters with a pair of double quotes.
    The first `%s` parameter is for the count field, and the second `%s` parameter
    is for the user agent field. To add the double quotes in the proper places, I
    added a `\"` to both before and after the second `%s`. Using either the associative
    array method or the non-associative array method gives me the same results. Now,
    when I open the file in a spreadsheet program, I’ll just define the double quote
    as the field delimiter. Here’s how that looks on LibreOffice Calc:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我如何需要将 `printf` 的参数用一对双引号括起来。第一个 `%s` 参数是用于计数字段，第二个 `%s` 参数是用于用户代理字段。为了在正确的位置添加双引号，我在第二个
    `%s` 前后都加了一个 `\"`。使用关联数组方法或非关联数组方法都能得到相同的结果。现在，当我在电子表格程序中打开文件时，我只需将双引号定义为字段分隔符。下面是它在
    LibreOffice Calc 中的样子：
- en: '![B21693_14_1](img/B21693_14_01.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![B21693_14_1](img/B21693_14_01.png)'
- en: 'Figure 14.1: Setting the field delimiter in LibreOffice Calc'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1：在 LibreOffice Calc 中设置字段分隔符
- en: I know that I haven’t fully explained `print` versus `printf` yet, but I will
    in the next chapter.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道我还没有完全解释 `print` 和 `printf` 的区别，但我会在下一章中详细说明。
- en: The `user_agent.tsv` file should now display properly, with the count in the
    first column and the User Agent string in the second column.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`user_agent.tsv` 文件现在应该能够正确显示，第一列是计数，第二列是用户代理字符串。'
- en: 'Next, let’s count the number of times that each URL on the webserver was hit.
    I like having the count as the first field of output, so I’ll again pipe the `awk`
    output into `uniq` and `sort`, like so:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们统计一下每个 URL 在 Web 服务器上的访问次数。我喜欢将计数作为输出的第一个字段，所以我再次将 `awk` 的输出通过管道传递给 `uniq`
    和 `sort`，如下所示：
- en: '[PRE36]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Using the blank space as the field delimiter means that the URL field is field
    7\. At the end, I’m piping the output into `sort` again so that the list will
    print out according to the number of hits for each URL. But actually, I’d like
    that to show the most popular URLs at the top of the list. So, I’ll just add the
    `-r` option to sort in reverse, like this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用空格作为字段分隔符意味着 URL 字段是字段 7。最后，我再次将输出通过管道传递给 `sort`，以便按每个 URL 的点击次数输出列表。但实际上，我希望最受欢迎的
    URL 显示在列表的顶部。所以，我只需加上 `-r` 选项来反向排序，如下所示：
- en: '[PRE37]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: One thing we see is that someone tried to perform a directory traversal attack
    against me, as evidenced by the lines that begin with `/test.php?page` or `/test.php?module`.
    I’ll show you more about that later in *Chapter 18, Shell Scripting for Security
    Professionals*.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到的一件事是，有人试图对我进行目录遍历攻击，从以 `/test.php?page` 或 `/test.php?module` 开头的行中可以看出。我稍后会在
    *第 18 章：安全专家的 Shell 脚本* 中给你更多讲解。
- en: 'That last field we’ll look at is field 9, which is the **HTTP status code**.
    Again, we’ll use the blank space as the field delimiter, like so:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后要看的字段是字段 9，它是**HTTP 状态码**。同样，我们将使用空格作为字段分隔符，如下所示：
- en: '[PRE38]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Here’s the breakdown of what these codes mean:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这些代码含义的分解：
- en: '200: The `200` code means that users were able to access web pages normally,
    with no problems.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 200：`200` 代码意味着用户可以正常访问网页，没有任何问题。
- en: '304: The `304` code just means that when a user reloaded a page, nothing on
    the page had changed, so that it didn’t need to be reloaded.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 304：`304` 代码意味着当用户重新加载一个页面时，页面没有任何变化，因此不需要重新加载。
- en: '403: The `403` code means that someone tried to access a page for which the
    user wasn’t authorized.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 403：`403` 代码意味着有人尝试访问一个用户没有授权的页面。
- en: '404: The `404` means that a user tried to access a page that doesn’t exist.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 404：`404` 代码意味着用户尝试访问一个不存在的页面。
- en: 'Okay, all this is good. So now, let’s put all this into the `access_log_parse.sh`
    script, which will look like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这一切都很好。所以现在，让我们把所有这些放到`access_log_parse.sh`脚本中，它将如下所示：
- en: '[PRE39]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: I’ve decided that I want to create a separate `.tsv` file for each function,
    and that I want to have a timestamp in each filename. The `%F` option for `date`
    prints the date in `YEAR-MONTH-DATE` format, which is fine. I could have used
    the `%T` option to print the time, but that would have placed colons in the filenames,
    which would require me to escape the colons every time I want to access one of
    these files from the command line. So, I instead used the `%I-%M-%p` combination,
    in order to replace the colons with dashes. (To see more formatting options, consult
    the `date` man page.) The rest of the script consists of the commands that you’ve
    already seen, so I won’t repeat any of those explanations.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定为每个功能创建单独的`.tsv`文件，并且我想在每个文件名中加上时间戳。`date`命令的`%F`选项以`YEAR-MONTH-DATE`格式打印日期，这很好。我本可以使用`%T`选项打印时间，但那样会在文件名中加入冒号，这将要求我每次从命令行访问这些文件时都要转义冒号。因此，我改用了`%I-%M-%p`组合，以将冒号替换为破折号。（要了解更多格式选项，请参阅`date`手册页。）脚本的其余部分包括您已经看到的命令，所以我不会重复任何解释。
- en: Of course, you can fancy up any of these scripts to meet your own desires and
    needs. Just use the techniques that I’ve shown you in previous chapters to add
    markup language tags to the output, and convert the output files to `.html` or
    `.pdf` format. For the multi-function script that I’ve just now shown you, you
    could add either `if..then` or `case` constructs that would allow you to choose
    the specific function that you want to run. And, don’t feel bad if you need to
    refer back to the previous chapters to see how any of this is done. Trust me,
    I won’t hold it against you.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您可以使用正则表达式来优化任何这些脚本，以满足您自己的需求和需求。只需使用我在前几章中展示给您的技术，向输出添加标记语言标签，并将输出文件转换为`.html`或`.pdf`格式。对于我刚刚展示给您的多功能脚本，您可以添加`if..then`或`case`结构，以允许您选择要运行的特定功能。如果您需要回头查看以了解任何操作方式，也不必感到难过。相信我，我不会因此责怪您。
- en: 'So far, we’ve been parsing through the entire file to find what we want to
    see. Sometimes though, you might just want to view information from either a specific
    line or range of lines. For example, let’s say that you just want to see line
    10\. Do it like this:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在整个文件中解析以找到我们想要查看的内容。不过有时候，您可能只想查看特定行或一系列行的信息。例如，假设您只想查看第10行。请按照以下方式操作：
- en: '[PRE40]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The `NR` variable represents the **Number of Record**. Since each record in
    the `access_log` file consists of only a single line, this is the same as defining
    the line number that you want to see. To see a range of lines, do something like
    this:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`NR`变量表示**记录数**。由于`access_log`文件中的每条记录仅占一行，这与定义您想要查看的行号相同。要查看一系列行，请执行以下操作：'
- en: '[PRE41]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Here, I’m looking at field 1 of lines 10 through 15\. Of course, you could do
    the same thing by combining the `tail`, `head`, and `cut` utilities, but this
    is way easier.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我正在查看第10到15行的第1字段。当然，您也可以通过结合`tail`、`head`和`cut`工具来做同样的事情，但这种方式更简单。
- en: In this section, we’ve looked at `FS`, `OFS`, and `NR`. What I haven’t told
    you yet is that these three constructs are variables that are built into `awk`.
    There are many more built-in variables, but I’d rather not overwhelm you by explaining
    all of them now. If you’re interested in reading about all of them, just open
    the `awk` man page and scroll down to the **Built-in Variables** section.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已经看过`FS`、`OFS`和`NR`。我还没告诉你的是，这三个结构都是内置到`awk`中的变量。还有许多其他内置变量，但我现在不想一下子就把它们都解释清楚，以免让你感到不知所措。如果您有兴趣了解所有这些内容，只需打开`awk`手册页并滚动到**内置变量**部分即可。
- en: The log parsing techniques that I’ve presented here can be used for any type
    of log file. To design your `awk` commands, look through the log files that you
    want to process and take note of how the fields are laid out in each line, and
    what information they contain.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里介绍的日志解析技术可以用于任何类型的日志文件。要设计您的`awk`命令，请查看要处理的日志文件，并注意每行的字段布局及其包含的信息。
- en: Before we move on, let’s look at a few other log-parsing techniques.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们看看一些其他日志解析技术。
- en: Using Regular Expressions
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用正则表达式
- en: You can enhance your `awk` experience with regular expressions, just as you
    can with other text-manipulation utilities.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以像使用其他文本处理工具一样，通过正则表达式增强您的`awk`体验。
- en: If you need to, refer back to *Chapter 2, Text Stream Filters – Part 2* and
    *Chapter 9, Filtering Text with grep, sed, and Regular Expressions* to review
    the concepts of regular expressions and POSIX character classes.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，可以回顾一下*第 2 章，文本流过滤器 – 第 2 部分*和*第 9 章，使用 grep、sed 和正则表达式过滤文本*，复习正则表达式和 POSIX
    字符类的概念。
- en: 'For our first example, let’s say that you need to search through the `/etc/passwd`
    file for all users whose usernames begin with a lower-case *v*. Just use a simple
    regular expression, which will look like this:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第一个例子，假设你需要在 `/etc/passwd` 文件中查找所有用户名以小写字母 *v* 开头的用户。只需使用一个简单的正则表达式，像这样：
- en: '[PRE42]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This works because the username field is the first field of every line. So,
    you don’t need to do anything any fancier than just this. But, let’s suppose you
    need to search for something in another field that begins with a certain character.
    For example let’s say that you need to search through the Apache access log file
    for all HTTP status codes that are in the 400 range. Just do something like this:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 之所以这样有效，是因为用户名字段是每一行的第一个字段。所以，你不需要做任何复杂的操作，仅仅这样就可以了。但是，假设你需要在另一个字段中搜索以特定字符开头的内容。比如说，你需要在
    Apache 访问日志文件中查找所有属于 400 范围的 HTTP 状态码。你只需要像这样做：
- en: '[PRE43]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The `$9` in the pattern means that you’re looking for a certain pattern in
    field 9\. The `~` means that you want something in that field to match whatever
    is within the following forward slashes. In this case, it’s looking for anything
    in field 9 that begins with the number 4\. In the output, you see that I’ve found
    both the 403 and the 404 status codes. And, if you need to, you can save the output
    to a `.csv` file, like so:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 模式中的 `$9` 表示你在第 9 个字段中查找某个特定模式。`~` 表示你希望该字段中的内容匹配后面正斜杠之间的内容。在这种情况下，它是在寻找第 9
    个字段中以数字 4 开头的内容。在输出中，你会看到我找到了 403 和 404 状态码。如果需要，你还可以将输出保存为 `.csv` 文件，像这样：
- en: '[PRE44]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'If you prefer, you can save it to a `.tsv` file by omitting the `mlr --p2c
    cat` portion, like so:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更喜欢的话，你可以通过省略 `mlr --p2c cat` 部分，将其保存到 `.tsv` 文件中，像这样：
- en: '[PRE45]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'To see everything *except* for a certain pattern, use the `!~` construct, like
    this:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看所有*除了*某个模式以外的内容，可以使用 `!~` 构造，像这样：
- en: '[PRE46]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This allows us to see everything except for the 400 codes.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就可以查看所有除 400 状态码以外的内容。
- en: 'Next, let’s say that we want to see all instances where someone used either
    the Safari or the Lynx web browsers. You could do this:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，假设我们想要查看所有使用 Safari 或 Lynx 浏览器的实例。你可以这样做：
- en: '[PRE47]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'However, that doesn’t work, because it will include entries like this one:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，这样并不行，因为它会包含像这样的条目：
- en: '[PRE48]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'For some strange reason, Apache can’t exactly identify the Microsoft Edge browser,
    so it reports it as several different possibilities, including Safari. To narrow
    that down, I’ll exclude any users who are using Windows. (Safari used to be available
    for Windows, but the Windows version was discontinued in 2012.) Here’s how that
    looks:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 出于某种奇怪的原因，Apache 无法准确识别 Microsoft Edge 浏览器，所以它将其报告为多个不同的可能性，包括 Safari。为了缩小范围，我会排除所有使用
    Windows 的用户。（Safari 曾经在 Windows 上可用，但 Windows 版本在 2012 年就停止了。）下面是它的表现方式：
- en: '[PRE49]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: And here, you see something that’s rather strange. It’s that when you use an
    `or` or an `and` operator within a regular expression, you use either a single
    `|` or a single `&`. When you use an `or` or an `and` operator outside of a regular
    expression, you use either `||` or `&&`. I know, it’s confusing, but that’s just
    the way it is. Anyway, if you look through the output now, you’ll see that there
    are no lines from the Windows users.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现这里有点奇怪。当你在正则表达式中使用 `or` 或 `and` 操作符时，你使用的是单个 `|` 或单个 `&`。而当你在正则表达式外部使用 `or`
    或 `and` 操作符时，你需要使用 `||` 或 `&&`。我知道，这有点让人困惑，但就是这样。不管怎样，如果你现在查看输出，你会看到没有来自 Windows
    用户的行。
- en: I know, this is just scratching the surface for what you can do with `awk` and
    regular expressions. If you ask real nicely, I might show you a few more examples
    in the next section, which will be about how to use `awk` to process information
    from other commands.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道，这只是 `awk` 和正则表达式的冰山一角。如果你请求得特别恳切，我可能会在下一个部分给你展示一些更多的例子，内容是如何使用 `awk` 处理来自其他命令的信息。
- en: Obtaining Input from Commands
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从命令获取输入
- en: 'Let’s start with something simple, by obtaining some basic process information.
    On the Fedora Server virtual machine that’s running Apache, search for all `ps
    aux` output lines that contain the `httpd` pattern, like so:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的例子开始，获取一些基本的进程信息。在运行 Apache 的 Fedora Server 虚拟机上，搜索所有包含 `httpd` 模式的
    `ps aux` 输出行，像这样：
- en: '[PRE50]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Next, let’s say that we want to see all processes that are owned by the root
    user. That’s also easy. Just do this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，假设我们想查看所有由 root 用户拥有的进程。也很简单，直接执行以下命令：
- en: '[PRE51]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: There’s nothing really new here, because these `awk` commands are the same as
    you saw in the previous section. Indeed, pretty much all of the techniques that
    you can do with parsing log files also work here. So, let’s not repeat any more
    of that.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有什么新内容，因为这些 `awk` 命令和你在上一节中看到的一样。事实上，几乎所有解析日志文件的技巧在这里也同样适用。所以，接下来就不再重复这些内容了。
- en: 'The first step for parsing information from the `ps` utility is to see what
    the various fields are. The `aux` combination of options is what I find most useful
    for myself, simply because it displays the specific information that I most need
    to see. To see the `ps` header that shows the field names, I’ll pipe the `ps aux`
    output into `head -1`, like this:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 解析 `ps` 工具的信息的第一步是查看各个字段的含义。我个人发现 `aux` 选项组合最为实用，因为它显示了我最需要查看的特定信息。要查看显示字段名的
    `ps` 头部，我会将 `ps aux` 的输出通过管道传递给 `head -1`，像这样：
- en: '[PRE52]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Here’s the breakdown of what all these fields represent:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这是所有这些字段的含义说明：
- en: '`USER`: The user that owns each particular process.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`USER`：拥有每个进程的用户。'
- en: '`PID`: The **Process ID** number of each process.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PID`：每个进程的**进程 ID**。'
- en: '`%CPU`: The percentage of CPU resources that each process consumes.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`%CPU`：每个进程消耗的 CPU 资源百分比。'
- en: '`RSS`: The **Resident Set Size** is the amount of actual physical, non-swapped
    memory that each process uses. (I know that this is out of order, but you’ll soon
    see the reason.)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RSS`：**常驻内存集大小**，即每个进程使用的实际物理内存（未交换的内存）。(虽然这里的顺序可能有点乱，但很快你会明白原因。)'
- en: '`%MEM`: The ratio of the process’s RSS to the amount of physical memory that’s
    installed in the machine.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`%MEM`：进程的 RSS（常驻内存集）与计算机中安装的物理内存总量的比率。'
- en: '`VSZ`: The **Virtual Set Size** is the amount of virtual memory that each process
    is using. (This is expressed in numbers of 1024-byte units.)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VSZ`：**虚拟内存集大小**，即每个进程使用的虚拟内存量。（以 1024 字节单位表示。）'
- en: '`TTY`: This is the terminal which is controlling each process.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TTY`：控制每个进程的终端。'
- en: '`STAT`: This column holds the status code of each process.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`STAT`：此列显示每个进程的状态代码。'
- en: '`START`: The starting time or date of each process.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`START`：每个进程的启动时间或日期。'
- en: '`TIME`: This is the cumulative CPU time for each process, in “`[DD-]HH:MM:SS`"
    format.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TIME`：每个进程的累计 CPU 时间，格式为“`[DD-]HH:MM:SS`”。'
- en: '`COMMAND`: The commands that started each process.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`COMMAND`：启动每个进程的命令。'
- en: Bear in mind that there are many options switches for `ps`, which all show different
    types of process data. There are also many ways to combine the switches in order
    to get all of the information you need, displayed in your preferred format. For
    now though, I’m just going to stick with `ps aux`, mainly because it’s the most
    useful option combination for me. For more details, see the `ps` man page.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，`ps` 有许多选项开关，每个都显示不同类型的进程数据。你还可以通过组合这些选项来获取所有你需要的信息，并以你喜欢的格式显示。不过，现在我会坚持使用
    `ps aux`，主要是因为这是最适合我的选项组合。有关详细信息，请参阅 `ps` 的手册页。
- en: 'By default, `ps` commands always display this header along with the information
    that you want to see. So, you’ll see this header if you pipe `ps` into an `awk`
    command that doesn’t filter it out. For example, let’s look at the processes that
    are not owned by the root user, like this:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`ps` 命令总是显示此头部和你想查看的信息。因此，如果你将 `ps` 的输出通过管道传递给 `awk` 命令而不对其进行过滤，你也会看到这个头部。例如，看看那些不是
    root 用户拥有的进程，像这样：
- en: '[PRE53]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'That’s fine most of the time. But, having that header there might mess you
    up if you need to save the information to a formatted text file. To fix this,
    let’s use the **Number of Record** (`NR)` variable that I showed you in the previous
    section. Here’s how that works:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这样通常是没问题的。但是，如果你需要将信息保存到格式化的文本文件中，头部可能会给你带来麻烦。为了解决这个问题，我们可以使用我在前一节中展示过的 **记录数**（`NR`）变量。这样操作：
- en: '[PRE54]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The `NR > 1` clause means that we only want to see records that come after record
    1\. In other words, we don’t want to see the first line of output, which in this
    case would be the `ps` header.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`NR > 1` 条件意味着我们只想查看第 1 记录之后的记录。换句话说，我们不想看到输出的第一行，在这种情况下那就是 `ps` 头部。'
- en: 'Now that we know what each field is, we can create some useful one-liners to
    extract information. First, let’s see how many processes are in either the **Running**
    state or the **Zombie** state. (A Zombie process is a dead process that hasn’t
    yet been properly destroyed by its parent process. You can view the `ps` man page
    to learn more about them.) We know that the `STAT` column is field 8, so the command
    will look like this:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了每个字段的含义，我们可以创建一些有用的一行命令来提取信息。首先，让我们看看有多少进程处于 **运行中** 或 **僵尸** 状态。（僵尸进程是已经死掉的进程，但其父进程尚未完全销毁它们。你可以查看
    `ps` 的手册页来了解更多。）我们知道 `STAT` 列是第 8 个字段，因此命令将如下所示：
- en: '[PRE55]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: It looks a bit jumbled up because the `COMMAND` field for the second process
    contains a very long string, but that’s okay. You can still see that field 8 in
    every line begins with the letter `R`. (You’ll rarely see any Zombie processes
    on your systems, so don’t worry about not seeing any of them here. And no, Zombie
    processes don’t go around looking for brains to steal.)
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来有些混乱，因为第二个进程的 `COMMAND` 字段包含了一个很长的字符串，但这没关系。你仍然可以看到每一行的第 8 字段都以字母 `R` 开头。（你在系统中很少会看到僵尸进程，所以不用担心这里没有看到它们。而且，不，僵尸进程不会四处寻找大脑来偷。）
- en: 'The `w` command shows you a list of all users who are logged into the system,
    and what they’re doing. It looks like this:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`w` 命令会显示所有已登录系统的用户以及他们正在做什么。它看起来是这样的：'
- en: '[PRE56]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'You see that I’m logged in via `tty1`, which is the local terminal. I’m also
    logged in remotely via a `pts` terminal, along with Vicky and Frank. (Remember
    that `tty` terminals indicate that someone is logged in locally, while `pts` terminals
    indicate that someone is logged in remotely.) Now, let’s use `ps` to see more
    information about the processes that the remote users are running, like this:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，我是通过 `tty1` 登录的，这是本地终端。我也通过一个 `pts` 终端远程登录，并且 Vicky 和 Frank 也在其中。（记住，`tty`
    终端表示本地登录，而 `pts` 终端表示远程登录。）现在，让我们使用 `ps` 查看远程用户正在运行的进程的更多信息，如下所示：
- en: '[PRE57]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'A few moments ago, I showed you how to strip the header line out of the output
    if your `awk` command doesn’t already strip it out. This time, the `awk` command
    does strip it out, but I’ve decided that I want to see it. To fix that, I’ll do
    this:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 刚才，我向你展示了如果你的 `awk` 命令没有自动去除头部行时，如何去除它。这次，`awk` 命令已经去除了它，但我决定还是要看到它。为了解决这个问题，我会这样做：
- en: '[PRE58]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Note here that I’m using two different methods of finding a pattern. The `$7
    ~ "pts"` portion finds all lines that contain the `pts` text string in field 7\.
    So, we see that `pts/0`, `pts/1`, and `pts/2` all match this search criterion.
    The `$1 == "USER"` portion is looking for an exact, whole-word match. To demonstrate,
    look at this `user.txt` file:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我正在使用两种不同的方法来查找模式。`$7 ~ "pts"` 部分会查找第 7 字段中包含 `pts` 文本字符串的所有行。因此，我们看到 `pts/0`、`pts/1`
    和 `pts/2` 都符合这个搜索条件。`$1 == "USER"` 部分则是在查找一个精确的、完整的单词匹配。为了演示这一点，请查看这个 `user.txt`
    文件：
- en: '[PRE59]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Using the `~` to search for all lines with `USER` in field 1 gives us this:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `~` 在第 1 字段中查找所有包含 `USER` 的行，我们得到如下结果：
- en: '[PRE60]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Replacing the `~` with `==` gives us this:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `~` 替换为 `==` 后，我们得到如下结果：
- en: '[PRE61]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: So you see that there is a big difference. Also, note that since I’m searching
    for a literal text string, I can surround the search term (`USER`) within either
    a pair of double quotes or a pair of forward slashes when using the ~. However,
    when using the `==`, you’ll need to use the double quotes, because using the double
    slashes shows you nothing.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以看到两者之间有很大的区别。另外，请注意，由于我在搜索一个字面文本字符串，因此在使用 `~` 时，我可以将搜索词（`USER`）放在一对双引号或一对斜杠内。但在使用
    `==` 时，你需要使用双引号，因为使用双斜杠什么也不会显示。
- en: And, with that bit of a digression out of the way, let’s get back to our regularly
    scheduled program.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 话题稍微有些跑题，回到我们的正题。
- en: 'I’ve now decided that I want to see all processes with a virtual memory size
    (`VSZ`) of more than 500,000 bytes. `VSZ` information is in field 5, so my `awk`
    command looks like this:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我现在决定查看所有虚拟内存大小（`VSZ`）超过 500,000 字节的进程。`VSZ` 信息在第 5 字段，因此我的 `awk` 命令看起来是这样的：
- en: '[PRE62]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'But, that’s more information than I really need. I just want to look at the
    relevant fields, and I’ve decided to place each field on its own line, along with
    a label. Here’s how I’ll do it:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 但这些信息对我来说其实有些多余。我只是想查看相关的字段，并决定将每个字段单独放在一行上，并加上标签。以下是我的做法：
- en: '[PRE63]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: As noted before, `NR > 1` prevents `ps` from printing the default header. In
    the action, the `print` command places a pair of tabs (`\t\t`) between `USER`,
    `PID`, `VSZ`, and their respective values. The `COMMAND` label is longer, so it
    only requires one tab (`\t`) between it and its values. This ensures that all
    values in the second column line up nice and neat. The newlines (`\n`) after the
    `USER`, `PID`, and `VSZ` values cause the next field to print on a new line. After
    the `COMMAND` value, I placed two newlines (`\n\n`) so that there would be a blank
    line between each record.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`NR > 1` 防止 `ps` 打印默认的标题。在动作部分，`print` 命令在 `USER`、`PID`、`VSZ` 及其相应值之间放置一对制表符（`\t\t`）。由于
    `COMMAND` 标签较长，因此它和其值之间只需要一个制表符（`\t`）。这确保了第二列的所有值整齐对齐。在 `USER`、`PID` 和 `VSZ` 的值后面的换行符（`\n`）使得下一个字段在新的一行上打印。`COMMAND`
    的值后面，我放置了两个换行符（`\n\n`），以确保每个记录之间有一个空白行。
- en: 'Next, let’s turn this command into a function that we can add to the `sysinfo.lib`
    function library that I showed you in *Chapter 10--Understanding Functions*. Our
    new `VSZ_info()` function looks like this:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们将这个命令转换成一个可以添加到我在*第10章—理解函数*中展示的 `sysinfo.lib` 函数库的函数。我们新的 `VSZ_info()`
    函数如下所示：
- en: '[PRE64]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Now, in the `system_info.sh` script that I also showed you in *Chapter 10*,
    you’ll need to add `$(VSZ_info)` to the end of the list of functions that the
    script calls. Now when you run the script, you’ll see the `VSZ` information at
    the end of the output file. (Both files are too long to reproduce here, but you
    can download them from GitHub.)
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我在*第10章*展示给你看的 `system_info.sh` 脚本中，你需要将 `$(VSZ_info)` 添加到脚本调用的函数列表的末尾。现在，当你运行脚本时，你会看到输出文件末尾的
    `VSZ` 信息。（两个文件太长，无法在这里展示，但你可以从 GitHub 下载它们。）
- en: Okay, that about wraps it up for the basics of using `awk` in shell scripts.
    Let’s summarize and move on.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，关于在 shell 脚本中使用`awk`的基础知识就讲到这里。让我们总结一下并继续。
- en: Summary
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, I introduced you to the sacred mysteries of using `awk`. We
    started by looking at the numerous implementations of `awk`, and at how a basic
    `awk` command is constructed. Next, we saw how to use `awk` to process information
    either from a text file or from another program. Then, we saw how to run `awk`
    commands from within a normal shell script. Finally, we turned an `awk` command
    into a function, and added it to our function library file.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我向你介绍了使用 `awk` 的神秘技巧。我们从研究 `awk` 的多个实现方式开始，并了解了基本 `awk` 命令的构建方式。接着，我们看到了如何使用
    `awk` 处理来自文本文件或其他程序的信息。然后，我们学习了如何在普通的 shell 脚本中运行 `awk` 命令。最后，我们将一个 `awk` 命令转化为函数，并将其添加到我们的函数库文件中。
- en: In the next chapter, we’ll look at how to create `awk` program scripts. I’ll
    see you there.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何创建 `awk` 程序脚本。到时候见。
- en: Questions
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the two parts of an `awk` command? (Choose two.)
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个 `awk` 命令有哪两个部分？（选择两个。）
- en: action
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: action
- en: expression
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: expression
- en: pattern
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: pattern
- en: command
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: command
- en: E. order
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: E. 顺序
- en: What does `{print $0}` do in an `awk` command?
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`{print $0}` 在 `awk` 命令中做什么？'
- en: It prints the name of the script that you’re running, because `$0` is the bash
    positional parameter that hold the name of the script.
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它打印你正在运行的脚本的名称，因为`$0`是保存脚本名称的 bash 位置参数。
- en: It prints the value that was assigned to the `0` variable.
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它打印分配给 `0` 变量的值。
- en: It prints all fields of a record.
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它打印记录的所有字段。
- en: It’s an invalid command that doesn’t do anything.
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个无效的命令，不会执行任何操作。
- en: You want to perform an exact, whole-word match for all lines that contain a
    certain text string. Which of the following `awk` operators would you use?
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想对所有包含某个特定文本字符串的行执行精确的全字匹配，以下哪种 `awk` 操作符适合使用？
- en: '`==`'
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`==`'
- en: '`=`'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`=`'
- en: '`eq`'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`eq`'
- en: '`~`'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`~`'
- en: Where is the best place to define values for `FS` and `OFS`?
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在哪里定义 `FS` 和 `OFS` 的值最合适？
- en: In the END section of an `awk` command.
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `awk` 命令的 END 部分。
- en: You can’t. They already have pre-defined values.
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不能。它们已经有了预定义的值。
- en: In the `BEGIN` section of an `awk` command.
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `awk` 命令的 `BEGIN` 部分。
- en: In the action of an `awk` command.
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `awk` 命令的动作部分。
- en: How do you use regular expressions with `awk`?
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在 `awk` 中使用正则表达式？
- en: Surround the regular expression with a pair of forward slashes.
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将正则表达式用一对斜杠括起来。
- en: Surround the regular expression with a pair of single quotes.
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将正则表达式用一对单引号括起来。
- en: Surround the regular expression with a pair of double quotes.
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将正则表达式用一对双引号括起来。
- en: Don’t surround the regular expression with anything.
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不要在正则表达式周围加上任何东西。
- en: Further Reading
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'The GNU awk Users’ Guide: [https://www.gnu.org/software/gawk/manual/gawk.html](https://www.gnu.org/software/gawk/manual/gawk.html)'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GNU awk 用户指南：[https://www.gnu.org/software/gawk/manual/gawk.html](https://www.gnu.org/software/gawk/manual/gawk.html)
- en: 'Awk by Example: [https://developer.ibm.com/tutorials/l-awk1/](https://developer.ibm.com/tutorials/l-awk1/)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《Awk 实例》：[https://developer.ibm.com/tutorials/l-awk1/](https://developer.ibm.com/tutorials/l-awk1/)
- en: 'awklang.org--The site for things related to the awk language: [http://www.awklang.org/](http://www.awklang.org/)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: awklang.org——关于 awk 语言的相关内容网站：[http://www.awklang.org/](http://www.awklang.org/)
- en: 'awk: One True awk: [https://github.com/onetrueawk/awk](https://github.com/onetrueawk/awk)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'awk: One True awk：[https://github.com/onetrueawk/awk](https://github.com/onetrueawk/awk)'
- en: 'Awk Scripts YouTube channel: [https://www.youtube.com/@awkscripts](mailto:https://www.youtube.com/@awkscripts)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Awk Scripts YouTube 频道：[https://www.youtube.com/@awkscripts](mailto:https://www.youtube.com/@awkscripts)
- en: 'Miller Documentation: [https://miller.readthedocs.io/en/latest/](https://miller.readthedocs.io/en/latest/)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miller 文档：[https://miller.readthedocs.io/en/latest/](https://miller.readthedocs.io/en/latest/)
- en: 'The GAWK Manual-Useful “One-liners”: [http://web.mit.edu/gnu/doc/html/gawk_7.html](http://web.mit.edu/gnu/doc/html/gawk_7.html)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《GAWK 手册 - 有用的“一行代码”》：[http://web.mit.edu/gnu/doc/html/gawk_7.html](http://web.mit.edu/gnu/doc/html/gawk_7.html)
- en: 'How to Use awk in Bash Scripting: [https://www.cyberciti.biz/faq/bash-scripting-using-awk/](https://www.cyberciti.biz/faq/bash-scripting-using-awk/)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Bash 脚本中使用 awk：[https://www.cyberciti.biz/faq/bash-scripting-using-awk/](https://www.cyberciti.biz/faq/bash-scripting-using-awk/)
- en: 'Advanced Bash Shell Scripting Guide-Shell Wrappers: [https://www.linuxtopia.org/online_books/advanced_bash_scripting_guide/wrapper.html](https://www.linuxtopia.org/online_books/advanced_bash_scripting_guide/wrapper.html)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《高级 Bash Shell 脚本指南 - Shell 包装器》：[https://www.linuxtopia.org/online_books/advanced_bash_scripting_guide/wrapper.html](https://www.linuxtopia.org/online_books/advanced_bash_scripting_guide/wrapper.html)
- en: 'Awk: The Power and Promise of a 40-year-old Language: [https://www.fosslife.org/awk-power-and-promise-40-year-old-language](https://www.fosslife.org/awk-power-and-promise-40-year-old-language)'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Awk：一个 40 年历史语言的力量与前景：[https://www.fosslife.org/awk-power-and-promise-40-year-old-language](https://www.fosslife.org/awk-power-and-promise-40-year-old-language)
- en: Answers
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回答
- en: a and c
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: a 和 c
- en: c
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: c
- en: a
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: a
- en: c
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: c
- en: a
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: a
- en: Join our community on Discord!
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区！
- en: Read this book alongside other users, Linux experts, and the author himself.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他用户、Linux 专家及作者本人一起阅读本书。
- en: Ask questions, provide solutions to other readers, chat with the author via
    Ask Me Anything sessions, and much more. Scan the QR code or visit the link to
    join the community.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 提问、为其他读者提供解决方案、通过“问我任何问题”环节与作者互动，更多精彩内容尽在其中。扫描二维码或访问链接加入社区。
- en: '[https://packt.link/SecNet](https://packt.link/SecNet)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/SecNet](https://packt.link/SecNet)'
- en: '![](img/QR_Code10596186092701843.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code10596186092701843.png)'
- en: Leave a Review!
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 留下您的评论！
- en: Thank you for purchasing this book from Packt Publishing—we hope you enjoy it!
    Your feedback is invaluable and helps us improve and grow. Once you've completed
    reading it, please take a moment to leave an Amazon review; it will only take
    a minute, but it makes a big difference for readers like you.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您从 Packt 出版社购买此书——希望您喜欢它！您的反馈对我们非常宝贵，帮助我们改进和成长。完成阅读后，请花一点时间在亚马逊上留下评价；这仅需一分钟，但对像您这样的读者来说意义重大。
- en: Scan the QR code below to receive a free ebook of your choice.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描下面的二维码，领取您选择的免费电子书。
- en: '[https://packt.link/NzOWQ](https://packt.link/NzOWQ)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/NzOWQ](https://packt.link/NzOWQ)'
- en: '![](img/review.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/review.png)'
