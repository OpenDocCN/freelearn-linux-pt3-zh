<html><head></head><body>
<div id="sbo-rt-content"><div class="Basic-Text-Frame" id="_idContainer272">
<h1 class="chapterNumber">19</h1>
<h1 class="chapterTitle" id="_idParaDest-243">Deploying Ubuntu in the Cloud</h1>
<p class="normal">Up until now, in each chapter, we’ve been working with an instance of Ubuntu installed on either a local virtual machine, a physical computer or server, or even a Raspberry Pi. We’ve learned how to deploy Ubuntu on such devices, and we’ve even gone as far as deploying virtual machines as well as containers. These on-premises devices have served us well, but the concept of cloud computing has become quite popular, even more so since the previous edition of this book. In this chapter, we’re going to take a look at running Ubuntu in the cloud. Specifically, we’ll deploy an Ubuntu instance on <strong class="keyWord">Amazon Web Services</strong> (<strong class="keyWord">AWS</strong>), which is a very popular platform for cloud computing. While we won’t go into extreme detail on AWS (it’s an extremely large and complex platform), you’ll definitely get a feel for what it’s like to deploy resources in the cloud, which will be more than enough to get you started.</p>
<p class="normal">This exploration will involve the following topics:</p>
<ul>
<li class="bulletList">Understanding the difference between on-premises and cloud infrastructure</li>
<li class="bulletList">Important considerations when considering cloud computing as a potential solution</li>
<li class="bulletList">Becoming familiar with some basic AWS concepts</li>
<li class="bulletList">Creating an AWS account</li>
<li class="bulletList">Choosing a region</li>
<li class="bulletList">Deploying Ubuntu as an AWS EC2 instance</li>
<li class="bulletList">Creating and deploying Ubuntu AMIs</li>
<li class="bulletList">Automatically scaling Ubuntu EC2 deployments with Auto Scaling</li>
<li class="bulletList">Keeping costs down: understanding how to save money and make cost-effective decisions</li>
<li class="bulletList">Taking the cloud further: additional resources to grow your knowledge</li>
</ul>
<p class="normal">Since cloud computing is something of a different mindset than we’re used to, we’ll first go through a few sections that are dedicated to helping us understand the difference, as well as some of the considerations we should make before choosing to implement Ubuntu in the cloud. In the next section, we’ll explore how the concept of cloud computing differs from on-premises hardware.</p>
<h1 class="heading-1" id="_idParaDest-244">Understanding the difference between on-premises and cloud infrastructure</h1>
<p class="normal">As mentioned<a id="_idIndexMarker1027"/> at the very beginning <a id="_idIndexMarker1028"/>of this chapter, we’ve been solely utilizing on-premises Ubuntu installations thus far. Even if we’re running Ubuntu on a virtual machine in our data center, it’s still considered an on-premises installation even when it’s not on physical hardware. In short, an on-premises installation is something that resides locally with us, regardless of the type of server that serves as the foundation.</p>
<p class="normal">The first difference when it comes to cloud computing might be somewhat obvious: it’s the exact opposite of a resource being on-premises. With a cloud instance of Ubuntu, it’s someone else’s hardware that it runs on. Most of the time, we won’t know what kind of server a cloud instance is running on—when we subscribe to the services of a cloud provider and pay a fee to run a server on that platform, we’re able to access the operating system just like we would a virtual machine, with little knowledge of the underlying data center. Although utilizing a cloud instance will have some sort of recurring cost, we don’t need to worry about monitoring hardware components or replacing failed physical devices. With the cloud, that becomes someone else’s problem.</p>
<p class="normal">There are various cloud providers <a id="_idIndexMarker1029"/>you can<a id="_idIndexMarker1030"/> choose<a id="_idIndexMarker1031"/> from, with <strong class="keyWord">AWS</strong>, <strong class="keyWord">Google Cloud Platform</strong> (<strong class="keyWord">GCP</strong>), and <strong class="keyWord">Microsoft Azure</strong> being popular choices. Those are three very popular platforms. Each of them has its own strengths and weaknesses, and even some differentiation as far as how resources on the platform are managed. For the most part, there’s no right or wrong choice here, it’s important to research each of the platforms and make the appropriate decision for you and your organization.</p>
<p class="normal">In addition to cloud <a id="_idIndexMarker1032"/>providers, there are also <strong class="keyWord">Virtual Private Server</strong> (<strong class="keyWord">VPS</strong>) providers. There used to be more of a distinction between a full cloud provider and a VPS provider – but as time goes on, the line between the two types of platforms is becoming increasingly thin. For the most part, VPS providers are lighter or “simpler” alternatives to standard cloud providers. They provide the same core features, such as allowing you to build virtual machines – but they don’t usually offer as many features as full cloud providers do. Nowadays, VPS providers are rolling out new features regularly and are catching up to cloud providers in terms of features. Examples of popular VPS <a id="_idIndexMarker1033"/>providers <a id="_idIndexMarker1034"/>include <strong class="keyWord">DigitalOcean</strong> and <strong class="keyWord">Linode</strong>, among others. In fact, even Amazon themselves have gotten into the VPS business, offering a VPS alternative to their own <a id="_idIndexMarker1035"/>platform, called <strong class="keyWord">Amazon Lightsail</strong>.</p>
<p class="normal">For your organization, which should you choose between a full cloud provider and VPS provider? Many <a id="_idIndexMarker1036"/>administrators would answer <a id="_idIndexMarker1037"/>this question without hesitation and recommend a full cloud provider. I can certainly see their point – why go with a “lighter” platform when you can use a solution that has all the bells and whistles? However, based on my experience with many organizations, I wouldn’t recommend going with a full cloud provider without first finding out if a VPS provider has all the features you need. The reason for this is that one of the trade-offs of having more features is that complexity increases. With an increase in complexity comes a larger responsibility to manage resources on that platform. And that complexity can create a very large administration overhead. For that reason, I don’t recommend full cloud providers like AWS or Azure to small organizations with limited IT staff. For those organizations, VPS providers would be best as the burden of administration is lower. Larger organizations with a team of administrators should have no problem tackling something like AWS.</p>
<p class="normal">As I mentioned, we’ll be going over AWS in this chapter. Even if you’re not considering migrating resources to the cloud, it’s something that’s still worth practicing. If nothing else, you’ll gain some familiarity with another platform, which will increase your skillset and marketability. And I don’t know about you, but speaking for myself, I really enjoy checking out technologies and learning something new.</p>
<p class="normal">However, perhaps I’m getting ahead of myself. Before you migrate anything to the cloud, the most important question to ask right now is whether or not creating cloud resources is appropriate for your goals. That’s exactly what we’ll explore in the next section. We’ll also explore some of the differences in mindset when it comes to cloud computing as well.</p>
<h1 class="heading-1" id="_idParaDest-245">Important considerations when considering cloud computing as a potential solution</h1>
<p class="normal">Before choosing<a id="_idIndexMarker1038"/> to sign up with a provider, it’s important to first make sure that creating cloud resources is a good idea for you or your organization in the first place. Often, IT professionals can get so excited when it comes to a new trend that they may make the mistake of trying to use such a service even when it doesn’t make sense to do so. Above all, as an administrator, it’s important to utilize the best tool available for whatever it is that you wish to accomplish, instead of using a technology just because you’re excited about it. Cloud computing is awesome for sure, but for some use cases, it’s just not a good fit. This is similar to containers as well: containerization is an exciting technology but some applications just don’t run well on that platform. It takes trial and error.</p>
<p class="normal">There are some considerable benefits when it comes to cloud computing. When it comes to physical servers, the hardware will fail eventually. It’s not a matter of “if” but “when.” All hardware <em class="italic">will</em> fail eventually. And even if you have hardware that doesn’t end up failing in the short term and lasts for a long time, it will be made obsolete by more powerful hardware that is more efficient. When it comes to managing physical servers, you’ll need to replace the hardware eventually.</p>
<p class="normal">This is also true when it comes to cloud computing; the hardware such services run on will need to be replaced whenever it fails or becomes obsolete (whichever happens first). The difference is that when that happens, the liability on you (the administrator) is greatly reduced. You won’t have to order a new server, replace parts, or even pay attention to the hardware at all. It’s solely the responsibility of the cloud service or VPS provider to keep track of that. A virtual machine you run on a cloud platform could be running on a physical server that’s a couple of years old, and then tomorrow be moved to a brand-new piece of hardware. And you might not even be aware that it was ever moved.</p>
<p class="normal">The trade-off, though, is potentially the cost. The reason why I mention cost as a “potential” trade-off is that whether or not it’s cheaper for your organization to purchase physical servers or pay a monthly fee for servers in the cloud comes down to which offers a <a id="_idIndexMarker1039"/>better <strong class="keyWord">Return on Investment</strong> (<strong class="keyWord">ROI</strong>). To better understand this, consider an organization that utilizes only on-premises hardware for their data center with no cloud resources being used at all. Let’s also assume that every 3 years or so, they have to replace some of the more critical servers with newer hardware; and every 5-10 years the less-important servers are replaced. There’s also a need to pay for full-time administrators with specialties in managing physical hardware, as well as maintaining a cooling system and making sure a room is available to designate as a data center. Also, consider the electric bill for running your own data center. Add all of this up—how much is it costing the organization on average?</p>
<p class="normal">With physical infrastructure, you’re paying an up-front cost to purchase servers every time you need to do so. With cloud computing, you never have to purchase physical server hardware, but instead you’re paying a fee each and every month for the privilege of utilizing cloud infrastructure. When you add up the monthly costs for cloud resources, how much would that cost the organization? Would it cost more than running physical hardware or less?</p>
<p class="normal">Often, whether or not running a server in the cloud results in cost savings (or ends up being cost prohibitive) comes down to what types of services you wish to use on that platform. Running more virtual machines in the cloud is generally fairly inexpensive, and might often result in cost savings when compared to running physical infrastructure of your own. However, an example of something that might end up being cost prohibitive in the cloud is storage.</p>
<p class="normal">If your organization<a id="_idIndexMarker1040"/> doesn’t store much data, then storage costs won’t really be a concern. Many companies are perfectly satisfied with employees utilizing something like Google Drive for shared storage and won’t even need cloud storage at all. Some organizations, especially those that develop software, have <em class="italic">massive</em> storage needs. For these companies, there could be tens or even hundreds of terabytes of data being stored, as well as the bandwidth costs for the data going in and out of the company. If you were to attempt to migrate such a large amount of data to a cloud server provider, you wouldn’t have to manage the storage hardware anymore, but your costs for cloud storage would go up dramatically and might easily be much more expensive than it costs you to continue to use physical hardware. Personally, I’ve seen storage costs result in tens of thousands of dollars extra in monthly billing.</p>
<p class="normal">Another consideration is stability. It’s often argued that utilizing a cloud provider will result in a more stable infrastructure. That mindset seems to make sense at first, considering that by using a cloud provider you’re no longer responsible for managing the hardware. There’s definitely some truth to the claim that cloud resources are more stable, but it’s not quite that simple. Cloud providers <em class="italic">do</em> experience downtime, and it happens more often than you’d think.</p>
<p class="normal">Cloud providers will often advertise a high level of uptime, often measured in “9s.” For example, AWS offers a general uptime of 99.999%, as of the date this book is being prepared for publishing. That sounds great, doesn’t it? Before you get too excited about a cloud provider’s uptime claim, it’s important to also know what exactly they count as part of that uptime. If an upstream provider, such as a backend internet resource, goes down and service is completely unavailable, they may not count that and continue to claim the same amount of uptime. Massive outages of cloud providers are not uncommon; in 2017, Amazon’s S3 service suffered a major outage due to one of their engineers mistyping a command. In that situation, many services on the internet were unavailable to customers. So while it is true that a cloud service provider is less likely to suffer an outage than you are to witness hardware failures, it’s important to keep in mind that outages are still possible. We can’t ever assume any service (our own or otherwise) is bulletproof.</p>
<p class="normal">Automation is a very important consideration with the cloud. If your resources encounter an issue, it’s a really good idea to have an automated means of re-deploying your important services. On a physical server, you can set it up exactly as you want it and take an image of the<a id="_idIndexMarker1041"/> hard drive in case the server fails. Cloud providers offer you essentially the same service, giving you the ability to create images of your important servers so you can redeploy them in the future should you need to do so. </p>
<p class="normal">If you do go with a cloud provider, make sure you keep regular backups as well as images. And be sure to keep a copy of at least the most recent backups locally outside of the cloud provider, because if the cloud provider itself goes down then you also lose the backup. I can probably better summarize this by advising you to not become over-confident in the stability of your cloud provider. Always assume your infrastructure will fail eventually, regardless of where it’s located or how stable their marketing team claims it is.</p>
<p class="normal">The warnings I have given around the stability of cloud providers are not intended to scare you away from using them, but instead to steer you toward maintaining good hygiene with the cloud, just as you would with physical infrastructure. Basically, to be successful when it comes to managing servers, you’ll have to assume that cloud providers can fail just as easily as on-premises equipment, and make sure you’re well prepared if there is ever an issue. Cloud providers actually provide you with all the tools you need in order to build a stable infrastructure that’s easily reproducible and recoverable. If you utilize those tools effectively, you shouldn’t have anything to worry about. We’ll explore these concepts further as we go along, but you can go as far as to have cloud servers recover <em class="italic">themselves</em> when a problem occurs. It all depends on how you architect your solution.</p>
<div class="note">
<p class="normal">It’s also important that you understand any company policies (and laws) that may exist regarding data retention, what type of information is allowed to be stored within the cloud, or any other rule or regulation that might be in place in your area. (GDPR is a great example of legal requirements.) If in doubt, consulting with your company’s management, security, and human resources teams would be a great place to start when it comes to what data-related policies and laws may be applicable while you design your cloud solution.</p>
</div>
<p class="normal">In the next <a id="_idIndexMarker1042"/>section, we’re going to explore some concepts specific to AWS, so we’ll have a stronger foundation of knowledge to use for building an actual cloud solution later on in this chapter.</p>
<h1 class="heading-1" id="_idParaDest-246">Becoming familiar with some basic AWS concepts</h1>
<p class="normal">As discussed earlier, AWS is<a id="_idIndexMarker1043"/> one of several competing cloud service providers. For the purpose of this chapter, AWS was chosen because more than any other provider, the platform requires an administrator to adopt a completely different mindset when it comes to managing infrastructure. This different mindset is a healthy one even outside of AWS, so it represents a logical evolution at this point in our journey.</p>
<p class="normal">Up until now, we’ve discussed server installations as essentially pets, meaning we want to keep them around, make sure they’re healthy, and if something goes wrong, try to fix it. We want to keep our servers operational for as long as possible. We want to be able to rely on them, and that helps our organization - customers and clients appreciate using a website or service that is stable, with minimal or no downtime.</p>
<p class="normal">That last part, minimal downtime, doesn’t change regardless of the mindset we use when managing our infrastructure. Downtime and service disruption is bad in this industry, and that’s always going to be the case. The difference is what we do about it, and how we go about recovering from it. In fact, we can even try our best to automatically recover when we have a problem. If the customer never notices there was ever an issue, even better.</p>
<p class="normal">With AWS, the mindset is different – we consider our servers as disposable, not as pets. This may seem a bit surprising at first, but if we effectively use the tools we’re provided, we can build an infrastructure that is scalable. This concept in particular is known as <strong class="keyWord">Auto Scaling</strong> and is a very important aspect of AWS. With Auto Scaling, resources are automatically created and destroyed as demand increases and decreases. For example, let’s say that your web server receives more visitors than normal, and its CPU is starting to max out. Auto Scaling would then bring up a new web server automatically, and with a load balancer, route clients between instances as needed to spread the load. You can set the maximum number of instances that can be brought online, and then when the load decreases, the servers that were brought online to handle the load will automatically get deleted. This means that you can architect your cloud solution such that you’ll have the exact number of servers in existence as you need at any given time.</p>
<p class="normal">Another level above Auto Scaling is <strong class="keyWord">Auto healing</strong>. Just as the name implies, auto healing means that if your server runs into a problem, it will automatically be “healed,” and in the case of cloud computing, this means the instance will be disposed of and recreated from a known good image or template. This is the ultimate goal of AWS (or pretty much any implementation): to have infrastructure that is not only scalable but also able to recover by itself. For <a id="_idIndexMarker1044"/>example, perhaps you have a pair of web servers that handle requests from clients. One of them encounters some sort of issue and fails some sort of test that would imply that the server is unreliable. Such a test is known as a <strong class="keyWord">health check</strong>. With auto healing, a server that fails health checks is considered unhealthy and is deleted. With Auto Scaling, you also set a minimum number of servers for your application. If the number of servers falls below the minimum, then a new one is created to replace it. Depending on how you architect your solution, the customer may notice some degradation if the application is running on fewer servers, but that’s only temporary. Everything will return back to normal when the new server comes online.</p>
<p class="normal">With AWS, Auto Scaling and auto healing are extremely important. I’ve seen many administrators make the mistake of not utilizing those features of the platform, and that should never be the case. Without such high-availability features, you risk having your server go away at any moment. This may be a bigger problem than you think. AWS consists of physical servers all over the world, and just like any other physical server, hardware failures are not only possible but happen regularly. If your application is running on a physical host within an AWS data center that encounters a hardware failure, your server may get deleted when they go and replace it. With Auto Scaling, this isn’t a problem. A new virtual server will be brought online to replace the one that was removed.</p>
<p class="normal">But without Auto Scaling, this can result in manually having to rebuild your server. Don’t worry though, we’ll cover Auto Scaling in this very chapter, so you’ll definitely understand how to implement it before we’re done.</p>
<p class="normal">The concepts around high availability are not limited to AWS. Similar features exist on other cloud platforms as well. The main difference between competing cloud providers is the marketing terms they use for these features, but you can set up similar infrastructure on each. With AWS, they really focus on this aspect though, so it’s important to learn. But even if you’re not utilizing AWS in production at your organization, the concepts around being able to easily recover from disasters are still important and can still be implemented. If nothing else, you should at least consider implementing automation for rebuilding servers so you don’t have to do so much manual work if a problem occurs.</p>
<p class="normal">Back to AWS: there are many services within the platform that you can use that will provide a variety of features. In fact, there are well over a hundred different services within the platform. Therefore, it’s impossible for us to cover each in this chapter. It would be difficult to cover every service even in a book dedicated only to AWS. But don’t let the number of services overwhelm you; you’ll only need to learn about the services that are related to what you’re trying to achieve with the platform. For example, if your organization doesn’t develop multiplayer computer games, then learning the GameLift service will be of no benefit to you at all. In this chapter, we’ll focus on the services required<a id="_idIndexMarker1045"/> to get you up and running with a basic web server running in the cloud. The following services and terms will be discussed:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Virtual Private Cloud</strong> (<strong class="keyWord">VPC</strong>): A VPC is a higher-level abstraction of your overall <a id="_idIndexMarker1046"/>cloud network and resources. Each of the servers and related services you provision will fit within a VPC. You can think of a VPC as your overall network. In your organization, you may have various routers, gateways, firewalls, virtual machines, printers, or other network-connected devices. Your organization’s network is essentially a VPC in AWS, a software version of a complete network.</li>
<li class="bulletList"><strong class="keyWord">Elastic Compute Cloud</strong> (<strong class="keyWord">EC2</strong>): EC2 is<a id="_idIndexMarker1047"/> the service within AWS that your virtual machines will run in. Individual virtual machines within AWS are referred to as EC2 instances. You can think of this service as the AWS equivalent of VMware ESXi, Microsoft Hyper-V, Proxmox, or whatever virtual machine platform you’re more familiar with. EC2 instances, just like a virtual machine, have memory and CPU allocated to them and run an operating system. We’ll run Ubuntu in an EC2 instance before the<a id="_idIndexMarker1048"/> end of the chapter.</li>
<li class="bulletList"><strong class="keyWord">Elastic Block Store</strong> (<strong class="keyWord">EBS</strong>): As you learn more about AWS, you’ll notice that even the <a id="_idIndexMarker1049"/>simplest component seems to have a marketing buzzword attached. EBS provides block storage, essentially the same type of storage we’ve been working with all along. So in a nutshell, an EBS volume is a hard disk. When you create an EC2 instance, the operating system for your server will run from an EBS volume, and you can set the size of the volume accordingly. We’ll work through this later in the chapter.</li>
<li class="bulletList"><strong class="keyWord">Elastic Load Balancer</strong> (<strong class="keyWord">ELB</strong>): As you may be able to guess from the name, an ELB is the AWS<a id="_idIndexMarker1050"/> equivalent of a load balancer and offers similar features. This allows you to have multiple EC2 instances serving your application, and you can create an ELB to route traffic between them. ELB is actually a feature of EC2 and not its own service.</li>
<li class="bulletList"><strong class="keyWord">Identity and Access Management</strong> (<strong class="keyWord">IAM</strong>): IAM is the tool within AWS that you’ll use to <a id="_idIndexMarker1051"/>create and manage user accounts, determine user permissions, and even create API keys that can be used to programmatically access and manage AWS. Basically, it’s your one-stop shop for all things related to user privileges, regardless of whether the “user” is a human or a script.</li>
<li class="bulletList"><strong class="keyWord">Route 53</strong>: Although<a id="_idIndexMarker1052"/> we’re not going to cover Route 53 in this book, I recommend at least understanding what it is in case you need it in the future. If you do<a id="_idIndexMarker1053"/> decide to utilize AWS in production, Route 53 will simplify the process of managing DNS entries and also registering new domain names. If your organization is a managed service provider, you may find yourself using this quite a bit.</li>
<li class="bulletList"><strong class="keyWord">Simple Storage Service</strong> (<strong class="keyWord">S3</strong>): Amazon’s S3 service is another offering we’re not going to <a id="_idIndexMarker1054"/>cover in this chapter, but it’s a good idea to know that it exists and what it’s for, in case you find a use for it later. S3 is actually a very popular service, and it<a id="_idIndexMarker1055"/> provides <strong class="keyWord">object storage</strong>. 
    <p class="normal">Object storage is a new type of storage that is different than a disk (virtual or physical) that you add to your server, format, and mount. While you can still mount S3 on your server, it doesn’t have a filesystem (such as ext4 or STON), nor does it understand permissions. It’s simply a name-object pair, where you store files, and they have a name. With S3, you create “buckets,” and each bucket can have files stored inside. Each bucket name must be unique. S3 is very useful if you want to make downloadable files available to your clients or store backup files.</p></li>
</ul>
<ul>
<li class="bulletList"><strong class="keyWord">Elastic Kubernetes</strong> <strong class="keyWord">Service</strong> (<strong class="keyWord">EKS</strong>): In the previous chapter, we covered Kubernetes <a id="_idIndexMarker1056"/>and even set up our own cluster. AWS has its own Kubernetes solution, called <strong class="keyWord">EKS</strong>. Although we’re not going to cover it in this book, it’s worth considering if you want to continue to use Kubernetes and have your containers running in a managed service, rather than managing your own cluster. EKS combines Kubernetes with the flexibility of the AWS platform, so it’s a very useful service to consider.</li>
<li class="bulletList"><strong class="keyWord">Security groups</strong>: Access<a id="_idIndexMarker1057"/> to many AWS resources from the public internet is disabled by default; security groups are used to determine what is able to access a resource within AWS, and you can allow or disallow access by IP address as well as port. With regard to EC2 instances, outbound access is allowed by default, but every port is blocked inbound. You can create a security group that allows specific IPs to access the instance, which increases security. We’ll see an example of this later.</li>
</ul>
<p class="normal">Now that we have<a id="_idIndexMarker1058"/> some basic understanding out of the way, we can get started and build an application in the cloud, running on AWS.</p>
<h1 class="heading-1" id="_idParaDest-247">Creating an AWS account</h1>
<p class="normal">As mentioned in the<a id="_idIndexMarker1059"/> previous section, a VPC within AWS represents a high-level abstraction of your overall network. All of the resources that we create will run inside a VPC. Therefore, we’ll need to create a VPC first before we can create an EC2 instance and deploy Ubuntu.</p>
<p class="normal">Before we can create a VPC though, we’ll need an AWS account. Before this chapter, I typically advised you to use whatever hardware you have available in order to create Ubuntu installations to work with the platform. This time, we’re going to utilize an actual cloud provider, which comes at a cost. While there are free components available for a limited time with a new account, it’s up to you, the reader, to keep track of billing. We’ll discuss costs in greater detail later in this chapter. But as a general rule of thumb for now, always use whatever the cheapest option is. If a free instance type is available, go with that. Of course, if you’re intending to deploy actual resources for production use within an organization, then you’ll want to choose whatever instance type is appropriate for the use case. For our purposes, we’re just learning the platform for the first time, so be sure to go with the lowest-cost resources available and delete everything when you’re done.</p>
<p class="normal">That last point is especially important – the free tier is not unlimited, and if you forget to delete something, you might receive a bill at some point. What I recommend is to keep a running list of everything you create in AWS, so you have a list of things to delete if you don’t wish to continue using the platform. </p>
<p class="normal">You should also remove any snapshots/storage volumes, or anything else that you end up creating. Better yet, if you aren’t going to use the AWS account in production, you can simply delete the account so that it doesn’t <a id="_idIndexMarker1060"/>continue to bill you. If ever in doubt, be sure to consult the documentation for billing within AWS itself.</p>
<h2 class="heading-2" id="_idParaDest-248">Signing up for AWS</h2>
<p class="normal">Now it’s time for <a id="_idIndexMarker1061"/>us to create our own AWS account. In this section (and in each of the remaining sections of this chapter) I’ll walk you through each step when it comes to navigating AWS. It’s important to keep in mind that the <strong class="keyWord">AWS Management Console</strong> that <a id="_idIndexMarker1062"/>we’ll be navigating has a history of changing quite often. In fact, the console has changed no fewer than twice since the previous edition of this book was written, and that’s not even counting the fact that in the third edition, the interface changed in the middle of writing the previous version of this chapter. The screenshots and walkthrough are accurate as of the time this chapter has been written, but it’s always possible (and quite likely) that the interface will be updated <em class="italic">again</em> at some point. That said, if the screenshots or layout have changed, you should still be able to follow the instructions here since the verbiage generally doesn’t typically change, just the layout. With that said, let’s get started.</p>
<p class="normal">To begin, navigate to <a href="https://aws.amazon.com"><span class="url">https://aws.amazon.com</span></a> and you should see an orange button in the upper-right corner with the label <strong class="keyWord">Create an AWS Account</strong>. It’s possible that the layout of the page may change after publication, but you should see a button to create a new account somewhere on the page:</p>
<figure class="mediaobject"><img alt="" height="439" src="../Images/B18425_19_01.png" width="877"/></figure>
<p class="packt_figref">Figure 19.1: The AWS main page</p>
<p class="normal">When you click the <a id="_idIndexMarker1063"/>button to create a new account, a form will appear asking you for basic information. An example of some of the fields you may be asked for is shown in <em class="italic">Figure 19.2</em>, though the exact information you may be asked for may vary. Fill out each field accordingly, then click <strong class="screenText">Continue</strong>:</p>
<figure class="mediaobject"><img alt="" height="635" src="../Images/B18425_19_02.png" width="875"/></figure>
<p class="packt_figref">Figure 19.2: Signing up for a new AWS account</p>
<p class="normal">After you click <strong class="screenText">Continue</strong>, another<a id="_idIndexMarker1064"/> screen will appear asking you to fill out additional fields, such as your full name, company name, address, and so on. This process will also include asking you to provide credit card details as well, so proceed through each screen and enter the required information. At the end of the process, you’ll see a selection where you can choose your support plan:</p>
<figure class="mediaobject"><img alt="" height="623" src="../Images/B18425_19_03.png" width="884"/></figure>
<p class="packt_figref">Figure 19.3: Choosing a support plan while signing up for an AWS account</p>
<p class="normal">If you are asked to <a id="_idIndexMarker1065"/>select a support plan during the process, choose the one that makes sense for your use case. If you’re going to be using AWS to create production instances for your organization, the Developer or Business plan may offer additional value to you. If you’re only going through the process to learn AWS and work through the examples in this chapter, choose the Basic plan.</p>
<p class="normal">Once you’ve finished the process of creating your new account, it may take some time before your new account is ready. When it is, you should receive an e-mail saying that it’s ready for use. After you do receive that e-mail, you’ll be able to log in. To do so, navigate to <a href="https://aws.amazon.com"><span class="url">https://aws.amazon.com</span></a> and click the <strong class="screenText">Sign In to the Console</strong> button, which will bring you to another page where you can type in your account login info:</p>
<figure class="mediaobject"><img alt="" height="789" src="../Images/B18425_19_04.png" width="552"/></figure>
<p class="packt_figref">Figure 19.4: Signing in as Root user</p>
<p class="normal">Here, you have a <a id="_idIndexMarker1066"/>choice to log in as the root user or an IAM user. We haven’t created any IAM users yet, so we only have a root user at this point. The root user is accessed by signing in with the same e-mail address that you’ve provided during the sign-up process. Enter that e-mail address in the prompt, click <strong class="screenText">Next</strong>, then enter your password on the next screen.</p>
<p class="normal">If all goes well, you should be logged in and see the <strong class="screenText">AWS Management Console</strong>:</p>
<figure class="mediaobject"><img alt="" height="499" src="../Images/B18425_19_05.png" width="878"/></figure>
<p class="packt_figref">Figure 19.5: The AWS Management Console main screen</p>
<p class="normal">Now that you have<a id="_idIndexMarker1067"/> access to the management console, you can begin using AWS. Before we start creating cloud resources, we should implement some basic security to protect our account.</p>
<h2 class="heading-2" id="_idParaDest-249">Implementing basic user security</h2>
<p class="normal">Before we<a id="_idIndexMarker1068"/> continue any further, there are some very important security best practices we should employ regarding the ability to authenticate to our AWS account. Although it’s very likely that our new account was created as a test account for following along with examples in this chapter, we should make it a habit to always protect our AWS account, regardless of how important it actually is.</p>
<p class="normal">We can begin with protecting the root account, as it’s a common target for hackers. Specifically, we should enable two-factor authentication for this account. Doing so will make it much harder for an outside threat to access it, since they would need access to your second factor in addition to your password. Since we’re already logged in as the root user at this point, we can set this up immediately.</p>
<p class="normal">In the management console, you’ll see a search field near the top of the screen. If you already know the name of the service you would like to configure, you can begin typing its name in the search field, and if your query matches an available service, it will show it in the list. If you don’t know the name of the service you’d like to use, you can click on <strong class="screenText">Services</strong> in the top-left corner of the console, to see a complete list of the services available. </p>
<p class="normal">For setting up second-factor authentication, we will access the IAM service. You can start typing <code class="inlineCode">IAM</code> into the search field, and it should show it as an available option. Go ahead and <a id="_idIndexMarker1069"/>click on it:</p>
<figure class="mediaobject"><img alt="" height="500" src="../Images/B18425_19_06.png" width="878"/></figure>
<p class="packt_figref">Figure 19.6: Using search within the AWS Management Console to locate the IAM service</p>
<p class="normal">When the IAM dashboard appears, you may see a security alert that complains about the root user not <a id="_idIndexMarker1070"/>having <strong class="keyWord">Multi-Factor Authentication</strong> (<strong class="keyWord">MFA</strong>) enabled. Although enabling this feature is optional, I recommend you enable it.</p>
<p class="normal">MFA is critical for ensuring the security of any account that is important to your organization, especially an account for a cloud computing provider such as AWS. MFA will enhance the security of the account in terms of authentication, requiring an additional factor before a user will be able to access the account. The root account is the most critical account to protect in AWS, since it has full access to every available service. To enable MFA, click on the button that reads <strong class="screenText">Add MFA</strong> (or similar verbiage if the layout on this page changes):</p>
<figure class="mediaobject"><img alt="" height="253" src="../Images/B18425_19_07.png" width="827"/></figure>
<p class="packt_figref">Figure 19.7: IAM dashboard, with an alert that MFA is recommended to be set up</p>
<p class="normal">Next, click on <strong class="screenText">MFA</strong> to <a id="_idIndexMarker1071"/>expand it (if it isn’t already), and then click on the <strong class="screenText">Activate MFA</strong> button:</p>
<figure class="mediaobject"><img alt="" height="121" src="../Images/B18425_19_08.png" width="877"/></figure>
<p class="packt_figref">Figure 19.8: Setting up MFA (continued)</p>
<p class="normal">The next screen will give you a choice of which type of device to use to facilitate MFA. The<a id="_idIndexMarker1072"/> default (<strong class="keyWord">Virtual MFA device</strong>) is a good one to go with if you don’t have a physical hardware key, such as a YubiKey. If you have no other preference, choose the <strong class="screenText">Virtual MFA device</strong> option and click <strong class="screenText">Continue</strong>:</p>
<figure class="mediaobject"><img alt="" height="449" src="../Images/B18425_19_09.png" width="775"/></figure>
<p class="packt_figref">Figure 19.9: Choosing a type of MFA device to set up</p>
<p class="normal">To set up your virtual MFA device, you’ll need to download a second-factor application to serve this <a id="_idIndexMarker1073"/>purpose. Google Authenticator is a popular choice here, but I recommend Authy instead. Both are perfectly acceptable, but Authy also features a desktop app you can use, as well as the ability to recover your account if your primary device is not accessible for any reason. Authy is compatible with Google Authenticator, so you can typically use it with services that offer a Google Authenticator option. To continue, reveal the QR code, scan it with your phone app, and then type in two subsequent values generated by the app.</p>
<p class="normal">Finally, click <strong class="screenText">Assign MFA</strong> to finalize the process:</p>
<figure class="mediaobject"><img alt="" height="575" src="../Images/B18425_19_10.png" width="595"/></figure>
<p class="packt_figref">Figure 19.10: Setting up the MFA device</p>
<p class="normal">Now that we have<a id="_idIndexMarker1074"/> two-factor authentication enabled for our root account, we should stop using that account immediately. This is actually a best practice when it comes to AWS; it’s recommended that you create individual accounts for the individuals that will work on your AWS account, giving them the permissions they need to perform the tasks they need to complete. We’ll discuss the <strong class="keyWord">principle of least privilege</strong> in <em class="chapterRef">Chapter 21</em>, <em class="italic">Securing Your Server</em>, but it doesn’t hurt to start thinking about the concept now. For now, what we’ll do is create an administrator account for ourselves that we can use in place of the root account. We can always use the new account to create additional users if we need to do so.</p>
<p class="normal">To create a new administrator account, we will again utilize the IAM console. Once there, you’ll see a <strong class="screenText">Users</strong> link on the left, and then you can click the blue <strong class="screenText">Add users</strong> button to begin the process:</p>
<figure class="mediaobject"><img alt="" height="173" src="../Images/B18425_19_11.png" width="876"/></figure>
<p class="packt_figref">Figure 19.11: Setting up a new administrative user for AWS</p>
<p class="normal">The next screen will have you type the desired username, as well as setting <strong class="screenText">Access Type</strong>. For the username, you<a id="_idIndexMarker1075"/> can name the user whatever you’d like. For <strong class="screenText">Access Type</strong>, we’ll choose <strong class="screenText">AWS Management Console access</strong>. Click <strong class="screenText">Next: Permissions</strong> to continue:</p>
<figure class="mediaobject"><img alt="" height="657" src="../Images/B18425_19_12.png" width="878"/></figure>
<p class="packt_figref">Figure 19.12: Setting up a new administrative user for AWS</p>
<p class="normal">Next, we will set up the appropriate permissions for our user. The third icon, labeled <strong class="screenText">Attach existing policies directly</strong>, is the first selection we’ll make here, and then below that we’ll place a mark next to the check box for <strong class="screenText">Administrative Access</strong>, and then we’ll click <strong class="screenText">Next: Tags</strong>:</p>
<figure class="mediaobject"><img alt="" height="416" src="../Images/B18425_19_13.png" width="778"/></figure>
<p class="packt_figref">Figure 19.13: Setting up a new administrative user for AWS (continued)</p>
<p class="normal">We can skip <a id="_idIndexMarker1076"/>the tags screen by leaving the fields blank and clicking <strong class="screenText">Next: Review</strong>.</p>
<p class="normal">The next screen will provide us with an overview, and if everything appears to be correct here, we can click <strong class="screenText">Create user</strong>:</p>
<figure class="mediaobject"><img alt="" height="481" src="../Images/B18425_19_14.png" width="778"/></figure>
<p class="packt_figref">Figure 19.14: Setting up a new administrative user for AWS (continued)</p>
<p class="normal">Finally, we’ll see a <a id="_idIndexMarker1077"/>confirmation message that our user was created. If you chose to have a randomly generated password during the process, you should also see a button there to retrieve it:</p>
<figure class="mediaobject"><img alt="" height="384" src="../Images/B18425_19_15.png" width="877"/></figure>
<p class="packt_figref">Figure 19.15: Setting up a new administrative user for AWS (continued)</p>
<p class="normal">You can now log in to the AWS Management Console with the new user and the password that was provided. You will also need the <strong class="keyWord">account ID</strong>, which is visible within the URL on this screen (it’s the number right after <code class="inlineCode">https://</code>). To make it easier, you can click on the URL that’s shown in order to have the account ID autofilled.</p>
<p class="normal">Going forward, I recommend that you use the new user we’ve created for managing the AWS <a id="_idIndexMarker1078"/>account, as it’s a good practice to not use the root account unless you absolutely have to. In addition, I recommend you follow the procedure to set up MFA as we did earlier, but this time with the new user.</p>
<h1 class="heading-1" id="_idParaDest-250">Choosing a region</h1>
<p class="normal">As discussed <a id="_idIndexMarker1079"/>earlier, a VPC within AWS is the high-level abstraction of your overall network. You can have multiple VPCs, which is similar to the concept of managing several physical networks. In fact, we already have VPCs created for us in our account, so we won’t need to create one. In the future, keep in mind that creating additional VPCs is an option, should you ever need to have more than one. In our account, we have a default VPC in each <strong class="keyWord">Region</strong>, so choosing which one to utilize comes down to which region is most appropriate for our use.</p>
<p class="normal">For production use, you’ll want to create instances in AWS that are as close to your customer as you can get. For example, let’s say that the customers that your organization markets to are primarily located in the Eastern United States. There’s a region available within AWS that is available that’s labeled <strong class="keyWord">US East</strong>, so that would be an obvious choice in that scenario. You’re not limited to regions within the USA though; there are regions available all over the world, such as in Germany, China, and Canada (among others). In a nutshell, you’ll want to create resources as close to your customers as possible. If you don’t have a preference, you can choose to utilize whichever region is closer to you.</p>
<p class="normal">Although it’s beyond the scope of this book, AWS offers a service<a id="_idIndexMarker1080"/> called <strong class="keyWord">CloudFront</strong> that acts as<a id="_idIndexMarker1081"/> a <strong class="keyWord">Content Delivery Network</strong> (<strong class="keyWord">CDN</strong>) that you can use to make your resources available in various edge locations that users can be routed to in order to ensure they’re retrieving your content from a location closest to where they are geographically. For organizations that produce media content, this is especially valuable. If this is something that might benefit you, I recommend reading more about CloudFront.</p>
<p class="normal">In addition, there are often multiple <strong class="keyWord">Availability Zones</strong> within various regions, which allow you to get even closer to your target audience. For example, when it comes to the US East region, there are two availability zones inside it, one in Virginia as well as another in Ohio. Availability zones not only give us the ability to get another step closer to our customers but also offer us additional options for redundancy. For example, if one availability zone goes down for whatever reason, you can route your customers to another. Availability zones have a specific naming syntax that consists of both the name of the region as well as the availability zone within that region. Using the Eastern United States as an example again, the two availability zones there are labeled <strong class="keyWord">us-east-1</strong> for Virginia and <strong class="keyWord">us-east-2</strong> for Ohio. Not all regions will have multiple availability zones, though. Canada currently only has one region with one availability zone: <strong class="keyWord">ca-central-1</strong>.</p>
<p class="normal">In addition to availability zones, there are also <strong class="keyWord">local zones</strong>, which are intended to allow you to set up resources even closer to your customers than availability zones are able to get. Local zones are a great choice if your application is sensitive to network latency, such as running a server for an online game. We won’t go over local zones in this book at all, because this is a very new offering from AWS, and there are only two of them in existence as of the time this book is being prepared for publishing. Amazon intends to add additional local zones in the future, so there may be more of them available by the time you’re reading this. If your organization offers a service that is sensitive to network latency, this may be a feature you’ll want to keep up to date on as they roll it out to more locations.</p>
<p class="normal">For now, the only consideration is which region will benefit your customers by being as close to them as <a id="_idIndexMarker1082"/>possible. When it comes to following along with the examples in this book though, choosing a region closest to you geographically is a good idea.</p>
<p class="normal">Now that we’ve selected our region, how about we create an actual Ubuntu instance in the cloud? That’s exactly what we’ll do in the next section.</p>
<h1 class="heading-1" id="_idParaDest-251">Deploying Ubuntu as an AWS EC2 instance</h1>
<p class="normal">With a <a id="_idIndexMarker1083"/>great <a id="_idIndexMarker1084"/>deal of discussion out of the way, it’s time to create an actual Ubuntu deployment in the cloud. This will allow us to see the AWS service in action and give us some working experience with the EC2 service. This requires two individual steps: the first to create a required IAM role and the second to create our instance. Let’s first make sure we understand the requirements of the IAM role, then we’ll set up<a id="_idIndexMarker1085"/> the<a id="_idIndexMarker1086"/> role and then create our new instance.</p>
<h2 class="heading-2" id="_idParaDest-252">Setting up an IAM role for Session Manager</h2>
<p class="normal"><strong class="keyWord">Session Manager</strong> is a<a id="_idIndexMarker1087"/> service <a id="_idIndexMarker1088"/>within AWS that we can use to access a command prompt for our instance. It’s actually part of <strong class="keyWord">Systems Manager</strong> and not its own service. If you want to access Session Manager, you will need to search for Systems Manager, and you’ll find Session Manager as a service underneath that. You’ll see this shortly.</p>
<p class="normal">Why should we use Session Manager? Just like with any other Linux server, we can still use OpenSSH to connect to the EC2 instance we’ll be creating, just as we have many times while working with non-AWS instances throughout this book.</p>
<p class="normal">There’s nothing wrong with using OpenSSH; with the right settings it can be a very secure option. In fact, we will explore methods of better securing it in <em class="chapterRef">Chapter 21</em>, <em class="italic">Securing Your Server</em>. With AWS, we can use Session Manager as an alternative to OpenSSH, and it’s a worthwhile alternative to learn that offers additional security in that its backend security is not something we have to manage ourselves. In addition, we can control access to it through the AWS console as well.</p>
<p class="normal">By default, Session Manager is not accessible at all. It requires a specific package to be installed within Ubuntu Server for it to work, and it also requires specific permissions to be enabled. The required package for Ubuntu is preinstalled by default, so the first requirement will be automatically taken care of for us immediately when we create our instance. </p>
<p class="normal">For the second requirement of adding permissions, we’ll need to create an IAM role to allow the EC2 instance we’re about to create to communicate with the Session Manager service. When I mentioned earlier that Session Manager isn’t accessible by default, this is why—it’s missing the permissions needed until we add them. To add the required permissions, we’ll access the IAM service within the AWS console, the very same one that we used earlier to create a user account for ourselves. IAM itself has many tricks up its sleeves, more than just simply allowing us to create users. It also allows us to create <strong class="keyWord">IAM roles</strong>, which give us the ability to add permissions to entire objects. For example, we can create a role with the permissions that are required, and then we can attach that role to any EC2 instance to immediately give it the ability to be connected to by Session Manager.</p>
<p class="normal">Let’s get started and set up the required IAM role for Session Manager. Return to the IAM section of the AWS console that we’ve worked with a few times now, and we’ll create the required role.</p>
<p class="normal">In the IAM menu on the left side of the window, click on <strong class="screenText">Roles</strong>, and then click on the blue<a id="_idIndexMarker1089"/> button<a id="_idIndexMarker1090"/> labeled <strong class="screenText">Create role</strong>:</p>
<figure class="mediaobject"><img alt="" height="370" src="../Images/B18425_19_16.png" width="876"/></figure>
<p class="packt_figref">Figure 19.16: Creating an IAM role to enable Session Manager</p>
<p class="normal">On the next screen, make sure <strong class="screenText">AWS service</strong> is selected, and in the menu below that, choose <strong class="screenText">EC2</strong> as the service. Click <strong class="screenText">Next</strong> to continue along:</p>
<figure class="mediaobject"><img alt="" height="850" src="../Images/B18425_19_17.png" width="878"/></figure>
<p class="packt_figref">Figure 19.17: Creating an IAM role to enable Session Manager (continued)</p>
<p class="normal">Next, we are able<a id="_idIndexMarker1091"/> to <a id="_idIndexMarker1092"/>attach policies to our role. In the search field that appears, we can type a keyword to narrow down the list, and then click on a checkbox next to a policy we wish to attach to our role. A full overview of all of the built-in policies and what they’re for is beyond our scope, but as a short summary, each service within AWS has pre-built policies that can be attached to a role, which allows access to various features. Specific to our needs, we will add the <strong class="screenText">AmazonSSMFullAccess</strong> policy to the role we’re creating.</p>
<p class="normal">The purpose of this will become clearer when we create our EC2 instance, so for now, click <strong class="screenText">Next</strong> to continue on:</p>
<figure class="mediaobject"><img alt="" height="553" src="../Images/B18425_19_18.png" width="876"/></figure>
<p class="packt_figref">Figure 19.18: Attaching the AmazonSSMFullAccess policy to our role</p>
<p class="normal">The next screen<a id="_idIndexMarker1093"/> that <a id="_idIndexMarker1094"/>will appear will give us the ability to add one or more tags. We’ll skip this for now, but you can feel free to add any tags you’d like here. Tags allow you to attach information to a resource and aren’t limited to IAM roles. You can add any descriptive information you feel is pertinent, if you wish. Tags are simply <strong class="screenText">key: value</strong> pairs, so there’s no specific naming scheme to follow here. Add tags if you wish to do so, and when you’re finished with this screen click <strong class="screenText">Next: Review</strong>.</p>
<p class="normal">The final screen will give us a review of the settings we’ve chosen so far, as well as an option to name the role, and add a description if we wish to do so. Although it’s optional, I recommend giving the role a name, to make it easier to identify later. When you’re finished, click <strong class="screenText">Create role</strong>:</p>
<figure class="mediaobject"><img alt="" height="570" src="../Images/B18425_19_19.png" width="878"/></figure>
<p class="packt_figref">Figure 19.19: Adding a name and description to our role</p>
<p class="normal">When it comes<a id="_idIndexMarker1095"/> to<a id="_idIndexMarker1096"/> setting up our IAM role, we’re all set—the role has been created and we can go ahead and use it. Next, it’s time to create our Ubuntu instance.</p>
<h2 class="heading-2" id="_idParaDest-253">Creating an Ubuntu Server instance in AWS</h2>
<p class="normal">Now it’s <a id="_idIndexMarker1097"/>time <a id="_idIndexMarker1098"/>to see our work come together and create our Ubuntu instance. In the AWS console, we should first access the EC2 service to get started. You can easily find any service by typing its name into the search box within the console; so if you start typing EC2 into that field, you should see <strong class="screenText">EC2</strong> on the list. After you click on that, click on <strong class="screenText">Instances</strong> on the left side of the screen. After doing that, you’ll see a screen with a button labeled <strong class="screenText">Launch instances</strong>:</p>
<figure class="mediaobject"><img alt="" height="154" src="../Images/B18425_19_20.png" width="877"/></figure>
<p class="packt_figref">Figure 19.20: The main window of the EC2 service</p>
<p class="normal">Normally, the <strong class="screenText">Instances</strong> section of the EC2 console will show us a list of all of our server instances, but unless you’ve read ahead, we don’t have any yet so the window is blank. When you click on <strong class="screenText">Launch instances</strong>, you’ll see various operating systems in the list. But for <a id="_idIndexMarker1099"/>our <a id="_idIndexMarker1100"/>purposes, Ubuntu is shown in the <strong class="screenText">Quick Start</strong> section, so we’ll select that:</p>
<figure class="mediaobject"><img alt="" height="796" src="../Images/B18425_19_21.png" width="876"/></figure>
<p class="packt_figref">Figure 19.21: The Ubuntu option for EC2</p>
<p class="normal">Further down, make sure that <strong class="screenText">t2.micro</strong> is selected, which should show the verbiage <strong class="screenText">Free tier eligible</strong> alongside it. That’s the instance type that we’ll want to use:</p>
<figure class="mediaobject"><img alt="" height="214" src="../Images/B18425_19_22.png" width="880"/></figure>
<p class="packt_figref">Figure 19.22: Choosing an instance type</p>
<p class="normal">On the <strong class="screenText">Choose an Instance Type</strong> screen, there will be quite a few instance types from which to choose. I selected the <strong class="screenText">t2.micro</strong> instance type, and I recommend you do the same. It’s eligible<a id="_idIndexMarker1101"/> for <a id="_idIndexMarker1102"/>the free tier, which is a special tier you’ll have access to within the first 12 months of the age of the account. You most likely wouldn’t choose this instance type for a production server, as it will be quite slow—it only has 1 CPU and 1 GiB of memory. And it’s a burstable instance type, which means the speed fluctuates based on usage. It’s able to burst to take care of busy workloads, but its ability to do so depends on CPU credits that it earns in a particular time. A full explanation is beyond the scope of this chapter, but if you’re going to use AWS in production, it’s a good idea to read about the various instance types available. Although you don’t see it in the screenshot, you should also see the cost on this page as well. But again, we’ll utilize the free tier for now.</p>
<p class="normal">Further down the page, you’ll generate a new key pair, assuming you don’t have one already. This will be used for connecting to the instance via SSH. To generate a new key, click <strong class="screenText">Create new key pair</strong>:</p>
<figure class="mediaobject"><img alt="" height="199" src="../Images/B18425_19_23.png" width="876"/></figure>
<p class="packt_figref">Figure 19.23: Key pair settings during instance creation</p>
<p class="normal">The next screen that appears will allow us to configure the key, such as setting encryption options. For our purposes, we can leave the defaults as is after giving the key a name, and <a id="_idIndexMarker1103"/>then <a id="_idIndexMarker1104"/>we can click <strong class="screenText">Create key pair</strong>:</p>
<figure class="mediaobject"><img alt="" height="798" src="../Images/B18425_19_24.png" width="759"/></figure>
<p class="packt_figref">Figure 19.24: Customizing our SSH key</p>
<p class="normal">The previous step will trigger your browser to download the SSH key that you’ve generated. Be sure to keep it in a safe place. You can use the key you’ve just downloaded to connect to your instance via OpenSSH with a command similar to the following:</p>
<pre class="programlisting con"><code class="hljs-con">ssh -i /path/to/key.pem ubuntu@&lt;Instance Public IP&gt;
</code></pre>
<p class="normal">For me, if I add the path of my key as well as the public IP address listed for my instance, the command becomes this:</p>
<pre class="programlisting con"><code class="hljs-con">ssh -i /home/jay/downloads/jay_ssh.pem ubuntu@54.81.234.225
</code></pre>
<p class="normal">From here, managing the server is just a matter of interacting with its shell and entering commands.</p>
<p class="normal">But anyway, I’m <a id="_idIndexMarker1105"/>getting ahead of myself. After you<a id="_idIndexMarker1106"/> safeguard your key, we can move on to the next section by scrolling down. Network settings are what we’ll work on next:</p>
<figure class="mediaobject"><img alt="" height="673" src="../Images/B18425_19_25.png" width="877"/></figure>
<p class="packt_figref">Figure 19.25: Setting options for our new EC2 instance</p>
<p class="normal">The first consideration on this screen is where we’ll allow OpenSSH connections from. The default option, <code class="inlineCode">0.0.0.0/0</code>, allows connections from anywhere (and is even labeled as such). As<a id="_idIndexMarker1107"/> we’ll <a id="_idIndexMarker1108"/>discuss in <em class="chapterRef">Chapter 21</em>, <em class="italic">Securing Your Server</em>, allowing SSH connections publicly is a bad idea, since outside threat actors might try to use that as a means to access the server. With the instance we’re creating right now, we can make a case for allowing connections from anywhere, since it’s a test instance for the purposes of learning (and we’ll be deleting the instance before the close of the chapter). However, it might be a better idea to get into the habit of restricting access to OpenSSH to specific IP addresses. To do that, you can choose the option <strong class="keyWord">My IP</strong> from the dropdown, which will restrict access to OpenSSH to your public IP address.</p>
<p class="normal">If you do choose to restrict access, keep in mind that unless your public IP is static, it can change at any time. When it does, you’ll lose access to your EC2 instances via OpenSSH. You can regain access by updating the security group for the instance to include your new IP address, but that inconvenience is a small price to pay for added security benefit.</p>
<p class="normal">Continuing in that same section, we have an option to allow traffic in addition to OpenSSH:</p>
<figure class="mediaobject"><img alt="" height="566" src="../Images/B18425_19_26.png" width="877"/></figure>
<p class="packt_figref">Figure 19.26: Network settings while creating an EC2 instance on AWS</p>
<p class="normal">The <a id="_idIndexMarker1109"/>other <a id="_idIndexMarker1110"/>options, <strong class="keyWord">HTTPS</strong> and <strong class="keyWord">HTTP</strong> respectively, are essential if you’re planning on setting up a website on the instance. It’s very common to restrict OpenSSH on a web server, while at the same time allowing full access to ports <code class="inlineCode">80</code> and <code class="inlineCode">443 </code>from the public <code class="inlineCode">internet</code>. The reason for this is, OpenSSH gives you access to manage the server, so we definitely wouldn’t want that open to the public. When it comes to a website, we’ll most likely want the general public to be able to access it, which is why we allow those options. You should only check the latter two boxes in the situation where you’re actually planning on setting up a web server. For our needs, we should allow these boxes, since we will be installing Apache later.</p>
<p class="normal">Next, we’ll configure the <strong class="keyWord">storage</strong> for our instance:</p>
<figure class="mediaobject"><img alt="" height="380" src="../Images/B18425_19_27.png" width="877"/></figure>
<p class="packt_figref">Figure 19.27: Storage options while creating an EC2 instance</p>
<p class="normal">By default, your EC2 instance will be set up with 8 GiB of storage space. As indicated in the <a id="_idIndexMarker1111"/>highlighted <a id="_idIndexMarker1112"/>message on the screen, you can get up to 30 GB of EBS storage space as part of the free tier, if you’re eligible. For that reason, you can consider setting this higher. You can also add additional storage volumes to the instance, which might help if you wanted to segregate storage between block storage devices. We shouldn’t need that for our use case in this chapter.</p>
<p class="normal">Below that, the final section on this screen allows you to configure <strong class="keyWord">Advanced details</strong>. There are quite a few extra options here, but we’ll be ignoring all but one of them. At the very bottom, there’s a large text box labeled <strong class="keyWord">User data</strong>. This is the only option within the advanced details section we’ll change:</p>
<figure class="mediaobject"><img alt="" height="389" src="../Images/B18425_19_28.png" width="886"/></figure>
<p class="packt_figref">Figure 19.28: Adding user data for our EC2 instance</p>
<p class="normal">The <strong class="screenText">User data</strong> section is often overlooked, but it’s <em class="italic">incredibly</em> useful. But what exactly is this for, and<a id="_idIndexMarker1113"/> what <a id="_idIndexMarker1114"/>does it do? If I didn’t know any better myself, I’d probably assume that this is where you’d add information that pertains to your users. But that’s not what it’s for. What<strong class="keyWord"> </strong><strong class="screenText">User data</strong><strong class="keyWord"> </strong>allows you to do is add a series of commands, or even a full script, that you’d like to have executed as the instance is created.</p>
<p class="normal">Already, you can think of any command you might run, or configuration you might tweak, any time you set up a server. Instead of manually executing setup commands after the instance is online, you can simplify this quite a bit and have much of that done automatically before you even log in for the first time.</p>
<p class="normal">In my case, I’ve added the following code to the <strong class="screenText">User data</strong> field:</p>
<pre class="programlisting code"><code class="hljs-code">#!/bin/bash
apt update
apt dist-upgrade -y
apt install -y apache2
</code></pre>
<p class="normal">If you think the code that I’ve added resembles a Bash script, then you’re correct—that’s exactly what it is. I added four lines of Bash statements to the <strong class="keyWord">User data</strong> field, to have some commands run automatically. The code should be relatively straightforward: I have it set up to update the repository index, then perform a full system upgrade.</p>
<p class="normal">This is important; we always want our servers to start with the latest patches available. As a proof of concept, I added a statement to install Apache. Notice that I included the <code class="inlineCode">-y</code> option to all of the <code class="inlineCode">apt</code> commands. This automatically responds “yes” to any question <code class="inlineCode">apt</code> may ask, since we don’t have a display hooked up to this server and are unable to answer questions ourselves. Without that option, the user data will fail to apply.</p>
<p class="normal">Anyway, the moment of truth is here – it’s time to launch our instance, and we can do so by clicking the <strong class="screenText">Launch instance</strong> button near the bottom of the page. Assuming we didn’t forget anything along the way, our new Ubuntu Server cloud instance is moments away from existing!</p>
<p class="normal">At this point, we<a id="_idIndexMarker1115"/> should see the new instance in the <a id="_idIndexMarker1116"/>list of EC2 instances in our account, and it will take some time for it to be ready for use. When the status indicates that the instance is <strong class="keyWord">Running</strong>, then that means it’s ready for us to connect to:</p>
<figure class="mediaobject"><img alt="" height="63" src="../Images/B18425_19_29.png" width="881"/></figure>
<p class="packt_figref">Figure 19.29: Checking the status of our EC2 instance </p>
<p class="normal">In order to set up a connection so we can manage the instance, we’ll need to change the <strong class="keyWord">IAM role</strong> for the instance. If you recall, we created an IAM role earlier, and this is where we’ll attach that role to our new instance. This will ensure that the settings within the role are applied to the instance, which in turn will give us access to Session Manager for connecting to that instance. To change the IAM role, we’ll check the box to the left of the instance, then click on <strong class="screenText">Actions</strong> at the top of the screen. In the menu that opens, click on <strong class="screenText">Security</strong>, and then <strong class="screenText">Modify IAM role</strong>:</p>
<figure class="mediaobject"><img alt="" height="210" src="../Images/B18425_19_30.png" width="885"/></figure>
<p class="packt_figref">Figure 19.30: Navigating to the IAM role settings for an EC2 instance</p>
<p class="normal">The screen <a id="_idIndexMarker1117"/>that<a id="_idIndexMarker1118"/> follows is where we’ll change the IAM role to the one we created earlier:</p>
<figure class="mediaobject"><img alt="" height="414" src="../Images/B18425_19_31.png" width="876"/></figure>
<p class="packt_figref">Figure 19.31: Changing the IAM role of an instance</p>
<p class="normal">After you click <strong class="screenText">Update IAM role</strong>, you’ll be brought back to the list of current EC2 instances. If you click on the blue instance ID text near the name of the instance, you’ll be taken to a screen where you can customize additional options for the instance:</p>
<figure class="mediaobject"><img alt="" height="274" src="../Images/B18425_19_32.png" width="877"/></figure>
<p class="packt_figref">Figure 19.32: Additional EC2 instance settings</p>
<p class="normal">Among the various items on the page, of special interest to us is the <strong class="screenText">Connect</strong> button. If we click on that, we’ll<a id="_idIndexMarker1119"/> begin the process of setting up a remote <a id="_idIndexMarker1120"/>connection we can use to manage the instance. On the screen that appears, click on the <strong class="screenText">Session Manager</strong> tab:</p>
<figure class="mediaobject"><img alt="" height="488" src="../Images/B18425_19_33.png" width="876"/></figure>
<p class="packt_figref">Figure 19.33: Preparing a session to connect to an instance</p>
<p class="normal">Once you click the <strong class="screenText">Connect</strong> button, a new browser window will appear that you can use to issue commands to your instance:</p>
<figure class="mediaobject"><img alt="" height="457" src="../Images/B18425_19_34.png" width="880"/></figure>
<p class="packt_figref">Figure 19.34: An instance session open within a web browser</p>
<p class="normal">In <em class="italic">Figure 19.34</em>, I entered<a id="_idIndexMarker1121"/> the following command in order to <a id="_idIndexMarker1122"/>display details for the version of Ubuntu that was deployed in the instance:</p>
<pre class="programlisting con"><code class="hljs-con">cat /etc/os-release
</code></pre>
<p class="normal">The <code class="inlineCode">/etc/os-release</code> file is included with all Ubuntu installations, and as you can see from the output, it contains some information regarding the version of Ubuntu we’re running. That command was entered directly into the Session Manager window, to show that the connection is actually working and we can now configure the instance right from within our web browser!</p>
<p class="normal">If you recall, we added <strong class="keyWord">User Data</strong> earlier, and that included a command to install Apache. If you enter the public IP address of your EC2 instance into a web browser, you should see the default Apache web page:</p>
<figure class="mediaobject"><img alt="" height="619" src="../Images/B18425_19_35.png" width="873"/></figure>
<p class="packt_figref">Figure 19.35: The Apache default web page running on an EC2 instance</p>
<p class="normal">Congratulations! You’ve successfully deployed Ubuntu Server to the cloud, and now have an actual web server running on it. That’s all there is to it. Using Session Manager is also simple; all you need to do to customize the server further is right-click on it, click <strong class="screenText">Connect</strong>, and you can then continue to build the instance. That’s awesome!</p>
<p class="normal">What’s not<a id="_idIndexMarker1123"/> so <a id="_idIndexMarker1124"/>awesome, though, is when something happens to your server and you have to start over and rebuild it from scratch. In the next section, we’re going to explore the process of creating an image of the server that we can utilize to deploy customized versions of Ubuntu.</p>
<h1 class="heading-1" id="_idParaDest-254">Creating and deploying Ubuntu AMIs</h1>
<p class="normal">Just about <a id="_idIndexMarker1125"/>every <a id="_idIndexMarker1126"/>cloud platform I know of includes some sort of feature that can be used to create images of the instance’s hard disk. An image can be used to create copies of the original server, as well as acting as a starting point so if the server needs to be rebuilt, we won’t have to start over from scratch. In AWS, images are known as <strong class="keyWord">Amazon Machine Images</strong> (<strong class="keyWord">AMIs</strong>). For all intents and purposes, there’s <a id="_idIndexMarker1127"/>nothing very unique about AMIs; if you’ve worked with disk images in the past, it’s the same thing. When it comes to what to include in an AMI, you can (and should) use your imagination here—anything you find yourself manually setting up or configuring while rolling out a new server is a candidate to be included in an image, and the more customizations you include inside the image, the more time it will save you later.</p>
<p class="normal">Let’s see this in action and create an image of the server we’ve just set up. We should consider shutting down our server first, although this isn’t required. Taking an AMI of a server that is shut down is preferred over doing the same on a server that is running. When the server is shut down, nothing is writing to its disk, so we don’t have to worry about corruption if we’re capturing an AMI in the middle of a critical write operation. The likelihood of running into an issue while creating an AMI of a running server is very small, but I recommend shutting down the server if you can just to be on the safe side.</p>
<p class="normal">In the EC2 console <a id="_idIndexMarker1128"/>of AWS, you can right-click on the instance to <a id="_idIndexMarker1129"/>access <strong class="keyWord">Session Manager</strong>, and then you can simply power it off from the command prompt:</p>
<pre class="programlisting con"><code class="hljs-con">sudo poweroff
</code></pre>
<p class="normal">In AWS, it can take a minute or two for an instance to power down. You can refresh the page after some time, and the status should change to <strong class="screenText">Stopped</strong>:</p>
<figure class="mediaobject"><img alt="" height="55" src="../Images/B18425_19_36.png" width="885"/></figure>
<p class="packt_figref">Figure 19.36: Checking the status of an EC2 instance</p>
<p class="normal">Once the instance has stopped, you can right-click on it to begin the process of creating an AMI. Hover over <strong class="screenText">Image and templates</strong> and then click <strong class="screenText">Create image</strong>:</p>
<figure class="mediaobject"><img alt="" height="409" src="../Images/B18425_19_37.png" width="679"/></figure>
<p class="packt_figref">Figure 19.37: The Apache default web page running on an EC2 instance</p>
<p class="normal">Next, we can <a id="_idIndexMarker1130"/>enter <a id="_idIndexMarker1131"/>some details about our AMI. Give it a name and a description. This information will help others you work with understand what the image is for, and it can also help you remember why you’ve created the image later on down the road. There are other options on this page, but we can leave the rest as is. A name and description should be good enough for now. Once you’re finished, click <strong class="screenText">Create image</strong> to continue:</p>
<figure class="mediaobject"><img alt="" height="541" src="../Images/B18425_19_38.png" width="877"/></figure>
<p class="packt_figref">Figure 19.38: Creating a new AMI</p>
<p class="normal">Believe it or not, that’s <a id="_idIndexMarker1132"/>all there is to it. The process of creating an AMI is<a id="_idIndexMarker1133"/> very straightforward, with just a few steps. You should now see a confirmation screen, letting you know the image is in the process of being created:</p>
<figure class="mediaobject"><img alt="" height="72" src="../Images/B18425_19_39.png" width="876"/></figure>
<p class="packt_figref">Figure 19.39: Confirmation while creating a new AMI</p>
<p class="normal">If you click on the underlined text that contains the AMI ID, you’ll be directed to the AMI section of the EC2 console, where it will show your image on the list:</p>
<figure class="mediaobject"><img alt="" height="144" src="../Images/B18425_19_40.png" width="877"/></figure>
<p class="packt_figref">Figure 19.40: Our newly created AMI, available for use</p>
<p class="normal">In the AMI section of the EC2 console, you should see the list narrowed down to just the AMI we created just now. We only have one AMI anyway, unless you created multiple AMIs for practice. At the end, the <strong class="keyWord">Status</strong> column should read <strong class="keyWord">available</strong> if the AMI is ready for use. If not, give it some time, and refresh the page later. Sometimes it can take a few minutes. But with regard to creating an AMI, that’s it!</p>
<p class="normal">Now that we have an AMI, how do we go about using it? Well, that’s even easier actually. Simply right-click on the AMI on the list and click <strong class="keyWord">Launch</strong>. You’ll see the same launch settings we worked through earlier when we originally created the instance, but this time, we’re using our own AMI instead of the one provided to us. And now, we have our own custom AMI <a id="_idIndexMarker1134"/>of <a id="_idIndexMarker1135"/>Ubuntu with Apache built in that we can use to simplify our process a bit. Keep in mind, though, that our original instance is still stopped. You can return to your list of EC2 instances and start it by right-clicking on it, then clicking <strong class="keyWord">Start</strong>, but you don’t have to; we’re going to work through a fun automation example shortly.</p>
<p class="normal">In the next section, we’re going to take a look at the concept of Auto Scaling.</p>
<h1 class="heading-1" id="_idParaDest-255">Automatically scaling Ubuntu EC2 deployments with Auto Scaling</h1>
<p class="normal">If we maintain<a id="_idIndexMarker1136"/> one or more<a id="_idIndexMarker1137"/> servers for our organization, it’s hard to predict sometimes what the demand will be on that server. In the case of a popular news site, some articles may be more popular than others, and if something goes viral online, then requests to our site can increase by orders of magnitude in a short period of time. In the past, keeping up with customer demand was a very tedious process, one that may result in having to purchase an entirely new server with more powerful hardware. With our instance being in the cloud, we have more flexibility and can automate the process of bringing more servers online. And that’s exactly what we’re going to work on in this section.</p>
<p class="normal">Before we get started, keep in mind that we don’t actually have a popular server in AWS; we only have a simple test server that’s currently running Apache. We can simulate things to a point, but <strong class="keyWord">Auto Scaling</strong> is one of those things that requires a bit of practice to fully utilize. We will definitely get a working example here, though.</p>
<p class="normal">But another important thing to keep in mind is that the more instances we run, the higher the potential cost. We’ll explore how to keep costs down in the next section, but as a general rule of thumb, delete whatever you’re not using. As you’ve gone through examples in this chapter, we’ve set up our own EC2 instance. This is great: we were able to practice some concepts around AWS and put that to use. But if we leave something running that we don’t need, we can have a surprise bill. It’s a good idea to write yourself a reminder to delete everything in your test AWS account when we’re done with the chapter, so you won’t have to worry about that.</p>
<p class="normal">Continuing, one of the requirements of Auto Scaling is that we have an AMI ready that it will use to bring additional servers online. Since we’ve worked through creating an AMI in the previous <a id="_idIndexMarker1138"/>section, we <a id="_idIndexMarker1139"/>already have that requirement met. If you haven’t already worked through the previous section, make sure you do so before we continue. The process of setting up Auto Scaling involves a handful of steps, and we’ll work through each in their own subsection within this chapter.</p>
<h2 class="heading-2" id="_idParaDest-256">Creating a launch template</h2>
<p class="normal">Earlier in the <a id="_idIndexMarker1140"/>chapter, we walked through the process of creating a new EC2 instance. We chose the option to launch an instance, and then configured various settings within multiple screens we worked through. We chose Ubuntu as our platform, added user data, and set an IAM role (among other things). What a <strong class="keyWord">launch template</strong> does is allow us to automate these choices. A launch template gives us the ability to automate the entire launch process.</p>
<p class="normal">On the left-hand menu of the EC2 console, there will be a link titled <strong class="keyWord">Launch Templates</strong>. Click on it. Once you do, you can click on the orange button labeled <strong class="keyWord">Create launch template</strong>. You’ll then see a form you’ll need to fill out, where you select all the defaults for the launch template. There’s no screenshot on this page, because it’s quite long and won’t fit on one page. Instead, I’ll include the relevant options below, with a short description and a recommendation <a id="_idIndexMarker1141"/>regarding what to set the option to:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Launch template name</strong>: This is simply a name for your launch template; set it to the name you feel is most appropriate. Note that this cannot contain spaces.</li>
<li class="bulletList"><strong class="keyWord">Template version description</strong>: For the description, you can add some details that you think are relevant to the purpose of the launch template.</li>
<li class="bulletList"><strong class="keyWord">Amazon Machine Image</strong> (<strong class="keyWord">AMI</strong>): Choose <a id="_idIndexMarker1142"/>the AMI that you created in the previous section. You should see it listed if you click on the <strong class="keyWord">My AMIs</strong> tab, and ensure <strong class="keyWord">Owned by me</strong> is selected. This will narrow down the list of AMIs quite a bit, and since we’ve only created one AMI, it should be easy to find.</li>
<li class="bulletList"><strong class="keyWord">Key pair</strong> (<strong class="keyWord">login</strong>): When you created the EC2 instance earlier, it had you create an OpenSSH key pair. If you drop down this list, that same key pair should be available. Choose that same key.</li>
<li class="bulletList"><strong class="keyWord">Instance type</strong>: If you recall, we chose t2.micro as the instance type earlier. That’s a good selection for this field as well, since t2.micro is eligible for the free tier.</li>
<li class="bulletList"><strong class="keyWord">Security groups</strong>: Earlier, when we added a security group, we set it up to allow OpenSSH and Apache. Feel free to choose that same security group for this.</li>
<li class="bulletList"><strong class="keyWord">IAM instance profile</strong>: This option is a bit hidden, but you should see it as soon as you expand <strong class="keyWord">Advanced details</strong> near the bottom. Although this is optional, it’s a good idea to select the IAM profile we created earlier, to ensure we have access to Session Manager for each instance the launch template creates.</li>
</ul>
<p class="normal">With all of those <a id="_idIndexMarker1143"/>details set, click <strong class="keyWord">Create Launch Template</strong> near the bottom of this screen. Now we have our launch template created and configured, and we can use it as part of the Auto Scaling feature we’re in the process of building.</p>
<h2 class="heading-2" id="_idParaDest-257">Creating an Auto Scaling group</h2>
<p class="normal">Our next <a id="_idIndexMarker1144"/>requirement is to create an <strong class="keyWord">Auto Scaling group</strong>, which will be a shorter process than setting up the launch template. An Auto Scaling group is a logical group of instances that are related to the overall application. We will add our launch template to this group and use it to customize requirements such as how many instances to have online.</p>
<p class="normal">Back in the EC2 dashboard, you’ll find an option for creating Auto Scaling groups in the menu on the left side of the screen, closer to the bottom. Once there, give it a name:</p>
<figure class="mediaobject"><img alt="" height="221" src="../Images/B18425_19_41.png" width="876"/></figure>
<p class="packt_figref">Figure 19.41: Naming the Auto Scaling group</p>
<p class="normal">Further down <a id="_idIndexMarker1145"/>on that same screen, we will choose the launch template we created earlier. Go ahead and do so, and then click <strong class="screenText">Next</strong>:</p>
<figure class="mediaobject"><img alt="" height="720" src="../Images/B18425_19_42.png" width="808"/></figure>
<p class="packt_figref">Figure 19.42: Selecting a launch template for our new Auto Scaling group</p>
<p class="normal">On the next screen, several <a id="_idIndexMarker1146"/>additional sections worth of options will appear. The first of which will have you configure some defaults around networking. For the VPC, you can leave that as is, and for the availability zone, you can simply choose the first on the list:</p>
<figure class="mediaobject"><img alt="" height="495" src="../Images/B18425_19_43.png" width="877"/></figure>
<p class="packt_figref">Figure 19.43: Creating an Auto Scaling group (continued)</p>
<p class="normal">Continuing, the <a id="_idIndexMarker1147"/>next section will ask us about our preference around instance types. On my end, I chose the <strong class="screenText">Manually add instance types</strong> option, and then <strong class="screenText">t2.nano</strong> as the instance type:</p>
<figure class="mediaobject"><img alt="" height="641" src="../Images/B18425_19_44.png" width="878"/></figure>
<p class="packt_figref">Figure 19.44: Creating an Auto Scaling group (continued)</p>
<p class="normal">Once you’re finished<a id="_idIndexMarker1148"/> choosing your instance type(s), there’s nothing left for us to do on this particular page, so click <strong class="screenText">Next</strong> to continue. This will take you to another section, this time asking you if you want to create a load balancer. In the first section of this screen, choose to <strong class="screenText">Attach to a new load balancer</strong>:</p>
<figure class="mediaobject"><img alt="" height="288" src="../Images/B18425_19_45.png" width="877"/></figure>
<p class="packt_figref">Figure 19.45: Creating an Auto Scaling group (continued)</p>
<p class="normal">A <strong class="keyWord">load balancer</strong> allows us to route clients between multiple servers, so the end-users only see one endpoint, but behind the load balancer we can have more than one server available to serve client connections. This is going to be key to setting up our auto-scaled test site, so we’ll definitely want to configure this.</p>
<p class="normal">After choosing to create a new load balancer, we can configure additional options in the next section. Most of these options we’ll leave at their defaults, but there are a few things we’ll want to<a id="_idIndexMarker1149"/> pay attention to:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Load balancer type</strong>: By default, <strong class="keyWord">Application Load Balancer</strong> should be selected. If it isn’t, then make sure that’s the highlighted option before continuing.</li>
<li class="bulletList"><strong class="keyWord">Load balancer name</strong>: This is simply a name for your load balancer; set it to the name you feel is most appropriate. Note that this field is somewhat limited on what types of characters it will accept, so it’s best to keep the name simple.</li>
<li class="bulletList"><strong class="keyWord">Availability Zones and subnets</strong>: We’ll need at least two availability zones for the load balancer, and one will be chosen for you already. The quickest way through this section is to enable the next availability zone in the list.</li>
</ul>
<p class="normal">There are other options on this screen, but the next thing we’ll be doing is creating a <strong class="screenText">target group</strong>, which is directly underneath the availability zone options. There, we’ll choose to create a <strong class="screenText">target group</strong>:</p>
<figure class="mediaobject"><img alt="" height="243" src="../Images/B18425_19_46.png" width="876"/></figure>
<p class="packt_figref">Figure 19.46: Creating an Auto Scaling group (continued)</p>
<p class="normal">A <strong class="screenText">target group</strong> is a logical grouping of EC2 instances that serve a common goal. A load balancer will send traffic to a target group, and instances within that group will answer the request. If an instance is not a member of a target group, then it won’t be a part of our application. It’s not uncommon for an organization to have more than one app, and as a result, several target groups. After you choose to create a target group, you can accept the default name if you wish, and then we should be finished with configuring our auto-scaling group. Click <strong class="screenText">Next</strong> to continue, which will bring us to a section where we can configure <a id="_idIndexMarker1150"/>our <strong class="screenText">scaling policy</strong>:</p>
<figure class="mediaobject"><img alt="" height="612" src="../Images/B18425_19_47.png" width="877"/></figure>
<p class="packt_figref">Figure 19.47: Creating an Auto Scaling group (continued)</p>
<p class="normal">This is where the magic happens: we can choose the minimum number of instances to have running at any one time and the maximum number of instances we will allow the application to scale up to. We can leave each field at <strong class="screenText">1</strong> for now.</p>
<p class="normal">That should be about all we’ll need to configure for our auto scaling group. You can click <strong class="screenText">Skip to review</strong> to take a shortcut that will take you to the final screen of the process, which will show you an overview of your selections. If you’re satisfied with the settings that are shown, you can finalize the process by clicking <strong class="screenText">Create Auto Scaling group</strong>.</p>
<p class="normal">At this point, our Auto Scaling group is created, and we should have everything ready to go. At first, we’ll have <strong class="screenText">0</strong> instances within this group, so we’ll see the current number of instances shown as <strong class="screenText">0</strong>. </p>
<p class="normal">After it finishes updating capacity, it will automatically spin up a new EC2 instance in order to meet our requirement of always having one instance online. If we check our list of EC2 instances, we should have a new one on the list now:</p>
<figure class="mediaobject"><img alt="" height="95" src="../Images/B18425_19_48.png" width="877"/></figure>
<p class="packt_figref">Figure 19.48: A new instance was created as part of our Auto Scaling configuration</p>
<p class="normal">As you can see in the screenshot, the original EC2 instance has a state of <strong class="screenText">Stopped</strong>. We stopped it earlier so <a id="_idIndexMarker1151"/>that we could create an AMI of that instance. In my case, I never started that instance again after creating the AMI, so it’s completely stopped. The Auto Scaling configuration went ahead and created a new instance, because its requirement of having at least one instance running was not met.</p>
<p class="normal">Before we implement the final component we need for everything to function properly, let’s take a moment to understand the value that we already have in place. If we were to increase the number of desired instances within the Auto Scaling group, then it would immediately spin up a new instance for us. Although advanced usage is more appropriate for a book that’s dedicated to AWS, we can set this up to automatically happen when the CPU of our instance gets to a certain point, which can trigger Auto Scaling to bring another one online.</p>
<p class="normal">With just a single instance, we don’t have Auto Scaling in play yet, but we can easily enable that. Another benefit that we get automatically is auto healing, and we have that benefit even with a single instance. If something were to happen to our only running instance, Auto Scaling will bring a new one online to replace it automatically.</p>
<p class="normal">In this situation, the website will be down for several minutes while the new instance is being created, but a bit of downtime is certainly better than having to manually replace the server ourselves. If we set the desired instances to a number higher than 1, a user will not notice anything if one of the servers goes down, the other will take care of the load while the new one comes up. These are amazing benefits to be able to take advantage of and will give us additional peace of mind right away. To test this yourself, feel free to delete the running EC2 instance by right-clicking it and then clicking <strong class="keyWord">Terminate</strong>. The instance should then get terminated, and a new one should appear within several minutes to replace it.</p>
<p class="normal">Since we have a load balancer in use, this changes the way that we’ll access the application that’s running on our instance(s), which in this case is Apache (we had Apache installed when we built our AMI, so every instance will automatically have Apache set up). Normally, we can access the application by navigating to the public IP address of the instance. We can still do this, actually – and the same is true for other instances within our load balancer setup as well. But in order to benefit from the overall solution we’ve built, we should instead access the application from the <strong class="keyWord">DNS name</strong> of the load balancer. This will ensure that our request is routed through the load balancer, rather than directly to a specific server. If you navigate to the <strong class="keyWord">Load balancers</strong> section of the management console, you should see the DNS name there. Going forward, the application or services you run on your instances should be served by having users access it via that DNS name.</p>
<p class="normal">Congratulations! At this point, you’ve created a complete load-balanced solution in AWS that will automatically heal from failures. Feel free to experiment a bit more, and then when you’re <a id="_idIndexMarker1152"/>finished, consider removing the test components we’ve created in this chapter to avoid a cost later on.</p>
<p class="normal">Speaking of cost, in the next section, we’ll talk a bit further about how to manage costs and keep our bills under control.</p>
<h1 class="heading-1" id="_idParaDest-258">Keeping costs down: understanding how to save money and make cost-effective decisions</h1>
<p class="normal">As you just saw, there were many components and configurations we had to implement in order to build a load-balanced solution in AWS. As we grow our AWS infrastructure and implement more solutions, we should also keep an eye on our bill. Although we can utilize the free tier for now, production applications will likely need more powerful instances than what the free tier will provide, and the free tier itself won’t last forever. Not only that, but we should also know how to check how our bill is trending to make sure we don’t accidentally implement something that is expensive or waste money by running something we no longer need.</p>
<p class="normal">In this section, we’ll explore some concepts around billing. Although it’s beyond the scope of this chapter to do a complete deep dive into the world of billing, the subsections that follow will provide you with essential advice to help prevent unexpected charges.</p>
<h2 class="heading-2" id="_idParaDest-259">Viewing billing information</h2>
<p class="normal">Within AWS, the <a id="_idIndexMarker1153"/>billing section is its own service along with others, such as EC2 and S3. You can find the <strong class="screenText">Billing</strong> area from the service list. Once there, you’ll be shown the <strong class="screenText">Billing &amp; Cost Management Dashboard</strong>, which will show you your current expenses and allow you to see current and past billing information:</p>
<figure class="mediaobject"><img alt="" height="244" src="../Images/B18425_19_49.png" width="875"/></figure>
<p class="packt_figref">Figure 19.49: Viewing the Billing &amp; Cost Management Dashboard</p>
<p class="normal">Since the account I’m working with currently was just created a week or so ago, and I’m only using instances in the free tier, I have no costs currently. But if I did incur charges, I’d see the current balance on the main page of the dashboard. In addition, I’ll receive the same information in a monthly statement that is sent to the primary email account.</p>
<p class="normal">However, I don’t recommend waiting for the bill to arrive before checking your totals. To effectively manage billing, you should check this dashboard manually, which might enable you to catch an error before the end of the month, which might save you money. The links on the left will give you additional billing information, as well as providing a way of accessing previous bills.</p>
<h2 class="heading-2" id="_idParaDest-260">Adding a billing alert</h2>
<p class="normal">In this section, I’m going<a id="_idIndexMarker1154"/> to give you some high-level tips regarding some of the things you can do in order to help keep your AWS bill down. </p>
<p class="normal">In the previous section, I recommended that you check the bill regularly instead of only when the monthly invoice arrives. While that is good advice (if I do say so myself), the reality is that server administrators like us are busy and may not remember to check the bill on a regular basis. This is why we typically set up system alerts to notify us when our servers are encountering an issue. Similarly, we can actually set up an alert inside our AWS account that can notify us if our bill gets too high. In fact, even though the AWS account we’ve been working with was likely only created as a test account, it’s especially important that we add a billing alert so we can be alerted if any of our experiments were misconfigured in such a way that we’re incurring costs we didn’t intend to.</p>
<p class="normal">In the <em class="italic">Further reading</em> section at the end of the chapter, I have included a link to AWS documentation that details how to set up billing alerts, and I definitely recommend you enable them. If you’re using an AWS account for your organization to run actual production servers, it’s a good idea to enable billing alerts there as well. In fact, be sure to create billing alerts in every AWS account you manage. Another important element to consider is removing backups that aren’t needed anymore, which can also lower costs.</p>
<h2 class="heading-2" id="_idParaDest-261">Removing unneeded backups</h2>
<p class="normal">This may seem like <a id="_idIndexMarker1155"/>a no-brainer, but you’d be surprised—every organization I’ve ever worked for or consulted with in regard to AWS has run into an issue where backups get out of control and generate large costs. My personal record for witnessing a waste of money in this manner is one company that had over 23,000 unnecessary snapshots in their account, sitting around for over 5 years. I don’t remember the exact dollar amount, but this error cost them thousands of dollars a month for years!</p>
<p class="normal">Backups themselves are extremely important though, and the previous example might’ve been understandable if the organization had legal requirements that forced them to retain all backups for a specific period (such as 5 years). And backups, as you well know by now, are essential if the organization runs into some sort of issue and needs to restore something from the past. But the general rule of thumb here is to ensure that when the day comes to add an automatic backup feature, you also implement (and regularly test) an <a id="_idIndexMarker1156"/>automatic cleanup procedure as well.</p>
<h2 class="heading-2" id="_idParaDest-262">Running EC2 instances only when they’re needed</h2>
<p class="normal">Many organizations <a id="_idIndexMarker1157"/>do business around the<a id="_idIndexMarker1158"/> clock and all year round, while others conduct business only during daytime business hours. While it might not be immediately apparent why this matters, consider the fact that you don’t get charged for an EC2 instance while it’s powered off. You do get charged for things like storage regardless of its state, but you aren’t charged for the instance itself if it is not running. If your organization has a server that is only used during certain hours, consider stopping the instance outside of that time period and then starting it back up when it’s needed.</p>
<p class="normal">There’s additional functionality in AWS that allows you to automatically schedule an instance to run only during certain hours, so there are ways to ensure your infrastructure is available when it’s needed. Make sure you keep this in mind as you navigate AWS; if you’re creating a new server, is it going to be necessary to make it run 24/7, or is it only necessary to run it at certain times? You’d be surprised how much money this may save you.</p>
<h2 class="heading-2" id="_idParaDest-263">Stopping or terminating unneeded EC2 instances</h2>
<p class="normal">Similar to the<a id="_idIndexMarker1159"/> advice in the previous <a id="_idIndexMarker1160"/>section about having instances run only when necessary, consider deleting instances completely if they’re not needed at all. Unless you’re utilizing a very specific type of instance, you won’t be billed for an EC2 instance that doesn’t exist. Make a habit of deleting things when you’re done with them. If you think you may need a server again in the future but you’re not sure, consider creating an AMI of the server, and then removing it. Although the AMI itself will have a cost, it’s going to be less than running an actual server.</p>
<p class="normal">This advice isn’t exclusive to EC2 instances; other services within AWS will also cause you to incur costs if you don’t clean them up. Make sure to keep an eye on other components and services that charge by usage, such as RDS, S3, EBS volumes, and so on.</p>
<p class="normal">So, there you have it—with some basic advice, you should be able to keep your billing under control. And even if you make a mistake, as long as you’ve configured billing alerts, you should be notified and be able to correct the problem quickly. I can understand if some of the billing advice was overwhelming, but you’ll get used to it. AWS has a lot of components that can make up a bill, but as long as you set up alerts and delete items you’re not using, you shouldn’t have any problems.</p>
<p class="normal">We’ve gone over <a id="_idIndexMarker1161"/>quite a bit in this <a id="_idIndexMarker1162"/>chapter, but where should you go from here? In the next section, I’ll provide some advice for continuing your learning and taking your AWS skills to the next level.</p>
<h1 class="heading-1" id="_idParaDest-264">Taking the cloud further: additional resources to grow your knowledge</h1>
<p class="normal">AWS is a huge service, and we haven’t even scratched the surface of the platform in this chapter. We’ve just created a simple load-balanced application in an earlier section, and we’ll even learn how to automate creating cloud resources in the next chapter. But if you’ve found this chapter fun and want to work with AWS more and enhance your skills, I thought I’d provide some additional advice that will hopefully help you do that.</p>
<h2 class="heading-2" id="_idParaDest-265">Online training and labs</h2>
<p class="normal">There is quite<a id="_idIndexMarker1163"/> a bit in the way of online resources to expand your knowledge. Some of these resources are free, such as a section of the AWS website that provides free hands-on training: <a href="https://aws.amazon.com/training/digital/"><span class="url">https://aws.amazon.com/training/digital/</span></a></p>
<p class="normal">While you may already be aware of the value of YouTube when it comes to training videos, it’s a great source of knowledge. (And you may have even stumbled across my YouTube channel, over at Learn Linux TV.) </p>
<p class="normal">There are many videos on YouTube that can provide training, but that’s not the only source of video content; Packt Publishing features video training courses as well, in addition to Udemy, which also has some great content.</p>
<p class="normal">Overall, there’s no shortage of training materials available, but I’d recommend starting with the free training provided by AWS that I’ve mentioned above, as well as the additional training content that Amazon makes available at <a href="https://aws.training"><span class="url">https://aws.training</span></a>.</p>
<h2 class="heading-2" id="_idParaDest-266">Certification</h2>
<p class="normal">While it will <a id="_idIndexMarker1164"/>take a bit of work, achieving one or more certifications in AWS will lead you down a path where you’ll learn the platform in much greater detail. In addition, individuals with AWS certifications are in high demand in the IT industry, so achieving certification is a good idea all around. I recommend looking into the <strong class="keyWord">AWS Certified Cloud Practitioner</strong> credential, which<a id="_idIndexMarker1165"/> is a more entry-level certification that is approachable to those just starting out.</p>
<p class="normal">After you grow your expertise, you may want to<a id="_idIndexMarker1166"/> consider the <strong class="keyWord">AWS Certified Sysops Administrator</strong> credential, which is more challenging but will boost your knowledge even further.</p>
<h2 class="heading-2" id="_idParaDest-267">Keep experimenting and learning</h2>
<p class="normal">Even if you don’t <a id="_idIndexMarker1167"/>decide to achieve a certification, keep experimenting with the platform. Getting your hands on the technology and making use of it on a regular basis is usually the best way to learn and keep your skills sharp. Try to create additional types of infrastructure, build and rebuild test instances, and above all, have fun. For many people, there’s no greater way to learn something than to get your hands dirty and experience it. I also recommend you follow any blogs around cloud computing and related technologies as well.</p>
<h2 class="heading-2" id="_idParaDest-268">AWS documentation</h2>
<p class="normal">The documentation<a id="_idIndexMarker1168"/> provided by AWS is well written and very detailed. You can learn everything you need to know from the AWS documentation alone. The documentation pages are above and beyond the typical level of quality you would expect from such a large service; Amazon takes the AWS documentation seriously. The documentation pages are available here: <a href="https://docs.aws.amazon.com/index.xhtml"><span class="url">https://docs.aws.amazon.com/index.xhtml</span></a>.</p>
<p class="normal">New resources for learning about AWS are being created on a regular basis, so keep your eyes open for new books, training videos, and more as you study the platform. I think you’ll have a lot of fun taking your skills to the next level and exploring everything the AWS platform has to offer.</p>
<h1 class="heading-1" id="_idParaDest-269">Summary</h1>
<p class="normal">This chapter has been one of the most involved in the entire book so far, and you’ve accomplished a lot. During the course of this chapter, you learned about AWS, set up your own cloud server, set up Auto Scaling to ensure that your server is able to automatically heal from disasters, and even set up a load balancer to enable routing between multiple instances. Make sure you take some time to let all this knowledge sink in before continuing on, and I also recommend you spend some additional time with AWS before moving on to the next chapter.</p>
<p class="normal">Speaking of the next chapter, we’re going to work with AWS again, but this time, we’re going to focus on learning Terraform, which is an awesome tool that will enable us to automate the building of our cloud resources from the ground up. It’s going to be a lot of fun.</p>
<h1 class="heading-1" id="_idParaDest-270">Further reading</h1>
<ul>
<li class="bulletList">Amazon Elastic Compute Cloud documentation: <a href="https://learnlinux.link/ec2-docs"><span class="url">https://learnlinux.link/ec2-docs</span></a></li>
<li class="bulletList">Security groups for your VPC: <a href="https://learnlinux.link/vpc-docs"><span class="url">https://learnlinux.link/vpc-docs</span></a></li>
<li class="bulletList">Auto Scaling documentation: <a href="https://learnlinux.link/as-docs"><span class="url">https://learnlinux.link/as-docs</span></a></li>
<li class="bulletList">Amazon Machine Images (AMIs) : <a href="https://learnlinux.link/ami-docs"><span class="url">https://learnlinux.link/ami-docs</span></a></li>
<li class="bulletList">Amazon Elastic Kubernetes Service documentation: <a href="https://learnlinux.link/eks-docs"><span class="url">https://learnlinux.link/eks-docs</span></a></li>
<li class="bulletList">AWS Billing Alert documentation: <a href="https://learnlinux.link/cw-docs"><span class="url">https://learnlinux.link/cw-docs</span></a></li>
</ul>
<h1 class="heading-1">Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the author and other readers: </p>
<p class="normal"><a href="https://packt.link/LWaZ0"><span class="url">https://packt.link/LWaZ0</span></a></p>
<p class="normal"><img alt="" height="177" src="../Images/QR_Code50046724-1955875156.png" width="177"/></p>
</div>
</div></body></html>