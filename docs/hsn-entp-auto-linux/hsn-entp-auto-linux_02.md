# 第一章：在 Linux 上构建标准操作环境

本章详细探讨了 Linux 中的**标准操作环境**（以下简称**SOE**）概念。虽然我们稍后会详细讨论，但简而言之，SOE 是指所有事物都以标准化的方式进行创建和修改的环境。例如，这意味着所有 Linux 服务器都以相同的方式构建，使用相同的软件版本。这个概念很重要，因为它使得管理环境变得更容易，并减少了管理人员的工作量。尽管本章的内容较为理论，但它为本书的其余部分奠定了基础。

我们将从探讨这种环境的基本定义开始，然后继续研究为什么希望创建这种环境是有利的。从这里出发，我们将探讨一些 SOE 的陷阱，为你提供如何在这种环境中保持正确平衡的视角，最后讨论如何将 SOE 融入到日常维护流程中。有效应用这一概念，可以在非常大的规模下高效且有效地管理 Linux 环境。

在本章中，我们将涵盖以下主题：

+   理解 Linux 环境扩展的挑战

+   什么是 SOE？

+   探索 SOE 的好处

+   知道何时偏离标准

+   SOE 的持续维护

# 理解 Linux 环境扩展的挑战

在深入探讨 SOE 的定义之前，让我们先来探索没有标准的 Linux 环境扩展所面临的挑战。对这一问题的探讨将帮助我们理解 SOE 的定义，同时也帮助我们为特定场景定义适当的标准。

# 非标准环境的挑战

需要考虑的是，许多企业在拥有技术资源（无论是 Linux 还是其他）的过程中所遇到的挑战，并非一开始就显现出来。事实上，在增长的早期阶段，许多系统和流程完全是可持续的，在下一部分中，我们将探讨环境增长的这一早期阶段，以便为理解大规模增长相关的挑战做铺垫。

# 非标准环境的早期增长

在许多公司中，Linux 环境的初始阶段往往没有任何标准化形式。通常，它们随着时间的推移而自然增长。最初的部署可能很小，可能仅覆盖一些核心功能，随着时间的推移和需求的增长，环境也随之扩展。熟练的系统管理员通常根据每台服务器手动进行更改，部署新服务，并根据业务需求扩展服务器规模。

这种有机增长是大多数公司选择的最小阻力路径——项目的截止日期通常很紧，而且预算和资源也很紧张。因此，当有一位熟练的 Linux 人员时，这位人员几乎可以协助完成所有需要的任务，从简单的维护任务到复杂应用栈的调试与部署。这节省了大量在架构设计上花费的时间和金钱，并且能够充分利用现有员工的技能，因为他们可以用来处理紧急问题和部署，而不是在架构设计上浪费时间。因此，简而言之，这是有道理的，作者在几家公司，甚至一些知名的跨国公司中都经历过这种情况。

# 非标准环境的影响

从技术角度更深入地看这个问题。Linux 有多种版本，也有多种应用程序执行（在高层次上）相同的功能，并且有多种方式解决给定的问题。例如，如果你想写一个任务脚本，你是写一个 shell 脚本、Perl、Python 还是 Ruby？对于某些任务，所有这些方式都能实现预期的最终结果。不同的人在解决问题时有不同的偏好方式和技术解决方案，通常会发现一个 Linux 环境是使用一种当时“月度风味”的技术或负责此环境的人最喜欢的技术构建的。就其本身而言，这没有什么问题，最初也不会引发任何问题。

如果有机增长带来一个根本性的问题，那就是：规模。当环境的规模相对较小时，手动进行更改并始终使用最新、最先进的技术是非常不错的，通常也会带来有趣的挑战，因此能够保持技术人员的积极性和价值感。对从事技术工作的人来说，保持技能的更新至关重要，因此，能够在日常工作中运用最新技术，常常是一个激励因素。

# 扩展非标准环境

当服务器数量达到数百，甚至数千（或更多！）时，这个*有机*过程就会崩溃。曾经有趣的挑战变成了繁重且单调的任务，甚至带来压力。新团队成员的学习曲线陡峭。新员工可能会发现自己面对一个不同技术堆栈的环境，需要学习大量不同的技术，可能还需要一段时间的培训才能真正发挥作用。长期服务的团队成员可能成为知识孤岛，如果他们离开公司，知识的流失可能会导致连续性问题。随着非标准环境的无序扩展，问题和故障会变得更多，故障排除也会变得漫长——当你试图实现 99.99%的服务正常运行时间协议时，每一秒的停机时间都至关重要，这显然不是理想的。因此，在下一节中，我们将探讨如何通过 SOE 来解决这些挑战。

# 解决挑战

从中我们意识到对标准化的需求。构建合适的 SOE 的关键在于以下几点：

+   实现规模经济

+   在日常操作中高效工作

+   使所有参与者能够快速轻松地掌握并适应

+   与企业不断增长的需求保持一致

毕竟，如果一个环境在定义上简洁明了，那么所有参与其中的人都更容易理解和使用它。反过来，这意味着任务能更快完成，且更加轻松。简而言之，标准化可以带来成本节约并提高可靠性。

必须强调，这只是一个概念，而非绝对的标准。虽然构建这种环境没有绝对对错之分，但有一些最佳实践。在本章中，我们将进一步探讨这一概念，并帮助你识别与 SOE 相关的核心最佳实践，以便在定义自己的环境时做出明智的决策。

让我们继续深入探讨这个问题。每个企业对其 IT 环境都有一定的需求，无论是基于 Linux、Windows、FreeBSD 还是其他技术。有时，这些需求是清晰且有文档支持的，而有时它们只是隐性的——也就是说，大家假设环境已经符合这些*标准*，但没有正式定义。这些需求通常包括以下几个方面：

+   安全性

+   可靠性

+   可扩展性

+   长期性

+   支持性

+   易用性

这些当然都是高层次的要求，且它们往往彼此交织。让我们更详细地探讨这些要求。

# 安全性

安全性由多个因素共同决定。让我们通过一些问题来了解其中涉及的因素：

+   配置是否安全？

+   我们是否允许使用弱密码？

+   超级用户 root 是否允许远程登录？

+   我们是否记录并审计所有连接？

在非标准环境下，你如何真正说这些要求在所有的 Linux 服务器上都得到了强制执行？要做到这一点，需要相当大的信任，假设所有服务器的构建方式相同，应用了相同的安全参数，并且没有人曾经重新审视该环境进行更改。简而言之，这需要相当频繁的审计以确保合规性。

然而，当环境已标准化，并且所有服务器都从相同的源构建或使用相同的自动化工具（我们将在本书后续内容中展示这一点）时，就更容易有信心地说你的 Linux 系统是安全的。

基于标准的环境当然并不意味着自动安全——如果存在导致构建过程中出现漏洞的问题，自动化意味着这种漏洞将会在整个环境中被复制！因此，了解你环境的安全要求，并小心实施这些要求，持续维护和审计环境，以确保安全水平得到保持，是非常重要的。

安全性还通过补丁得到强制执行，补丁确保你不会运行任何有漏洞的软件，这些漏洞可能允许攻击者侵入你的服务器。一些 Linux 发行版的生命周期比其他的要长。例如，Red Hat Enterprise Linux（以及 CentOS 等衍生版）和 Ubuntu LTS 版本都具有较长、可预测的生命周期，是你的 Linux 系统的不错选择。

因此，它们应该成为你标准的一部分。相反，如果使用了如 Fedora 这样的*前沿* Linux 发行版，可能是因为它当时提供了所需的最新软件包，你可以确信它的生命周期会很短，并且不久后更新会停止，这样就会使你暴露于潜在的未修补漏洞中，并且需要升级到 Fedora 的新版本。

即使升级到 Fedora 的新版本，有时也会出现软件包被*遗弃*的情况——也就是说，这些包没有包含在新的发行版本中。这可能是因为它们被其他包取代了。无论原因如何，升级一个发行版到另一个可能会导致虚假的安全感，除非经过彻底研究，否则应避免这种做法。通过这种方式，标准化有助于确保良好的安全实践。

# 可靠性

许多企业希望其 IT 运维能够保持 99.99%（或更高）的正常运行时间。实现这一目标的一部分途径是使用稳健的软件，应用相关的 bug 修复以及明确定义的故障排除流程。这确保了在最坏的情况下发生停机时，停机时间最小化。

标准化在这里同样起到帮助作用*——*正如我们在上一节关于安全的讨论中所提到的，一个合适的操作系统选择能够确保你持续获得漏洞修复和更新，而且如果你知道企业需要供应商备份来确保业务连续性，那么选择一个有支持合同的 Linux 操作系统（例如 Red Hat 或 Canonical 提供的）是明智的选择。

同样地，当所有服务器都按照一个明确定义且被充分理解的标准构建时，对其进行修改应该能产生可预测的结果，因为每个人都知道自己在处理什么。如果所有的服务器构建方式略有不同，那么即便是出于好意的修改或更新，也可能会产生意想不到的后果，从而导致昂贵的停机时间。

再次强调标准化，即使发生最坏的情况，所有参与者应该知道如何解决问题，因为他们知道所有的服务器都基于某个基础镜像并拥有相同的配置。这种知识和信心能减少故障排除的时间，最终也能减少停机时间。

# 可扩展性

所有企业都希望自己的业务增长，而大多数时候，这意味着 IT 环境需要扩展以应对不断增加的需求。在一个服务器构建方式非标准化的环境中，扩展环境就成了一个更大的挑战。

例如，如果进行横向扩展（向现有服务添加更多相同的服务器），新服务器应该与现有服务器具有相同的配置。如果没有标准化，第一步是弄清楚初始服务器集群是如何构建的，然后克隆这些服务器并进行必要的更改，创建更多独特的服务器。

这个过程有些繁琐，而在标准化环境下，调查步骤完全不必要，水平扩展也变成了一个可预测、可重复的*日常任务*。它还确保了更高的可靠性，因为在新服务器中如果漏掉了非标准配置项，应该不会产生意外的结果。人类是令人难以置信的智能生物，能够把人类送上月球，但同样也能忽视配置文件中的一行。标准化的目的是减少这种风险，从而使得在使用经过深思熟虑的操作系统模板进行环境扩展时，无论是纵向扩展还是横向扩展，都变得既快速又高效，我们将在本章中进一步探讨这一概念。

# 长期可用性

有时在部署某个服务时，需要特定的软件版本。比如，我们以一个运行在 PHP 上的 Web 应用为例。假设你的企业因为历史原因，标准化使用的是 CentOS 6（或 RHEL 6）。该操作系统默认提供 PHP 5.3 版本，这意味着如果你突然需要运行一个仅支持 PHP 7.0 及以上版本的应用，你就得想办法如何托管它。

一个显而易见的解决方案可能是推出 Fedora 虚拟机镜像。毕竟，它与 CentOS 和 RHEL 共享类似的技术，并且包含了更新的库。作者在多个角色中都有直接使用这种解决方案的经验！不过，让我们从更大的视角来看待这个问题。

RHEL（以及基于此的 CentOS）的生命周期大约为 10 年，具体取决于你购买的时间点。在企业环境中，这是一个宝贵的选择*——*这意味着你可以确保任何构建的服务器在构建后的 10 年内（以及可能更长时间的延长生命周期支持）都能获得补丁和支持。这与我们之前提到的安全性、可靠性和可支持性（在下文中）相契合。

然而，在 Fedora 上构建的任何服务器的生命周期大约是 12-18 个月（取决于 Fedora 发布周期）*——*在企业环境中，必须在例如 12-18 个月后重新部署服务器，显然是一个不必要的麻烦。

这并不是说在 Fedora 或任何其他快速发展的 Linux 平台上部署没有必要*——*只是想说明，在安全性和可靠性至关重要的企业环境中，你不太可能想要一个生命周期短的 Linux 平台，因为短期的收益（更新的库支持）将在 12-18 个月后被缺少更新和需要重新构建/升级平台的痛苦所取代。

当然，这在很大程度上取决于你对基础设施的处理方式*——*有些企业采用类似容器的方式管理服务器，并在每次新的软件发布或应用部署时重新部署它们。当你的基础设施和构建标准由代码定义（如 Ansible）时，完全可以做到这一点，且对日常操作的影响最小，且不太可能有任何单一的服务器存在足够长的时间，导致操作系统过时或不再受支持。

归根结底，选择权在你手中，你必须确定哪条路径能为你提供最大的商业利益，而又不会使你的运营面临风险。标准化的一部分是做出合理的、理智的技术决策，并在可行的情况下采纳这些决策，你的标准可能包括频繁的重建，从而可以使用像 Fedora 这样的快速发展操作系统。同样，你也可能决定标准是服务器将有较长的生命周期，并在原地升级，在这种情况下，你最好选择像 Ubuntu LTS 版本或 RHEL/CentOS 这样的操作系统。

在下一个部分中，我们将更详细地探讨 SOE 如何促进支持性这一概念。

# 可支持性

正如我们已经讨论过的，拥有标准化的环境带来了两个好处。第一个好处是，精心选择的平台意味着较长的供应商支持生命周期。反过来，这意味着无论是来自供应商（例如 RHEL 产品）的长期支持，还是来自社区（例如 CentOS）的长期支持。某些操作系统，如 Ubuntu Server，可以选择通过社区支持或直接从 Canonical 获得付费合同支持。

然而，可支持性不仅仅意味着来自供应商或 Linux 社区的支持。请记住，在企业中，你的员工是前线支持，外部人员介入之前，员工就已经在处理问题了。现在，想象一下你有一支优秀的 Linux 团队，并且他们面对的是由 Debian、SuSe、CentOS、Fedora、Ubuntu 和 Manjaro 组成的服务器环境。它们之间有相似之处，但也有大量的差异。它们之间有四种不同的软件包管理器来安装和管理软件包，这只是其中的一个例子。

虽然完全可以支持，但这对你的员工提出了更大的挑战，这意味着对于任何加入公司的人，你需要一套广泛且深入的 Linux 经验——或者需要一个广泛的入职过程来帮助他们快速上手。

在一个标准化的环境中，你可能会使用多个操作系统，但如果你能够通过选择例如 CentOS 7 和 Ubuntu Server 18.04 LTS 来满足所有的需求，并且知道你在未来几年内选择是有保障的，那么你立刻就能减少 Linux 团队的工作负担，让他们有更多时间去创造性地解决问题（例如，通过 Ansible 自动化解决方案！），而不是花时间去琢磨操作系统之间的细微差别。正如我们所讨论的，在出现问题时，他们会更熟悉每个操作系统，因此需要花费更少的时间来调试，从而减少停机时间。

这引出了一个关于大规模易用性的话题，我们将在下一节中对此进行概述。

# 易用性

这一最终类别与前两个类别有很大重叠——也就是说，更标准化的环境使得给定的员工更容易掌握。这样就自动促进了我们之前讨论的所有好处，包括减少停机时间、简化员工招聘和入职等。

在列出了 SOE 帮助解决的挑战之后，我们将在下一节中继续探讨这种环境的结构，从技术角度理解它。

# 什么是 SOE？

现在我们已经探讨了 SOE 对企业重要性的原因，并且在高层次上了解了这些问题的解决方案，让我们详细了解 SOE。我们将从定义 SOE 本身开始。

# 定义 SOE

让我们从一个更实际的角度来看一下这个问题。正如我们已经提到的，SOE 是一个概念，而非绝对的标准。从最简单的层面来看，它是一个在公司多个服务器上部署的通用服务器镜像或构建标准。在这里，所有必需的任务都以一种已知且文档化的方式完成。

首先是基础操作系统——正如我们讨论的那样，选择 Linux 发行版有成百上千种。有些在系统管理方面非常相似（例如，Debian 和 Ubuntu），而有些则有显著不同（例如，Fedora 和 Manjaro）。举个简单的例子，假设你想在 Ubuntu 18.04 LTS 上安装 Apache Web 服务器——你需要输入以下命令：

```
# sudo apt-get update
# sudo apt-get install apache2
```

现在，如果你想在 CentOS 7 上做相同的事情，你需要输入以下命令：

```
# sudo yum install httpd
```

如你所见，这些命令之间没有任何共同之处——即便最终结果在两种情况下都是安装 Apache，命令的包名也完全不同。在小规模环境下这不是问题，但当服务器数量增多时，管理这样一个环境的复杂度也会随之增加。

基础操作系统只是开始。我们上面的例子是安装 Apache，但我们也可以安装 nginx 或者 lighttpd。毕竟，它们也是网页服务器。

然后是配置。你是否希望用户能够通过 SSH 以 root 身份登录？你是否需要某种级别的日志记录以便审计或调试？你需要本地认证还是集中式认证？这些问题不胜枚举，正如你所看到的，如果不加以控制，它们可能会发展成一场巨大的头痛。

这就是 SOE 的作用所在。它实际上是一种规范，从高层来看，它可能包含以下内容：

+   我们的标准基础操作系统是 Ubuntu 18.04 LTS。

+   我们的标准网页服务器将是 Apache 2.4。

+   启用了 SSH 登录，但仅限于具有 SSH 密钥的用户，并且禁止 root 登录。

+   所有用户登录必须进行记录并归档，以供审计使用。

+   除了一些本地的*紧急账户*外，所有账户必须集中管理（例如，通过 LDAP 或 Active Directory）。

+   我们的企业监控解决方案必须集成（例如，必须安装并配置 Nagios NCPA 代理，以便与我们的 Nagios 服务器进行通信）。

+   所有系统日志必须发送到企业的中央日志管理系统。

+   必须对系统进行安全加固。

上述只是一个示例，绝非完整的内容；然而，它应该能让你初步了解 SOE 的高层次定义。随着本章的推进，我们将深入探讨这一主题，并提供更多示例，以帮助清晰地定义 SOE。

# 知道需要包含什么内容

在我们继续之前，让我们更详细地了解一下环境中需要包含的内容。在前面的章节中，我们概述了 SOE 的一个非常简化的定义。任何良好的 SOE 操作流程的一部分就是拥有一个预定义的操作系统构建，可以在任何时刻进行部署。有多种方法可以实现这一点，我们将在本书后续章节讨论这些方法——然而，暂时假设我们之前提到的 Ubuntu 18.04 LTS 基础镜像已经构建完成。我们在这个*标准*构建中应该集成哪些内容呢？

例如，我们知道我们的登录策略将在整个组织中实施——因此，在创建镜像时，`/etc/ssh/sshd_config`必须定制为包含`PermitRootLogin no`和`PasswordAuthentication no`。在后期部署配置中执行这个步骤没有意义，因为每次部署都需要执行这一操作。简单来说，这样做效率低下。

我们的操作系统镜像还需要考虑一些重要的自动化问题。我们知道 Ansible 本身是通过 SSH 进行通信的，因此我们知道需要某种类型的凭证（很可能是基于 SSH 密钥）才能让 Ansible 在所有已部署的服务器上运行。在你能够执行任何自动化操作之前，如果需要手动将 Ansible 凭证分发到每一台机器上，是没有意义的，因此考虑 Ansible 使用的认证方式非常重要（例如，基于密码或 SSH 密钥），并且在构建镜像时创建相应的账户和凭证。实现这一点的具体方法将取决于你们公司安全标准，但我建议可以考虑以下解决方案：

+   在标准镜像上创建一个本地账户，供 Ansible 进行身份验证

+   为该账户授予适当的 sudo 权限，确保能够执行所有预定的自动化任务

+   为这个账户设置本地密码，或者将 Ansible 密钥对中的 SSH 公钥添加到你创建的本地 Ansible 账户的`authorized_keys`文件中

这样做当然会带来一些安全风险。最有可能的是，Ansible 需要完全访问服务器上的 root 权限，才能有效地执行你要求的所有自动化任务，因此，如果凭证被泄露，这个 Ansible 帐户可能会成为一个后门。建议尽量让尽可能少的人访问凭证，并使用像 AWX 或 Ansible Tower 这样的工具（我们将在第三章，*通过 AWX 简化基础设施管理*中进行探讨）来管理凭证，从而防止不当人员获取凭证。你几乎肯定还会希望启用对 Ansible 帐户执行的所有活动进行审计，并将这些活动记录到某个中央服务器上，这样你就可以检查是否有任何可疑活动，并根据需要进行审计。

从用户帐户和身份验证转移开，考虑一下**Nagios 跨平台代理**（**NCPA**）。我们在示例中知道，所有部署的服务器都需要进行监控，因此可以认为 NCPA 代理必须安装，并且令牌必须被定义，以便它可以与 Nagios 服务器进行通信。同样，在标准映像部署后，没必要在每台服务器上都执行这个操作。

那么，关于 Web 服务器呢？拥有一个标准是明智的，因为这意味着所有负责环境的人都能熟悉这项技术。这使得管理变得更容易，尤其对自动化非常有利，正如我们将在下一节中看到的。然而，除非你只部署运行 Linux 的 Web 服务器，否则这不应该作为标准构建的一部分。

作为一种基本原则，标准构建应尽可能简单且轻量。没有必要在它们上运行额外的服务，这些服务占用内存和 CPU 周期，尤其是在它们是冗余的情况下。同样，未配置的服务会增加潜在攻击者的攻击面，因此出于安全原因，建议将它们排除在外。

简而言之，标准构建应该只包含那些将对每台部署的服务器都通用的配置和/或服务。这种方法有时被称为**恰到好处的操作系统**，简称**JeOS**，它是 SOE 的最佳起点。

理解了 SOE 的基本原则后，我们将在下一节中更详细地探讨 SOE 为企业带来的好处。

# 探索 SOE 的好处

到目前为止，你应该已经对 SOE 有了一些了解，并且知道它如何为 Linux 环境带来规模经济和更高的效率。现在，让我们在此基础上，详细了解标准化的重要性示例。

# 在 Linux 环境中，SOE 的示例好处

说 Linux 环境中存在共性，就是说组成它的服务器都有一些共享的属性和特征。例如，它们可能都建立在 Ubuntu Linux 之上，或者它们可能都使用 Apache 作为 Web 服务器。

我们可以通过一个例子来探索这个概念。假设你有 10 台 Linux Web 服务器，它们都在一个负载均衡器后面，且它们都在提供简单的静态内容。所有一切运行正常，但随后需要进行配置更改。也许这是为了更改每台 Web 服务器的文档根目录，以指向由其他团队部署到这些服务器的新代码版本。

作为负责人，你知道因为整体解决方案是负载均衡的，所以所有服务器应该提供相同的内容。因此，配置更改将在每台服务器上都需要进行。这意味着如果你手动操作，就需要做 10 次配置更改。

当然，你可以手动完成这个操作，但这将是一个繁琐的过程，显然对于一个熟练的 Linux 管理员来说，这并不是最好的时间利用方式。它也容易出错——可能在 10 台服务器中的某一台上输入了错误的内容，且没有被发现。或者管理员可能被其他地方的故障打断，只对部分服务器的配置进行了更改。

更好的解决方案是编写一个脚本来进行更改。这正是自动化的基础，而且几乎可以肯定，运行一个脚本一次以更改 10 台服务器的配置，比手动重复更改 10 次要更高效。不仅效率更高，而且如果一个月后需要做相同的更改，这个脚本可以在仅做最小调整的情况下重复使用。

现在，让我们再增加一点复杂性。如果，出于某些未知原因，五台 Web 服务器使用的是基于 CentOS 7 的 Apache，另外五台则使用的是基于 Ubuntu 18.04 LTS 的 nginx，会发生什么呢？最终结果其实是相同的——从基本层面来看，它们都是 Web 服务器。然而，如果你想在 CentOS 7 上的 Apache 中更改文档根目录，你需要做如下操作：

1.  找到`/etc/httpd/conf.d`中的适当配置文件。

1.  对`DocumentRoot`参数进行所需的更改。

1.  使用`systemctl reload httpd.service`重新加载 Web 服务器。

如果你需要在 Ubuntu 18.04 LTS 上的 nginx 中做相同的更改，你需要做如下操作：

1.  找到`/etc/nginx/sites-available`中的正确配置文件。

1.  对`root`参数进行所需的更改。

1.  确保使用`a2ensite`命令启用站点配置文件——否则，Apache 将不会实际看到配置文件。

1.  使用`systemctl reload apache2.service`重新加载 Web 服务器。

从这个相当简单（尽管是人为设定的）例子中可以看出，缺乏共性是自动化的敌人。为了应对这种情况，你需要做如下操作：

1.  检测每台服务器上的操作系统。这本身并不简单——没有一种方法可以检测 Linux 操作系统，因此你的脚本需要依次进行一系列检查，包括以下内容：

    1.  ` /etc/os-release` 的内容（如果存在）

    1.  ` lsb_release` 的输出（如果已安装）

    1.  ` /etc/redhat-release` 的内容（如果存在）

    1.  ` /etc/debian_version` 的内容（如果存在）

    1.  根据需要的其他操作系统特定文件，如果前面的检查没有产生有意义的结果

1.  在不同的目录中运行不同的修改命令，以实现之前讨论的更改。

1.  运行不同的命令来重新加载 Web 服务器，正如之前所详细描述的那样。

因此，脚本变得复杂，编写和维护变得更加困难，显然也更难以保证其可靠性。

虽然这个特定的例子在现实生活中不太可能发生，但它确实突出了一个重要的观点——当环境被构建为符合某个标准时，自动化的实现要容易得多。如果决定所有的 Web 服务器都基于 CentOS 7，运行 Apache 2，并且站点配置文件以服务名称命名，那么我们的自动化就变得更加简单。事实上，你甚至可以运行一个简单的`sed`命令来完成这个更改；例如，假设新的 Web 应用程序部署到了`/var/www/newapp`：

```
# sed -i 's!DocumentRoot.*!DocumentRoot /var/www/newapp!g' /etc/httpd/conf.d/webservice.conf
# systemctl reload httpd.service
```

完全不需要环境检测——只需要两个简单的 Shell 命令。这可以成为一个非常简单的自动化脚本的基础，既可以在 10 台服务器中依次运行，也可以通过 SSH 远程运行。无论哪种方式，我们的自动化任务现在变得非常简单，充分展示了公共性的的重要性。重要的是，SOE 本身就提供了这种公共性。然而，缺乏公共性不仅使得自动化变得困难——它还会妨碍测试，通常会扭曲测试结果，因为如果环境不同，测试结果可能不具代表性。

在本章的下一部分，我们将基于这些知识，展示 SOE 如何有利于软件测试过程。

# SOE 对软件测试的好处

我在许多环境中看到的一个常见问题是：一个新的软件部署在隔离的预生产环境中经过成功测试，但在发布到生产环境后却不能正常工作。这个问题往往可以追溯到生产环境和预生产环境之间的根本差异，因此很明显，要使测试有效，两个环境必须尽可能相似。

实际上，像 Docker 这样的容器平台旨在解决的问题之一就是这个，因此可移植性是容器环境的核心特性。在 Docker 上部署的代码是建立在一个容器镜像之上的，简单来说，这是一个精简的操作系统镜像（记得 JeOS 吗？）。实际上，这只是在容器中运行而不是在裸金属服务器或虚拟机上运行的一个非常小的 SOE。然而，值得考虑的是，如果通过环境标准化实现可移植性是容器技术的一个关键特性，那么我们不应该在不考虑基础设施的情况下努力实现这一点吗？

毕竟，如果生产服务器的配置与预生产服务器不同，那么测试的有效性又有多大保证呢？如果预生产环境是建立在 CentOS 7.6 上，而生产环境却落后于 CentOS 7.4，那么你真的能确保在一个环境中的成功测试结果在另一个环境中也能保证吗？在理论上，应该可以，但由于环境中软件和库版本的根本差异，这永远无法保证。这甚至还没有考虑到配置文件和安装软件可能存在的差异。

因此，SOE 在这里可以起到帮助的作用——如果所有环境都按照相同的标准构建，那么理论上它们都应该是相同的。那些眼尖的人会注意到前面一句中使用“*应该*”这个词，这是有充分理由的。SOE 在定义测试失败解决方案方面迈出了重要一步，但它们并非全部内容。

只有当没有人修改它时，环境才能保持标准化，如果所有用户都拥有管理级别的权限，那么某人（无论出于善意还是其他原因）登录并进行更改，使环境偏离标准就非常容易了。

解决这个问题的答案是自动化——SOE 不仅促进和实现自动化，它们也依赖于它来维持最初所需的标准化水平。这两者直接支持彼此，并且理想情况下应该成为不可分割的伙伴——SOE 是环境本身的定义，而自动化则提供标准的实施、执行和审计。事实上，这本书的核心前提就是——环境应尽可能地标准化，并且尽可能多的变更应该是自动化的。

本书的重点将放在这个方程式的自动化方面，除了遵循本章概述的原则之外，采用的标准将对每个环境都是独特的，本书并不旨在低级别确定它们。与之前的例子一起工作，Apache 和 nginx 都有各自的好处，适合一个用例的可能并不适合另一个用例。

操作系统也是如此——有些组织可能依赖于 Red Hat Enterprise Linux 所提供的支持包，而其他组织则不需要此支持包，但需要例如 Fedora 提供的前沿技术。定义标准并没有绝对对错，只要它满足所支撑服务的需求即可。到目前为止，我们非常注重共同性和标准化；然而，总会有一些特殊情况需要采用替代方案。在下一节中，我们将讨论如何判断何时应该偏离标准。

# 知道何时偏离标准

标准化的好处很容易被过度宣扬，尽管它们无疑是自动化有效性的必要条件。然而，像任何事物一样，标准化也可以被推得过头。例如，完全没有必要在 2019 年仅仅因为某个时间点曾被定义为标准而在 Red Hat Enterprise Linux 5.7 上构建服务器（该版本现在已到达生命周期终点，不再支持或更新）。同样，软件供应商有时会在某些特定的 Linux 发行版或应用堆栈上对其产品进行认证，除非软件运行在该生态系统内，否则不会提供支持。

这些都是需要偏离 SOE 的情况，但必须以受控的方式进行。例如，如果企业已经在 Ubuntu 18.04 LTS 上构建了其 Linux 服务器环境，然后购买了一个仅在 RHEL 7 上经过认证的新软件堆栈，那么显然需要构建 RHEL 7。但如果可能的话，这些应该成为新标准的一部分，并成为一个次要 SOE。

例如，如果将 CIS 安全加固基准应用于 Ubuntu SOE，那么同等的基准也应该应用于 RHEL。同样，如果企业已经在 nginx 上实现了标准化，那么在环境中应该继续使用它，除非有令人信服的理由不使用（提示：令人信服的理由不是它“新”和“炫酷”，而是它解决了一个实际问题或以某种方式在可衡量的方面改进了某些东西）。

这导致企业从一个 Linux SOE（标准操作环境）转向两个，虽然这仍然完全可以管理，并且无疑比回到那些阻碍有效自动化的有机增长方法要好。

简而言之，要预期会有偏离，并且不要害怕它们。相反，应该处理它们，并利用这些需求来扩展你的标准，但在可能的情况下坚持标准。SOE 对于每个人来说都是一种平衡——一方面，它们带来了规模优势，使得自动化变得更容易，并减少了对新员工的培训时间（因为所有服务器的构建和配置大致相同）；但如果过于严格地应用，它们也可能阻碍创新。它们不能作为以*“因为一直都是这么做的”*为理由的借口。

总会有充分的理由偏离标准；只需要寻找它所带来的业务利益，无论是供应商支持、较低的资源需求（从而节省电力和金钱）、更长的支持周期，还是其他原因。尽量避免仅仅因为一种新技术看起来*光鲜亮丽*而去偏离标准。只要你牢记这一点，你就能在偏离标准时做出明智的决策。在本章的下一部分，我们将探讨 SOE 的持续维护。

# SOE 的持续维护

虽然本书后面会更详细地讨论补丁和维护，但在此提及它是因为它与常规性和偏差的讨论密切相关。

如果没有其他原因，你至少需要为你的 Linux 环境打补丁。仅仅出于安全考虑，这也是一项理所当然且良好的实践，即使是在隔离环境中也是如此。假设你的环境完全由虚拟机组成，而你早些时候决定将 CentOS 7.2 作为标准。你创建了一个虚拟机，执行了所有必要的配置步骤将其变成 SOE 镜像，然后将其转换为虚拟化环境中的模板。这就成为了你的*黄金构建*。到目前为止，一切顺利。

然而，CentOS 7.2 发布于 2015 年 12 月，距今已经快四年了。如果你今天部署这样的镜像，首先需要做的就是为其打补丁。根据构建定义（以及包含的包数量），这可能意味着你需要下载一 GB 或更多的包，以使其符合最新标准，并确保修补所有已发现的漏洞，并完成所有必要的 bug 修复。

显然，如果你在大规模操作中进行这种操作，这是低效的——每台新服务器都需要通过网络（或者更糟，如果没有内部镜像，还需要通过互联网）下载所有数据，并且在应用补丁时会消耗大量的 I/O 时间和 CPU 时间，而在此期间服务器无法用于任何有意义的任务。如果你每隔几个月才部署一台服务器，你可能还能忍受这个过程。如果你更频繁地部署服务器，这将浪费大量宝贵的时间和资源。

因此，除了对你的环境本身进行持续维护外，持续维护你的标准同样重要。在 2019 年，更新你的 CentOS 构建到 7.6 是有意义的。至少，你的持续维护计划应该包括定期更新*黄金构建*。

本书稍后将详细讨论如何执行这一过程。然而，对于那些急于了解的人来说，这可能简单到只需启动虚拟机镜像，执行更新，清理它（例如，删除克隆模板时可能重复的 SSH 主机密钥），然后从中创建一个新模板。显然，如果自上次维护周期以来对 SOE 进行了任何更改，那么这些更改也可以纳入其中。

您应该预期您的 SOE 会随着时间的推移而发展——或许在这个问题上会花费很多篇幅，但创建和维护标准与过于僵化之间需要有一个重要的平衡。您必须接受有时您需要偏离这些标准，如我们在前一节中讨论的那样，并且随着时间推移，这些标准会不断演变。

总而言之，SOE 应该成为您常规 IT 流程的一部分；如果正确使用，它们不会妨碍创新——相反，它们通过将时间返还给使用它们的人，积极支持创新，确保他们花更少的时间在繁琐、重复的任务上，从而有更多的时间评估新技术和寻找更好的工作方式。这毕竟是自动化的关键好处之一，而 SOE 正是直接支持这一点。

# 总结

SOE（标准化操作环境）是几乎所有环境中技术流程的宝贵补充。它们需要在设计工作和定义标准方面花费一些前期时间，但随着它支持环境的高效自动化，这段时间在后期得到了充分的回报，从而真正为负责环境管理的人们节省了时间，让他们有更多时间评估新技术、寻找更高效的工作方式，并在总体上进行创新。

在本章中，您了解了 SOE 的基本定义。您探讨了它们为几乎所有对规模要求较高的 Linux 环境带来的好处，它们如何支持自动化，以及如何在确保不会过于僵化并妨碍发展的情况下，何时以及如何偏离标准。最后，您了解了持续维护的重要性，包括作为持续维护周期一部分的标准维护。

在下一章中，我们将探讨如何将 Ansible 作为一个有效的自动化框架应用于您的 Linux 环境。

# 问题

1.  SOE 的缩写代表什么？

1.  为什么您会选择支持周期长的操作系统，如 CentOS，而不是支持周期较短、发布频率较高的操作系统，如 Fedora？

1.  如果您偏离了为环境定义的标准，应该怎么办？

1.  列出三个将 Linux 环境扩展到企业规模时面临的挑战。

1.  列举三个 SOE 为企业中的 Linux 带来的好处。

1.  SOE 如何帮助减少企业中的培训需求？

1.  为什么 SOE 有助于提高 Linux 环境的安全性？

# 进一步阅读

+   要从 Red Hat 的角度了解更多关于 SOE 的信息，请参考这篇文章：[`servicesblog.redhat.com/2016/11/03/standard-operating-environment-part-i-concepts-and-structures/`](https://servicesblog.redhat.com/2016/11/03/standard-operating-environment-part-i-concepts-and-structures/)。
