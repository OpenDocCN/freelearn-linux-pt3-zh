- en: '19'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Ubuntu in the Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until now, in each chapter, we’ve been working with an instance of Ubuntu
    installed on either a local virtual machine, a physical computer or server, or
    even a Raspberry Pi. We’ve learned how to deploy Ubuntu on such devices, and we’ve
    even gone as far as deploying virtual machines as well as containers. These on-premises
    devices have served us well, but the concept of cloud computing has become quite
    popular, even more so since the previous edition of this book. In this chapter,
    we’re going to take a look at running Ubuntu in the cloud. Specifically, we’ll
    deploy an Ubuntu instance on **Amazon Web Services** (**AWS**), which is a very
    popular platform for cloud computing. While we won’t go into extreme detail on
    AWS (it’s an extremely large and complex platform), you’ll definitely get a feel
    for what it’s like to deploy resources in the cloud, which will be more than enough
    to get you started.
  prefs: []
  type: TYPE_NORMAL
- en: 'This exploration will involve the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the difference between on-premises and cloud infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important considerations when considering cloud computing as a potential solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Becoming familiar with some basic AWS concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an AWS account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a region
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Ubuntu as an AWS EC2 instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and deploying Ubuntu AMIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically scaling Ubuntu EC2 deployments with Auto Scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keeping costs down: understanding how to save money and make cost-effective
    decisions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Taking the cloud further: additional resources to grow your knowledge'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since cloud computing is something of a different mindset than we’re used to,
    we’ll first go through a few sections that are dedicated to helping us understand
    the difference, as well as some of the considerations we should make before choosing
    to implement Ubuntu in the cloud. In the next section, we’ll explore how the concept
    of cloud computing differs from on-premises hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the difference between on-premises and cloud infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned at the very beginning of this chapter, we’ve been solely utilizing
    on-premises Ubuntu installations thus far. Even if we’re running Ubuntu on a virtual
    machine in our data center, it’s still considered an on-premises installation
    even when it’s not on physical hardware. In short, an on-premises installation
    is something that resides locally with us, regardless of the type of server that
    serves as the foundation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first difference when it comes to cloud computing might be somewhat obvious:
    it’s the exact opposite of a resource being on-premises. With a cloud instance
    of Ubuntu, it’s someone else’s hardware that it runs on. Most of the time, we
    won’t know what kind of server a cloud instance is running on—when we subscribe
    to the services of a cloud provider and pay a fee to run a server on that platform,
    we’re able to access the operating system just like we would a virtual machine,
    with little knowledge of the underlying data center. Although utilizing a cloud
    instance will have some sort of recurring cost, we don’t need to worry about monitoring
    hardware components or replacing failed physical devices. With the cloud, that
    becomes someone else’s problem.'
  prefs: []
  type: TYPE_NORMAL
- en: There are various cloud providers you can choose from, with **AWS**, **Google
    Cloud Platform** (**GCP**), and **Microsoft Azure** being popular choices. Those
    are three very popular platforms. Each of them has its own strengths and weaknesses,
    and even some differentiation as far as how resources on the platform are managed.
    For the most part, there’s no right or wrong choice here, it’s important to research
    each of the platforms and make the appropriate decision for you and your organization.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to cloud providers, there are also **Virtual Private Server** (**VPS**)
    providers. There used to be more of a distinction between a full cloud provider
    and a VPS provider – but as time goes on, the line between the two types of platforms
    is becoming increasingly thin. For the most part, VPS providers are lighter or
    “simpler” alternatives to standard cloud providers. They provide the same core
    features, such as allowing you to build virtual machines – but they don’t usually
    offer as many features as full cloud providers do. Nowadays, VPS providers are
    rolling out new features regularly and are catching up to cloud providers in terms
    of features. Examples of popular VPS providers include **DigitalOcean** and **Linode**,
    among others. In fact, even Amazon themselves have gotten into the VPS business,
    offering a VPS alternative to their own platform, called **Amazon Lightsail**.
  prefs: []
  type: TYPE_NORMAL
- en: For your organization, which should you choose between a full cloud provider
    and VPS provider? Many administrators would answer this question without hesitation
    and recommend a full cloud provider. I can certainly see their point – why go
    with a “lighter” platform when you can use a solution that has all the bells and
    whistles? However, based on my experience with many organizations, I wouldn’t
    recommend going with a full cloud provider without first finding out if a VPS
    provider has all the features you need. The reason for this is that one of the
    trade-offs of having more features is that complexity increases. With an increase
    in complexity comes a larger responsibility to manage resources on that platform.
    And that complexity can create a very large administration overhead. For that
    reason, I don’t recommend full cloud providers like AWS or Azure to small organizations
    with limited IT staff. For those organizations, VPS providers would be best as
    the burden of administration is lower. Larger organizations with a team of administrators
    should have no problem tackling something like AWS.
  prefs: []
  type: TYPE_NORMAL
- en: As I mentioned, we’ll be going over AWS in this chapter. Even if you’re not
    considering migrating resources to the cloud, it’s something that’s still worth
    practicing. If nothing else, you’ll gain some familiarity with another platform,
    which will increase your skillset and marketability. And I don’t know about you,
    but speaking for myself, I really enjoy checking out technologies and learning
    something new.
  prefs: []
  type: TYPE_NORMAL
- en: However, perhaps I’m getting ahead of myself. Before you migrate anything to
    the cloud, the most important question to ask right now is whether or not creating
    cloud resources is appropriate for your goals. That’s exactly what we’ll explore
    in the next section. We’ll also explore some of the differences in mindset when
    it comes to cloud computing as well.
  prefs: []
  type: TYPE_NORMAL
- en: Important considerations when considering cloud computing as a potential solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before choosing to sign up with a provider, it’s important to first make sure
    that creating cloud resources is a good idea for you or your organization in the
    first place. Often, IT professionals can get so excited when it comes to a new
    trend that they may make the mistake of trying to use such a service even when
    it doesn’t make sense to do so. Above all, as an administrator, it’s important
    to utilize the best tool available for whatever it is that you wish to accomplish,
    instead of using a technology just because you’re excited about it. Cloud computing
    is awesome for sure, but for some use cases, it’s just not a good fit. This is
    similar to containers as well: containerization is an exciting technology but
    some applications just don’t run well on that platform. It takes trial and error.'
  prefs: []
  type: TYPE_NORMAL
- en: There are some considerable benefits when it comes to cloud computing. When
    it comes to physical servers, the hardware will fail eventually. It’s not a matter
    of “if” but “when.” All hardware *will* fail eventually. And even if you have
    hardware that doesn’t end up failing in the short term and lasts for a long time,
    it will be made obsolete by more powerful hardware that is more efficient. When
    it comes to managing physical servers, you’ll need to replace the hardware eventually.
  prefs: []
  type: TYPE_NORMAL
- en: This is also true when it comes to cloud computing; the hardware such services
    run on will need to be replaced whenever it fails or becomes obsolete (whichever
    happens first). The difference is that when that happens, the liability on you
    (the administrator) is greatly reduced. You won’t have to order a new server,
    replace parts, or even pay attention to the hardware at all. It’s solely the responsibility
    of the cloud service or VPS provider to keep track of that. A virtual machine
    you run on a cloud platform could be running on a physical server that’s a couple
    of years old, and then tomorrow be moved to a brand-new piece of hardware. And
    you might not even be aware that it was ever moved.
  prefs: []
  type: TYPE_NORMAL
- en: The trade-off, though, is potentially the cost. The reason why I mention cost
    as a “potential” trade-off is that whether or not it’s cheaper for your organization
    to purchase physical servers or pay a monthly fee for servers in the cloud comes
    down to which offers a better **Return on Investment** (**ROI**). To better understand
    this, consider an organization that utilizes only on-premises hardware for their
    data center with no cloud resources being used at all. Let’s also assume that
    every 3 years or so, they have to replace some of the more critical servers with
    newer hardware; and every 5-10 years the less-important servers are replaced.
    There’s also a need to pay for full-time administrators with specialties in managing
    physical hardware, as well as maintaining a cooling system and making sure a room
    is available to designate as a data center. Also, consider the electric bill for
    running your own data center. Add all of this up—how much is it costing the organization
    on average?
  prefs: []
  type: TYPE_NORMAL
- en: With physical infrastructure, you’re paying an up-front cost to purchase servers
    every time you need to do so. With cloud computing, you never have to purchase
    physical server hardware, but instead you’re paying a fee each and every month
    for the privilege of utilizing cloud infrastructure. When you add up the monthly
    costs for cloud resources, how much would that cost the organization? Would it
    cost more than running physical hardware or less?
  prefs: []
  type: TYPE_NORMAL
- en: Often, whether or not running a server in the cloud results in cost savings
    (or ends up being cost prohibitive) comes down to what types of services you wish
    to use on that platform. Running more virtual machines in the cloud is generally
    fairly inexpensive, and might often result in cost savings when compared to running
    physical infrastructure of your own. However, an example of something that might
    end up being cost prohibitive in the cloud is storage.
  prefs: []
  type: TYPE_NORMAL
- en: If your organization doesn’t store much data, then storage costs won’t really
    be a concern. Many companies are perfectly satisfied with employees utilizing
    something like Google Drive for shared storage and won’t even need cloud storage
    at all. Some organizations, especially those that develop software, have *massive*
    storage needs. For these companies, there could be tens or even hundreds of terabytes
    of data being stored, as well as the bandwidth costs for the data going in and
    out of the company. If you were to attempt to migrate such a large amount of data
    to a cloud server provider, you wouldn’t have to manage the storage hardware anymore,
    but your costs for cloud storage would go up dramatically and might easily be
    much more expensive than it costs you to continue to use physical hardware. Personally,
    I’ve seen storage costs result in tens of thousands of dollars extra in monthly
    billing.
  prefs: []
  type: TYPE_NORMAL
- en: Another consideration is stability. It’s often argued that utilizing a cloud
    provider will result in a more stable infrastructure. That mindset seems to make
    sense at first, considering that by using a cloud provider you’re no longer responsible
    for managing the hardware. There’s definitely some truth to the claim that cloud
    resources are more stable, but it’s not quite that simple. Cloud providers *do*
    experience downtime, and it happens more often than you’d think.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud providers will often advertise a high level of uptime, often measured
    in “9s.” For example, AWS offers a general uptime of 99.999%, as of the date this
    book is being prepared for publishing. That sounds great, doesn’t it? Before you
    get too excited about a cloud provider’s uptime claim, it’s important to also
    know what exactly they count as part of that uptime. If an upstream provider,
    such as a backend internet resource, goes down and service is completely unavailable,
    they may not count that and continue to claim the same amount of uptime. Massive
    outages of cloud providers are not uncommon; in 2017, Amazon’s S3 service suffered
    a major outage due to one of their engineers mistyping a command. In that situation,
    many services on the internet were unavailable to customers. So while it is true
    that a cloud service provider is less likely to suffer an outage than you are
    to witness hardware failures, it’s important to keep in mind that outages are
    still possible. We can’t ever assume any service (our own or otherwise) is bulletproof.
  prefs: []
  type: TYPE_NORMAL
- en: Automation is a very important consideration with the cloud. If your resources
    encounter an issue, it’s a really good idea to have an automated means of re-deploying
    your important services. On a physical server, you can set it up exactly as you
    want it and take an image of the hard drive in case the server fails. Cloud providers
    offer you essentially the same service, giving you the ability to create images
    of your important servers so you can redeploy them in the future should you need
    to do so.
  prefs: []
  type: TYPE_NORMAL
- en: If you do go with a cloud provider, make sure you keep regular backups as well
    as images. And be sure to keep a copy of at least the most recent backups locally
    outside of the cloud provider, because if the cloud provider itself goes down
    then you also lose the backup. I can probably better summarize this by advising
    you to not become over-confident in the stability of your cloud provider. Always
    assume your infrastructure will fail eventually, regardless of where it’s located
    or how stable their marketing team claims it is.
  prefs: []
  type: TYPE_NORMAL
- en: The warnings I have given around the stability of cloud providers are not intended
    to scare you away from using them, but instead to steer you toward maintaining
    good hygiene with the cloud, just as you would with physical infrastructure. Basically,
    to be successful when it comes to managing servers, you’ll have to assume that
    cloud providers can fail just as easily as on-premises equipment, and make sure
    you’re well prepared if there is ever an issue. Cloud providers actually provide
    you with all the tools you need in order to build a stable infrastructure that’s
    easily reproducible and recoverable. If you utilize those tools effectively, you
    shouldn’t have anything to worry about. We’ll explore these concepts further as
    we go along, but you can go as far as to have cloud servers recover *themselves*
    when a problem occurs. It all depends on how you architect your solution.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important that you understand any company policies (and laws) that
    may exist regarding data retention, what type of information is allowed to be
    stored within the cloud, or any other rule or regulation that might be in place
    in your area. (GDPR is a great example of legal requirements.) If in doubt, consulting
    with your company’s management, security, and human resources teams would be a
    great place to start when it comes to what data-related policies and laws may
    be applicable while you design your cloud solution.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’re going to explore some concepts specific to AWS, so
    we’ll have a stronger foundation of knowledge to use for building an actual cloud
    solution later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Becoming familiar with some basic AWS concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed earlier, AWS is one of several competing cloud service providers.
    For the purpose of this chapter, AWS was chosen because more than any other provider,
    the platform requires an administrator to adopt a completely different mindset
    when it comes to managing infrastructure. This different mindset is a healthy
    one even outside of AWS, so it represents a logical evolution at this point in
    our journey.
  prefs: []
  type: TYPE_NORMAL
- en: Up until now, we’ve discussed server installations as essentially pets, meaning
    we want to keep them around, make sure they’re healthy, and if something goes
    wrong, try to fix it. We want to keep our servers operational for as long as possible.
    We want to be able to rely on them, and that helps our organization - customers
    and clients appreciate using a website or service that is stable, with minimal
    or no downtime.
  prefs: []
  type: TYPE_NORMAL
- en: That last part, minimal downtime, doesn’t change regardless of the mindset we
    use when managing our infrastructure. Downtime and service disruption is bad in
    this industry, and that’s always going to be the case. The difference is what
    we do about it, and how we go about recovering from it. In fact, we can even try
    our best to automatically recover when we have a problem. If the customer never
    notices there was ever an issue, even better.
  prefs: []
  type: TYPE_NORMAL
- en: With AWS, the mindset is different – we consider our servers as disposable,
    not as pets. This may seem a bit surprising at first, but if we effectively use
    the tools we’re provided, we can build an infrastructure that is scalable. This
    concept in particular is known as **Auto Scaling** and is a very important aspect
    of AWS. With Auto Scaling, resources are automatically created and destroyed as
    demand increases and decreases. For example, let’s say that your web server receives
    more visitors than normal, and its CPU is starting to max out. Auto Scaling would
    then bring up a new web server automatically, and with a load balancer, route
    clients between instances as needed to spread the load. You can set the maximum
    number of instances that can be brought online, and then when the load decreases,
    the servers that were brought online to handle the load will automatically get
    deleted. This means that you can architect your cloud solution such that you’ll
    have the exact number of servers in existence as you need at any given time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another level above Auto Scaling is **Auto healing**. Just as the name implies,
    auto healing means that if your server runs into a problem, it will automatically
    be “healed,” and in the case of cloud computing, this means the instance will
    be disposed of and recreated from a known good image or template. This is the
    ultimate goal of AWS (or pretty much any implementation): to have infrastructure
    that is not only scalable but also able to recover by itself. For example, perhaps
    you have a pair of web servers that handle requests from clients. One of them
    encounters some sort of issue and fails some sort of test that would imply that
    the server is unreliable. Such a test is known as a **health check**. With auto
    healing, a server that fails health checks is considered unhealthy and is deleted.
    With Auto Scaling, you also set a minimum number of servers for your application.
    If the number of servers falls below the minimum, then a new one is created to
    replace it. Depending on how you architect your solution, the customer may notice
    some degradation if the application is running on fewer servers, but that’s only
    temporary. Everything will return back to normal when the new server comes online.'
  prefs: []
  type: TYPE_NORMAL
- en: With AWS, Auto Scaling and auto healing are extremely important. I’ve seen many
    administrators make the mistake of not utilizing those features of the platform,
    and that should never be the case. Without such high-availability features, you
    risk having your server go away at any moment. This may be a bigger problem than
    you think. AWS consists of physical servers all over the world, and just like
    any other physical server, hardware failures are not only possible but happen
    regularly. If your application is running on a physical host within an AWS data
    center that encounters a hardware failure, your server may get deleted when they
    go and replace it. With Auto Scaling, this isn’t a problem. A new virtual server
    will be brought online to replace the one that was removed.
  prefs: []
  type: TYPE_NORMAL
- en: But without Auto Scaling, this can result in manually having to rebuild your
    server. Don’t worry though, we’ll cover Auto Scaling in this very chapter, so
    you’ll definitely understand how to implement it before we’re done.
  prefs: []
  type: TYPE_NORMAL
- en: The concepts around high availability are not limited to AWS. Similar features
    exist on other cloud platforms as well. The main difference between competing
    cloud providers is the marketing terms they use for these features, but you can
    set up similar infrastructure on each. With AWS, they really focus on this aspect
    though, so it’s important to learn. But even if you’re not utilizing AWS in production
    at your organization, the concepts around being able to easily recover from disasters
    are still important and can still be implemented. If nothing else, you should
    at least consider implementing automation for rebuilding servers so you don’t
    have to do so much manual work if a problem occurs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back to AWS: there are many services within the platform that you can use that
    will provide a variety of features. In fact, there are well over a hundred different
    services within the platform. Therefore, it’s impossible for us to cover each
    in this chapter. It would be difficult to cover every service even in a book dedicated
    only to AWS. But don’t let the number of services overwhelm you; you’ll only need
    to learn about the services that are related to what you’re trying to achieve
    with the platform. For example, if your organization doesn’t develop multiplayer
    computer games, then learning the GameLift service will be of no benefit to you
    at all. In this chapter, we’ll focus on the services required to get you up and
    running with a basic web server running in the cloud. The following services and
    terms will be discussed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Virtual Private Cloud** (**VPC**): A VPC is a higher-level abstraction of
    your overall cloud network and resources. Each of the servers and related services
    you provision will fit within a VPC. You can think of a VPC as your overall network.
    In your organization, you may have various routers, gateways, firewalls, virtual
    machines, printers, or other network-connected devices. Your organization’s network
    is essentially a VPC in AWS, a software version of a complete network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elastic Compute Cloud** (**EC2**): EC2 is the service within AWS that your
    virtual machines will run in. Individual virtual machines within AWS are referred
    to as EC2 instances. You can think of this service as the AWS equivalent of VMware
    ESXi, Microsoft Hyper-V, Proxmox, or whatever virtual machine platform you’re
    more familiar with. EC2 instances, just like a virtual machine, have memory and
    CPU allocated to them and run an operating system. We’ll run Ubuntu in an EC2
    instance before the end of the chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elastic Block Store** (**EBS**): As you learn more about AWS, you’ll notice
    that even the simplest component seems to have a marketing buzzword attached.
    EBS provides block storage, essentially the same type of storage we’ve been working
    with all along. So in a nutshell, an EBS volume is a hard disk. When you create
    an EC2 instance, the operating system for your server will run from an EBS volume,
    and you can set the size of the volume accordingly. We’ll work through this later
    in the chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elastic Load Balancer** (**ELB**): As you may be able to guess from the name,
    an ELB is the AWS equivalent of a load balancer and offers similar features. This
    allows you to have multiple EC2 instances serving your application, and you can
    create an ELB to route traffic between them. ELB is actually a feature of EC2
    and not its own service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identity and Access Management** (**IAM**): IAM is the tool within AWS that
    you’ll use to create and manage user accounts, determine user permissions, and
    even create API keys that can be used to programmatically access and manage AWS.
    Basically, it’s your one-stop shop for all things related to user privileges,
    regardless of whether the “user” is a human or a script.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Route 53**: Although we’re not going to cover Route 53 in this book, I recommend
    at least understanding what it is in case you need it in the future. If you do
    decide to utilize AWS in production, Route 53 will simplify the process of managing
    DNS entries and also registering new domain names. If your organization is a managed
    service provider, you may find yourself using this quite a bit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simple Storage Service** (**S3**): Amazon’s S3 service is another offering
    we’re not going to cover in this chapter, but it’s a good idea to know that it
    exists and what it’s for, in case you find a use for it later. S3 is actually
    a very popular service, and it provides **object storage**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object storage is a new type of storage that is different than a disk (virtual
    or physical) that you add to your server, format, and mount. While you can still
    mount S3 on your server, it doesn’t have a filesystem (such as ext4 or STON),
    nor does it understand permissions. It’s simply a name-object pair, where you
    store files, and they have a name. With S3, you create “buckets,” and each bucket
    can have files stored inside. Each bucket name must be unique. S3 is very useful
    if you want to make downloadable files available to your clients or store backup
    files.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Elastic Kubernetes** **Service** (**EKS**): In the previous chapter, we covered
    Kubernetes and even set up our own cluster. AWS has its own Kubernetes solution,
    called **EKS**. Although we’re not going to cover it in this book, it’s worth
    considering if you want to continue to use Kubernetes and have your containers
    running in a managed service, rather than managing your own cluster. EKS combines
    Kubernetes with the flexibility of the AWS platform, so it’s a very useful service
    to consider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security groups**: Access to many AWS resources from the public internet
    is disabled by default; security groups are used to determine what is able to
    access a resource within AWS, and you can allow or disallow access by IP address
    as well as port. With regard to EC2 instances, outbound access is allowed by default,
    but every port is blocked inbound. You can create a security group that allows
    specific IPs to access the instance, which increases security. We’ll see an example
    of this later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have some basic understanding out of the way, we can get started
    and build an application in the cloud, running on AWS.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an AWS account
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in the previous section, a VPC within AWS represents a high-level
    abstraction of your overall network. All of the resources that we create will
    run inside a VPC. Therefore, we’ll need to create a VPC first before we can create
    an EC2 instance and deploy Ubuntu.
  prefs: []
  type: TYPE_NORMAL
- en: Before we can create a VPC though, we’ll need an AWS account. Before this chapter,
    I typically advised you to use whatever hardware you have available in order to
    create Ubuntu installations to work with the platform. This time, we’re going
    to utilize an actual cloud provider, which comes at a cost. While there are free
    components available for a limited time with a new account, it’s up to you, the
    reader, to keep track of billing. We’ll discuss costs in greater detail later
    in this chapter. But as a general rule of thumb for now, always use whatever the
    cheapest option is. If a free instance type is available, go with that. Of course,
    if you’re intending to deploy actual resources for production use within an organization,
    then you’ll want to choose whatever instance type is appropriate for the use case.
    For our purposes, we’re just learning the platform for the first time, so be sure
    to go with the lowest-cost resources available and delete everything when you’re
    done.
  prefs: []
  type: TYPE_NORMAL
- en: That last point is especially important – the free tier is not unlimited, and
    if you forget to delete something, you might receive a bill at some point. What
    I recommend is to keep a running list of everything you create in AWS, so you
    have a list of things to delete if you don’t wish to continue using the platform.
  prefs: []
  type: TYPE_NORMAL
- en: You should also remove any snapshots/storage volumes, or anything else that
    you end up creating. Better yet, if you aren’t going to use the AWS account in
    production, you can simply delete the account so that it doesn’t continue to bill
    you. If ever in doubt, be sure to consult the documentation for billing within
    AWS itself.
  prefs: []
  type: TYPE_NORMAL
- en: Signing up for AWS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now it’s time for us to create our own AWS account. In this section (and in
    each of the remaining sections of this chapter) I’ll walk you through each step
    when it comes to navigating AWS. It’s important to keep in mind that the **AWS
    Management Console** that we’ll be navigating has a history of changing quite
    often. In fact, the console has changed no fewer than twice since the previous
    edition of this book was written, and that’s not even counting the fact that in
    the third edition, the interface changed in the middle of writing the previous
    version of this chapter. The screenshots and walkthrough are accurate as of the
    time this chapter has been written, but it’s always possible (and quite likely)
    that the interface will be updated *again* at some point. That said, if the screenshots
    or layout have changed, you should still be able to follow the instructions here
    since the verbiage generally doesn’t typically change, just the layout. With that
    said, let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, navigate to [https://aws.amazon.com](https://aws.amazon.com) and
    you should see an orange button in the upper-right corner with the label **Create
    an AWS Account**. It’s possible that the layout of the page may change after publication,
    but you should see a button to create a new account somewhere on the page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.1: The AWS main page'
  prefs: []
  type: TYPE_NORMAL
- en: 'When you click the button to create a new account, a form will appear asking
    you for basic information. An example of some of the fields you may be asked for
    is shown in *Figure 19.2*, though the exact information you may be asked for may
    vary. Fill out each field accordingly, then click **Continue**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.2: Signing up for a new AWS account'
  prefs: []
  type: TYPE_NORMAL
- en: 'After you click **Continue**, another screen will appear asking you to fill
    out additional fields, such as your full name, company name, address, and so on.
    This process will also include asking you to provide credit card details as well,
    so proceed through each screen and enter the required information. At the end
    of the process, you’ll see a selection where you can choose your support plan:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.3: Choosing a support plan while signing up for an AWS account'
  prefs: []
  type: TYPE_NORMAL
- en: If you are asked to select a support plan during the process, choose the one
    that makes sense for your use case. If you’re going to be using AWS to create
    production instances for your organization, the Developer or Business plan may
    offer additional value to you. If you’re only going through the process to learn
    AWS and work through the examples in this chapter, choose the Basic plan.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’ve finished the process of creating your new account, it may take
    some time before your new account is ready. When it is, you should receive an
    e-mail saying that it’s ready for use. After you do receive that e-mail, you’ll
    be able to log in. To do so, navigate to [https://aws.amazon.com](https://aws.amazon.com)
    and click the **Sign In to the Console** button, which will bring you to another
    page where you can type in your account login info:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.4: Signing in as Root user'
  prefs: []
  type: TYPE_NORMAL
- en: Here, you have a choice to log in as the root user or an IAM user. We haven’t
    created any IAM users yet, so we only have a root user at this point. The root
    user is accessed by signing in with the same e-mail address that you’ve provided
    during the sign-up process. Enter that e-mail address in the prompt, click **Next**,
    then enter your password on the next screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'If all goes well, you should be logged in and see the **AWS Management Console**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.5: The AWS Management Console main screen'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have access to the management console, you can begin using AWS.
    Before we start creating cloud resources, we should implement some basic security
    to protect our account.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing basic user security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we continue any further, there are some very important security best
    practices we should employ regarding the ability to authenticate to our AWS account.
    Although it’s very likely that our new account was created as a test account for
    following along with examples in this chapter, we should make it a habit to always
    protect our AWS account, regardless of how important it actually is.
  prefs: []
  type: TYPE_NORMAL
- en: We can begin with protecting the root account, as it’s a common target for hackers.
    Specifically, we should enable two-factor authentication for this account. Doing
    so will make it much harder for an outside threat to access it, since they would
    need access to your second factor in addition to your password. Since we’re already
    logged in as the root user at this point, we can set this up immediately.
  prefs: []
  type: TYPE_NORMAL
- en: In the management console, you’ll see a search field near the top of the screen.
    If you already know the name of the service you would like to configure, you can
    begin typing its name in the search field, and if your query matches an available
    service, it will show it in the list. If you don’t know the name of the service
    you’d like to use, you can click on **Services** in the top-left corner of the
    console, to see a complete list of the services available.
  prefs: []
  type: TYPE_NORMAL
- en: 'For setting up second-factor authentication, we will access the IAM service.
    You can start typing `IAM` into the search field, and it should show it as an
    available option. Go ahead and click on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.6: Using search within the AWS Management Console to locate the IAM
    service'
  prefs: []
  type: TYPE_NORMAL
- en: When the IAM dashboard appears, you may see a security alert that complains
    about the root user not having **Multi-Factor Authentication** (**MFA**) enabled.
    Although enabling this feature is optional, I recommend you enable it.
  prefs: []
  type: TYPE_NORMAL
- en: 'MFA is critical for ensuring the security of any account that is important
    to your organization, especially an account for a cloud computing provider such
    as AWS. MFA will enhance the security of the account in terms of authentication,
    requiring an additional factor before a user will be able to access the account.
    The root account is the most critical account to protect in AWS, since it has
    full access to every available service. To enable MFA, click on the button that
    reads **Add MFA** (or similar verbiage if the layout on this page changes):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.7: IAM dashboard, with an alert that MFA is recommended to be set
    up'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click on **MFA** to expand it (if it isn’t already), and then click on
    the **Activate MFA** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.8: Setting up MFA (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next screen will give you a choice of which type of device to use to facilitate
    MFA. The default (**Virtual MFA device**) is a good one to go with if you don’t
    have a physical hardware key, such as a YubiKey. If you have no other preference,
    choose the **Virtual MFA device** option and click **Continue**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.9: Choosing a type of MFA device to set up'
  prefs: []
  type: TYPE_NORMAL
- en: To set up your virtual MFA device, you’ll need to download a second-factor application
    to serve this purpose. Google Authenticator is a popular choice here, but I recommend
    Authy instead. Both are perfectly acceptable, but Authy also features a desktop
    app you can use, as well as the ability to recover your account if your primary
    device is not accessible for any reason. Authy is compatible with Google Authenticator,
    so you can typically use it with services that offer a Google Authenticator option.
    To continue, reveal the QR code, scan it with your phone app, and then type in
    two subsequent values generated by the app.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, click **Assign MFA** to finalize the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.10: Setting up the MFA device'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have two-factor authentication enabled for our root account, we
    should stop using that account immediately. This is actually a best practice when
    it comes to AWS; it’s recommended that you create individual accounts for the
    individuals that will work on your AWS account, giving them the permissions they
    need to perform the tasks they need to complete. We’ll discuss the **principle
    of least privilege** in *Chapter 21*, *Securing Your Server*, but it doesn’t hurt
    to start thinking about the concept now. For now, what we’ll do is create an administrator
    account for ourselves that we can use in place of the root account. We can always
    use the new account to create additional users if we need to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a new administrator account, we will again utilize the IAM console.
    Once there, you’ll see a **Users** link on the left, and then you can click the
    blue **Add users** button to begin the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.11: Setting up a new administrative user for AWS'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next screen will have you type the desired username, as well as setting
    **Access Type**. For the username, you can name the user whatever you’d like.
    For **Access Type**, we’ll choose **AWS Management Console access**. Click **Next:
    Permissions** to continue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.12: Setting up a new administrative user for AWS'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will set up the appropriate permissions for our user. The third icon,
    labeled **Attach existing policies directly**, is the first selection we’ll make
    here, and then below that we’ll place a mark next to the check box for **Administrative
    Access**, and then we’ll click **Next: Tags**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.13: Setting up a new administrative user for AWS (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can skip the tags screen by leaving the fields blank and clicking **Next:
    Review**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next screen will provide us with an overview, and if everything appears
    to be correct here, we can click **Create user**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.14: Setting up a new administrative user for AWS (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we’ll see a confirmation message that our user was created. If you
    chose to have a randomly generated password during the process, you should also
    see a button there to retrieve it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.15: Setting up a new administrative user for AWS (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: You can now log in to the AWS Management Console with the new user and the password
    that was provided. You will also need the **account ID**, which is visible within
    the URL on this screen (it’s the number right after `https://`). To make it easier,
    you can click on the URL that’s shown in order to have the account ID autofilled.
  prefs: []
  type: TYPE_NORMAL
- en: Going forward, I recommend that you use the new user we’ve created for managing
    the AWS account, as it’s a good practice to not use the root account unless you
    absolutely have to. In addition, I recommend you follow the procedure to set up
    MFA as we did earlier, but this time with the new user.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a region
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed earlier, a VPC within AWS is the high-level abstraction of your
    overall network. You can have multiple VPCs, which is similar to the concept of
    managing several physical networks. In fact, we already have VPCs created for
    us in our account, so we won’t need to create one. In the future, keep in mind
    that creating additional VPCs is an option, should you ever need to have more
    than one. In our account, we have a default VPC in each **Region**, so choosing
    which one to utilize comes down to which region is most appropriate for our use.
  prefs: []
  type: TYPE_NORMAL
- en: For production use, you’ll want to create instances in AWS that are as close
    to your customer as you can get. For example, let’s say that the customers that
    your organization markets to are primarily located in the Eastern United States.
    There’s a region available within AWS that is available that’s labeled **US East**,
    so that would be an obvious choice in that scenario. You’re not limited to regions
    within the USA though; there are regions available all over the world, such as
    in Germany, China, and Canada (among others). In a nutshell, you’ll want to create
    resources as close to your customers as possible. If you don’t have a preference,
    you can choose to utilize whichever region is closer to you.
  prefs: []
  type: TYPE_NORMAL
- en: Although it’s beyond the scope of this book, AWS offers a service called **CloudFront**
    that acts as a **Content Delivery Network** (**CDN**) that you can use to make
    your resources available in various edge locations that users can be routed to
    in order to ensure they’re retrieving your content from a location closest to
    where they are geographically. For organizations that produce media content, this
    is especially valuable. If this is something that might benefit you, I recommend
    reading more about CloudFront.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, there are often multiple **Availability Zones** within various
    regions, which allow you to get even closer to your target audience. For example,
    when it comes to the US East region, there are two availability zones inside it,
    one in Virginia as well as another in Ohio. Availability zones not only give us
    the ability to get another step closer to our customers but also offer us additional
    options for redundancy. For example, if one availability zone goes down for whatever
    reason, you can route your customers to another. Availability zones have a specific
    naming syntax that consists of both the name of the region as well as the availability
    zone within that region. Using the Eastern United States as an example again,
    the two availability zones there are labeled **us-east-1** for Virginia and **us-east-2**
    for Ohio. Not all regions will have multiple availability zones, though. Canada
    currently only has one region with one availability zone: **ca-central-1**.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to availability zones, there are also **local zones**, which are
    intended to allow you to set up resources even closer to your customers than availability
    zones are able to get. Local zones are a great choice if your application is sensitive
    to network latency, such as running a server for an online game. We won’t go over
    local zones in this book at all, because this is a very new offering from AWS,
    and there are only two of them in existence as of the time this book is being
    prepared for publishing. Amazon intends to add additional local zones in the future,
    so there may be more of them available by the time you’re reading this. If your
    organization offers a service that is sensitive to network latency, this may be
    a feature you’ll want to keep up to date on as they roll it out to more locations.
  prefs: []
  type: TYPE_NORMAL
- en: For now, the only consideration is which region will benefit your customers
    by being as close to them as possible. When it comes to following along with the
    examples in this book though, choosing a region closest to you geographically
    is a good idea.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve selected our region, how about we create an actual Ubuntu instance
    in the cloud? That’s exactly what we’ll do in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Ubuntu as an AWS EC2 instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With a great deal of discussion out of the way, it’s time to create an actual
    Ubuntu deployment in the cloud. This will allow us to see the AWS service in action
    and give us some working experience with the EC2 service. This requires two individual
    steps: the first to create a required IAM role and the second to create our instance.
    Let’s first make sure we understand the requirements of the IAM role, then we’ll
    set up the role and then create our new instance.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an IAM role for Session Manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Session Manager** is a service within AWS that we can use to access a command
    prompt for our instance. It’s actually part of **Systems Manager** and not its
    own service. If you want to access Session Manager, you will need to search for
    Systems Manager, and you’ll find Session Manager as a service underneath that.
    You’ll see this shortly.'
  prefs: []
  type: TYPE_NORMAL
- en: Why should we use Session Manager? Just like with any other Linux server, we
    can still use OpenSSH to connect to the EC2 instance we’ll be creating, just as
    we have many times while working with non-AWS instances throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: There’s nothing wrong with using OpenSSH; with the right settings it can be
    a very secure option. In fact, we will explore methods of better securing it in
    *Chapter 21*, *Securing Your Server*. With AWS, we can use Session Manager as
    an alternative to OpenSSH, and it’s a worthwhile alternative to learn that offers
    additional security in that its backend security is not something we have to manage
    ourselves. In addition, we can control access to it through the AWS console as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: By default, Session Manager is not accessible at all. It requires a specific
    package to be installed within Ubuntu Server for it to work, and it also requires
    specific permissions to be enabled. The required package for Ubuntu is preinstalled
    by default, so the first requirement will be automatically taken care of for us
    immediately when we create our instance.
  prefs: []
  type: TYPE_NORMAL
- en: For the second requirement of adding permissions, we’ll need to create an IAM
    role to allow the EC2 instance we’re about to create to communicate with the Session
    Manager service. When I mentioned earlier that Session Manager isn’t accessible
    by default, this is why—it’s missing the permissions needed until we add them.
    To add the required permissions, we’ll access the IAM service within the AWS console,
    the very same one that we used earlier to create a user account for ourselves.
    IAM itself has many tricks up its sleeves, more than just simply allowing us to
    create users. It also allows us to create **IAM roles**, which give us the ability
    to add permissions to entire objects. For example, we can create a role with the
    permissions that are required, and then we can attach that role to any EC2 instance
    to immediately give it the ability to be connected to by Session Manager.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started and set up the required IAM role for Session Manager. Return
    to the IAM section of the AWS console that we’ve worked with a few times now,
    and we’ll create the required role.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the IAM menu on the left side of the window, click on **Roles**, and then
    click on the blue button labeled **Create role**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.16: Creating an IAM role to enable Session Manager'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next screen, make sure **AWS service** is selected, and in the menu
    below that, choose **EC2** as the service. Click **Next** to continue along:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.17: Creating an IAM role to enable Session Manager (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are able to attach policies to our role. In the search field that appears,
    we can type a keyword to narrow down the list, and then click on a checkbox next
    to a policy we wish to attach to our role. A full overview of all of the built-in
    policies and what they’re for is beyond our scope, but as a short summary, each
    service within AWS has pre-built policies that can be attached to a role, which
    allows access to various features. Specific to our needs, we will add the **AmazonSSMFullAccess**
    policy to the role we’re creating.
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of this will become clearer when we create our EC2 instance, so
    for now, click **Next** to continue on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.18: Attaching the AmazonSSMFullAccess policy to our role'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next screen that will appear will give us the ability to add one or more
    tags. We’ll skip this for now, but you can feel free to add any tags you’d like
    here. Tags allow you to attach information to a resource and aren’t limited to
    IAM roles. You can add any descriptive information you feel is pertinent, if you
    wish. Tags are simply **key: value** pairs, so there’s no specific naming scheme
    to follow here. Add tags if you wish to do so, and when you’re finished with this
    screen click **Next: Review**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The final screen will give us a review of the settings we’ve chosen so far,
    as well as an option to name the role, and add a description if we wish to do
    so. Although it’s optional, I recommend giving the role a name, to make it easier
    to identify later. When you’re finished, click **Create role**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.19: Adding a name and description to our role'
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to setting up our IAM role, we’re all set—the role has been created
    and we can go ahead and use it. Next, it’s time to create our Ubuntu instance.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Ubuntu Server instance in AWS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now it’s time to see our work come together and create our Ubuntu instance.
    In the AWS console, we should first access the EC2 service to get started. You
    can easily find any service by typing its name into the search box within the
    console; so if you start typing EC2 into that field, you should see **EC2** on
    the list. After you click on that, click on **Instances** on the left side of
    the screen. After doing that, you’ll see a screen with a button labeled **Launch
    instances**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.20: The main window of the EC2 service'
  prefs: []
  type: TYPE_NORMAL
- en: 'Normally, the **Instances** section of the EC2 console will show us a list
    of all of our server instances, but unless you’ve read ahead, we don’t have any
    yet so the window is blank. When you click on **Launch instances**, you’ll see
    various operating systems in the list. But for our purposes, Ubuntu is shown in
    the **Quick Start** section, so we’ll select that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.21: The Ubuntu option for EC2'
  prefs: []
  type: TYPE_NORMAL
- en: 'Further down, make sure that **t2.micro** is selected, which should show the
    verbiage **Free tier eligible** alongside it. That’s the instance type that we’ll
    want to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.22: Choosing an instance type'
  prefs: []
  type: TYPE_NORMAL
- en: On the **Choose an Instance Type** screen, there will be quite a few instance
    types from which to choose. I selected the **t2.micro** instance type, and I recommend
    you do the same. It’s eligible for the free tier, which is a special tier you’ll
    have access to within the first 12 months of the age of the account. You most
    likely wouldn’t choose this instance type for a production server, as it will
    be quite slow—it only has 1 CPU and 1 GiB of memory. And it’s a burstable instance
    type, which means the speed fluctuates based on usage. It’s able to burst to take
    care of busy workloads, but its ability to do so depends on CPU credits that it
    earns in a particular time. A full explanation is beyond the scope of this chapter,
    but if you’re going to use AWS in production, it’s a good idea to read about the
    various instance types available. Although you don’t see it in the screenshot,
    you should also see the cost on this page as well. But again, we’ll utilize the
    free tier for now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Further down the page, you’ll generate a new key pair, assuming you don’t have
    one already. This will be used for connecting to the instance via SSH. To generate
    a new key, click **Create new key pair**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.23: Key pair settings during instance creation'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next screen that appears will allow us to configure the key, such as setting
    encryption options. For our purposes, we can leave the defaults as is after giving
    the key a name, and then we can click **Create key pair**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.24: Customizing our SSH key'
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous step will trigger your browser to download the SSH key that you’ve
    generated. Be sure to keep it in a safe place. You can use the key you’ve just
    downloaded to connect to your instance via OpenSSH with a command similar to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For me, if I add the path of my key as well as the public IP address listed
    for my instance, the command becomes this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: From here, managing the server is just a matter of interacting with its shell
    and entering commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'But anyway, I’m getting ahead of myself. After you safeguard your key, we can
    move on to the next section by scrolling down. Network settings are what we’ll
    work on next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.25: Setting options for our new EC2 instance'
  prefs: []
  type: TYPE_NORMAL
- en: The first consideration on this screen is where we’ll allow OpenSSH connections
    from. The default option, `0.0.0.0/0`, allows connections from anywhere (and is
    even labeled as such). As we’ll discuss in *Chapter 21*, *Securing Your Server*,
    allowing SSH connections publicly is a bad idea, since outside threat actors might
    try to use that as a means to access the server. With the instance we’re creating
    right now, we can make a case for allowing connections from anywhere, since it’s
    a test instance for the purposes of learning (and we’ll be deleting the instance
    before the close of the chapter). However, it might be a better idea to get into
    the habit of restricting access to OpenSSH to specific IP addresses. To do that,
    you can choose the option **My IP** from the dropdown, which will restrict access
    to OpenSSH to your public IP address.
  prefs: []
  type: TYPE_NORMAL
- en: If you do choose to restrict access, keep in mind that unless your public IP
    is static, it can change at any time. When it does, you’ll lose access to your
    EC2 instances via OpenSSH. You can regain access by updating the security group
    for the instance to include your new IP address, but that inconvenience is a small
    price to pay for added security benefit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing in that same section, we have an option to allow traffic in addition
    to OpenSSH:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.26: Network settings while creating an EC2 instance on AWS'
  prefs: []
  type: TYPE_NORMAL
- en: The other options, **HTTPS** and **HTTP** respectively, are essential if you’re
    planning on setting up a website on the instance. It’s very common to restrict
    OpenSSH on a web server, while at the same time allowing full access to ports
    `80` and `443` from the public `internet`. The reason for this is, OpenSSH gives
    you access to manage the server, so we definitely wouldn’t want that open to the
    public. When it comes to a website, we’ll most likely want the general public
    to be able to access it, which is why we allow those options. You should only
    check the latter two boxes in the situation where you’re actually planning on
    setting up a web server. For our needs, we should allow these boxes, since we
    will be installing Apache later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we’ll configure the **storage** for our instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.27: Storage options while creating an EC2 instance'
  prefs: []
  type: TYPE_NORMAL
- en: By default, your EC2 instance will be set up with 8 GiB of storage space. As
    indicated in the highlighted message on the screen, you can get up to 30 GB of
    EBS storage space as part of the free tier, if you’re eligible. For that reason,
    you can consider setting this higher. You can also add additional storage volumes
    to the instance, which might help if you wanted to segregate storage between block
    storage devices. We shouldn’t need that for our use case in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below that, the final section on this screen allows you to configure **Advanced
    details**. There are quite a few extra options here, but we’ll be ignoring all
    but one of them. At the very bottom, there’s a large text box labeled **User data**.
    This is the only option within the advanced details section we’ll change:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.28: Adding user data for our EC2 instance'
  prefs: []
  type: TYPE_NORMAL
- en: The **User data** section is often overlooked, but it’s *incredibly* useful.
    But what exactly is this for, and what does it do? If I didn’t know any better
    myself, I’d probably assume that this is where you’d add information that pertains
    to your users. But that’s not what it’s for. What**User data**allows you to do
    is add a series of commands, or even a full script, that you’d like to have executed
    as the instance is created.
  prefs: []
  type: TYPE_NORMAL
- en: Already, you can think of any command you might run, or configuration you might
    tweak, any time you set up a server. Instead of manually executing setup commands
    after the instance is online, you can simplify this quite a bit and have much
    of that done automatically before you even log in for the first time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In my case, I’ve added the following code to the **User data** field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If you think the code that I’ve added resembles a Bash script, then you’re
    correct—that’s exactly what it is. I added four lines of Bash statements to the
    **User data** field, to have some commands run automatically. The code should
    be relatively straightforward: I have it set up to update the repository index,
    then perform a full system upgrade.'
  prefs: []
  type: TYPE_NORMAL
- en: This is important; we always want our servers to start with the latest patches
    available. As a proof of concept, I added a statement to install Apache. Notice
    that I included the `-y` option to all of the `apt` commands. This automatically
    responds “yes” to any question `apt` may ask, since we don’t have a display hooked
    up to this server and are unable to answer questions ourselves. Without that option,
    the user data will fail to apply.
  prefs: []
  type: TYPE_NORMAL
- en: Anyway, the moment of truth is here – it’s time to launch our instance, and
    we can do so by clicking the **Launch instance** button near the bottom of the
    page. Assuming we didn’t forget anything along the way, our new Ubuntu Server
    cloud instance is moments away from existing!
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we should see the new instance in the list of EC2 instances
    in our account, and it will take some time for it to be ready for use. When the
    status indicates that the instance is **Running**, then that means it’s ready
    for us to connect to:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.29: Checking the status of our EC2 instance'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to set up a connection so we can manage the instance, we’ll need to
    change the **IAM role** for the instance. If you recall, we created an IAM role
    earlier, and this is where we’ll attach that role to our new instance. This will
    ensure that the settings within the role are applied to the instance, which in
    turn will give us access to Session Manager for connecting to that instance. To
    change the IAM role, we’ll check the box to the left of the instance, then click
    on **Actions** at the top of the screen. In the menu that opens, click on **Security**,
    and then **Modify IAM role**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.30: Navigating to the IAM role settings for an EC2 instance'
  prefs: []
  type: TYPE_NORMAL
- en: 'The screen that follows is where we’ll change the IAM role to the one we created
    earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.31: Changing the IAM role of an instance'
  prefs: []
  type: TYPE_NORMAL
- en: 'After you click **Update IAM role**, you’ll be brought back to the list of
    current EC2 instances. If you click on the blue instance ID text near the name
    of the instance, you’ll be taken to a screen where you can customize additional
    options for the instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.32: Additional EC2 instance settings'
  prefs: []
  type: TYPE_NORMAL
- en: 'Among the various items on the page, of special interest to us is the **Connect**
    button. If we click on that, we’ll begin the process of setting up a remote connection
    we can use to manage the instance. On the screen that appears, click on the **Session
    Manager** tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.33: Preparing a session to connect to an instance'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you click the **Connect** button, a new browser window will appear that
    you can use to issue commands to your instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.34: An instance session open within a web browser'
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 19.34*, I entered the following command in order to display details
    for the version of Ubuntu that was deployed in the instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `/etc/os-release` file is included with all Ubuntu installations, and as
    you can see from the output, it contains some information regarding the version
    of Ubuntu we’re running. That command was entered directly into the Session Manager
    window, to show that the connection is actually working and we can now configure
    the instance right from within our web browser!
  prefs: []
  type: TYPE_NORMAL
- en: 'If you recall, we added **User Data** earlier, and that included a command
    to install Apache. If you enter the public IP address of your EC2 instance into
    a web browser, you should see the default Apache web page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.35: The Apache default web page running on an EC2 instance'
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You’ve successfully deployed Ubuntu Server to the cloud, and
    now have an actual web server running on it. That’s all there is to it. Using
    Session Manager is also simple; all you need to do to customize the server further
    is right-click on it, click **Connect**, and you can then continue to build the
    instance. That’s awesome!
  prefs: []
  type: TYPE_NORMAL
- en: What’s not so awesome, though, is when something happens to your server and
    you have to start over and rebuild it from scratch. In the next section, we’re
    going to explore the process of creating an image of the server that we can utilize
    to deploy customized versions of Ubuntu.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and deploying Ubuntu AMIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just about every cloud platform I know of includes some sort of feature that
    can be used to create images of the instance’s hard disk. An image can be used
    to create copies of the original server, as well as acting as a starting point
    so if the server needs to be rebuilt, we won’t have to start over from scratch.
    In AWS, images are known as **Amazon Machine Images** (**AMIs**). For all intents
    and purposes, there’s nothing very unique about AMIs; if you’ve worked with disk
    images in the past, it’s the same thing. When it comes to what to include in an
    AMI, you can (and should) use your imagination here—anything you find yourself
    manually setting up or configuring while rolling out a new server is a candidate
    to be included in an image, and the more customizations you include inside the
    image, the more time it will save you later.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see this in action and create an image of the server we’ve just set up.
    We should consider shutting down our server first, although this isn’t required.
    Taking an AMI of a server that is shut down is preferred over doing the same on
    a server that is running. When the server is shut down, nothing is writing to
    its disk, so we don’t have to worry about corruption if we’re capturing an AMI
    in the middle of a critical write operation. The likelihood of running into an
    issue while creating an AMI of a running server is very small, but I recommend
    shutting down the server if you can just to be on the safe side.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the EC2 console of AWS, you can right-click on the instance to access **Session
    Manager**, and then you can simply power it off from the command prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In AWS, it can take a minute or two for an instance to power down. You can
    refresh the page after some time, and the status should change to **Stopped**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.36: Checking the status of an EC2 instance'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the instance has stopped, you can right-click on it to begin the process
    of creating an AMI. Hover over **Image and templates** and then click **Create
    image**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.37: The Apache default web page running on an EC2 instance'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can enter some details about our AMI. Give it a name and a description.
    This information will help others you work with understand what the image is for,
    and it can also help you remember why you’ve created the image later on down the
    road. There are other options on this page, but we can leave the rest as is. A
    name and description should be good enough for now. Once you’re finished, click
    **Create image** to continue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.38: Creating a new AMI'
  prefs: []
  type: TYPE_NORMAL
- en: 'Believe it or not, that’s all there is to it. The process of creating an AMI
    is very straightforward, with just a few steps. You should now see a confirmation
    screen, letting you know the image is in the process of being created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.39: Confirmation while creating a new AMI'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on the underlined text that contains the AMI ID, you’ll be directed
    to the AMI section of the EC2 console, where it will show your image on the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_40.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.40: Our newly created AMI, available for use'
  prefs: []
  type: TYPE_NORMAL
- en: In the AMI section of the EC2 console, you should see the list narrowed down
    to just the AMI we created just now. We only have one AMI anyway, unless you created
    multiple AMIs for practice. At the end, the **Status** column should read **available**
    if the AMI is ready for use. If not, give it some time, and refresh the page later.
    Sometimes it can take a few minutes. But with regard to creating an AMI, that’s
    it!
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an AMI, how do we go about using it? Well, that’s even easier
    actually. Simply right-click on the AMI on the list and click **Launch**. You’ll
    see the same launch settings we worked through earlier when we originally created
    the instance, but this time, we’re using our own AMI instead of the one provided
    to us. And now, we have our own custom AMI of Ubuntu with Apache built in that
    we can use to simplify our process a bit. Keep in mind, though, that our original
    instance is still stopped. You can return to your list of EC2 instances and start
    it by right-clicking on it, then clicking **Start**, but you don’t have to; we’re
    going to work through a fun automation example shortly.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’re going to take a look at the concept of Auto Scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Automatically scaling Ubuntu EC2 deployments with Auto Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we maintain one or more servers for our organization, it’s hard to predict
    sometimes what the demand will be on that server. In the case of a popular news
    site, some articles may be more popular than others, and if something goes viral
    online, then requests to our site can increase by orders of magnitude in a short
    period of time. In the past, keeping up with customer demand was a very tedious
    process, one that may result in having to purchase an entirely new server with
    more powerful hardware. With our instance being in the cloud, we have more flexibility
    and can automate the process of bringing more servers online. And that’s exactly
    what we’re going to work on in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get started, keep in mind that we don’t actually have a popular server
    in AWS; we only have a simple test server that’s currently running Apache. We
    can simulate things to a point, but **Auto Scaling** is one of those things that
    requires a bit of practice to fully utilize. We will definitely get a working
    example here, though.
  prefs: []
  type: TYPE_NORMAL
- en: 'But another important thing to keep in mind is that the more instances we run,
    the higher the potential cost. We’ll explore how to keep costs down in the next
    section, but as a general rule of thumb, delete whatever you’re not using. As
    you’ve gone through examples in this chapter, we’ve set up our own EC2 instance.
    This is great: we were able to practice some concepts around AWS and put that
    to use. But if we leave something running that we don’t need, we can have a surprise
    bill. It’s a good idea to write yourself a reminder to delete everything in your
    test AWS account when we’re done with the chapter, so you won’t have to worry
    about that.'
  prefs: []
  type: TYPE_NORMAL
- en: Continuing, one of the requirements of Auto Scaling is that we have an AMI ready
    that it will use to bring additional servers online. Since we’ve worked through
    creating an AMI in the previous section, we already have that requirement met.
    If you haven’t already worked through the previous section, make sure you do so
    before we continue. The process of setting up Auto Scaling involves a handful
    of steps, and we’ll work through each in their own subsection within this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a launch template
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier in the chapter, we walked through the process of creating a new EC2
    instance. We chose the option to launch an instance, and then configured various
    settings within multiple screens we worked through. We chose Ubuntu as our platform,
    added user data, and set an IAM role (among other things). What a **launch template**
    does is allow us to automate these choices. A launch template gives us the ability
    to automate the entire launch process.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the left-hand menu of the EC2 console, there will be a link titled **Launch
    Templates**. Click on it. Once you do, you can click on the orange button labeled
    **Create launch template**. You’ll then see a form you’ll need to fill out, where
    you select all the defaults for the launch template. There’s no screenshot on
    this page, because it’s quite long and won’t fit on one page. Instead, I’ll include
    the relevant options below, with a short description and a recommendation regarding
    what to set the option to:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Launch template name**: This is simply a name for your launch template; set
    it to the name you feel is most appropriate. Note that this cannot contain spaces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Template version description**: For the description, you can add some details
    that you think are relevant to the purpose of the launch template.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon Machine Image** (**AMI**): Choose the AMI that you created in the
    previous section. You should see it listed if you click on the **My AMIs** tab,
    and ensure **Owned by me** is selected. This will narrow down the list of AMIs
    quite a bit, and since we’ve only created one AMI, it should be easy to find.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Key pair** (**login**): When you created the EC2 instance earlier, it had
    you create an OpenSSH key pair. If you drop down this list, that same key pair
    should be available. Choose that same key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instance type**: If you recall, we chose t2.micro as the instance type earlier.
    That’s a good selection for this field as well, since t2.micro is eligible for
    the free tier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security groups**: Earlier, when we added a security group, we set it up
    to allow OpenSSH and Apache. Feel free to choose that same security group for
    this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IAM instance profile**: This option is a bit hidden, but you should see it
    as soon as you expand **Advanced details** near the bottom. Although this is optional,
    it’s a good idea to select the IAM profile we created earlier, to ensure we have
    access to Session Manager for each instance the launch template creates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With all of those details set, click **Create Launch Template** near the bottom
    of this screen. Now we have our launch template created and configured, and we
    can use it as part of the Auto Scaling feature we’re in the process of building.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Auto Scaling group
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our next requirement is to create an **Auto Scaling group**, which will be a
    shorter process than setting up the launch template. An Auto Scaling group is
    a logical group of instances that are related to the overall application. We will
    add our launch template to this group and use it to customize requirements such
    as how many instances to have online.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back in the EC2 dashboard, you’ll find an option for creating Auto Scaling
    groups in the menu on the left side of the screen, closer to the bottom. Once
    there, give it a name:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.41: Naming the Auto Scaling group'
  prefs: []
  type: TYPE_NORMAL
- en: 'Further down on that same screen, we will choose the launch template we created
    earlier. Go ahead and do so, and then click **Next**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_42.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.42: Selecting a launch template for our new Auto Scaling group'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next screen, several additional sections worth of options will appear.
    The first of which will have you configure some defaults around networking. For
    the VPC, you can leave that as is, and for the availability zone, you can simply
    choose the first on the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_43.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.43: Creating an Auto Scaling group (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing, the next section will ask us about our preference around instance
    types. On my end, I chose the **Manually add instance types** option, and then
    **t2.nano** as the instance type:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.44: Creating an Auto Scaling group (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’re finished choosing your instance type(s), there’s nothing left for
    us to do on this particular page, so click **Next** to continue. This will take
    you to another section, this time asking you if you want to create a load balancer.
    In the first section of this screen, choose to **Attach to a new load balancer**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.45: Creating an Auto Scaling group (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: A **load balancer** allows us to route clients between multiple servers, so
    the end-users only see one endpoint, but behind the load balancer we can have
    more than one server available to serve client connections. This is going to be
    key to setting up our auto-scaled test site, so we’ll definitely want to configure
    this.
  prefs: []
  type: TYPE_NORMAL
- en: 'After choosing to create a new load balancer, we can configure additional options
    in the next section. Most of these options we’ll leave at their defaults, but
    there are a few things we’ll want to pay attention to:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load balancer type**: By default, **Application Load Balancer** should be
    selected. If it isn’t, then make sure that’s the highlighted option before continuing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load balancer name**: This is simply a name for your load balancer; set it
    to the name you feel is most appropriate. Note that this field is somewhat limited
    on what types of characters it will accept, so it’s best to keep the name simple.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Availability Zones and subnets**: We’ll need at least two availability zones
    for the load balancer, and one will be chosen for you already. The quickest way
    through this section is to enable the next availability zone in the list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are other options on this screen, but the next thing we’ll be doing is
    creating a **target group**, which is directly underneath the availability zone
    options. There, we’ll choose to create a **target group**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_46.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.46: Creating an Auto Scaling group (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: 'A **target group** is a logical grouping of EC2 instances that serve a common
    goal. A load balancer will send traffic to a target group, and instances within
    that group will answer the request. If an instance is not a member of a target
    group, then it won’t be a part of our application. It’s not uncommon for an organization
    to have more than one app, and as a result, several target groups. After you choose
    to create a target group, you can accept the default name if you wish, and then
    we should be finished with configuring our auto-scaling group. Click **Next**
    to continue, which will bring us to a section where we can configure our **scaling
    policy**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_47.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.47: Creating an Auto Scaling group (continued)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where the magic happens: we can choose the minimum number of instances
    to have running at any one time and the maximum number of instances we will allow
    the application to scale up to. We can leave each field at **1** for now.'
  prefs: []
  type: TYPE_NORMAL
- en: That should be about all we’ll need to configure for our auto scaling group.
    You can click **Skip to review** to take a shortcut that will take you to the
    final screen of the process, which will show you an overview of your selections.
    If you’re satisfied with the settings that are shown, you can finalize the process
    by clicking **Create Auto Scaling group**.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, our Auto Scaling group is created, and we should have everything
    ready to go. At first, we’ll have **0** instances within this group, so we’ll
    see the current number of instances shown as **0**.
  prefs: []
  type: TYPE_NORMAL
- en: 'After it finishes updating capacity, it will automatically spin up a new EC2
    instance in order to meet our requirement of always having one instance online.
    If we check our list of EC2 instances, we should have a new one on the list now:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.48: A new instance was created as part of our Auto Scaling configuration'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the screenshot, the original EC2 instance has a state of **Stopped**.
    We stopped it earlier so that we could create an AMI of that instance. In my case,
    I never started that instance again after creating the AMI, so it’s completely
    stopped. The Auto Scaling configuration went ahead and created a new instance,
    because its requirement of having at least one instance running was not met.
  prefs: []
  type: TYPE_NORMAL
- en: Before we implement the final component we need for everything to function properly,
    let’s take a moment to understand the value that we already have in place. If
    we were to increase the number of desired instances within the Auto Scaling group,
    then it would immediately spin up a new instance for us. Although advanced usage
    is more appropriate for a book that’s dedicated to AWS, we can set this up to
    automatically happen when the CPU of our instance gets to a certain point, which
    can trigger Auto Scaling to bring another one online.
  prefs: []
  type: TYPE_NORMAL
- en: With just a single instance, we don’t have Auto Scaling in play yet, but we
    can easily enable that. Another benefit that we get automatically is auto healing,
    and we have that benefit even with a single instance. If something were to happen
    to our only running instance, Auto Scaling will bring a new one online to replace
    it automatically.
  prefs: []
  type: TYPE_NORMAL
- en: In this situation, the website will be down for several minutes while the new
    instance is being created, but a bit of downtime is certainly better than having
    to manually replace the server ourselves. If we set the desired instances to a
    number higher than 1, a user will not notice anything if one of the servers goes
    down, the other will take care of the load while the new one comes up. These are
    amazing benefits to be able to take advantage of and will give us additional peace
    of mind right away. To test this yourself, feel free to delete the running EC2
    instance by right-clicking it and then clicking **Terminate**. The instance should
    then get terminated, and a new one should appear within several minutes to replace
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Since we have a load balancer in use, this changes the way that we’ll access
    the application that’s running on our instance(s), which in this case is Apache
    (we had Apache installed when we built our AMI, so every instance will automatically
    have Apache set up). Normally, we can access the application by navigating to
    the public IP address of the instance. We can still do this, actually – and the
    same is true for other instances within our load balancer setup as well. But in
    order to benefit from the overall solution we’ve built, we should instead access
    the application from the **DNS name** of the load balancer. This will ensure that
    our request is routed through the load balancer, rather than directly to a specific
    server. If you navigate to the **Load balancers** section of the management console,
    you should see the DNS name there. Going forward, the application or services
    you run on your instances should be served by having users access it via that
    DNS name.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! At this point, you’ve created a complete load-balanced solution
    in AWS that will automatically heal from failures. Feel free to experiment a bit
    more, and then when you’re finished, consider removing the test components we’ve
    created in this chapter to avoid a cost later on.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of cost, in the next section, we’ll talk a bit further about how to
    manage costs and keep our bills under control.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keeping costs down: understanding how to save money and make cost-effective
    decisions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you just saw, there were many components and configurations we had to implement
    in order to build a load-balanced solution in AWS. As we grow our AWS infrastructure
    and implement more solutions, we should also keep an eye on our bill. Although
    we can utilize the free tier for now, production applications will likely need
    more powerful instances than what the free tier will provide, and the free tier
    itself won’t last forever. Not only that, but we should also know how to check
    how our bill is trending to make sure we don’t accidentally implement something
    that is expensive or waste money by running something we no longer need.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll explore some concepts around billing. Although it’s beyond
    the scope of this chapter to do a complete deep dive into the world of billing,
    the subsections that follow will provide you with essential advice to help prevent
    unexpected charges.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing billing information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Within AWS, the billing section is its own service along with others, such
    as EC2 and S3\. You can find the **Billing** area from the service list. Once
    there, you’ll be shown the **Billing & Cost Management Dashboard**, which will
    show you your current expenses and allow you to see current and past billing information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_19_49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.49: Viewing the Billing & Cost Management Dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: Since the account I’m working with currently was just created a week or so ago,
    and I’m only using instances in the free tier, I have no costs currently. But
    if I did incur charges, I’d see the current balance on the main page of the dashboard.
    In addition, I’ll receive the same information in a monthly statement that is
    sent to the primary email account.
  prefs: []
  type: TYPE_NORMAL
- en: However, I don’t recommend waiting for the bill to arrive before checking your
    totals. To effectively manage billing, you should check this dashboard manually,
    which might enable you to catch an error before the end of the month, which might
    save you money. The links on the left will give you additional billing information,
    as well as providing a way of accessing previous bills.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a billing alert
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, I’m going to give you some high-level tips regarding some of
    the things you can do in order to help keep your AWS bill down.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous section, I recommended that you check the bill regularly instead
    of only when the monthly invoice arrives. While that is good advice (if I do say
    so myself), the reality is that server administrators like us are busy and may
    not remember to check the bill on a regular basis. This is why we typically set
    up system alerts to notify us when our servers are encountering an issue. Similarly,
    we can actually set up an alert inside our AWS account that can notify us if our
    bill gets too high. In fact, even though the AWS account we’ve been working with
    was likely only created as a test account, it’s especially important that we add
    a billing alert so we can be alerted if any of our experiments were misconfigured
    in such a way that we’re incurring costs we didn’t intend to.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Further reading* section at the end of the chapter, I have included
    a link to AWS documentation that details how to set up billing alerts, and I definitely
    recommend you enable them. If you’re using an AWS account for your organization
    to run actual production servers, it’s a good idea to enable billing alerts there
    as well. In fact, be sure to create billing alerts in every AWS account you manage.
    Another important element to consider is removing backups that aren’t needed anymore,
    which can also lower costs.
  prefs: []
  type: TYPE_NORMAL
- en: Removing unneeded backups
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This may seem like a no-brainer, but you’d be surprised—every organization I’ve
    ever worked for or consulted with in regard to AWS has run into an issue where
    backups get out of control and generate large costs. My personal record for witnessing
    a waste of money in this manner is one company that had over 23,000 unnecessary
    snapshots in their account, sitting around for over 5 years. I don’t remember
    the exact dollar amount, but this error cost them thousands of dollars a month
    for years!
  prefs: []
  type: TYPE_NORMAL
- en: Backups themselves are extremely important though, and the previous example
    might’ve been understandable if the organization had legal requirements that forced
    them to retain all backups for a specific period (such as 5 years). And backups,
    as you well know by now, are essential if the organization runs into some sort
    of issue and needs to restore something from the past. But the general rule of
    thumb here is to ensure that when the day comes to add an automatic backup feature,
    you also implement (and regularly test) an automatic cleanup procedure as well.
  prefs: []
  type: TYPE_NORMAL
- en: Running EC2 instances only when they’re needed
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many organizations do business around the clock and all year round, while others
    conduct business only during daytime business hours. While it might not be immediately
    apparent why this matters, consider the fact that you don’t get charged for an
    EC2 instance while it’s powered off. You do get charged for things like storage
    regardless of its state, but you aren’t charged for the instance itself if it
    is not running. If your organization has a server that is only used during certain
    hours, consider stopping the instance outside of that time period and then starting
    it back up when it’s needed.
  prefs: []
  type: TYPE_NORMAL
- en: There’s additional functionality in AWS that allows you to automatically schedule
    an instance to run only during certain hours, so there are ways to ensure your
    infrastructure is available when it’s needed. Make sure you keep this in mind
    as you navigate AWS; if you’re creating a new server, is it going to be necessary
    to make it run 24/7, or is it only necessary to run it at certain times? You’d
    be surprised how much money this may save you.
  prefs: []
  type: TYPE_NORMAL
- en: Stopping or terminating unneeded EC2 instances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the advice in the previous section about having instances run only
    when necessary, consider deleting instances completely if they’re not needed at
    all. Unless you’re utilizing a very specific type of instance, you won’t be billed
    for an EC2 instance that doesn’t exist. Make a habit of deleting things when you’re
    done with them. If you think you may need a server again in the future but you’re
    not sure, consider creating an AMI of the server, and then removing it. Although
    the AMI itself will have a cost, it’s going to be less than running an actual
    server.
  prefs: []
  type: TYPE_NORMAL
- en: This advice isn’t exclusive to EC2 instances; other services within AWS will
    also cause you to incur costs if you don’t clean them up. Make sure to keep an
    eye on other components and services that charge by usage, such as RDS, S3, EBS
    volumes, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: So, there you have it—with some basic advice, you should be able to keep your
    billing under control. And even if you make a mistake, as long as you’ve configured
    billing alerts, you should be notified and be able to correct the problem quickly.
    I can understand if some of the billing advice was overwhelming, but you’ll get
    used to it. AWS has a lot of components that can make up a bill, but as long as
    you set up alerts and delete items you’re not using, you shouldn’t have any problems.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve gone over quite a bit in this chapter, but where should you go from here?
    In the next section, I’ll provide some advice for continuing your learning and
    taking your AWS skills to the next level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking the cloud further: additional resources to grow your knowledge'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS is a huge service, and we haven’t even scratched the surface of the platform
    in this chapter. We’ve just created a simple load-balanced application in an earlier
    section, and we’ll even learn how to automate creating cloud resources in the
    next chapter. But if you’ve found this chapter fun and want to work with AWS more
    and enhance your skills, I thought I’d provide some additional advice that will
    hopefully help you do that.
  prefs: []
  type: TYPE_NORMAL
- en: Online training and labs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is quite a bit in the way of online resources to expand your knowledge.
    Some of these resources are free, such as a section of the AWS website that provides
    free hands-on training: [https://aws.amazon.com/training/digital/](https://aws.amazon.com/training/digital/)'
  prefs: []
  type: TYPE_NORMAL
- en: While you may already be aware of the value of YouTube when it comes to training
    videos, it’s a great source of knowledge. (And you may have even stumbled across
    my YouTube channel, over at Learn Linux TV.)
  prefs: []
  type: TYPE_NORMAL
- en: There are many videos on YouTube that can provide training, but that’s not the
    only source of video content; Packt Publishing features video training courses
    as well, in addition to Udemy, which also has some great content.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, there’s no shortage of training materials available, but I’d recommend
    starting with the free training provided by AWS that I’ve mentioned above, as
    well as the additional training content that Amazon makes available at [https://aws.training](https://aws.training).
  prefs: []
  type: TYPE_NORMAL
- en: Certification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While it will take a bit of work, achieving one or more certifications in AWS
    will lead you down a path where you’ll learn the platform in much greater detail.
    In addition, individuals with AWS certifications are in high demand in the IT
    industry, so achieving certification is a good idea all around. I recommend looking
    into the **AWS Certified Cloud Practitioner** credential, which is a more entry-level
    certification that is approachable to those just starting out.
  prefs: []
  type: TYPE_NORMAL
- en: After you grow your expertise, you may want to consider the **AWS Certified
    Sysops Administrator** credential, which is more challenging but will boost your
    knowledge even further.
  prefs: []
  type: TYPE_NORMAL
- en: Keep experimenting and learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even if you don’t decide to achieve a certification, keep experimenting with
    the platform. Getting your hands on the technology and making use of it on a regular
    basis is usually the best way to learn and keep your skills sharp. Try to create
    additional types of infrastructure, build and rebuild test instances, and above
    all, have fun. For many people, there’s no greater way to learn something than
    to get your hands dirty and experience it. I also recommend you follow any blogs
    around cloud computing and related technologies as well.
  prefs: []
  type: TYPE_NORMAL
- en: AWS documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The documentation provided by AWS is well written and very detailed. You can
    learn everything you need to know from the AWS documentation alone. The documentation
    pages are above and beyond the typical level of quality you would expect from
    such a large service; Amazon takes the AWS documentation seriously. The documentation
    pages are available here: [https://docs.aws.amazon.com/index.xhtml](https://docs.aws.amazon.com/index.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: New resources for learning about AWS are being created on a regular basis, so
    keep your eyes open for new books, training videos, and more as you study the
    platform. I think you’ll have a lot of fun taking your skills to the next level
    and exploring everything the AWS platform has to offer.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has been one of the most involved in the entire book so far, and
    you’ve accomplished a lot. During the course of this chapter, you learned about
    AWS, set up your own cloud server, set up Auto Scaling to ensure that your server
    is able to automatically heal from disasters, and even set up a load balancer
    to enable routing between multiple instances. Make sure you take some time to
    let all this knowledge sink in before continuing on, and I also recommend you
    spend some additional time with AWS before moving on to the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of the next chapter, we’re going to work with AWS again, but this time,
    we’re going to focus on learning Terraform, which is an awesome tool that will
    enable us to automate the building of our cloud resources from the ground up.
    It’s going to be a lot of fun.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Amazon Elastic Compute Cloud documentation: [https://learnlinux.link/ec2-docs](https://learnlinux.link/ec2-docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Security groups for your VPC: [https://learnlinux.link/vpc-docs](https://learnlinux.link/vpc-docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Auto Scaling documentation: [https://learnlinux.link/as-docs](https://learnlinux.link/as-docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amazon Machine Images (AMIs) : [https://learnlinux.link/ami-docs](https://learnlinux.link/ami-docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amazon Elastic Kubernetes Service documentation: [https://learnlinux.link/eks-docs](https://learnlinux.link/eks-docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AWS Billing Alert documentation: [https://learnlinux.link/cw-docs](https://learnlinux.link/cw-docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/LWaZ0](https://packt.link/LWaZ0)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code50046724-1955875156.png)'
  prefs: []
  type: TYPE_IMG
