- en: '*Chapter 5*: Patch Management Strategies'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In day-to-day operations of your Linux systems probably the most common task
    for an average system administrator is going to be patch management (aka patching.)
    Unlike the Windows and macOS worlds, it is standard for the system administrator
    to handle a broad variety of operating system and application patching tasks covering
    both primary and third-party ecosystems. It is also standard for there to be built
    in, and sometimes third party, application management ecosystems to assist with
    this potentially daunting task.
  prefs: []
  type: TYPE_NORMAL
- en: Patching, and of course system updates, are large parts of what we do and while
    it may feel mundane it is very important that it be something that we get right.
    And production Linux systems today have become much more complex and diverse than
    they were just ten years ago. And of course, patching has become more important
    than ever, something that we expect to only see increase over time as well.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by understanding how patches and updates are provided and what
    we mean by different installation methodologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we are going to learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Binary, Source, and Script Software Deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Patching Theory and Strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compilation for the Administrator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linux Installation and Redeployment Strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rebooting Servers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary, source, and script software deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software can come in all shapes and sizes. So, software deployments are not
    a one size fits all affair. The standard means of deploying software are directly
    as a binary package, through source code that needs to be compiled into a binary
    package, or as a script. We will dig into each of these as it is necessary to
    understand what each is and when they might be appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: Compiled and interpreted software
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Many system administrators have never worked as developers and often are not
    aware of how software exists. There are two fundamental types of programming languages:
    compiled and interpreted.'
  prefs: []
  type: TYPE_NORMAL
- en: Compiled languages are written in one language (source code) and run through
    a compiler to produce binary executable code that can run directly on an operating
    system. This can be an oversimplification, but we are not developers and need
    only be concerned with the original code being compiled into a binary format.
    For Linux, this format is called **ELF**, which stands for **Executable and Linkable
    Format**. Compiled binaries run on the operating system.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreted languages are different. Instead of being compiled into a binary,
    they remain as written, and are processed in real time by a program called an
    interpreter which itself is a binary executable and which treats the code as an
    input file to process. So interpreted software requires that an appropriate interpreter
    for the language in which it is written is installed on the operating system in
    order for the software to work. For example, if you have a Python program that
    you want to be able to run, the system on which you want to run it will need to
    have a Python interpreter installed to process that file.
  prefs: []
  type: TYPE_NORMAL
- en: Both approaches to software are completely normal and valid. As system administrators,
    we will work with both all of the time. Modern computers (and interpreters) are
    so fast that performance is of little concern between the two types and other
    concerns (mostly of the developers) are generally more important in deciding how
    a given piece of software will be written.
  prefs: []
  type: TYPE_NORMAL
- en: Software is not quite this simplistic, there are bizarre concepts like code
    that looks like it is interpreted but is actually compiled at the last moment
    and run like a binary. Some languages like those based on .NET and Java are compiled,
    but not to a binary, and so are essentially an amalgam taking some benefits of
    both approaches.
  prefs: []
  type: TYPE_NORMAL
- en: However, by and large we think of all software as either binary executable (runs
    directly on the operating system without assistance) or interpreted (requires
    a programming language environment or *platform* on which to run, on top of the
    operating system.) For the purposes of understanding code deployment, languages
    like .NET and Java, as well as **JIT** (**just in time**) compiled ones like Perl
    are lumped with interpreted languages due to behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Common languages that are generally precompiled include C, C++, Rust, and Go.
    Common languages that are interpreted, or act as though they are, include Python,
    PHP, Perl, and Ruby. To make matters more confusing, any interpreted language
    can be compiled. A standardly compiled language could even be interpreted! It
    is less *what a language does* as much as *what is it doing in this specific situation*?
    Essentially, any given language *can* be compiled or interpreted depending on
    how we treat it in practice. However, in the real world, no one is interpreting
    C++, and no one is compiling Python. But if you wanted to, it is possible.
  prefs: []
  type: TYPE_NORMAL
- en: As system administrators, we really have no say in how software is built, we
    simply have to deploy software as it is given to us. What we have to understand
    most is how much control and influence we may have on the total platform. If we
    run a binary application, it is possible that our only real options are around
    the version of the kernel that we run. But if we are installing a PHP script,
    we may have to decide how to install PHP as well, what version to run, which PHP
    provider, and so forth. It can become rather complex in some situations.
  prefs: []
  type: TYPE_NORMAL
- en: The majority of software that we will deploy is going to be binary in nearly
    all business scenarios. Often we might not even know (or care) about specific
    software as so much of the process will typically be handled for us. It is quite
    common to have to install software blindly.
  prefs: []
  type: TYPE_NORMAL
- en: It is increasingly common for system administrators to install software that
    is built of scripts which are readily readable code. These files are simply processed
    by an interpreter. So, the software never exists on disk in binary form. Since
    modern computer systems are so powerful, the seemingly problematic lack of efficiency
    in this process is often no problem at all. Many popular software packages are
    now written and delivered in this way, so most system administrators will commonly
    work with script installations.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, scripts are installed using the same automation methods as binary
    software packages making the entire process often transparent. As a system administrator,
    you might not always even know what kind of package you are deploying unless you
    dig into its underlying components. This becomes especially true of non-critical
    packages, and packages deployed using a dependency resolving system that handles
    any platform inclusion (for example, PHP or Python) for you, or if those dependencies
    were already installed for other components ahead of time.
  prefs: []
  type: TYPE_NORMAL
- en: Today we expect that the installation of scripts will be a common task that
    may not represent the majority of all packages that are deployed to a system but
    that can easily form the majority of primary workload code on a system. By that
    I mean that the operating system, supporting utilities, and large system libraries
    will often be binary packages. But the final workload, for which we are running
    the system in the first place, will have a very good chance of being a script
    rather than a compiled binary.
  prefs: []
  type: TYPE_NORMAL
- en: And, finally, the last type is the source code that cannot be run as is and
    must first be compiled into binary packages before being run. We are going to
    cover this topic, in depth, in just two sections, so I am only going to touch
    on it briefly here. You could argue that this approach is still a binary installation
    because the resulting deployed package is binary and that is totally correct.
    However, the workflow that must be followed to get and deploy that binary is quite
    different and makes this a valid tertiary deployment option. Some systems implement
    compilation steps automatically, and so it is plausible to have a deployment package
    that is compiling and installing a binary, and the system administrator is not
    even aware that it is happening.
  prefs: []
  type: TYPE_NORMAL
- en: Misleading use of source installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For reasons we will dig into a little later in this chapter, installing from
    source code generally developed a bad reputation. In some ways this was deserved,
    and in some ways it was not.
  prefs: []
  type: TYPE_NORMAL
- en: Because source based installation is, for all intents and purposes, unique to
    the free and open source software world it was heavily targeted by vendors and
    IT practitioners in the 1990s and 2000s in an attempt to discredit it because
    it was cutting heavily into more traditional closed source products (and the jobs
    of people who only supported that software.) This was, of course, completely fabricated
    but as source licensing is complicated to understand it is easy to instill fear
    and doubt into those that fail to grasp the nuances of the topic.
  prefs: []
  type: TYPE_NORMAL
- en: More importantly, however, source installation got a bad reputation because
    it was seen as being a generally unprofessional and unnecessary practice being
    promoted by system administrators who acted more like hobbyists and installed
    in this manner without real consideration for business needs. It was fun or looked
    impressive or their friends did it, so they did it, too. This, I am afraid to
    say, was broadly accurate. There was an era when lots of software was installed
    in unnecessarily complex and convoluted ways without regard for the business efficacy
    of the process. Not to say that source code compilation never has a place, it
    most certainly does. But even twenty years ago or more that place was in a niche,
    not the majority of deployment situations. So, in many ways, the bad reputation
    was earned honestly, but not completely.
  prefs: []
  type: TYPE_NORMAL
- en: Today, however, it is not a big deal as source code compilation is nearly forgotten
    and almost no one today knows the standard processes with which to do it and the
    installation of the necessary tools is often banned or at least the tools are
    not readily available making compilation quite difficult, if even possible. Only
    software that has a strong need to be compiled is distributed in this fashion.
    So, the market has all but eliminated this in practice.
  prefs: []
  type: TYPE_NORMAL
- en: But the fear and shaming of those that used to do compilation often still exists.
    Saying that someone is performing a source code installation remains a derogatory
    statement. Sadly, in an attempt to discredit even more software today, it has
    become common to use the term not to reference software that has to be compiled
    from source into binary, but to refer to script-based software which does not
    have a compilation step in this way. The term source code implies that the code
    has to be turned from source into binary. Scripts are not considered source code,
    at least not in this context. Technically, however, they are the original code,
    the source, but the implied bad step does not exist. But few people would follow
    up and can be easily misled by this little linguist trick. So, it is an easy way
    to take a manager who is just looking for an excuse to make an emotional decision,
    rather than more difficult rational, one, and mislead them. It sounds reasonable,
    and few will bother to actually think it through.
  prefs: []
  type: TYPE_NORMAL
- en: The trick really comes from semantic shorthand, something that is always dangerous,
    especially in IT. The concern with self-compiling software has nothing to do with
    the availability of the source code, but from the need to compile it before using
    it. If that step did not exist, the existence of the source code is purely a positive
    for us. People then incorrectly refer to the compilation as a source code installation.
    This semantic mistake opens the doors for someone to take something that technically
    truly is a source code install, without compilation, and because the term has
    been used incorrectly for so long it becomes a negative connotation applied to
    the wrong thing, and no one understands why any of it is wrong or backwards.
  prefs: []
  type: TYPE_NORMAL
- en: Linux offers us many standard enterprise methods for software deployments. The
    plethora of options, while powerful, is making it far more difficult to standardize
    and plan for long term support.
  prefs: []
  type: TYPE_NORMAL
- en: One thing that is ubiquitous in all production Linux systems, regardless of
    the vendor, is a package management system that exists by default. More than anything
    else over the years, these package management systems have come to define one
    Linux based operating system from another. Several software packaging formats
    exist, but two, that is, DEB and RPM, have become dominant with all others remaining
    very niche.
  prefs: []
  type: TYPE_NORMAL
- en: It is increasingly common for Linux distributions to either have multiple software
    packaging systems or to use multiple formats under a single software package management
    system. This variety is good as it gives us more options for how we may want to
    maintain specific packages on our systems, but it also means more complexity as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: As with all software deployments, we have a few standard concerns that are universal
    to all operating systems. First is whether software is self-contained or requires
    access to other packages or libraries. Traditionally, most software, especially
    on Linux and other UNIX-like operating systems, has been designed to reduce their
    size both to install and for the operating system itself, by utilizing extended
    system and third-party libraries (collectively called dependencies.) This means
    that we can have software that is as tiny as possible and other software that
    utilizes the same resources can share them on disk minimizing, sometimes significantly,
    how much we need to store and maintain. Updating a package or library for one
    piece of software will update it for all. The alternative is to have each individual
    software package come packaged with all of its own dependencies included with
    the package and available only within the singular package. This makes for much
    larger software installations and the potential for the same data to exist on
    the system multiple times. Possibly a great many times. This leads to bloat, but
    also makes individual software packages far easier to maintain as there is reduced
    interaction between different software components.
  prefs: []
  type: TYPE_NORMAL
- en: For example, dozens or scores of software packages will potentially want to
    use the OpenSSL libraries. If each of twenty packages include OpenSSL, we have
    the same code stored on disk twenty times. Moreover, if an update for OpenSSL
    is released or, more importantly, if a bug is discovered and we need to patch
    OpenSSL we will need to patch it twenty times, not just once. Whereas if we used
    a single, shared OpenSSL library then whether we have one application that relies
    on it or one hundred, we would only need to patch the library to make sure that
    any bug or update had been addressed.
  prefs: []
  type: TYPE_NORMAL
- en: Both approaches are completely valid. It used to be that shared libraries were
    a necessary evil because system storage was small and shared resources allowed
    for not just reduced disk usage, but better memory optimization because potentially
    a shared library might be able to be loaded into memory and shared by multiple
    pieces of software there as well. Today, we generally have more storage and memory
    than we can practically use, and this small efficiency is no longer necessary,
    even if potentially nice. Non-shared approaches trade this efficiency for the
    stability and flexibility of each package having their own dependencies included
    with them so that conflicting needs or an unavailability of shared resources does
    not pose a problem.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest advantage to shared resource approaches is probably that patching
    a known vulnerability can be far simpler. As an example, if we assume that OpenSSL
    (a broadly shared library) discovers a critical vulnerability and releases an
    update. If our systems have shared resources, we need only to find systems with
    OpenSSL installed and update that one package. All systems that depend on that
    package are automatically patched together. If OpenSSL were instead to be individually
    packaged with dozens of separate applications that all depend on it individually,
    we would need a way to identify that all of those packages use OpenSSL *and* patch
    all of them individually. A potentially daunting task. We rely on the package
    maintainers of every piece of software to do their due diligence, patch their
    dependencies quickly, and provide updated packages to us right away. Not something
    that happens too often.
  prefs: []
  type: TYPE_NORMAL
- en: 'Often systems with multiple packaging approaches will use one type of package
    management and software repository system, such as DEB, when there are shared
    system components and many dependencies to handle. They will use another package
    management system, such as SNAP, when they are going to keep all dependencies
    included in the final package. But it is far more complex than that makes it sound,
    for example, make a DEB package that include all dependencies or one that expects
    them to be provided externally and shared. It is only a convention that DEB tends
    to be shared libraries for software packages. In Linux we also have a completely
    different set of concerns that you would be used to if coming from a Windows or
    macOS background: a software ecosystem tied to the operating system itself. In
    Linux, we expect our operating system (for example, RHEL, Ubuntu, Fedora, SUSE
    Tumbleweed, and others.) to not only include the basic operating system functionality
    and a few extremely basic utilities, but also a plethora of software of nearly
    every possible description including core libraries, programming languages, databases,
    web servers, end user applications, and on and on. In many cases, you might never
    use any software that did not come packaged with your Linux distribution of choice,
    and when you do add in third party software it is often a key application that
    represents a strategic line of business application or, somewhat obviously, is
    bespoke internally developed software.'
  prefs: []
  type: TYPE_NORMAL
- en: Because of this, when working with software on Linux we have to consider if
    we are going to use software that is built into the operating system, software
    that we acquire and install independently (this would include bespoke software),
    or a mix of the two where many components of the software come from the operating
    system, but some are provided otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: Digging into specifics of different packaging systems would not make sense,
    especially as they tend to overlap heavily in their general usage but be very
    unique as to real world usage. Now we know the options that exist for them. Software
    package management systems are more important in Linux than on other operating
    systems, such as Windows or macOS, because there is typically much more complexity
    in the big server systems that Linux tends to run, and the software being installed
    typically uses much broader sets of dependencies pulling components or support
    libraries from often many different projects. Linux packaging systems that maintain
    online repositories of the software, libraries, components, and so forth make
    this all reasonably possible.
  prefs: []
  type: TYPE_NORMAL
- en: Probably the most important aspect of the large Linux software package management
    systems and their associated software repositories is that they allow the distribution
    vendors to assemble and test vast amounts and combinations of software against
    their exact kernel and component selection and configuration providing a large,
    reliable platform on which to deploy solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Best practice here is difficult. Really, we are left only with rules of thumb,
    but very strong ones. The rule of thumb is to use the vendor repos whenever possible
    for as much software deployment as you can. This might seem simple and obvious,
    but surprisingly there are a great many people who will still go and acquire software
    through a manual means and install it without the benefit of vendor testing and
    dependency management.
  prefs: []
  type: TYPE_NORMAL
- en: The real best practice is, as you might expect, to get to know the package management
    ecosystem of your distribution(s) of choice so that you are well prepared to leverage
    their features. Features tend to include logging, version control, roll back,
    both patching and system update automation, check summing, automatic configuration,
    and more.
  prefs: []
  type: TYPE_NORMAL
- en: The more common and foundational a software component is, the more likely you
    should have it supplied by the vendor as part of your distribution. The more niche
    and close to the line of business, the more likely that it will be acceptable
    to install it manually or through a non-standard process as end user products
    are far less likely to be included in a vendor software repository and are much
    more likely to have a need to carefully manage versions and update schedules rather
    than primarily caring about stability and testing with respect to the rest of
    the system.
  prefs: []
  type: TYPE_NORMAL
- en: It is not uncommon for software vendors making products that are not included
    in distribution repositories to make and maintain their own repositories allowing
    you to configure their repository and still manage all installation and patching
    tasks via the standard tools.
  prefs: []
  type: TYPE_NORMAL
- en: Software deployments are made up of so many special cases. It is tempting to
    want to delivery standard, clear *always do this* style of guidance, but software
    just does not work that way. Learn the tools of your system, use them when you
    can, be prepared to do or learn something unique for every workload that you have
    to deploy. Some, like WordPress, may turn out to be so standard that you never
    need to do anything but use the distributions own packages. Others may be so unique
    that you simple deploy a basic operating install, download the vendor's installer
    and it installs every needed piece of software, and potentially even compiles
    it! It just all depends, and more than anything else it will depend on how the
    software vendor chooses to build and package the software and if your distribution
    decides to include the package in the operating system or will require it separately.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a scope of the software installation processes and considerations,
    we can dive into the real heart of our concerns with patching and updates.
  prefs: []
  type: TYPE_NORMAL
- en: Patching theory and strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One might think that patching is pretty straightforward, and that there would
    be little to discuss. This is not the case. In fact, if you talk to several system
    administrators you are bound to get some pretty widely varying opinions. Some
    people patch daily, some weekly, some wait as long as they can, some do so only
    haphazardly, and some believe that you should never patch at all (hey, it if isn't
    broke, don't fix it!)
  prefs: []
  type: TYPE_NORMAL
- en: We should first establish why we patch our software. Patching, as opposed to
    updating or upgrading, implies that we are applying minor fixes to software to
    fix a known problem or bug but not to implement new features or functionality.
    Adding new features is generally considered to be an update.
  prefs: []
  type: TYPE_NORMAL
- en: Most software vendors and operating system vendors honor this system and maintain
    patching systems that only address security or stability issues in their software
    between releases. In the Linux ecosystem this is primarily tied to an operating
    system release. So, for example, if you use Ubuntu 22.04 and you use its own patching
    mechanisms to patch the software that comes with the distribution, then you will
    safely get nothing but security and stability fixes for the existing software
    versions and not new versions, features, or functionality. The logic here is that
    upgrading to a new version may break the software, change usability, or cause
    other products that depend on that software to fail.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading to new versions are assumed to only happen when a new version of the
    operating system itself comes out and then the operating system and all the packages
    included in it can be upgraded together at the same time. This allows the operating
    system vendor to, theoretically, test the software together as a singular package
    to give the customer (you) confidence that all of your software components will
    work together even after you move everything to new versions.
  prefs: []
  type: TYPE_NORMAL
- en: So, we assume that if a patch has been made available to us, then this indicates
    that a vendor, quite likely in conjunction with our distribution vendor, has identified
    a problem that needs to be fixed, a fix has been created, it has been tested,
    and it is now being distributed. However, even with testing, many eyes watching
    for errors, and the intent to do nothing but fix known bugs, things can still
    go wrong. Both the patch itself can be bad and the process of patching can run
    into unexpected problems. This means that we have to remain cautious about patching
    no matter how good the intentions are of those providing the patches.
  prefs: []
  type: TYPE_NORMAL
- en: When patching, we are left with two opposing concerns. One is that if the system
    is currently working for us, why introduce the risk (and effort) of the patching
    process when we do not have to. On the other hand, why keep running a system where
    known bugs are left exposed once a patch has been made available to us? We have
    to look at the concerns and pick a reasonable course of action.
  prefs: []
  type: TYPE_NORMAL
- en: Risk aversion is really not a key concern here, we are not looking at expense
    versus risk but rather two nearly equal courses of action (from an effort and
    cost perspective) with two very different outcomes. We need to pick the approach
    that reduces risk the most for our business and that is all. It is not how risk
    averse we are but what our risk profile is like that matters most. If our business
    is heavily susceptible to small downtime events, then patching may be deprioritized.
    If our company has highly sensitive data that is a likely target or we are very
    sensitive to public relations blunders in the event of a breach, then we might
    patch very aggressively. To make a sensible determination we must understand how
    each approach creates and mitigates different risks and how those risks affect
    our specific organization.
  prefs: []
  type: TYPE_NORMAL
- en: The risk of delayed patching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Simply pushing off patching does not eliminate certain types of risks. It may
    prove to have benefits but may also introduce even more risks depending on the
    situation. Under normal circumstances, new patches are made available with great
    frequency, potentially as often as multiple times per day, but at least multiple
    times per month.
  prefs: []
  type: TYPE_NORMAL
- en: If we patch often, such as once a week, then theoretically we will normally
    have to deal with extremely few patches at any given time and any break or incompatibility
    will be relatively easy to identify and to roll back as there are so few patches
    to work with.
  prefs: []
  type: TYPE_NORMAL
- en: If we save up patches over a period of time and only patch, for example, once
    a year then we have a few problems. First, the patching process may take quite
    some time as many patches may be needed. Second, if there is a break it may be
    very difficult to identify the offending patch as it could be lost in a sea of
    patches that all have to be deployed. And third, the greater volume of changes
    made at once, as well as the increased *drift* from any tested scenario (few,
    if any, vendors will test a system that is specifically as out of date as yours
    against a large volume of sudden changes) means that the chances of there being
    a break caused by the patching process is greater.
  prefs: []
  type: TYPE_NORMAL
- en: Delaying patches, therefore, becomes a self-fulfilling prophecy in many cases
    where neigh sayers who avoid patching because *patches break things* will often
    see this come to pass because they create a situation where it is more likely
    to occur.
  prefs: []
  type: TYPE_NORMAL
- en: There is no one size fits all approach. Every organization has to tailor the
    patching process to meet their needs. Some organizations will avoid patching altogether
    by making stateless systems and simply deploying new systems that were built already
    patched and destroying older, unpatched instances neatly sidestepping the problem
    altogether. But not every workload can be handled that way and not every organization
    is able to make that kind of infrastructure leap to enable that process.
  prefs: []
  type: TYPE_NORMAL
- en: Some organizations run continuous patch testing processes to see how patches
    will be expected to behave in their environment. Some just avoid patching completely
    and hope for the best. Some patch blindly. We will discuss all of these options.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding patches because of Windows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A culture of *patching avoidance* has sprung up in recent years within the ranks
    of system administrators. Given how critical patching is in general and how central
    it is to our careers this seems counter-intuitive. No one could be as strong of
    a cheerleader for rapid, regular patching as the system administrators.
  prefs: []
  type: TYPE_NORMAL
- en: In the Windows world, patching is very unlike what it is like in the Linux,
    or any other world. It is often delayed, secretive, slow, unreliable, and worst
    of all buggy and error prone. Patching in Windows was always problematic but during
    the 2010s became so bad that it is no longer deterministic, can take much longer
    than simply deploying new systems, and fails with great regularity.
  prefs: []
  type: TYPE_NORMAL
- en: And failures with Windows patching can mean almost anything from the patch simply
    failing to install and needing to devote resources to getting it to work, to causing
    software to fail and no longer function. Some patches can take many hours to run
    only to fail and then take hours to roll back!
  prefs: []
  type: TYPE_NORMAL
- en: Because of this it has become common and almost expected that system administrators
    in the Windows realm will range from gun-shy about patches, to practicing total
    avoidance. This has sprawled to not just include patches but full system version
    updates as well. So now finding Windows systems that are years or even a decade
    out of date is becoming commonplace creating more and more security vulnerabilities
    throughout the ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft then has responded, not by fixing the patching problems, but by attempting
    to force patching without permission, and obscuring the patching process creating
    even more reliability problems and in many cases breaking patch management systems
    so dramatically that even administrators who desire to stay fully updated are
    often unsure how to do so or are simply unable to do so.
  prefs: []
  type: TYPE_NORMAL
- en: These problems are unique to Microsoft today and are mostly unique to Microsoft
    in the modern era. We must not allow an emotional reaction to a uniquely bad situation
    influence our practices in the Linux or other realms that are not impacted nor
    influenced by Microsoft. Outside of Microsoft's isolated piece of the industry
    no other ecosystem has experienced these types of issues. Not in Ubuntu, Red Hat,
    Fedora, SUSE, IBM AIX, Oracle Solaris, FreeBSD, NetBSD, DragonFly BSD, macOS,
    Apple iOS, Android, Chromebooks, and on and on. Patching always carries risk and
    we should be aware of this, but Microsoft's problems are unique and have nothing
    to do with our practices in the rest of the industry.
  prefs: []
  type: TYPE_NORMAL
- en: Patching can be automated or manual. Both approaches are perfectly fine. Automation
    requires less effort and can protect against patching being forgotten or deprioritized.
    In a large organization formal patching procedures that require manual intervention
    may be simple to ensure consistency, but in small organizations with just a few
    servers it can often be easy to overlook patching for months. When looking at
    manual versus automated patching just consider the potential reliability of the
    process and the cost (generally in time) of the human labor involved.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit to manual patching is that you have an opportunity for a human to
    *inspect* each package as it is patched and to test the system in real time as
    it occurs. If something was to go wrong, every detail of the patching process
    is fresh in their memory as they just performed it and they know exactly what
    to test and what to roll back or address if something fails.
  prefs: []
  type: TYPE_NORMAL
- en: Automation benefits from happening automatically, potentially at very predictable
    times, and being able to happen even if no humans are present to do the work.
    Scheduling automated patching for evenings, overnight, weekends, or holidays can
    minimize impact to humans while speeding the patching process. Automated patching
    is unlikely to be missed and it is easy to send alerts when patching happens or
    when there are problems caused by patching.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases automation is going to be preferred to manual patching simply
    because it is less costly and nearly all manual benefits can be automated in some
    form as well, such as by having a human on standby to receive alerts in case of
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: Testing patches is rarely feasible
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Everyone talks about how important it is to test patches. System administrators
    often demand it and attempt to refuse to apply patches until testing can be done
    (a convenient way to avoid having to patch systems at all.) And if patches ever
    go wrong, management will almost always demand to know why patch testing was not
    done beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the harsh reality: there is no practical or realistic means of testing
    patches on any scale. There, I said it. Say it out loud, go tell your bosses.
    The cost, both in time and money, to test patches is much larger than anyone believes.
    In order to thoroughly test patches, we need a replicated environment that gives
    us a mirror of our production environment so that we can test the patches that
    we want to deploy against software, hardware, and configurations. Attempting to
    shortcut this process does not work as it is the interplay of all these parts
    that make testing important. If you change anything, you may totally nullify the
    benefits (or worse, create a false sense of security) to a very expensive process.'
  prefs: []
  type: TYPE_NORMAL
- en: In a real-world environment, every system is effectively unique. There are exceptions,
    but generally, this is true. There are so many variables that are possible, including
    hardware manufacturing dates, varying parts, firmware versions, and on up the
    infrastructure stack (that is, code and components that sit closer to the final
    application at the top of the stack). Computer systems are so complex today that
    there are millions of variables that could result in a combination that causes
    a bug in a patch to be triggered.
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the reasons why virtualization is so important, it creates a
    middle layer of standardization that allows some of the more complex parts of
    the system to be standardized. So at least one portion, a very complex portion
    involving many drivers, can be reduced in complexity.
  prefs: []
  type: TYPE_NORMAL
- en: In very rare organizations real patch testing is done. Doing so is costly. Generally,
    this involves carefully replicating the entire production environment right down
    to matching hardware versions, firmware revisions, patch history, and so forth.
    Every possible aspect should be identical. Patches must then be run through a
    battery of tests quite quickly in order to test any given patch in the company's
    range of scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: In practical terms this means duplicating all hardware and software and having
    a team dedicated to patch testing. Very few companies can afford that and even
    fewer still could justify the small amount of potential protection that it might
    provide.
  prefs: []
  type: TYPE_NORMAL
- en: Timeliness of patching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Patching is an activity that generally has to happen extremely quickly, and
    as the industry matures the importance of rapid patching continues to increase.
    Those of us trained in the 1990s and earlier will tend to have memories of a time
    when patching a system had almost no time sensitivity because most computers were
    offline, and patches were almost exclusively for stability issues that if you
    had not experienced already that you were unlikely to experience. So, waiting
    months or years to patch a system, if you ever did, tended to not be a very big
    deal.
  prefs: []
  type: TYPE_NORMAL
- en: Oh how times have changed. Software is so much bigger and more dynamic today,
    there are so many more interconnected layers, and all but the rarest of computer
    systems are now on the Internet and potentially exposed to active security threats
    and a dynamically changing environment all of the time. Everything, as pertains
    to patching, has been flipped on its ear over the past two decades, although most
    of the significant changes had happened by around 2001.
  prefs: []
  type: TYPE_NORMAL
- en: Today patching tends to focus heavily on shoring up security gaps that have
    been discovered recently and every step of the process is one of rushing the patch
    to market before the bad guys are able to discover the vulnerability and exploit
    it. Bad actors know that patches will come for any vulnerability that they find
    quite quickly and so exploitation is all about speed. In some cases, it is the
    release of a patch itself that alerts the greater community to the existence of
    a vulnerability and so the action of releasing a patch triggers a sudden need
    for everyone to apply said patch in a way that was not necessary just hours before.
  prefs: []
  type: TYPE_NORMAL
- en: Because of this, patching quickly is incredibly important. Attacks based on
    a patch are most likely to either already be occurring and will increase in a
    last-ditch effort to leverage a soon-to-be-dwindling vulnerability or will soon
    start as a previously unknown vulnerability becomes public knowledge. For many,
    this means that we want to consider patching in terms of hours rather than days
    or longer. We still have to consider potential stability risks or impacts that
    might occur during production hours, so patching immediately is rarely an option,
    but it is certainly possible when it makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: In Linux, because patching is generally quick and easy and almost always reliable,
    it is reasonable to consider patching throughout the production day in some cases,
    and daily patching in most other cases. Potentially smart approaches might include
    using a built-in randomizer to patch, somewhat randomly (for reasons of system
    load reduction) every four to eight hours, or having a scheduled patch time every
    day at ten in the evening or other appropriate time.
  prefs: []
  type: TYPE_NORMAL
- en: In extreme environments, patching on a weekly schedule is possible and this
    was popular in the enterprise just one to two decades ago. Today, waiting up to
    six days to patch a known vulnerability borders on the reckless and should be
    done only with caution. Six days is a very long time in the world of exposed system
    vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The choice of time frames is generally based on workload patterns. Some workloads,
    like email or an inventory control system, might have little susceptibility to
    momentary disruption and can be rolled back or failed over quickly. So, patching
    these in the middle of the day might make sense. Most companies have their workloads
    have a cyclical use pattern throughout the day and can predict that an application
    becomes very lightly used from one to two in the morning, or perhaps that by seven
    in the evening every single user has signed out and even a ten-hour outage would
    be noticed by no one.
  prefs: []
  type: TYPE_NORMAL
- en: Whether or not intra-day patterns exist or not we almost always see inter-day
    patterns on a weekly basis. A workload might be light on the weekends or heavy
    during the week or vice versa. Once in a while, especially with financial applications,
    the pattern is more monthly based with the beginning of the month probably seeing
    a heavy load and the middle of the month being light.
  prefs: []
  type: TYPE_NORMAL
- en: Any given workload will typically need to be assessed to understand when patching
    is reasonable and practical. Sometimes we have to be creative with our timing
    to be able to get patching in when the workloads allow. If workloads cannot be
    interrupted for patching, then they cannot experience other, less planned, downtime
    events either and we should have a continuity plan that allows us to patch, repair,
    or failover in case anything happens. In most cases we can, when necessary, do
    zero impact patching through these methods.
  prefs: []
  type: TYPE_NORMAL
- en: The old idea that patching can be saved as a special monthly activity or done
    only when a specific need is identified for the organization is no longer realistic.
    Waiting that long leaves systems dangerously exposed and any workload that claims
    to have only one time a month when it can be patched should be questioned as to
    how any workload can be both important, and unable to be patched. Conceptually
    the two things cannot go together. The more important a workload is, the more
    important that it be patched in a timely fashion.
  prefs: []
  type: TYPE_NORMAL
- en: A common excuse for slow patching processes is that testing is required before
    rolling out a patch. On the surface this makes sense and sounds reasonable. You
    could probably sell this idea to non-technical management. There is nothing wrong
    with wanting to test a patch. But we have to consider that we are already, presumably,
    paying (or getting for free) a distribution vendor to test patches before we receive
    them. Those enterprise operating system vendors (Canonical, IBM, SUSE, and others.)
    have far more skills, experience, and resources to test patches than any but the
    largest organizations. If our testing does not add something significant to the
    extensive testing that we are already relying on them for, then our own internal
    testing process should be avoided, in order to avoid wasting resources and putting
    the organization at unnecessary risk by not getting potentially critical patches
    deployed promptly.
  prefs: []
  type: TYPE_NORMAL
- en: Rapid, light testing can be reasonable if it is kept light enough and never
    used as an excuse to avoid timely patching. A common approach to useful patch
    testing is to have just a few systems that represent typical workload environments
    in your organization that run demonstration workloads where you can test each
    patch before it is rolled out to allow you to observe a successful install and
    test the patches at the highest level. This could be as little as a single virtual
    machine in a smaller organization. Consider if any testing at all is valuable,
    and if it is, keep the testing as light as you can to ensure that production patching
    happens as quickly as it can within the confines of the needs of your workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Standard patching strategies will also generally suggest that you start either
    with highly vulnerable workloads or with low priority workloads to focus on shoring
    up exposures or using low priority workloads as tests of Guinea pigs for more
    critical workloads. If your environment has one hundred virtual machines to patch,
    you can probably arrange a schedule that allows you to patch systems that are
    not critical first and slowly build up confidence in the patching process as you
    approach the patching of more critical or fragile workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Consider patching to be unquestionably one of the most important, and truly
    simple, tasks that you will be doing as a system administrator. Do not allow emotions
    or irrational advice from businesses or system administrators that do not understand
    what patching is (or influence from Windows admins) to lead you astray. Patching
    is hyper-critical and any organizational management that is not supportive of
    patching processes does not understand the risk and reward valuation of the process
    and we need to be prepared to explain it to them.
  prefs: []
  type: TYPE_NORMAL
- en: Find a patching process that meets the needs of your organization. You do not
    need to patch on a rigid schedule, you do not need to patch the way that other
    organizations do. Find the testing that is adequate for you and the manual or
    automated patching process that keeps your systems updated without overly impacting
    the organization.
  prefs: []
  type: TYPE_NORMAL
- en: We should have a pretty solid handle on patching concepts at this point and
    you probably even feel a certain sense of urgency to go examine your current servers
    to see how recently they have been patched. This is understandable and if you
    want to look at them now before continuing on, I am happy to wait. Better safe
    than sorry. When you return, we will talk about software compilation and relate
    that process to patching.
  prefs: []
  type: TYPE_NORMAL
- en: Compilations for the administrator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It was not all that long ago when major system administrator guidelines included
    a requirement that any mid-level or senior administrator had to be well acquainted
    with the details of standard software compilation processes. Of course, all knowledge
    is good, and we would never say that it should not be learned at all. However,
    even at the time, this seemed like an odd amount of *under-the-hood* development
    knowledge and knowledge about the packaging of individual software solutions expected
    to be known by a person in a non-development role.
  prefs: []
  type: TYPE_NORMAL
- en: It would not be unlike if when ordering a new car from your favorite car company
    that it was expected to be delivered as parts and that every potential new car
    owner would be expected to assemble the car before driving it. It is important
    to note that this process was only ever possible in the open-source world and
    that the majority of software outside of the Linux space and even a significant
    portion within it cannot be compiled by the system administrator at all. So, the
    entire concept of this requirement was for an almost niche scenario and was not
    broadly applicable to system administration in the general sense, which alone
    should have been a serious red flag to organizations promoting this as an education
    and certification standard.
  prefs: []
  type: TYPE_NORMAL
- en: As a system administrator, the idea that we would need to take source code from
    developers and custom compile it, using a compiler that we provide, in our own
    environment feels almost absurd. In the Windows world this would be all but impossible,
    who would have access to an appropriate compiler or any of the necessary tools?
    In Linux and BSD systems it is often plausible because a compiler or multiple
    compilers may be included with the base operating system.
  prefs: []
  type: TYPE_NORMAL
- en: There was a time when compilation on target systems had some value. Often, generically
    compiled software was inefficient by necessity in order to support nearly any
    potential hardware, and with on-target compiling, we could leverage every last
    bit of performance from our very specific hardware combination. However, this
    was also in an era of long compile times due to limited CPU power and would result
    in systems taking potentially days to install rather than minutes. Software deployment
    was a lengthy, complex, and error-prone task. In the modern world, it would be
    almost unthinkable to waste the time and resources necessary to compile most software.
    When we can deploy entire fleets of servers in just a few minutes while using
    extremely little system resources, tying up many CPU cycles and spending hours
    to do the same task does not make sense from a resource perspective alone.
  prefs: []
  type: TYPE_NORMAL
- en: However, compilation carries far more risks than just wasting time and system
    resources. It also means that we, potentially, get slightly different resulting
    software on different systems that we run, between times that we deploy, from
    systems that we have tested, or, more importantly, from systems that the vendor
    has tested. As discussed earlier, with the challenges that we face with testing
    patching scenarios, compilation makes testing vastly harder. Likewise, patching
    becomes much harder.
  prefs: []
  type: TYPE_NORMAL
- en: Some software requires compilation today for deployment, generally software
    that leverages specific hardware drivers. This kind of software tends to be desktop
    software and not something that we would see on a server. That does not mean that
    we will never encounter it, but it should be quite uncommon. It is not technically
    wrong to self-compile software, but you should only be doing so if it is absolutely
    required and serves a very necessary purpose. It should not be done casually and
    there is no reason for a system administrator today to have any knowledge of the
    compilation process.
  prefs: []
  type: TYPE_NORMAL
- en: Several additional new factors have arisen that make compilation as a standard
    process less possible. Twenty years ago, we had one major compiler in the Linux
    ecosystem, and it was assumed that all software being deployed as code would be
    written in C and targeted (and tested) by the development team against that one
    compiler. There was a very standard toolchain that convention said would be what
    was used, and it was almost always correct. Today, not only are there multiple
    standard compilers now being used with different projects using different ones
    for testing, but also several common compiled languages that are now in common
    use with their own compilers and tool chains.
  prefs: []
  type: TYPE_NORMAL
- en: Compilation was never a single, standard process as was implied. However, the
    convention meant that it was very nearly so. Today. it is a scattered process
    for all of the reasons mentioned earlier. In addition to this, many projects that
    do require compilations by end users now build in a compilation process so that
    it acts much like a standalone deployer rather than requiring the system administrator
    to have any knowledge of the compilation or even be aware that the software being
    deployed is compiling! The world has changed in nearly every way.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world I have worked on tens of thousands of servers across thousands
    of clients and have not seen the assumed *standard* compilation process used in
    any organization for more than seventeen years and in the years before that it
    was still so rare as to be able to be generally ignored and always used under
    questionable circumstances when a system administrator was acting as if the business
    was a personal hobby rather than a serious business.
  prefs: []
  type: TYPE_NORMAL
- en: The compilation era
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the early days of Linux, being able to compile your own software commonly
    was a major feature compared to closed source systems, such as Windows and Netware,
    where compilers were not free, and the operating system code was not made available.
    It meant being able to move between different architectures without too much effort
    and at the time system resources were at a premium so the small performance advantage
    possible from unique compilation sometimes meant a real difference in software
    performance. System administrators used to be passionate about compiler flags
    and versions.
  prefs: []
  type: TYPE_NORMAL
- en: This trend was so dramatic that even entire operating systems were released
    around the concept. Most notably was Gentoo Linux where the entire operating system
    was custom compiled every time that it was deployed. This often led to people
    discussing how many days it would take to install a full operating system. The
    investment in initial installation was significant.
  prefs: []
  type: TYPE_NORMAL
- en: In the 1990s, it was not uncommon for operating system installations to take
    many days. We rarely virtualized and so installations were often from physical
    media onto unique hardware which was time consuming even when things went well
    and there were often installation hiccups that would cause you to have to attempt
    an install multiple times. In that environment, also taking the time to compile
    software, or even the entire operating system, was not as crazy as it is today.
    But rest assured, it was not completely sane, either.
  prefs: []
  type: TYPE_NORMAL
- en: The same era that saw compilation make sense because of resource constraints
    coincided with the pre-internet office world and the nascent Internet world where
    environmental threats looking to exploit unpatched computers were rare. Of course,
    computer viruses existed and were well known, but the ability to avoid them by
    not sharing physical media between systems allowed for high confidence in avoiding
    infection when well managed. So, the difficulties of patching custom compiled
    software did not present a problem most of the time. This was the era of *set
    and forget it* software. Compiled software was more likely to be forgotten than
    to be maintained. The effort of installation made the potential effort of patching
    monumental and very risky. When you custom compile code yourself there is a lot
    that can go wrong that could result in you being left without a working system.
  prefs: []
  type: TYPE_NORMAL
- en: CPU and RAM resources used to be so tight on the majority of systems that, in
    most cases, having to wait days longer to be able to put a system into production
    was considered worth it, even if only to gain one percent in additional performance.
    What was often ignored was the fact that if it took all of that time and all of
    those resources to compile the initial installation, that those resources or more
    might be needed over and over again in the future to compile future patches or
    updates. This carried a truly enormous risk and would commonly result in a complete
    lack of patching as, once deployed, there was little means to bring the system
    down for hours or days to attempt a compilation step in the hopes of being able
    to update the system.
  prefs: []
  type: TYPE_NORMAL
- en: Like so much in IT, there is a strong desire to build a house of cards and hope
    that, when it falls down, it is long enough in the future to qualify as someone
    else's problem. And sadly, that became a viable strategy as companies rarely associate
    failures with those that caused them and often blame, at random, whoever is at
    hand. Because of this, creating risky situations is often beneficial because any
    benefits will be attributed to the person who implemented it, and any disasters
    it causes will be attributed randomly at a later date.
  prefs: []
  type: TYPE_NORMAL
- en: A system administrator today would still do well to learn traditional software
    compilation, if only to understand historical perspective and be prepared for
    any unusual situation that might arise. But today (and for many years previously)
    compiling our own software as a standard process should be avoided as a rule of
    thumb, it is simply not a good use of resources and introduces too much risk for
    no real benefit.
  prefs: []
  type: TYPE_NORMAL
- en: When compilation is done today you cannot expect to be able to follow a generic
    process blindly as was often assumed (incorrectly) in the past. That convention,
    that protected so many administrators who just got lucky, is not a convention
    any longer. To compile software today we need instructions and guidance from the
    developers to have any hope of realistically knowing what tools, configurations,
    libraries, languages, and external packages may be required and how to make compilation
    work. There are so many potential moving parts and all of the knowledge here is
    developer knowledge, not IT knowledge at all, let alone system admin knowledge.
    System administrators have so much information that they need to know and deeply
    understand, it is one of the largest and most challenging technical arenas. The
    idea that system administrators should additionally learn deeply the knowledge
    and skills of a totally different field never made any sense. Why would developers
    even exist if all system administrators could perform these jobs in addition to
    their own duties? Software engineering is a huge field that requires immense knowledge
    to do well; it is both utterly absurd and insulting to developers to imply that
    a different discipline can perform their role casually without needing the same
    years of training and full-time dedication.
  prefs: []
  type: TYPE_NORMAL
- en: Compilation by engineering department
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is a middle ground that we should mention that can make sense. That is
    having an engineering group that takes software in code form from developers (internal
    bespoke teams or open-source projects generally) and performs internal compilation
    either as an additional security step or for an extreme level of performance tuning
    or simply because the software in question requires special compilation such as
    when tied to kernel versions or drivers.
  prefs: []
  type: TYPE_NORMAL
- en: By having a central group that is doing internal compilation and packaging source
    code into resultant binaries for the administration team they allow system administration
    processes to remain focused on standard, repeatable, and fast to deploy binary
    mechanisms while the organization gets the advantages of custom compilation.
  prefs: []
  type: TYPE_NORMAL
- en: This approach is typically reserved for only the largest of organizations capable
    of maintaining rapid software packaging workflows so that patching, testing, and
    customization happen almost as fast as it would, should it be done by the software
    vendors. At large scale it can be beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: This process works because it does not put software compilation and packaging
    into the hands of administrators where it is awkward and highly problematic.
  prefs: []
  type: TYPE_NORMAL
- en: Best practice is to compile software only when it is a requirement and not to
    do so otherwise, unless you have a department that can handle packaging compiled
    software rapidly and reliably fast enough to account for proper patch management
    needs and the overhead of doing so is justified by a savings at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Compilation is useful knowledge, but just because you *can* compile software
    does not mean that you *should*. Keep this skill in your back pocket for when
    you really need it or are directed to do so by your software vendor. Next, we
    will talk about how to deploy our Linux distribution itself and, even more importantly,
    how to *redeploy* a distribution after a disaster has struck.
  prefs: []
  type: TYPE_NORMAL
- en: Linux deployment and redeployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today we have many potential methods for deploying, and just as importantly,
    redeploying, our servers (or our workstations, for that matter.) In my opinion,
    this topic was relatively unimportant in the past because most companies depended
    on *slow deployment* methods and their disaster recovery models depended on restoring,
    rather than redeploying, their systems. But there are so many more modern disaster
    recovery methods today that depend on the ability to rapidly deploy servers that
    we have to look at this topic with a new eye.
  prefs: []
  type: TYPE_NORMAL
- en: With modern deployment technologies and techniques, it is not uncommon to be
    able to deploy a new base operating system in a matter of seconds when in the
    past, even heavily automated systems would often take many minutes if not hours
    (not even considering the possibilities that would come with custom compiled systems!).
    Of course, computers are just faster today, and this plays a role in speeding
    deployments. Vendors have improved installation procedures as well. This is not
    unique to Linux, but nearly any operating system.
  prefs: []
  type: TYPE_NORMAL
- en: Even doing the most traditional or *ISO-based install* where we take installation
    media in the form of a DVD image and install from USB media or virtual media,
    we can generally do a full operating system install from scratch, manually, in
    a matter of minutes. Perhaps ten to fifteen minutes on normal hardware. This is
    pretty fast compared to how installs were done nearly twenty years ago.
  prefs: []
  type: TYPE_NORMAL
- en: It was traditional in larger environments to use something akin to a response
    file to make these installation processes faster and more repeatable. This process
    would generally mean storing your installation ISO files somewhere on your network
    and storing a set of installation instruction files somewhere and defining systems
    in a list somewhere else often listing MAC addresses to assign appropriate configuration
    files to use. Essentially just automating the human responses used when performing
    a traditional install. Effective, but clunky.
  prefs: []
  type: TYPE_NORMAL
- en: Today any form of ISO, or similar media-based installation is typically reserved
    for truly manual installations that are generally done by very small companies
    (that only ever build a few servers, and each is likely completely unique anyway)
    or special situations. There is nothing wrong with the older response automation
    methodology, but so many newer options exist that it has simply fallen by the
    wayside and continues to lose traction as a popular installation method. It was
    truly most effective in the pre-virtualization days when few installation automation
    options existed, and installations were necessarily one operating system per physical
    device making MAC address-based management highly effective. Today this would
    work effectively for platform (hypervisor) installation, but not so much for operating
    system installation.
  prefs: []
  type: TYPE_NORMAL
- en: The advent of virtualization meant two big things changed. First, hypervisors
    installed to the bare metal of a physical server are rarely customized outside
    of the most basic options making the need for automation less (and the entire
    installation process is much smaller). And second, that operating system installation
    is now done in a non-physical space opening the field to more esoteric installation
    techniques than were previously available.
  prefs: []
  type: TYPE_NORMAL
- en: In the virtual space, we can continue to install systems manually, and many
    people do. We can continue to use response files, and while I know of no one that
    continues to do this, I am confident that it is still widely practiced, especially
    as so many large-scale semi-automated deployment systems for this were in place
    already. However, now, we have readily available options to use pre-built system
    images that can be called from a library to install even faster. With a method
    such as this, an already built system is simply copied or cloned to make a new
    system. The initial image can be preconfigured with the latest patches and custom
    packages and often installed in under a minute; sometimes, in just a few seconds.
    If it is using certain kinds of storage, it can perform so quickly as to appear
    instantaneous. With containers, we can, sometimes, observe new systems initialized
    so quickly that we can barely detect that there is a build process at all (because,
    for all intents and purposes, there is not).
  prefs: []
  type: TYPE_NORMAL
- en: What method you choose to use for deploying your servers is not the most important
    factor. All these deployment methods, and more, have a place. What we do want
    to consider is how quickly and reliably new systems can be built using the processes
    that you choose. When a new workload is needed, it is good to know that we can
    build a new server in a certain amount of time and feel confident in the final
    configuration of it. If a well-documented manual process achieves an acceptable
    result, then that is fine.
  prefs: []
  type: TYPE_NORMAL
- en: For many businesses, the ability to deploy rapidly is not very important. What
    becomes extremely important is the ability to redeploy. Of course, for certain
    types of applications, like those well suited to cloud computing, rapid initial
    deployments are absolutely critical, but this remains a niche and not the norm
    and will for the foreseeable future. But redeploying implies typically that some
    level of disaster has struck and that a system has to be returned to functionality
    and in that case, it is exceedingly rare that we are not under pressure to put
    the system back into production as quickly as possible.
  prefs: []
  type: TYPE_NORMAL
- en: So, it tends to be that redeployment speed, rather than deployment speed, is
    what matters more in our environments. However, because disaster recovery is rarely
    thought about in this way, the importance of this is often ignored during the
    only time that it can be realistically affected  meaning, we can only really
    address this during our initial design and implementation phases but typically
    ignore it until it is too late to effectively change. Additionally, redeployments
    need to be done with confidence so that what we have built quickly is built as
    we expect and behaves as we expect. Under these rushed and pressured conditions,
    it is easy to miss steps, ignore processes, take shortcuts, and make mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: The faster and more automated our systems are, the better chance we have to
    being able to turn out the same identical system time after time even under highly
    pressured circumstances. We should be planning for this situation when we make
    our initial deployment plans. Being able to recreate systems, without needing
    to resort to backup and restore mechanisms, can be a game changer for many companies
    who often feel forced to rely on a single approach to bring systems back online,
    when in many cases, superior alternatives may exist. We will dig much deeper into
    this when we talk about backups in a future chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Processes that allow us to recovery quickly also give us greater flexibility
    throughout our professional workflows. The ability to test patches, deployments,
    configurations, build temporary systems, and so forth. Flexibility is all about
    protecting against the unknown.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices in deployment processes are all about evaluating the time to
    engineer reliability deployment methods that work best for your environment and
    to streamline this as is sensible to allow for being able to restore a baseline
    operating system in a time period that makes the most sense for your environment.
  prefs: []
  type: TYPE_NORMAL
- en: Some environments are able to build new servers, and configure them for their
    necessary workloads, so quickly that they actually choose to do this over performing
    activities such as patching, updates, or potentially even reboots! Instead, they
    will rapidly build and deploy a completely new virtual machine or container and
    destroy the old one. A really effective practice if you can make the process work
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: In our next section, we will discuss the importance of rebooting and testing
    your environment under regular, frequent, and planned conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Rebooting servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ask your average system administrator, or even a non-technical but interested
    third party, and they will tell you the importance of long uptimes on servers
    and how they want to see those ultra-high *time since reboots* on them. It feels
    natural, and nearly everyone brags about it. *My servers have not needed a reboot
    in three years!*
  prefs: []
  type: TYPE_NORMAL
- en: There are two key problems with this, however.
  prefs: []
  type: TYPE_NORMAL
- en: The first problem is that *time since reboot* carries no business value, and
    business value determines IT value. So why should we care, let alone brag, about
    something that has no value? It might be interesting to know how long a system
    has managed to stay online, but an investor is not going to reap a reward from
    the fact that a computer system has gone an extended period of time without a
    reboot. We work for the good of the business, if we start to care about something
    other than resultant business value, we have lost our way. This happens when we
    focus on means instead of ends, server uptime easily carries an emotional value
    that *feels like it* might lead to good things and so we, as humans, often like
    to put proxies in place in our minds to simplify evaluating results and uptime
    is easily seen as a proxy for stability which is seen as a proxy for business
    value. All of this is false, none of those proxies are correct and, even worse,
    might be inverted.
  prefs: []
  type: TYPE_NORMAL
- en: The second problem is the big one - high uptime itself represents a risk. The
    risk of the unknown. Our system changes over time from wear and tear on the hardware
    to patches, updates, and general changes to software. There can be data corruption
    or unrecoverable read errors. There might be configuration changes that do not
    work as expected. There are so many things that can happen regardless of if anyone
    has made intentional system changes or not. And the longer that we go from our
    last reboot, the less confidence that we can have that we know how the system
    will react.
  prefs: []
  type: TYPE_NORMAL
- en: We always have to be confident, within reason, that a reboot will work. We cannot
    always control when a reboot will happen. We can attempt to have redundant power
    and redundant components, but every system has a chance of restarting and when
    they do, we want to have a high degree of confidence that it will reboot smoothly.
  prefs: []
  type: TYPE_NORMAL
- en: The process of rebooting triggers many risks for a server. It reloads a lot
    of data from disk or other storage locations that likely has not been read in
    its entirety since the last reboot so the potential for corruption or other storage
    problems is heightened. It puts stress on the physical system, especially if a
    physical restart is coupled with the reboot. This is the time that it will be
    discovered that a file is missing, a file has corrupted, or a memory stick has
    finally started to fail.
  prefs: []
  type: TYPE_NORMAL
- en: At first glance we might think that intentionally rebooting a system seems crazy,
    why would we want to encourage a failure to happen? But this is exactly what we
    want. We intentionally induce the potential for failure in order to hopefully
    avoid it at other times.
  prefs: []
  type: TYPE_NORMAL
- en: The logic here is that we reboot at a time that is convenient or safe, *a green
    zone*. If at the time that we reboot we have a hardware failure or discover an
    unknown software problem, it is at a time where we know what triggered the problem
    (planned reboot), how long it has been since the last reboot (hopefully not very
    long), what changed in between (in the case of a software or configuration problem),
    or that a reboot was the exposure event for hardware failure. This should happen
    at a time that we have designated for fixing a potential problem.
  prefs: []
  type: TYPE_NORMAL
- en: Finding your green zone
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your maintenance window or green zone is a designated time at which a workload
    is accepted to be unavailable in order to allow for regular administration tasks.
    Typical tasks might include a reboot, software installation, patching, database
    re-indexing, disk defragmentation, or other intensive tasks. Every industry, company,
    and even individual workload will be expected to have different time(s) when it
    is appropriate to assign a green zone. Do not expect that the correct green zone
    from one company will apply to a different company or even from one business unit
    to another within a single company.
  prefs: []
  type: TYPE_NORMAL
- en: A common green zone is weekends. For many companies some, if not all, of their
    workloads can safely be unavailable from Friday evening until Monday morning without
    any business impact. Often, no one outside of IT would even be aware. A good strategy
    if this is the case is to perform any patching or similar tasks almost immediately
    upon the commencement of the green zone on Friday evening and then follow that
    work immediately with a reboot. If the reboot causes anything to fail, you have
    more than two and a half days to get it back up and running before anyone comes
    in and complains that systems are down. Two days of impact-free time allows for
    far better repairs than attempting to get a system back up and running when pressure
    is high, money is being lost, and the business is pushing for answers from the
    same team they want focused on fixing the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In my own experience, I once managed an application in which we measured database
    records that were known to have a consistent period of zero use for at least one
    minute every week, across all customers of the system. This gave us an effective
    zone of just sixty seconds, but if we planned carefully, we were able to do system
    reboots, software updates, patching, and more in that window. It was hardly convenient,
    but it was very cost effective compared to asking customers to give us a universal
    maintenance window or to run extra systems to cover for that one minute.
  prefs: []
  type: TYPE_NORMAL
- en: Green zones can be creative and they might not be when you expect. They might
    be easy like long weekends, or maybe it happens during a recurring Tuesday lunch
    meeting. Work with your workload customers to learn when a workload is unused
    or not at risk.
  prefs: []
  type: TYPE_NORMAL
- en: This is really all about planning. Only trigger problems when we are actually
    available to recover the system. This is so that we are far less likely to encounter
    have the same thing happen at a time when perhaps we are not available, or the
    workload is heavily in use. Never let a business say that a workload is too important
    to have planned downtime, that is oxymoronic. We have planned downtime specifically
    because workloads are critical. If a workload does not matter, then saving maintenance
    until things fail is not a problem. The more critical a workload is, the more
    planned downtime is crucial. In fact, any workload given no downtime (at least
    at a system level) could be designated as non-critical or non-production level
    simply from being given no planned maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to a car, the more important a vehicle is to you the more likely that
    you will take it out of service to have regular maintenance like oil changes and
    brake checks. You do this because planned maintenance is trivial, and an unplanned
    seized engine is not. We know naturally that it is better to maintain our cars
    than to let them fail. It is no different with our servers.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding planned downtime is planning for unplanned downtime
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If a resultant workload has no reasonable allowance for downtime, then additional
    strategies are necessary. If you are Amazon running a global online store, for
    example, even a minute of downtime might cost you a great many sales. If you are
    an investment bank, a minute of downtime could mean that orders are not completed
    properly, and millions of dollars could be lost. If you are a hospital, a minute
    might mean critical life support fails and deaths occur. And if you are a military,
    a minute could cost you a war, so that there are types of workload outages that
    we truly want to avoid is not in dispute. Clearly there are times when we need
    to go to extreme measures to make sure that downtime does not happen.
  prefs: []
  type: TYPE_NORMAL
- en: In these cases, we need high availability at a level that allows us to take
    any arbitrary component of the infrastructure offline. This could be storage,
    networking, or any number of platform and compute resources. That means some amount
    of high availability at the application level so that we are able to properly
    patch everything from hard drive firmware to application libraries at the highest
    level and everything in between.
  prefs: []
  type: TYPE_NORMAL
- en: Critical workloads need smooth running well secured infrastructure to keep them
    running. A good maintenance plan is at the absolute heart of making workloads
    reliable.
  prefs: []
  type: TYPE_NORMAL
- en: There is no hard and fast rule about the frequency of reboots. But a good starting
    point is weekly and gauge from there what is appropriate for your environment.
    There is a tendency to opt for weekly or monthly because we often know that reboots
    are necessary, but we still think that they should be avoided. But, with rare
    exception, this is not true. We truly want to reboot as often as it is deemed
    safe and prudent to do so.
  prefs: []
  type: TYPE_NORMAL
- en: Rebooting monthly, under current patching regimes, is about the longest that
    you would want to consider waiting for a standard schedule. Remember that any
    schedule needs to have some accommodations for a system being missed and having
    to wait for an additional cycle. So, if you plan for monthly, you need to be accepting
    of some systems going two months, from time to time, without maintenance due to
    technical or logistical problems.
  prefs: []
  type: TYPE_NORMAL
- en: Weekly tends to be the most practical of schedules. Most workloads have a weekly
    usage pattern that makes it easy, or at least plausible, to allot a maintenance
    window. Weekly schedules are also good for users as they are easy to remember.
    For example, if a system reboots every Saturday morning at nine, users will get
    used to that and not try to use the system then even if they felt like working.
    It just becomes a habit. Weekly is frequent enough that the increased risk of
    the reboot process is very likely to evoke a pending hardware or software failure
    that would have otherwise occurred in the subsequent six days. This tends to be
    the best balance between convenience and reliability.
  prefs: []
  type: TYPE_NORMAL
- en: We should always evaluate the opportunity to reboot more often. If our workload
    schedules allow for it, a daily reboot can be perfect, for example. This is how
    we generally treat end user workloads, encouraging systems to restart at the end
    of the day so that they are fresh and ready for the next day when staff arrive
    to work (whether virtual or physical does not matter.) Doing exactly the same
    with servers might make sense.
  prefs: []
  type: TYPE_NORMAL
- en: Your reboot schedule should take into account your application update schedule.
    If the software that you run updates only rarely then a monthly reboot might make
    more sense. If you have workloads receiving nearly daily updates, then combining
    system reboots with application updates might make sense.
  prefs: []
  type: TYPE_NORMAL
- en: System reboots are especially important after software updates and primary workloads
    (generally assumed not to be managed by the operating system vendor) as there
    are so many possibilities for services to not start up as expected, to need additional
    configuration, or simply run into bugs when rebooting. If you do not reboot in
    conjunction with software updates you lack the full confidence of knowing that
    when it was installed that a reboot worked successfully. If an issue arises later,
    knowing that reboots were working when the last system changes were made can go
    a long way to hastening the recovery process.
  prefs: []
  type: TYPE_NORMAL
- en: If forgetting to reboot systems regularly is a common problem, then forgetting
    to have reboot monitoring is nearly ubiquitous. Even those IT departments that
    take reboot schedules seriously often never think to add *uptime monitoring* to
    their list of sensors to monitor in their environment. Reboot monitoring is generally
    pretty simple and can be generally done quite loosely. For example, in many of
    my environments where we desire the servers to reboot every week, we add a sensor
    for *uptime exceeding nine days*. If our monitoring system determines that a server
    has been up longer than nine days, it will email an alert. Missing one reboot
    event is not a major problem, and this gives plenty of time to avoid false positives
    and plenty of time to plan for manual intervention to find what caused the planned
    reboot to fail and to get it fixed before the next planned reboot should happen.
  prefs: []
  type: TYPE_NORMAL
- en: Best practice here is to seek to reboot as often as is practical and to not
    avoid reboots for anything but a solid business need which cannot include the
    false need of *the system cannot go down*. Shoot for weekly or even daily and
    accept monthly if it is the best that can be mustered and be sure to add monitoring
    as a system not being rebooted is difficult to catch casually.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: System patching, updates, and reboots may feel very pedantic. And in some ways,
    I suppose that they are. But sometimes really important things can also be kind
    of boring. And really, patching and basic system maintenance should be boring.
    It should be predictable, reliable, and scheduled. And if at all possible, it
    should be automated.
  prefs: []
  type: TYPE_NORMAL
- en: Patching should not become a challenge or a scary proposition. With proper planning,
    backups, testing and so forth, it is generally easy to have a reliable patching
    and even update processes that very rarely experience major issues of any kind.
    If we fail to make our patching and updates regular and reliable, we will begin
    to fear the process which will almost certainly lead us to avoid it more which
    will just exacerbate the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In the modern world of computing, there is always someone looking to exploit
    our systems and while nothing can protect against every possible attack, we can
    heavily mitigate our exposure through rapid, regular, and reliable patching.
  prefs: []
  type: TYPE_NORMAL
- en: You should now be confident to evaluate your workloads, get each up to date,
    and begin implementing a formal patching, update, and reboot schedule across your
    fleet.
  prefs: []
  type: TYPE_NORMAL
- en: In our next chapter we are going to look at databases and how they should be
    managed from the perspective of system administration.
  prefs: []
  type: TYPE_NORMAL
