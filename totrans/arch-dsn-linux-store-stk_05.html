<html><head></head><body>
<div id="_idContainer049">
<h1 class="chapter-number" id="_idParaDest-86"><a id="_idTextAnchor090"/><span class="koboSpan" id="kobo.1.1">5</span></h1>
<h1 id="_idParaDest-87"><a id="_idTextAnchor091"/><span class="koboSpan" id="kobo.2.1">Understanding the Block Layer, Multi-Queue, and Device Mapper</span></h1>
<p class="author-quote"><span class="koboSpan" id="kobo.3.1">“I feel the need... </span><span class="koboSpan" id="kobo.3.2">the need for speed.” </span><span class="koboSpan" id="kobo.3.3">– Maverick in Top Gun</span></p>
<p><a href="B19430_04.xhtml#_idTextAnchor072"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.4.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.5.1"> introduced us to the role of the block layer in the kernel. </span><span class="koboSpan" id="kobo.5.2">We were able to see what constitutes a block device and explored the major data structures in the block layer. </span><span class="koboSpan" id="kobo.5.3">This chapter will build on that knowledge as we continue understanding the </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">block layer.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">This chapter will introduce you to two major concepts: the multi-queue block I/O mechanism and the device mapper framework. </span><span class="koboSpan" id="kobo.7.2">The kernel’s block layer has undergone significant changes in recent years to tackle performance concerns. </span><span class="koboSpan" id="kobo.7.3">The introduction of the multi-queue framework was a significant milestone in this direction, as discussed in </span><a href="B19430_04.xhtml#_idTextAnchor072"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.8.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.9.1">. </span><span class="koboSpan" id="kobo.9.2">Performance is a critical consideration when dealing with block devices, and the kernel has implemented various improvements to optimize disk drive performance. </span><span class="koboSpan" id="kobo.9.3">In </span><a href="B19430_04.xhtml#_idTextAnchor072"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.10.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.11.1">, we looked at the request and response queue structures in the block layer, which handle the I/O requests for a block device. </span><span class="koboSpan" id="kobo.11.2">In this chapter, we’ll start by introducing the single-request queue model, its performance limitations, and the challenges faced by the block layer when working with modern high-performing storage drives such as NVMe and SSDs. </span><span class="koboSpan" id="kobo.11.3">We’ll also explain how the single-request queue model impacts the performance of </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">multicore systems.</span></span></p>
<p><span class="koboSpan" id="kobo.13.1">The second major topic of this chapter will be the mapping framework in the kernel, known as the device mapper. </span><span class="koboSpan" id="kobo.13.2">The device mapper framework in the kernel works in conjunction with the block layer and is responsible for mapping physical block devices to logical block devices. </span><span class="koboSpan" id="kobo.13.3">As we will see, the device mapper framework serves as the foundation for implementing various technologies, such as logical volume management, RAID, encryption, and thin provisioning. </span><span class="koboSpan" id="kobo.13.4">In the end, we’ll also briefly discuss caching mechanisms in the </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">block layer.</span></span></p>
<p><span class="koboSpan" id="kobo.15.1">We will discuss the following </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.17.1">The problem with </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">single-request queues</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">The multi-queue block </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">I/O mechanism</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">The device </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">mapper framework</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">Multi-tier caching in the </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">block layer</span></span><a id="_idTextAnchor092"/></li>
</ul>
<h1 id="_idParaDest-88"><a id="_idTextAnchor093"/><span class="koboSpan" id="kobo.25.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.26.1">In addition to the Linux operating system concepts we covered previously, the topics discussed in this chapter require a basic understanding of modern processors and storage technologies. </span><span class="koboSpan" id="kobo.26.2">Any practical experience in Linux storage administration will greatly enhance your understanding of </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">certain aspects.</span></span></p>
<p><span class="koboSpan" id="kobo.28.1">The commands and examples presented in this chapter are distribution-agnostic and can be run on any Linux operating system, such as Debian, Ubuntu, Red Hat, Fedora, and others. </span><span class="koboSpan" id="kobo.28.2">There are quite a few references to the kernel source code. </span><span class="koboSpan" id="kobo.28.3">If you want to download the kernel source, you can download it from </span><a href="https://www.kernel.org"><span class="koboSpan" id="kobo.29.1">https://www.kernel.org</span></a><span class="koboSpan" id="kobo.30.1">. </span><span class="koboSpan" id="kobo.30.2">The code segments referred to in this chapter and book are from </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">kernel </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.32.1">5.19.9</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">.</span></span></p>
<h1 id="_idParaDest-89"><a id="_idTextAnchor094"/><span class="koboSpan" id="kobo.34.1">Looking at problems with single-request queues</span></h1>
<p><span class="koboSpan" id="kobo.35.1">The operating system must handle block devices so that they operate at their full potential. </span><span class="koboSpan" id="kobo.35.2">An application may need to perform I/O operations on arbitrary locations on a block device, which requires seeking multiple disk locations and can prolong the operation’s duration. </span><span class="koboSpan" id="kobo.35.3">When rotating mechanical drives, constant random accesses can not only degrade performance but also produce noticeable noise. </span><span class="koboSpan" id="kobo.35.4">Although still used in the modern day, interfaces such as </span><strong class="bold"><span class="koboSpan" id="kobo.36.1">Serial Advanced Technology Attachment</span></strong><span class="koboSpan" id="kobo.37.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.38.1">SATA</span></strong><span class="koboSpan" id="kobo.39.1">) were the protocol of choice for mechanical drives. </span><span class="koboSpan" id="kobo.39.2">The original design of the kernel’s block layer was meant for a time when mechanical drives were the medium of choice. </span><span class="koboSpan" id="kobo.39.3">These legacy hard drives could only handle a few hundred IOPs. </span><span class="koboSpan" id="kobo.39.4">Two things changed this: the ascendance of multi-core processors and the advancement in drive technologies. </span><span class="koboSpan" id="kobo.39.5">With these changes, the bottleneck in the storage stack shifted from the physical hardware to the software layers in </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">the kernel.</span></span></p>
<p><span class="koboSpan" id="kobo.41.1">In the legacy design, the kernel’s block layer handled I/O requests in one of the </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">following ways:</span></span></p>
<ul>
<li><a id="_idTextAnchor095"/><span class="koboSpan" id="kobo.43.1">The block layer maintained a single-request queue, a linked list structure, to handle I/O requests. </span><span class="koboSpan" id="kobo.43.2">New requests were inserted at the tail end of the queue. </span><span class="koboSpan" id="kobo.43.3">The block layer implemented techniques such as merging and coalescing (which we’ll explain in the next chapter) on these requests before handing them over to </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">the driver.</span></span></li>
<li><span class="koboSpan" id="kobo.45.1">In some cases, the I/O requests had to bypass the request queues and land directly on the device driver. </span><span class="koboSpan" id="kobo.45.2">This meant that all the processing done in the request queue would be performed by the driver. </span><span class="koboSpan" id="kobo.45.3">This usually resulted in a negative </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">performance impact.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.47.1">Even with the use of modern solid-state drives, this design suffered from major limitations. </span><span class="koboSpan" id="kobo.47.2">This approach further results in a </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">three-fold problem:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.49.1">The request queue containing I/O requests didn’t scale to handle the needs of modern processors. </span><span class="koboSpan" id="kobo.49.2">On multi-core systems, a single-request queue had to be shared between multiple cores. </span><span class="koboSpan" id="kobo.49.3">Therefore, to access the request queue, a locking mechanism was used. </span><span class="koboSpan" id="kobo.49.4">This global lock was used to synchronize shared access to the block layer request queue. </span><span class="koboSpan" id="kobo.49.5">To implement the different I/O handling techniques, a CPU core needed to acquire a lock to the request queue. </span><span class="koboSpan" id="kobo.49.6">This meant that if another core needed to operate on the request queue, it had to wait a considerable amount of time. </span><span class="koboSpan" id="kobo.49.7">All CPU cores remain in a state of contention for the request queue lock. </span><span class="koboSpan" id="kobo.49.8">It’s not too difficult to see that this design made the request queue the single point of contention on </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">multi-core systems.</span></span></li>
<li><span class="koboSpan" id="kobo.51.1">A single-request queue also introduces cache coherency problems. </span><span class="koboSpan" id="kobo.51.2">Each CPU core has its own L1/L2 cache, which may contain a copy of the shared data. </span><span class="koboSpan" id="kobo.51.3">When a CPU core modifies some data after acquiring a global lock to the request queue and updates said data in its cache, the other cores may still contain stale copies of the same data in their caches. </span><span class="koboSpan" id="kobo.51.4">As a result, modifications made by one core may not be promptly propagated to the caches of other cores. </span><span class="koboSpan" id="kobo.51.5">This leads to an inconsistent view of the shared data across different cores. </span><span class="koboSpan" id="kobo.51.6">When the global lock to the request queue is freed by a core, its ownership is transferred to another core already waiting for the lock. </span><span class="koboSpan" id="kobo.51.7">Although several cache coherency protocols exist, which ensure that caches maintain a consistent view of the shared data, the bottom line is that the single-queue design does not inherently provide mechanisms to synchronize the caches of different CPU cores. </span><span class="koboSpan" id="kobo.51.8">This increases the overall workload required to ensure </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1">cache coherency.</span></span></li>
<li><span class="koboSpan" id="kobo.53.1">This frequent switching of request queue locks between cores results in an increased number </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">of interrupts.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.55.1">All in all, the use of multiple cores meant that multiple execution threads would be simultaneously competing for the same shared lock. </span><span class="koboSpan" id="kobo.55.2">The higher the number of CPUs/cores in the system, the higher the lock contention for the request queue. </span><span class="koboSpan" id="kobo.55.3">A significant number of CPU cycles are wasted due to the spinning and contention involved in acquiring this lock. </span><span class="koboSpan" id="kobo.55.4">On multi-socket systems, this greatly reduces the number </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">of IOPs.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.57.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.58.1">.1</span></em><span class="koboSpan" id="kobo.59.1"> highlights the limitations of using the single </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">queue model:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer043">
<span class="koboSpan" id="kobo.61.1"><img alt="Figure 5.1 – The single-request queue model" src="image/B19430_05_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.62.1">Figure 5.1 – The single-request queue model</span></p>
<p><span class="koboSpan" id="kobo.63.1">From </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.64.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.65.1">.1</span></em><span class="koboSpan" id="kobo.66.1">, it becomes abundantly clear that regardless of the CPU core count and the type of underlying physical storage, the single queue block layer’s design could not scale up to match their </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">performance requirements.</span></span></p>
<p><span class="koboSpan" id="kobo.68.1">In the past decade or so, enterprise storage environments have shifted to solid-state drives and non-volatile memory. </span><span class="koboSpan" id="kobo.68.2">These devices do not have mechanical parts and are capable of handling I/O requests in parallel. </span><span class="koboSpan" id="kobo.68.3">The design of these devices ensures that no performance penalty is observed when doing random access. </span><span class="koboSpan" id="kobo.68.4">With the emergence of flash drives as the preferred persistent storage medium, the traditional techniques that were used in the block layer for working with HDDs became obsolete. </span><span class="koboSpan" id="kobo.68.5">To fully leverage the enhanced capabilities of SSDs, the design of the block layer needed to </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">mature accordingly.</span></span></p>
<p><span class="koboSpan" id="kobo.70.1">In the next section, we’ll see how the block layer has evolved to meet </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">this challenge.</span></span></p>
<h1 id="_idParaDest-90"><a id="_idTextAnchor096"/><span class="koboSpan" id="kobo.72.1">Understanding the multi-queue block I/O framework</span></h1>
<p><span class="koboSpan" id="kobo.73.1">The organization of the storage hierarchy in Linux bears some resemblance to the network stack in Linux. </span><span class="koboSpan" id="kobo.73.2">Both are multi-layered and strictly define the role of each layer in the stack. </span><span class="koboSpan" id="kobo.73.3">Device drivers and physical interfaces are involved that dictate the overall performance. </span><span class="koboSpan" id="kobo.73.4">Similar to the behavior of the block layer, when a network packet was ready for transmission, it was placed in a single queue. </span><span class="koboSpan" id="kobo.73.5">This approach was used for several years until the network hardware evolved to support multiple queues. </span><span class="koboSpan" id="kobo.73.6">Hence, for devices with multiple queues, this approach </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">became obsolete.</span></span></p>
<p><span class="koboSpan" id="kobo.75.1">This problem was pretty similar to the one that was later faced by the block layer in the kernel. </span><span class="koboSpan" id="kobo.75.2">The network stack in the Linux kernel solved this problem a lot earlier than the storage stack. </span><span class="koboSpan" id="kobo.75.3">Hence, the kernel’s storage stack took a cue from this, which led to the creation of a new framework for the Linux block layer, known as the </span><strong class="bold"><span class="koboSpan" id="kobo.76.1">multi-queue block</span></strong><span class="koboSpan" id="kobo.77.1"> I/O queuing mechanism, shortened </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">to </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.79.1">blk-mq</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.81.1">The multi-queue framework solved the limitations in the block layer by isolating request queues for every CPU core. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.82.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.83.1">.2</span></em><span class="koboSpan" id="kobo.84.1"> illustrates how this approach fixes all three limitations in the single queue </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">framework’s design:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer044">
<span class="koboSpan" id="kobo.86.1"><img alt="Figure 5.2 – The multi-queue framework" src="image/B19430_05_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.87.1">Figure 5.2 – The multi-queue framework</span></p>
<p><span class="koboSpan" id="kobo.88.1">By using this approach, a CPU core can focus on executing its threads without worrying about the threads running on other cores. </span><span class="koboSpan" id="kobo.88.2">This approach resolves the limitations caused by the shared global lock and also minimizes the usage of interrupts and the need for </span><span class="No-Break"><span class="koboSpan" id="kobo.89.1">cache coherency.</span></span></p>
<p><span class="koboSpan" id="kobo.90.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.91.1">blk-mq</span></strong><span class="koboSpan" id="kobo.92.1"> framework implements the following two-level queue design for handling </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">I/O requests:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.94.1">Software staging queues</span></strong><span class="koboSpan" id="kobo.95.1">: The software staging queues that are represented consist of one or more </span><strong class="source-inline"><span class="koboSpan" id="kobo.96.1">bio</span></strong><span class="koboSpan" id="kobo.97.1"> structures. </span><span class="koboSpan" id="kobo.97.2">A block device will have multiple software I/O submission queues, usually one per CPU core, and each queue will have a lock. </span><span class="koboSpan" id="kobo.97.3">A system with </span><em class="italic"><span class="koboSpan" id="kobo.98.1">M</span></em><span class="koboSpan" id="kobo.99.1"> sockets and </span><em class="italic"><span class="koboSpan" id="kobo.100.1">N</span></em><span class="koboSpan" id="kobo.101.1"> cores can have a minimum of </span><em class="italic"><span class="koboSpan" id="kobo.102.1">M</span></em><span class="koboSpan" id="kobo.103.1"> and a maximum of </span><em class="italic"><span class="koboSpan" id="kobo.104.1">N</span></em><span class="koboSpan" id="kobo.105.1"> queues. </span><span class="koboSpan" id="kobo.105.2">Each core submits I/O requests in its queue and doesn’t interact with other cores. </span><span class="koboSpan" id="kobo.105.3">These queues eventually fan into a single queue for the device driver. </span><span class="koboSpan" id="kobo.105.4">The I/O schedulers can operate on the requests in the staging queue to reorder or merge them. </span><span class="koboSpan" id="kobo.105.5">However, this reordering doesn’t matter as SSDs and NVMe drives don’t care if an I/O request is random or sequential. </span><span class="koboSpan" id="kobo.105.6">This scheduling happens only between requests in the same queue, so no locking mechanism </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">is required.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.107.1">Hardware dispatch queues</span></strong><span class="koboSpan" id="kobo.108.1">: The number of hardware queues that can be supported depends on the number of hardware contexts that are supported by the hardware and its corresponding device driver. </span><span class="koboSpan" id="kobo.108.2">However, it should be noted that the maximum number of hardware queues will not exceed the number of cores in the system. </span><span class="koboSpan" id="kobo.108.3">The number of software staging queues can be less than, greater than, or equal to the number of hardware queues. </span><span class="koboSpan" id="kobo.108.4">The hardware dispatch queues represent the last stage of the block layer’s code and act as a mediator before the requests get handed over to the device driver for their final execution. </span><span class="koboSpan" id="kobo.108.5">When an I/O request arrives at the block layer and there isn’t an I/O scheduler associated with the block device, </span><strong class="source-inline"><span class="koboSpan" id="kobo.109.1">blk-mq</span></strong><span class="koboSpan" id="kobo.110.1"> will send the request directly to the </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">hardware queue.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.112.1">The multi-queue API makes use of tags to indicate which request has been completed. </span><span class="koboSpan" id="kobo.112.2">Every request is identified by a tag, which is an integer value ranging from zero to the size of the dispatch queue. </span><span class="koboSpan" id="kobo.112.3">The block layer generates a tag, which is subsequently utilized by the device driver, eliminating the need for a duplicate identifier. </span><span class="koboSpan" id="kobo.112.4">Once the driver has finished processing the request, the tag is returned to the block layer to signal the completion of the operation. </span><span class="koboSpan" id="kobo.112.5">The following section highlights some of the major data structures that play a vital role in the implementation of the multi-queue </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1">block layer.</span></span></p>
<h2 id="_idParaDest-91"><a id="_idTextAnchor097"/><span class="koboSpan" id="kobo.114.1">Looking at data structures</span></h2>
<p><span class="koboSpan" id="kobo.115.1">Here are some of the primary data structures that are essential to implement the multi-queue </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">block layer:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.117.1">The first relevant data structure that’s used by the multi-queue framework is the </span><strong class="source-inline"><span class="koboSpan" id="kobo.118.1">blk_mq_register_dev</span></strong><span class="koboSpan" id="kobo.119.1"> structure, which contains all the necessary information required when registering a new block device to the block layer. </span><span class="koboSpan" id="kobo.119.2">It contains various fields that provide details about the driver’s capabilities </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">and requirements.</span></span></li>
<li><span class="koboSpan" id="kobo.121.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.122.1">blk_mq_ops</span></strong><span class="koboSpan" id="kobo.123.1"> data structure serves as a reference for the multi-queue block layer to access the device driver’s specific routines. </span><span class="koboSpan" id="kobo.123.2">This structure serves as an interface for communication between the driver and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.124.1">blk-mq</span></strong><span class="koboSpan" id="kobo.125.1"> layer, enabling the driver to integrate seamlessly into the multi-queue </span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">processing framework.</span></span></li>
<li><span class="koboSpan" id="kobo.127.1">The software staging queues are represented by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.128.1">blk_mq_ctx</span></strong><span class="koboSpan" id="kobo.129.1"> structure. </span><span class="koboSpan" id="kobo.129.2">This structure is allocated on a per-CPU </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">core basis.</span></span></li>
<li><span class="koboSpan" id="kobo.131.1">The corresponding structure for hardware dispatch queues is defined by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.132.1">blk_mq_hw_ctx</span></strong><span class="koboSpan" id="kobo.133.1"> struct. </span><span class="koboSpan" id="kobo.133.2">This represents the hardware context with which a request queue </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">is associated.</span></span></li>
<li><span class="koboSpan" id="kobo.135.1">The task of mapping software staging queues to hardware dispatch queues is performed by the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.136.1">blk_mq_queue_map</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.137.1"> structure.</span></span></li>
<li><span class="koboSpan" id="kobo.138.1">The requests are created and sent to the block device through the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.139.1">blk_mq_submit_bio</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.140.1"> function.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.141.1">The following figure paints a picture of how these functions </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">are interconnected:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer045">
<span class="koboSpan" id="kobo.143.1"><img alt="Figure 5.3 – Interplay of major structures in the multi-queue framework" src="image/B19430_05_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.144.1">Figure 5.3 – Interplay of major structures in the multi-queue framework</span></p>
<p><span class="koboSpan" id="kobo.145.1">To summarize, the multi-queue interface solves the limitations faced by the block layer when working with modern storage devices that have multiple queues. </span><span class="koboSpan" id="kobo.145.2">Historically, regardless of the capabilities of the underlying physical storage medium, the block layer maintained a single-request queue to handle I/O requests. </span><span class="koboSpan" id="kobo.145.3">On systems with multiple cores, this quickly turned into a major bottleneck. </span><span class="koboSpan" id="kobo.145.4">As the request queue was being shared between all CPU cores through a global lock, a considerable amount of time was spent by each CPU core waiting for the lock to be released by another core. </span><span class="koboSpan" id="kobo.145.5">To overcome this challenge, a new framework was developed to cater to the requirements of modern processors and storage devices. </span><span class="koboSpan" id="kobo.145.6">The multi-queue framework resolves the limitations of the block layer by segregating request queues for each CPU core. </span><span class="koboSpan" id="kobo.145.7">This framework leverages a dual queue design that is comprised of software staging queues and hardware </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">dispatch queues.</span></span></p>
<p><span class="koboSpan" id="kobo.147.1">With that, we have analyzed the multi-queue framework in the block layer. </span><span class="koboSpan" id="kobo.147.2">We will now shift our focus and explore the device </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">mapper framework.</span></span></p>
<h2 id="_idParaDest-92"><a id="_idTextAnchor098"/><span class="koboSpan" id="kobo.149.1">Looking at the device mapper framework</span></h2>
<p><span class="koboSpan" id="kobo.150.1">By default, managing physical block devices is rigid in that there are only a handful of ways in which an application can make use of them. </span><span class="koboSpan" id="kobo.150.2">When dealing with block devices, informed decisions have to be made regarding disk partitioning and space management to ensure optimal usage of available resources. </span><span class="koboSpan" id="kobo.150.3">In the past, features such as thin provisioning, snapshots, volume management, and encryption were exclusive to enterprise storage arrays. </span><span class="koboSpan" id="kobo.150.4">However, over time, these features have become crucial components of any local storage infrastructure. </span><span class="koboSpan" id="kobo.150.5">When operating with physical drives, it is expected that the upper layers of the operating system will possess the necessary capabilities to implement and sustain these functionalities. </span><span class="koboSpan" id="kobo.150.6">The Linux kernel provides the device mapper framework for implementing these concepts. </span><span class="koboSpan" id="kobo.150.7">The device mapper is used by the kernel to map physical block devices to higher-level virtual block devices. </span><span class="koboSpan" id="kobo.150.8">The primary goal of the device mapper framework is to create a high-level layer of abstraction on top of physical devices. </span><span class="koboSpan" id="kobo.150.9">The device mapper provides a mechanism to modify bio structures in transit and map them to block devices. </span><span class="koboSpan" id="kobo.150.10">The use of the device mapper framework lays the foundation for implementing features such as logical </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">volume management.</span></span></p>
<p><span class="koboSpan" id="kobo.152.1">The device mapper provides a generic way to create virtual layers of block devices on top of physical devices and implement features such as striping, mirroring, snapshots, and multipathing. </span><span class="koboSpan" id="kobo.152.2">Like most things in Linux, the functionality of the device mapper framework is divided into kernel space and user space. </span><span class="koboSpan" id="kobo.152.3">The policy-related work, such as defining physical-to-logical mappings, is contained in the user space, while the functions that implement the policies to establish these mappings lie in the </span><span class="No-Break"><span class="koboSpan" id="kobo.153.1">kernel space.</span></span></p>
<p><span class="koboSpan" id="kobo.154.1">The device mapper’s application interface is the </span><strong class="source-inline"><span class="koboSpan" id="kobo.155.1">ioctl</span></strong><span class="koboSpan" id="kobo.156.1"> system call. </span><span class="koboSpan" id="kobo.156.2">This system call adjusts the special file’s underlying device parameters. </span><span class="koboSpan" id="kobo.156.3">The logical devices that employ the device mapper framework are managed via the </span><strong class="source-inline"><span class="koboSpan" id="kobo.157.1">dmsetup</span></strong><span class="koboSpan" id="kobo.158.1"> command and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.159.1">libdevmapper</span></strong><span class="koboSpan" id="kobo.160.1"> library, which implement the respective user interface, as depicted in the </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">following figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer046">
<span class="koboSpan" id="kobo.162.1"><img alt="Figure 5.4 – Major components of the device mapper framework" src="image/B19430_05_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.163.1">Figure 5.4 – Major components of the device mapper framework</span></p>
<p><span class="koboSpan" id="kobo.164.1">If we run </span><strong class="source-inline"><span class="koboSpan" id="kobo.165.1">strace</span></strong><span class="koboSpan" id="kobo.166.1"> on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.167.1">dmsetup</span></strong><span class="koboSpan" id="kobo.168.1"> command, we will see that it makes use of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.169.1">libdevmapper</span></strong><span class="koboSpan" id="kobo.170.1"> library and the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.171.1">ioctl</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.172.1"> interface:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.173.1">root@linuxbox:~# strace dmsetup ls</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.174.1">execve("/sbin/dmsetup", ["dmsetup", "ls"], 0x7fffbd282c58 /* 22 vars */) = 0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.175.1">[..................]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.176.1">access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.177.1">openat(AT_FDCWD, "/lib/x86_64-linux-gnu/libdevmapper.so.1.02.1", O_RDONLY|O_CLOEXEC) = 3</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.178.1">[...............…]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.179.1">stat("/dev/mapper/control", {st_mode=S_IFCHR|0600, st_rdev=makedev(10, 236), ...}) = 0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.180.1">openat(AT_FDCWD, "/dev/mapper/control", O_RDWR) = 3</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.181.1">openat(AT_FDCWD, "/proc/devices", O_RDONLY) = 4</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.182.1">[...............…]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.183.1">ioctl(3, DM_VERSION, {version=4.0.0, data_size=16384, flags=DM_EXISTS_FLAG} =&gt; {version=4.41.0, data_size=16384, flags=DM_EXISTS_FLAG}) = 0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.184.1">ioctl(3, DM_LIST_DEVICES, {version=4.0.0, data_size=16384, data_start=312, flags=DM_EXISTS_FLAG} =&gt; {version=4.41.0, data_size=528, data_start=312, flags=DM_EXISTS_FLAG, ...}) = 0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.185.1">[..................]</span></strong></pre>
<p><span class="koboSpan" id="kobo.186.1">Applications that establish mapped devices, such as LVM, communicate with the device mapper framework via the </span><strong class="source-inline"><span class="koboSpan" id="kobo.187.1">libdevmapper</span></strong><span class="koboSpan" id="kobo.188.1"> library. </span><span class="koboSpan" id="kobo.188.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.189.1">libdevmapper</span></strong><span class="koboSpan" id="kobo.190.1"> library utilizes </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1">ioctl</span></strong><span class="koboSpan" id="kobo.192.1"> commands to transmit data to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.193.1">/dev/mapper/control</span></strong><span class="koboSpan" id="kobo.194.1"> device. </span><span class="koboSpan" id="kobo.194.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.195.1">/dev/mapper/control</span></strong><span class="koboSpan" id="kobo.196.1"> device is a specialized device that functions as a control mechanism for the device </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">mapper framework.</span></span></p>
<p><span class="koboSpan" id="kobo.198.1">From </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.199.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.200.1">.4</span></em><span class="koboSpan" id="kobo.201.1">, we can see that the device mapper framework in kernel space implements a modular architecture for storage management. </span><span class="koboSpan" id="kobo.201.2">The device mapper framework’s functionality consists of the following three </span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">major components:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.203.1">Mapped device</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.204.1">Mapping table</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.205.1">Target device</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.206.1">Let’s briefly look at their </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">respective roles.</span></span></p>
<h3><span class="koboSpan" id="kobo.208.1">Looking at the mapped device</span></h3>
<p><span class="koboSpan" id="kobo.209.1">A block device, such as a whole disk or an individual partition, can be </span><em class="italic"><span class="koboSpan" id="kobo.210.1">mapped</span></em><span class="koboSpan" id="kobo.211.1"> to another device. </span><span class="koboSpan" id="kobo.211.2">The mapped device is a logical device provided by the device mapper driver and usually exists in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.212.1">/dev/mapper</span></strong><span class="koboSpan" id="kobo.213.1"> directory. </span><span class="koboSpan" id="kobo.213.2">Logical volumes in LVM are examples of mapped devices. </span><span class="koboSpan" id="kobo.213.3">The mapped device is defined in </span><strong class="source-inline"><span class="koboSpan" id="kobo.214.1">drivers/md/dm-core.h</span></strong><span class="koboSpan" id="kobo.215.1">. </span><span class="koboSpan" id="kobo.215.2">If we look at this definition, we will come across a </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">familiar structure:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.217.1">
struct mapped_device {
[……..]
struct gendisk *disk;
[………..]</span></pre>
<p><span class="koboSpan" id="kobo.218.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.219.1">gendisk</span></strong><span class="koboSpan" id="kobo.220.1"> structure, as explained in </span><a href="B19430_04.xhtml#_idTextAnchor072"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.221.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.222.1">, represents the notion of a physical hard disk in </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">the kernel.</span></span></p>
<h3><span class="koboSpan" id="kobo.224.1">Looking at the mapping table</span></h3>
<p><span class="koboSpan" id="kobo.225.1">A mapped device is defined by a mapping table. </span><span class="koboSpan" id="kobo.225.2">This mapping table represents a mapping from a mapped device to target devices. </span><span class="koboSpan" id="kobo.225.3">A mapped device is defined by a table that describes how each range of logical sectors of the device should be mapped, using a device table mapping that is supported by the device mapper framework. </span><span class="koboSpan" id="kobo.225.4">The mapping table defined in </span><strong class="source-inline"><span class="koboSpan" id="kobo.226.1">drivers/md/dm-core.h</span></strong><span class="koboSpan" id="kobo.227.1"> contains a pointer to the </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">mapped device:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.229.1">
struct dm_table {
        struct mapped_device *md;
[……………..]</span></pre>
<p><span class="koboSpan" id="kobo.230.1">This structure allows mappings to be created, modified, and deleted in the device mapper stack. </span><span class="koboSpan" id="kobo.230.2">Details about the mapping table can be viewed by running the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.231.1">dmsetup</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.232.1"> command.</span></span></p>
<h3><span class="koboSpan" id="kobo.233.1">Looking at the target device</span></h3>
<p><span class="koboSpan" id="kobo.234.1">As explained earlier, the device mapper framework creates virtual block devices by defining mappings on physical block devices. </span><span class="koboSpan" id="kobo.234.2">Logical devices are created using “targets,” which can be thought of as modularized plugins. </span><span class="koboSpan" id="kobo.234.3">Different mapping types, such as linear, mirror, snapshot, and others, can be created using these targets. </span><span class="koboSpan" id="kobo.234.4">Data is passed from the virtual block device to the physical block device through these mappings. </span><span class="koboSpan" id="kobo.234.5">The target device structure is defined in </span><strong class="source-inline"><span class="koboSpan" id="kobo.235.1">include/linux/device-mapper.h</span></strong><span class="koboSpan" id="kobo.236.1">. </span><span class="koboSpan" id="kobo.236.2">The unit that’s used for mapping is </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">a sector:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.238.1">
struct dm_target {
        struct dm_table *table;
        sector_t begin;
        sector_t len;
[………….]</span></pre>
<p><span class="koboSpan" id="kobo.239.1">The device mapper can be a bit confusing to understand, so let’s illustrate a simple use case of the building blocks that we explained previously. </span><span class="koboSpan" id="kobo.239.2">We’re going to use the </span><em class="italic"><span class="koboSpan" id="kobo.240.1">linear</span></em><span class="koboSpan" id="kobo.241.1"> target, which lays the foundation of logical volume management. </span><span class="koboSpan" id="kobo.241.2">As discussed earlier, we’re going to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.242.1">dmsetup</span></strong><span class="koboSpan" id="kobo.243.1"> command for this purpose as it implements the user-space functionality of the device mapper. </span><span class="koboSpan" id="kobo.243.2">We’re going to create a linear mapping target called </span><strong class="source-inline"><span class="koboSpan" id="kobo.244.1">dm_disk</span></strong><span class="koboSpan" id="kobo.245.1">. </span><span class="koboSpan" id="kobo.245.2">If you plan on running the following commands, make sure that you run them on a blank disk. </span><span class="koboSpan" id="kobo.245.3">Here, I’ve used two disks, </span><strong class="source-inline"><span class="koboSpan" id="kobo.246.1">sdc</span></strong><span class="koboSpan" id="kobo.247.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.248.1">sdd</span></strong><span class="koboSpan" id="kobo.249.1"> (you can use any disk for the exercise, so long it’s empty!). </span><span class="koboSpan" id="kobo.249.2">Note that once you press </span><em class="italic"><span class="koboSpan" id="kobo.250.1">Enter</span></em><span class="koboSpan" id="kobo.251.1"> after the </span><strong class="source-inline"><span class="koboSpan" id="kobo.252.1">dmsetup create</span></strong><span class="koboSpan" id="kobo.253.1"> commands, it will prompt you for input. </span><span class="koboSpan" id="kobo.253.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.254.1">sdc</span></strong><span class="koboSpan" id="kobo.255.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.256.1">sdd</span></strong><span class="koboSpan" id="kobo.257.1"> disks are referred to using their respective major and minor numbers. </span><span class="koboSpan" id="kobo.257.2">You can find out the major and minor numbers for your disk using </span><strong class="source-inline"><span class="koboSpan" id="kobo.258.1">lsblk</span></strong><span class="koboSpan" id="kobo.259.1">. </span><span class="koboSpan" id="kobo.259.2">The major and minor numbers for </span><strong class="source-inline"><span class="koboSpan" id="kobo.260.1">sdc</span></strong><span class="koboSpan" id="kobo.261.1"> are 8 and 32, expressed as </span><strong class="source-inline"><span class="koboSpan" id="kobo.262.1">8:32</span></strong><span class="koboSpan" id="kobo.263.1">. </span><span class="koboSpan" id="kobo.263.2">Similarly, for </span><strong class="source-inline"><span class="koboSpan" id="kobo.264.1">sdd</span></strong><span class="koboSpan" id="kobo.265.1">, this combination is expressed as </span><strong class="source-inline"><span class="koboSpan" id="kobo.266.1">8:48</span></strong><span class="koboSpan" id="kobo.267.1">. </span><span class="koboSpan" id="kobo.267.2">The rest of the input fields will be explained shortly. </span><span class="koboSpan" id="kobo.267.3">Once you’ve entered the required data, use </span><em class="italic"><span class="koboSpan" id="kobo.268.1">Ctrl</span></em><span class="koboSpan" id="kobo.269.1"> + </span><em class="italic"><span class="koboSpan" id="kobo.270.1">D</span></em><span class="koboSpan" id="kobo.271.1"> to exit. </span><span class="koboSpan" id="kobo.271.2">The following example will create a linear target of </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">5 GiB:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.273.1">[root@linuxbox ~]# dmsetup create dm_disk</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.274.1">dm_disk: 0 2048000 linear 8:32 0</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.275.1">dm_disk: 2048000 8192000 linear 8:48 1024</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.276.1">[root@linuxbox ~]#</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.277.1">[root@linuxbox ~]# fdisk -l /dev/mapper/dm_disk</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.278.1">Disk /dev/mapper/dm_disk: 4.9 GiB, 5242880000 bytes, 10240000 sectors</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.279.1">Units: sectors of 1 * 512 = 512 bytes</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.280.1">Sector size (logical/physical): 512 bytes / 512 bytes</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.281.1">I/O size (minimum/optimal): 512 bytes / 512 bytes</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.282.1">[root@linuxbox ~]#</span></strong></pre>
<p><span class="koboSpan" id="kobo.283.1">Here’s what </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">we’ve done:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.285.1">We have created a logical device called </span><strong class="source-inline"><span class="koboSpan" id="kobo.286.1">dm_disk</span></strong><span class="koboSpan" id="kobo.287.1"> by using specific portions or ranges from two physical disks, </span><strong class="source-inline"><span class="koboSpan" id="kobo.288.1">sdc</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.289.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.290.1">sdd</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.292.1">The first line of input that we’ve entered, </span><strong class="source-inline"><span class="koboSpan" id="kobo.293.1">dm_disk: 0 2048000 linear 8:32 0</span></strong><span class="koboSpan" id="kobo.294.1">, means that the first </span><strong class="source-inline"><span class="koboSpan" id="kobo.295.1">2048000 sectors (0-2047999)</span></strong><span class="koboSpan" id="kobo.296.1"> of </span><strong class="source-inline"><span class="koboSpan" id="kobo.297.1">dm_disk</span></strong><span class="koboSpan" id="kobo.298.1"> will use the sectors of </span><strong class="source-inline"><span class="koboSpan" id="kobo.299.1">/dev/sdc</span></strong><span class="koboSpan" id="kobo.300.1">, starting from sector 0. </span><span class="koboSpan" id="kobo.300.2">Therefore, the first </span><strong class="source-inline"><span class="koboSpan" id="kobo.301.1">2048000 (0-2047999)</span></strong><span class="koboSpan" id="kobo.302.1"> sectors of </span><strong class="source-inline"><span class="koboSpan" id="kobo.303.1">sdc</span></strong><span class="koboSpan" id="kobo.304.1"> will be used </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">by </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.306.1">dm_disk</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.308.1">The second line, </span><strong class="source-inline"><span class="koboSpan" id="kobo.309.1">dm_disk: 2048000 8192000 linear 8:48 1024</span></strong><span class="koboSpan" id="kobo.310.1">, means that the next </span><strong class="source-inline"><span class="koboSpan" id="kobo.311.1">8192000 sectors</span></strong><span class="koboSpan" id="kobo.312.1"> (after </span><strong class="source-inline"><span class="koboSpan" id="kobo.313.1">sector number 2047999</span></strong><span class="koboSpan" id="kobo.314.1">) of </span><strong class="source-inline"><span class="koboSpan" id="kobo.315.1">dm_disk</span></strong><span class="koboSpan" id="kobo.316.1"> are being allocated from </span><strong class="source-inline"><span class="koboSpan" id="kobo.317.1">sdd</span></strong><span class="koboSpan" id="kobo.318.1">. </span><span class="koboSpan" id="kobo.318.2">These </span><strong class="source-inline"><span class="koboSpan" id="kobo.319.1">8192000</span></strong><span class="koboSpan" id="kobo.320.1"> sectors from </span><strong class="source-inline"><span class="koboSpan" id="kobo.321.1">sdd</span></strong><span class="koboSpan" id="kobo.322.1"> will be allocated from sector number </span><strong class="source-inline"><span class="koboSpan" id="kobo.323.1">1024</span></strong><span class="koboSpan" id="kobo.324.1"> onward. </span><span class="koboSpan" id="kobo.324.2">If the disks do not contain any data, we can use any sector number here. </span><span class="koboSpan" id="kobo.324.3">If existing data is present, then the sectors should be allocated from an </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">unused range.</span></span></li>
<li><span class="koboSpan" id="kobo.326.1">The total number of sectors in </span><strong class="source-inline"><span class="koboSpan" id="kobo.327.1">dm_disk</span></strong><span class="koboSpan" id="kobo.328.1"> will be </span><strong class="source-inline"><span class="koboSpan" id="kobo.329.1">8192000 +  2048000 = </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.330.1">10240000</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.332.1">With a sector size of 512 bytes, the size of </span><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">dm_disk</span></strong><span class="koboSpan" id="kobo.334.1"> will be </span><strong class="source-inline"><span class="koboSpan" id="kobo.335.1">(8192000 x 512) + (2048000 x 512) ≈ </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.336.1">5 GiB</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.337.1">.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.338.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.339.1">0-2047999</span></strong><span class="koboSpan" id="kobo.340.1"> sector numbers of </span><strong class="source-inline"><span class="koboSpan" id="kobo.341.1">dm_disk</span></strong><span class="koboSpan" id="kobo.342.1"> are mapped from </span><strong class="source-inline"><span class="koboSpan" id="kobo.343.1">sdc</span></strong><span class="koboSpan" id="kobo.344.1">, whereas the </span><strong class="source-inline"><span class="koboSpan" id="kobo.345.1">2048000-10239999</span></strong><span class="koboSpan" id="kobo.346.1"> sector numbers are mapped from </span><strong class="source-inline"><span class="koboSpan" id="kobo.347.1">sdd</span></strong><span class="koboSpan" id="kobo.348.1">. </span><span class="koboSpan" id="kobo.348.2">The example we’ve discussed is a simple one, but it should be evident that we can map a logical device to any number of drives and implement </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">different concepts.</span></span></p>
<p><span class="koboSpan" id="kobo.350.1">The following figure summarizes what we </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">explained earlier:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer047">
<span class="koboSpan" id="kobo.352.1"><img alt="Figure 5.5 – Linear target mapping in the device mapper framework" src="image/B19430_05_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.353.1">Figure 5.5 – Linear target mapping in the device mapper framework</span></p>
<p><span class="koboSpan" id="kobo.354.1">The device mapper framework supports a wide variety of targets. </span><span class="koboSpan" id="kobo.354.2">Some of them are </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">explained here:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.356.1">Linear</span></strong><span class="koboSpan" id="kobo.357.1">: As we saw earlier, a linear mapping target can map a continuous range of blocks to another block device. </span><span class="koboSpan" id="kobo.357.2">This is the basic building block of logical </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">volume management.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.359.1">Raid</span></strong><span class="koboSpan" id="kobo.360.1">: The raid target is used to implement the concept of software raid. </span><span class="koboSpan" id="kobo.360.2">It is capable of supporting different </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">raid types.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.362.1">Crypt</span></strong><span class="koboSpan" id="kobo.363.1">: The crypt target is used to encrypt data on </span><span class="No-Break"><span class="koboSpan" id="kobo.364.1">block devices.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.365.1">Stripe</span></strong><span class="koboSpan" id="kobo.366.1">: The stripe target is used to create a striped device called </span><strong class="source-inline"><span class="koboSpan" id="kobo.367.1">(raid 0)</span></strong><span class="koboSpan" id="kobo.368.1"> across multiple </span><span class="No-Break"><span class="koboSpan" id="kobo.369.1">underlying disks.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.370.1">Multipath</span></strong><span class="koboSpan" id="kobo.371.1">: The multipath mapping target is utilized in storage environments where a host has multiple paths to a storage device. </span><span class="koboSpan" id="kobo.371.2">It allows a multipath device to </span><span class="No-Break"><span class="koboSpan" id="kobo.372.1">be mapped.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.373.1">Thin</span></strong><span class="koboSpan" id="kobo.374.1">: The thin target is used for thin provisioning – that is, creating devices larger than the size of the underlying physical device. </span><span class="koboSpan" id="kobo.374.2">The physical space is allocated only when </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">written to.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.376.1">As repeatedly mentioned earlier, the linear mapping target is most commonly implemented in LVM. </span><span class="koboSpan" id="kobo.376.2">Most Linux distributions use LVM by default for space allocation and partitioning. </span><span class="koboSpan" id="kobo.376.3">To the common user, LVM is probably one of the more well-known features of Linux. </span><span class="koboSpan" id="kobo.376.4">It should not be too difficult to see how the previously mentioned example can be applied to LVM or any other target for </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">that matter.</span></span></p>
<p><span class="koboSpan" id="kobo.378.1">As most of you should be aware, LVM is divided into three </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">basic entities:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.380.1">Physical volume</span></strong><span class="koboSpan" id="kobo.381.1">: The physical volume is at the lowest layer. </span><span class="koboSpan" id="kobo.381.2">The underlying physical disk or partition is a </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">physical volume.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.383.1">Volume group</span></strong><span class="koboSpan" id="kobo.384.1">: The volume group divides the space available in a physical volume into a sequence of chunks, called physical extents. </span><span class="koboSpan" id="kobo.384.2">A physical extent represents a contiguous range of blocks. </span><span class="koboSpan" id="kobo.384.3">It is the smallest unit of disk space that can be individually managed by LVM. </span><span class="koboSpan" id="kobo.384.4">By default, an extent size of 4 MB </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1">is used.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.386.1">Logical volume</span></strong><span class="koboSpan" id="kobo.387.1">: From the space available in a volume group, logical volumes can be created. </span><span class="koboSpan" id="kobo.387.2">Logical volumes are typically divided into smaller chunks of data, each known as a logical extent. </span><span class="koboSpan" id="kobo.387.3">Since LVM utilizes linear target mapping, there is a direct correspondence between physical and logical extents. </span><span class="koboSpan" id="kobo.387.4">Consequently, a logical volume can be viewed as a mapping that’s established by LVM that associates logical extents with physical ones. </span><span class="koboSpan" id="kobo.387.5">This can be visualized in the </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">following figure:</span></span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer048">
<span class="koboSpan" id="kobo.389.1"><img alt="Figure 5.6 – LVM architecture" src="image/B19430_05_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.390.1">Figure 5.6 – LVM architecture</span></p>
<p><span class="koboSpan" id="kobo.391.1">The logical volumes, as we all </span><a id="_idIndexMarker183"/><span class="koboSpan" id="kobo.392.1">know, can be treated like any regular block device, and filesystems can be created on top of them. </span><span class="koboSpan" id="kobo.392.2">A single logical volume that spans multiple physical disks is </span><a id="_idIndexMarker184"/><span class="koboSpan" id="kobo.393.1">similar to </span><strong class="source-inline"><span class="koboSpan" id="kobo.394.1">RAID-0</span></strong><span class="koboSpan" id="kobo.395.1">. </span><span class="koboSpan" id="kobo.395.2">The type </span><a id="_idIndexMarker185"/><span class="koboSpan" id="kobo.396.1">of mapping to be used between physical and logical extents is determined by the target. </span><span class="koboSpan" id="kobo.396.2">As LVM is based on a linear target, there is a one-to-one mapping relationship between physical and logical </span><a id="_idIndexMarker186"/><span class="koboSpan" id="kobo.397.1">extents. </span><span class="koboSpan" id="kobo.397.2">Let’s say we were to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.398.1">dm-raid</span></strong><span class="koboSpan" id="kobo.399.1"> target and configure </span><strong class="source-inline"><span class="koboSpan" id="kobo.400.1">RAID-1</span></strong><span class="koboSpan" id="kobo.401.1"> to do mirroring between multiple block devices. </span><span class="koboSpan" id="kobo.401.2">In that case, multiple physical extents will map to a single </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">logical extent.</span></span></p>
<p><span class="koboSpan" id="kobo.403.1">Let’s wrap up our discussion of the device mapper framework by mapping some key facts in our minds. </span><span class="koboSpan" id="kobo.403.2">The device mapper framework plays a vital role in the kernel and is responsible for implementing several key concepts in the storage hierarchy. </span><span class="koboSpan" id="kobo.403.3">The kernel uses the device mapper framework to map physical block devices to higher-level virtual block devices. </span><span class="koboSpan" id="kobo.403.4">The functionality </span><a id="_idIndexMarker187"/><span class="koboSpan" id="kobo.404.1">of the device mapper framework is split into user space and kernel space. </span><span class="koboSpan" id="kobo.404.2">The user-space interface consists of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.405.1">libdevmapper</span></strong><span class="koboSpan" id="kobo.406.1"> library and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.407.1">dmsetup</span></strong><span class="koboSpan" id="kobo.408.1"> utility. </span><span class="koboSpan" id="kobo.408.2">The kernel part consists of three major components: the mapped device, mapping table, and target device. </span><span class="koboSpan" id="kobo.408.3">The device mapper framework </span><a id="_idIndexMarker188"/><span class="koboSpan" id="kobo.409.1">provides the basis for several important technologies in Linux, such as LVM. </span><span class="koboSpan" id="kobo.409.2">LVM provides a thin layer of abstraction above </span><a id="_idIndexMarker189"/><span class="koboSpan" id="kobo.410.1">physical disks and partitions. </span><span class="koboSpan" id="kobo.410.2">This </span><a id="_idIndexMarker190"/><span class="koboSpan" id="kobo.411.1">abstraction layer allows storage administrators to easily resize filesystems based on their space requirements, providing them with a high level of flexibility. </span><span class="koboSpan" id="kobo.411.2">Before concluding this chapter, let’s briefly touch on the caching mechanisms that are employed by the </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">block layer.</span></span></p>
<h2 id="_idParaDest-93"><a id="_idTextAnchor099"/><span class="koboSpan" id="kobo.413.1">Looking at multi-tier caching mechanisms in the block layer</span></h2>
<p><span class="koboSpan" id="kobo.414.1">The performance of physical storage is usually orders of magnitude slower than that of processors and memory. </span><span class="koboSpan" id="kobo.414.2">The Linux kernel is well aware of this limitation. </span><span class="koboSpan" id="kobo.414.3">Hence, it uses the available memory </span><a id="_idIndexMarker191"/><span class="koboSpan" id="kobo.415.1">as a cache and performs all operations in memory before writing all data to the underlying disks. </span><span class="koboSpan" id="kobo.415.2">This caching mechanism is the default behavior of the kernel and it plays a central role in improving the performance of block devices. </span><span class="koboSpan" id="kobo.415.3">This also positively contributes toward improving the system’s </span><span class="No-Break"><span class="koboSpan" id="kobo.416.1">overall performance.</span></span></p>
<p><span class="koboSpan" id="kobo.417.1">Although solid state and NVMe drives are now commonplace in most storage infrastructures, the traditional spinning drives are still being used for cases where capacity is required and performance is not a major concern. </span><span class="koboSpan" id="kobo.417.2">When we talk about drive performance, random workloads are the </span><em class="italic"><span class="koboSpan" id="kobo.418.1">Achilles heel</span></em><span class="koboSpan" id="kobo.419.1"> of spinning mechanical drives. </span><span class="koboSpan" id="kobo.419.2">In comparison, the performance of flash drives does not suffer from such limitations, but they are far more expensive than mechanical drives. </span><span class="koboSpan" id="kobo.419.3">Ideally, it would be nice to get the advantages of both media types. </span><span class="koboSpan" id="kobo.419.4">Most storage environments are hybrid and try to make efficient use of both types of drives. </span><span class="koboSpan" id="kobo.419.5">One of the most common techniques is to place </span><em class="italic"><span class="koboSpan" id="kobo.420.1">hot</span></em><span class="koboSpan" id="kobo.421.1"> or frequently used data on the fastest physical medium and move </span><em class="italic"><span class="koboSpan" id="kobo.422.1">cold</span></em><span class="koboSpan" id="kobo.423.1"> data to slower mechanical drives. </span><span class="koboSpan" id="kobo.423.2">Most enterprise storage arrays offer built-in storage tiering features that implement this </span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">caching functionality.</span></span></p>
<p><span class="koboSpan" id="kobo.425.1">The Linux kernel is also capable of implementing such a cache solution. </span><span class="koboSpan" id="kobo.425.2">The kernel offers several options to combine the capacity offered by spinning mechanical drives with the speed of access offered by SSDs. </span><span class="koboSpan" id="kobo.425.3">As we saw earlier, the device mapper framework offers a wide variety of targets that add functionalities on top of block devices. </span><span class="koboSpan" id="kobo.425.4">One such target is the </span><strong class="source-inline"><span class="koboSpan" id="kobo.426.1">dm-cache</span></strong><span class="koboSpan" id="kobo.427.1"> target. </span><span class="koboSpan" id="kobo.427.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1">dm-cache</span></strong><span class="koboSpan" id="kobo.429.1"> target can be used to improve the performance of mechanical </span><a id="_idIndexMarker192"/><span class="koboSpan" id="kobo.430.1">drives by migrating some of its data to faster drives, such as SSDs. </span><span class="koboSpan" id="kobo.430.2">This approach is a bit contrary to the kernel’s default caching mechanism, but it can be of </span><a id="_idIndexMarker193"/><span class="koboSpan" id="kobo.431.1">significant use in </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1">some cases.</span></span></p>
<p><span class="koboSpan" id="kobo.433.1">Most cache mechanisms offer the following </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">operational modes:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.435.1">Write-back</span></strong><span class="koboSpan" id="kobo.436.1">: This mode </span><a id="_idIndexMarker194"/><span class="koboSpan" id="kobo.437.1">caches newly written data but does not write it immediately to the </span><span class="No-Break"><span class="koboSpan" id="kobo.438.1">target device.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.439.1">Write-through</span></strong><span class="koboSpan" id="kobo.440.1">: In this mode, new data is written to the target while still retaining it in the cache for </span><span class="No-Break"><span class="koboSpan" id="kobo.441.1">subsequent reads.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.442.1">Write-around</span></strong><span class="koboSpan" id="kobo.443.1">: This mode implements read-only caching. </span><span class="koboSpan" id="kobo.443.2">Data written to the device goes directly to the slower mechanical drive and is not written to the </span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">fast SSD.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.445.1">Pass-through</span></strong><span class="koboSpan" id="kobo.446.1">: To enable pass-through mode, the cache needs to be clean. </span><span class="koboSpan" id="kobo.446.2">Reading is served from the origin device that bypasses the cache. </span><span class="koboSpan" id="kobo.446.3">Writing is forwarded to the origin device and </span><em class="italic"><span class="koboSpan" id="kobo.447.1">invalidates</span></em><span class="koboSpan" id="kobo.448.1"> the </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">cache block.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.450.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.451.1">dm-cache</span></strong><span class="koboSpan" id="kobo.452.1"> target supports all the previously mentioned modes, except write-around. </span><span class="koboSpan" id="kobo.452.2">The required functionality is implemented through the following </span><span class="No-Break"><span class="koboSpan" id="kobo.453.1">three devices:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.454.1">Origin device</span></strong><span class="koboSpan" id="kobo.455.1">: This will always be the slow primary </span><span class="No-Break"><span class="koboSpan" id="kobo.456.1">storage device</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.457.1">Cache device</span></strong><span class="koboSpan" id="kobo.458.1">: This is a high-performing drive, usually </span><span class="No-Break"><span class="koboSpan" id="kobo.459.1">an SSD</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.460.1">Metadata device</span></strong><span class="koboSpan" id="kobo.461.1">: Although this is optional and this information can also be saved on the fast cache device, this device is used for keeping track of all the metadata information, such as which disk blocks are in the cache, which blocks are dirty, and </span><span class="No-Break"><span class="koboSpan" id="kobo.462.1">so on</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.463.1">Another similar caching solution is </span><strong class="source-inline"><span class="koboSpan" id="kobo.464.1">dm-writecache</span></strong><span class="koboSpan" id="kobo.465.1">, which is also a device mapper target. </span><span class="koboSpan" id="kobo.465.2">As its name </span><a id="_idIndexMarker195"/><span class="koboSpan" id="kobo.466.1">suggests, the main focus of </span><strong class="source-inline"><span class="koboSpan" id="kobo.467.1">dm-writecache</span></strong><span class="koboSpan" id="kobo.468.1"> is strictly write-back caching. </span><span class="koboSpan" id="kobo.468.2">It only caches write operations and does not perform any read or write-through caching. </span><span class="koboSpan" id="kobo.468.3">The thought process for not caching reads is that read data should already be in the page cache. </span><span class="koboSpan" id="kobo.468.4">The write operations are cached on the faster storage device and then migrated to the slower disk in </span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">the background.</span></span></p>
<p><span class="koboSpan" id="kobo.470.1">Another notable solution that has gained widespread popularity is </span><strong class="source-inline"><span class="koboSpan" id="kobo.471.1">bcache</span></strong><span class="koboSpan" id="kobo.472.1">. </span><span class="koboSpan" id="kobo.472.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.473.1">bcache</span></strong><span class="koboSpan" id="kobo.474.1"> solution supports all four caching modes defined previously. </span><strong class="source-inline"><span class="koboSpan" id="kobo.475.1">bcache</span></strong><span class="koboSpan" id="kobo.476.1"> uses a far more complex </span><a id="_idIndexMarker196"/><span class="koboSpan" id="kobo.477.1">approach and lets all sequential operations go to the mechanical drives by default. </span><span class="koboSpan" id="kobo.477.2">Since SSDs excel at random operations, there generally won’t be many benefits to caching large sequential operations on SSDs. </span><span class="koboSpan" id="kobo.477.3">Hence, </span><strong class="source-inline"><span class="koboSpan" id="kobo.478.1">bcache</span></strong><span class="koboSpan" id="kobo.479.1"> detects sequential operations and skips them. </span><span class="koboSpan" id="kobo.479.2">The writers for </span><strong class="source-inline"><span class="koboSpan" id="kobo.480.1">bcache</span></strong><span class="koboSpan" id="kobo.481.1"> compare it to the L2 </span><strong class="bold"><span class="koboSpan" id="kobo.482.1">adaptive replacement cache</span></strong><span class="koboSpan" id="kobo.483.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.484.1">ARC</span></strong><span class="koboSpan" id="kobo.485.1">) in ZFS. </span><span class="koboSpan" id="kobo.485.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.486.1">bcache</span></strong><span class="koboSpan" id="kobo.487.1"> project</span><a id="_idIndexMarker197"/><span class="koboSpan" id="kobo.488.1"> has also led to the development of the </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.489.1">Bcachefs</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.490.1"> filesystem.</span></span></p>
<h1 id="_idParaDest-94"><a id="_idTextAnchor100"/><span class="koboSpan" id="kobo.491.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.492.1">This chapter was the second chapter in our exploration of the block layer in the kernel. </span><span class="koboSpan" id="kobo.492.2">The two main topics we discussed in detail were the multi-queue and device mapper frameworks. </span><span class="koboSpan" id="kobo.492.3">At the start of this chapter, we looked into the legacy single-request queue model in the block layer, its limitations, and its adverse impact on performance when working with modern storage drives and multi-core systems. </span><span class="koboSpan" id="kobo.492.4">From there, we introduced the multi-queue framework in the kernel. </span><span class="koboSpan" id="kobo.492.5">We described how the multi-queue framework addresses the limitations of the single-request model and improves the performance of modern storage drives, which are capable of supporting multiple </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1">hardware queues.</span></span></p>
<p><span class="koboSpan" id="kobo.494.1">We also got a chance to look at the device mapper framework in the kernel. </span><span class="koboSpan" id="kobo.494.2">The device mapper framework is an essential part of the kernel and is responsible for implementing several technologies, such as multipathing, logical volumes, encryption, and raid. </span><span class="koboSpan" id="kobo.494.3">The most well known of these is logical volume management. </span><span class="koboSpan" id="kobo.494.4">We saw how the device mapper can implement these powerful features through </span><span class="No-Break"><span class="koboSpan" id="kobo.495.1">mapping techniques.</span></span></p>
<p><span class="koboSpan" id="kobo.496.1">In the next chapter, we’ll conclude our discussion of the block layer after exploring the different I/O schedulers in </span><span class="No-Break"><span class="koboSpan" id="kobo.497.1">the kernel.</span></span></p>
</div>
</body></html>