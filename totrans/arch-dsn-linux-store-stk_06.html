<html><head></head><body>
<div id="_idContainer061">
<h1 class="chapter-number" id="_idParaDest-95"><a id="_idTextAnchor101"/><span class="koboSpan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-96"><a id="_idTextAnchor102"/><span class="koboSpan" id="kobo.2.1">Understanding I/O Handling and Scheduling in the Block Layer</span></h1>
<p class="author-quote"><span class="koboSpan" id="kobo.3.1">“The key is not to prioritize what’s on your schedule, but to schedule your priorities.” </span><span class="koboSpan" id="kobo.3.2">– Stephen Covey</span></p>
<p><a href="B19430_04.xhtml#_idTextAnchor072"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.4.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.5.1"> and </span><a href="B19430_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.6.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.7.1"> of this book focused on the role of the block layer in the kernel. </span><span class="koboSpan" id="kobo.7.2">We were able to see what constitutes a block device, the major data structures in the block layer, the multi-queue block I/O framework, and the device mapper. </span><span class="koboSpan" id="kobo.7.3">This chapter will focus on another important function of the block layer – </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">scheduling.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">Scheduling is an extremely critical component of any system, as the decisions taken by a scheduler can have a major say in dictating the overall system performance. </span><span class="koboSpan" id="kobo.9.2">The I/O scheduling in the block layer is no exception to this rule. </span><span class="koboSpan" id="kobo.9.3">The I/O scheduler holds significant importance in deciding the manner and timing of delivery for an I/O request to the lower layers. </span><span class="koboSpan" id="kobo.9.4">Given this, it becomes crucial to carefully analyze the I/O patterns of an application, as certain requests require prioritization </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">over others.</span></span></p>
<p><span class="koboSpan" id="kobo.11.1">This chapter will introduce us to the different I/O schedulers available in the block layer and their modus operandi. </span><span class="koboSpan" id="kobo.11.2">Each scheduler uses a different set of techniques to dispatch I/O requests to the lower layers. </span><span class="koboSpan" id="kobo.11.3">As we have mentioned repeatedly, when working with block devices, performance is a key concern. </span><span class="koboSpan" id="kobo.11.4">The block layer has gone through several enhancements so that maximum performance can be extracted from disk drives. </span><span class="koboSpan" id="kobo.11.5">This includes the development of schedulers to handle modern and high-performing </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">storage devices.</span></span></p>
<p><span class="koboSpan" id="kobo.13.1">We’ll start by introducing the common techniques used by the different schedulers to handle I/O requests more efficiently. </span><span class="koboSpan" id="kobo.13.2">Although these techniques were developed for traditional spinning drives, they are still considered useful for modern flash drives. </span><span class="koboSpan" id="kobo.13.3">The primary goal of these techniques was to reduce disk-seeking operations for mechanical drives, as these have an adverse effect on their performance. </span><span class="koboSpan" id="kobo.13.4">Most schedulers make use of these methods by default, regardless of the underlying </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">storage hardware.</span></span></p>
<p><span class="koboSpan" id="kobo.15.1">The major topic of discussion in this chapter will be the different I/O scheduling flavors available in the kernel. </span><span class="koboSpan" id="kobo.15.2">The older disk schedulers were developed for devices accessed using the single-queue mechanism and have become outdated, as they cannot scale up to meet the performance of modern drives. </span><span class="koboSpan" id="kobo.15.3">In the last few years, four multi-queue I/O schedulers have been integrated into the kernel. </span><span class="koboSpan" id="kobo.15.4">These schedulers are able to map I/O requests to </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">multiple queues.</span></span></p>
<p><span class="koboSpan" id="kobo.17.1">In this chapter, we’re going to discuss the following </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.19.1">Understanding the I/O handling techniques in the </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">block layer</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">Explaining the I/O schedulers </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">in Linux:</span></span><ul><li><span class="koboSpan" id="kobo.23.1">The MQ-deadline scheduler – guaranteeing a start </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">service time</span></span></li><li><span class="koboSpan" id="kobo.25.1">Budget fair queuing – providing proportional </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">disk share</span></span></li><li><span class="koboSpan" id="kobo.27.1">Kyber – </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">prioritizing throughput</span></span></li><li><a id="_idTextAnchor103"/><span class="koboSpan" id="kobo.29.1">None – minimal </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">scheduling overhead</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.31.1"> Discussing the </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1">scheduling conundrum</span></span></li>
</ul>
<h1 id="_idParaDest-97"><a id="_idTextAnchor104"/><span class="koboSpan" id="kobo.33.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.34.1">It would be helpful to have some knowledge about disk I/O basics to understand the concepts presented in this chapter. </span><span class="koboSpan" id="kobo.34.2">Having an idea about the different types of storage media, and concepts such as disk seek time and rotational latency, will help to comprehend the material presented in </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">this chapter.</span></span></p>
<p><span class="koboSpan" id="kobo.36.1">The commands and examples presented in this chapter are distribution-agnostic and can be run on any Linux operating system, such as Debian, Ubuntu, Red Hat, and Fedora. </span><span class="koboSpan" id="kobo.36.2">There are quite a few references to the kernel source code. </span><span class="koboSpan" id="kobo.36.3">If you want to download the kernel source, you can download it from </span><a href="https://www.kernel.org"><span class="koboSpan" id="kobo.37.1">https://www.kernel.org</span></a><span class="koboSpan" id="kobo.38.1">. </span><span class="koboSpan" id="kobo.38.2">The code segments referred to in this chapter and book are from the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.39.1">5.19.9</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.40.1"> kernel.</span></span></p>
<h1 id="_idParaDest-98"><a id="_idTextAnchor105"/><span class="koboSpan" id="kobo.41.1">Understanding the I/O handling techniques in block layer</span></h1>
<p><span class="koboSpan" id="kobo.42.1">While exploring the block layer in </span><a href="B19430_04.xhtml#_idTextAnchor072"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.43.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.44.1"> and </span><a href="B19430_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.45.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.46.1">, we often mentioned the performance sensitivity of block devices and how the block layer has to make informed and intelligent decisions to extract their maximum potential. </span><span class="koboSpan" id="kobo.46.2">So far, we haven’t really discussed any of the techniques that help to enhance the performance of </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">block devices.</span></span></p>
<p><span class="koboSpan" id="kobo.48.1">Going back to the era of spinning drives, the performance of storage drives was a major bottleneck in the I/O stack. </span><span class="koboSpan" id="kobo.48.2">Mechanical drives offered decent performance when doing sequential I/O operations. </span><span class="koboSpan" id="kobo.48.3">However, for random workloads, their performance deteriorates quite drastically. </span><span class="koboSpan" id="kobo.48.4">This is understandable, as mechanical drives have to </span><em class="italic"><span class="koboSpan" id="kobo.49.1">seek</span></em><span class="koboSpan" id="kobo.50.1"> requested locations on disk by spinning and positioning the read-write head on specific locations. </span><span class="koboSpan" id="kobo.50.2">The greater the number of random seeks, the greater the performance penalty. </span><span class="koboSpan" id="kobo.50.3">Filesystems created on top of block devices try to implement some practices that attempt to optimize disk performance, but it is impossible to avoid random </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">operations altogether.</span></span></p>
<p><span class="koboSpan" id="kobo.52.1">Given the enormous seek times of mechanical drives, it is imperative that some sort of optimization is applied to reduce seeking, before I/O requests are handed over to the underlying storage. </span><span class="koboSpan" id="kobo.52.2">Simply handing them down to the underlying physical storage seems a primitive approach. </span><span class="koboSpan" id="kobo.52.3">This is where I/O schedulers come to the fore. </span><span class="koboSpan" id="kobo.52.4">The I/O schedulers in the block layer employ some common methods to ensure that the overhead caused by random access operations is minimized. </span><span class="koboSpan" id="kobo.52.5">These techniques address some of the performance issues of spinning drives, although they might not have a considerable effect when using flash drives, as they are not impacted by </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">random operations.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1">Most schedulers employ a combination of the following techniques to optimize </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">disk performance:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.56.1">Sorting</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.57.1">Merging</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.58.1">Coalescing</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.59.1">Plugging</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.60.1">Let’s discuss these in a bit </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">more detail.</span></span></p>
<h2 id="_idParaDest-99"><a id="_idTextAnchor106"/><span class="koboSpan" id="kobo.62.1">Sorting</span></h2>
<p><span class="koboSpan" id="kobo.63.1">Let’s say that four I/O requests, A, B, C, and D, are received for sectors 2, 3, 1, and 4, respectively, in that particular order, as illustrated in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.64.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.65.1">.1</span></em><span class="koboSpan" id="kobo.66.1">. </span><span class="koboSpan" id="kobo.66.2">If the requests are delivered to the underlying spinning drive in this manner, they will be completed in </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">that order:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer050">
<span class="koboSpan" id="kobo.68.1"><img alt="Figure 6.1 – Disk seeking" src="image/B19430_06_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.69.1">Figure 6.1 – Disk seeking</span></p>
<p><span class="koboSpan" id="kobo.70.1">This means that after completing requests A and B in a sequential manner, for request C, the read-write head of the drive will have to go back to sector 1. </span><span class="koboSpan" id="kobo.70.2">After completing request C, it will have to perform another </span><em class="italic"><span class="koboSpan" id="kobo.71.1">seek</span></em><span class="koboSpan" id="kobo.72.1"> and move forward to sector D. </span><span class="koboSpan" id="kobo.72.2">It’s not difficult to see the inefficiency that results from such an approach. </span><span class="koboSpan" id="kobo.72.3">If the requests are simply handed over in the received order, the disk performance </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">will suffer.</span></span></p>
<p><span class="koboSpan" id="kobo.74.1">For spinning drives, random access operations kill performance, as the disk has to perform multiple </span><em class="italic"><span class="koboSpan" id="kobo.75.1">seek</span></em><span class="koboSpan" id="kobo.76.1"> operations. </span><span class="koboSpan" id="kobo.76.2">If incoming requests are simply inserted at the end of a first-in-first-out queue, each request in the queue will involve separate processing, and the overhead caused by random seeking will increase. </span><span class="koboSpan" id="kobo.76.3">Therefore, most schedulers keep the request queues ordered and try to insert new incoming requests in a sorted manner. </span><span class="koboSpan" id="kobo.76.4">The request queue is sorted sector by sector. </span><span class="koboSpan" id="kobo.76.5">This ensures that requests operating on neighboring sectors can be </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">performed sequentially.</span></span></p>
<h2 id="_idParaDest-100"><a id="_idTextAnchor107"/><span class="koboSpan" id="kobo.78.1">Merging</span></h2>
<p><span class="koboSpan" id="kobo.79.1">Merging acts as a compliment to the sorting mechanism and further tries to reduce random access. </span><span class="koboSpan" id="kobo.79.2">It can be performed in two ways, frontward and backward. </span><span class="koboSpan" id="kobo.79.3">Two requests can be merged if they are intended for contiguous sectors. </span><span class="koboSpan" id="kobo.79.4">If an I/O request enters the scheduler and it adjoins to an already enqueued request, then it qualifies as a front or back merge candidate. </span><span class="koboSpan" id="kobo.79.5">If the incoming request is merged with an existing request, it is called a back merge. </span><span class="koboSpan" id="kobo.79.6">The concept of back merging is shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.80.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.81.1">.2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer051">
<span class="koboSpan" id="kobo.83.1"><img alt="Figure 6.2 – A back merge" src="image/B19430_06_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.84.1">Figure 6.2 – A back merge</span></p>
<p><span class="koboSpan" id="kobo.85.1">In the same vein, when a newly generated request is combined with an existing request, it is referred to as a front merge, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.86.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.87.1">.3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer052">
<span class="koboSpan" id="kobo.89.1"><img alt="Figure 6.3 – A front merge" src="image/B19430_06_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.90.1">Figure 6.3 – A front merge</span></p>
<p><span class="koboSpan" id="kobo.91.1">The idea is simple – avoid continuous trips to random locations. </span><span class="koboSpan" id="kobo.91.2">This is most effective for spinning mechanical drives. </span><span class="koboSpan" id="kobo.91.3">By default, most block layer schedulers attempt to merge an incoming request with an </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">existing one.</span></span></p>
<h2 id="_idParaDest-101"><a id="_idTextAnchor108"/><span class="koboSpan" id="kobo.93.1">Coalescing</span></h2>
<p><span class="koboSpan" id="kobo.94.1">The coalescing operation includes both front and back merges. </span><span class="koboSpan" id="kobo.94.2">Coalescing happens when a new I/O request closes the gap between two existing requests, as shown in the </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">following figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer053">
<span class="koboSpan" id="kobo.96.1"><img alt="Figure 6.4 – Coalescing" src="image/B19430_06_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.97.1">Figure 6.4 – Coalescing</span></p>
<p><span class="koboSpan" id="kobo.98.1">Coalescing is employed to reduce the overhead associated with small and frequent I/O operations, particularly for spinning hard disk drives. </span><span class="koboSpan" id="kobo.98.2">By coalescing multiple requests, the disk can perform sequential reads and writes, resulting in faster I/O operations and reduced disk </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">head movement.</span></span></p>
<h2 id="_idParaDest-102"><a id="_idTextAnchor109"/><span class="koboSpan" id="kobo.100.1">Plugging</span></h2>
<p><span class="koboSpan" id="kobo.101.1">The kernel uses the concept of </span><em class="italic"><span class="koboSpan" id="kobo.102.1">plugging</span></em><span class="koboSpan" id="kobo.103.1"> to stop requests from being processed in the queue. </span><span class="koboSpan" id="kobo.103.2">We’re talking about improving performance here, so how does putting requests on hold help out? </span><span class="koboSpan" id="kobo.103.3">As we’ve learned, merging has a very positive effect on the drive performance. </span><span class="koboSpan" id="kobo.103.4">However, for smaller I/O requests to merge into a larger unified request, there must be existing requests for adjacent sectors in the queue. </span><span class="koboSpan" id="kobo.103.5">Therefore, in order to perform merging, the kernel first has to build up the request queue with a few requests so that there is a greater probability of merging. </span><span class="koboSpan" id="kobo.103.6">Plugging the queue helps to batch requests in anticipation of opportunities for merge and </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">sort operations.</span></span></p>
<p><span class="koboSpan" id="kobo.105.1">Plugging is a technique used to ensure that there are enough requests in the queue for potential merging operations. </span><span class="koboSpan" id="kobo.105.2">It involves waiting for additional requests to fill up the request queue and helps regulate the dispatch rate of requests to the device queue. </span><span class="koboSpan" id="kobo.105.3">The purpose of plugging is to control the dispatch rate of requests to the device queue. </span><span class="koboSpan" id="kobo.105.4">When there are no pending requests or a very small number of them in the block device queue, incoming requests are not dispatched to the device driver immediately. </span><span class="koboSpan" id="kobo.105.5">This results in the device being in a plugged state. </span><span class="koboSpan" id="kobo.105.6">The following figure demonstrates </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">this concept:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer054">
<span class="koboSpan" id="kobo.107.1"><img alt="Figure 6.5 – Plugging" src="image/B19430_06_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.108.1">Figure 6.5 – Plugging</span></p>
<p><span class="koboSpan" id="kobo.109.1">Plugging is executed at the process level rather than at the device level. </span><span class="koboSpan" id="kobo.109.2">The kernel initiates a plug sequence when a process carries out I/O operations. </span><span class="koboSpan" id="kobo.109.3">After the process has completed submitting its I/O requests to the queue, the requests are forwarded to the block layer and then dispatched to the device driver. </span><span class="koboSpan" id="kobo.109.4">A device is considered unplugged once the process has finished submitting I/O requests. </span><span class="koboSpan" id="kobo.109.5">If an application is blocked during a plug sequence, the scheduler proceeds to process the requests that are already in </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">the queue.</span></span></p>
<p><span class="koboSpan" id="kobo.111.1">Having discussed the most commonly used I/O scheduling techniques found in I/O schedulers, let us now delve into the reasoning and principles behind the decision-making process of the most widely used I/O schedulers </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">in Linux.</span></span></p>
<h1 id="_idParaDest-103"><a id="_idTextAnchor110"/><span class="koboSpan" id="kobo.113.1">Explaining the Linux I/O schedulers</span></h1>
<p><span class="koboSpan" id="kobo.114.1">Disk schedulers are an interesting topic. </span><span class="koboSpan" id="kobo.114.2">They serve as a bridge between the block layer and low-level device drivers. </span><span class="koboSpan" id="kobo.114.3">The requests issued to a block device are altered by an I/O scheduler and handed over to the device drivers. </span><span class="koboSpan" id="kobo.114.4">It is the job of the scheduler to perform operations such as merging, sorting, and plugging on the I/O requests and divide the storage resources among the queued I/O requests. </span><span class="koboSpan" id="kobo.114.5">One of the notable advantages of the disk schedulers in Linux is their Plug and Play capability, allowing them to be switched in real time. </span><span class="koboSpan" id="kobo.114.6">Additionally, depending on the characteristics of the storage hardware being used, a distinct scheduler can be assigned to each block device in the system. </span><span class="koboSpan" id="kobo.114.7">The selection of a disk scheduler is not something that frequently comes under the radar, unless you’re trying to extract the maximum from your system. </span><span class="koboSpan" id="kobo.114.8">The I/O scheduler is in charge of deciding the order in which I/O requests will be delivered to the device driver. </span><span class="koboSpan" id="kobo.114.9">The order is decided with a priority on the </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">following tasks:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.116.1">Reducing </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">disk seeking</span></span></li>
<li><span class="koboSpan" id="kobo.118.1">Ensuring fairness among </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">I/O requests</span></span></li>
<li><span class="koboSpan" id="kobo.120.1">Maximizing </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">disk throughput</span></span></li>
<li><span class="koboSpan" id="kobo.122.1">Reducing latency for </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">time-sensitive tasks</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.124.1">It’s a strenuous task to strike a balance among these goals. </span><span class="koboSpan" id="kobo.124.2">The different schedulers make use of multiple queues to achieve these goals. </span><span class="koboSpan" id="kobo.124.3">Operations such as merging and sorting are performed in request queues. </span><span class="koboSpan" id="kobo.124.4">The schedulers also perform additional processing, as per their internal algorithms, in these queues. </span><span class="koboSpan" id="kobo.124.5">Once the requests are ready, they are handed over to the dispatch queue managed by the </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">device drivers.</span></span></p>
<p><span class="koboSpan" id="kobo.126.1">The major performance optimizations in earlier block layer designs were directed toward hard disk drives. </span><span class="koboSpan" id="kobo.126.2">This is especially true for the disk scheduling algorithms. </span><span class="koboSpan" id="kobo.126.3">Most of the I/O handling techniques that we’ve discussed so far are most useful when the underlying storage media consists of rotating mechanical drives. </span><span class="koboSpan" id="kobo.126.4">As we’ll see in </span><a href="B19430_07.xhtml#_idTextAnchor124"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.127.1">Chapter 7</span></em></span></a><span class="koboSpan" id="kobo.128.1">, SSDs and NVMe drives are different beasts of nature and are not impacted by the limitations that impede a </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">mechanical drive.</span></span></p>
<p><span class="koboSpan" id="kobo.130.1">The scheduler controls the behavior of the underlying disks and thus plays a vital role in dictating the performance of an application. </span><span class="koboSpan" id="kobo.130.2">Just like the varying natures of physical storage, every application is also built differently. </span><span class="koboSpan" id="kobo.130.3">It is imperative to know the type of workload for the environment being tuned. </span><span class="koboSpan" id="kobo.130.4">There is no single scheduler that can be deemed fit enough to match the varying I/O characteristics of all applications. </span><span class="koboSpan" id="kobo.130.5">When choosing a scheduler, it is crucial to ask the </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">following questions:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.132.1">What is the host system type – that is, is it a desktop, laptop, virtual machine, or </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">a server?</span></span></li>
<li><span class="koboSpan" id="kobo.134.1">What sort of workload will be running? </span><span class="koboSpan" id="kobo.134.2">What type of application? </span><span class="koboSpan" id="kobo.134.3">Databases, multi-user desktop interface, games, </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">or videos?</span></span></li>
<li><span class="koboSpan" id="kobo.136.1">Is the hosted application a processor </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">or I/O-bound?</span></span></li>
<li><span class="koboSpan" id="kobo.138.1">What is the backend storage media type? </span><span class="koboSpan" id="kobo.138.2">HDDs, SSDs, </span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">or NVMe?</span></span></li>
<li><span class="koboSpan" id="kobo.140.1">Is the storage local to the host? </span><span class="koboSpan" id="kobo.140.2">Or is it provisioned from a large enterprise storage </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">area network?</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.142.1">The I/O requests generated by a real-time application should be completed within a certain deadline. </span><span class="koboSpan" id="kobo.142.2">For instance, when streaming a video through a multimedia player, it has to be guaranteed that the frames will be read in time so that the video can be played without any glitches. </span><span class="koboSpan" id="kobo.142.3">On the other hand, interactive applications have to wait for the completion of a task before proceeding to the next one. </span><span class="koboSpan" id="kobo.142.4">For example, when writing in a document editor, the end user expects the editor to respond immediately when a key is pressed. </span><span class="koboSpan" id="kobo.142.5">Plus, the text has to appear in the same order in which it </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">was typed.</span></span></p>
<p><span class="koboSpan" id="kobo.144.1">For individual systems, the choice of a scheduler may not matter much and default settings might suffice. </span><span class="koboSpan" id="kobo.144.2">For servers running enterprise workloads, margins are much finer, and how a scheduler handles I/O requests may well decide the overall performance of the application. </span><span class="koboSpan" id="kobo.144.3">As we have repeatedly mentioned in this book, disk I/O is much slower than the processor and memory subsystems. </span><span class="koboSpan" id="kobo.144.4">Therefore, any decision regarding the choice of a disk scheduler should be accompanied by a lot of consideration and </span><span class="No-Break"><span class="koboSpan" id="kobo.145.1">performance benchmarking.</span></span></p>
<p><span class="koboSpan" id="kobo.146.1">Disk scheduling should not be confused with CPU scheduling. </span><span class="koboSpan" id="kobo.146.2">To process any request, both I/O and CPU time are required. </span><span class="koboSpan" id="kobo.146.3">In simpler terms, a process requests time from the CPU, after which it is able to run (if the time is allocated). </span><span class="koboSpan" id="kobo.146.4">The process can issue read or write requests to the disk. </span><span class="koboSpan" id="kobo.146.5">It is then the job of the disk scheduler to order and shepherd those requests to the </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">underlying disks.</span></span></p>
<p><span class="koboSpan" id="kobo.148.1">I/O schedulers in Linux are also referred to as elevators. </span><span class="koboSpan" id="kobo.148.2">The elevator algorithm, also called </span><strong class="source-inline"><span class="koboSpan" id="kobo.149.1">SCAN</span></strong><span class="koboSpan" id="kobo.150.1">, compares the operation of legacy mechanical drives with elevators or lifts. </span><span class="koboSpan" id="kobo.150.2">When elevators go either up or down, they keep going in that same direction and stop to drop off people along the way. </span><span class="koboSpan" id="kobo.150.3">In disk scheduling, the read-write head of the drive starts from one end of the disk and moves toward the other end, while servicing requests along the way. </span><span class="koboSpan" id="kobo.150.4">To continue the analogy, mechanical drives need to read (</span><strong class="source-inline"><span class="koboSpan" id="kobo.151.1">pick up</span></strong><span class="koboSpan" id="kobo.152.1">) and write (</span><strong class="source-inline"><span class="koboSpan" id="kobo.153.1">drop off</span></strong><span class="koboSpan" id="kobo.154.1">) requests (</span><strong class="source-inline"><span class="koboSpan" id="kobo.155.1">people</span></strong><span class="koboSpan" id="kobo.156.1">) at different disk </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">locations (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.158.1">floors</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.160.1">The different types of I/O schedulers available in the kernel are suited to particular use cases, some more than others. </span><span class="koboSpan" id="kobo.160.2">As we learned in </span><a href="B19430_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.161.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.162.1">, the single-queue framework does not scale up to meet the performance levels of modern storage devices. </span><span class="koboSpan" id="kobo.162.2">The advancements in drive technologies and multi-core systems led to the development of the multi-queue block I/O framework. </span><span class="koboSpan" id="kobo.162.3">Even with the implementation of this framework, the kernel still lacked an important ingredient when dealing with modern drives – an I/O scheduler designed to work with multi-queue devices. </span><span class="koboSpan" id="kobo.162.4">Schedulers that were designed for the single-queue framework and intended to be used with single-queue devices do not function optimally with </span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">modern drives.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.164.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.165.1">.6</span></em><span class="koboSpan" id="kobo.166.1"> highlights the various types of I/O schedulers available for both single and </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">multi-queue frameworks:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer055">
<span class="koboSpan" id="kobo.168.1"><img alt="Figure 6.6 – Different I/O Scheduling options" src="image/B19430_06_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.169.1">Figure 6.6 – Different I/O Scheduling options</span></p>
<p><span class="koboSpan" id="kobo.170.1">Single-queue I/O schedulers are deprecated and have not been a part of the kernel since version 5.0. </span><span class="koboSpan" id="kobo.170.2">Although you can disable these and revert back to the single-queue </span><a id="_idTextAnchor111"/><span class="koboSpan" id="kobo.171.1">schedulers, the latest kernel releases default to the multi-queue schedulers, and as such we will keep our focus on the multi-queue schedulers that are a part of the kernel. </span><span class="koboSpan" id="kobo.171.2">There are four major players in this category. </span><span class="koboSpan" id="kobo.171.3">These schedulers </span><a id="_idTextAnchor112"/><span class="koboSpan" id="kobo.172.1">map I/O requests to multiple queues, which are handled by kernel </span><a id="_idTextAnchor113"/><span class="koboSpan" id="kobo.173.1">threads distributed across the multiple </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">CPU cores:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.175.1">MQ-deadline</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.176.1">Budget Fair </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.177.1">Queuing</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.178.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.179.1">BFQ</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">)</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.181.1">Kyber</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.182.1">None</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.183.1">Let’s take a look at the operational logic of </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">these schedulers.</span></span></p>
<h2 id="_idParaDest-104"><a id="_idTextAnchor114"/><span class="koboSpan" id="kobo.185.1">The MQ-deadline scheduler – guaranteeing a start service time</span></h2>
<p><span class="koboSpan" id="kobo.186.1">The deadline scheduler, as the name suggests, imposes a deadline to service I/O requests. </span><span class="koboSpan" id="kobo.186.2">Due to its latency-oriented design, it is often used for latency-sensitive workloads. </span><span class="koboSpan" id="kobo.186.3">Because of its high performance, it has also been adopted for multi-queue devices. </span><span class="koboSpan" id="kobo.186.4">Its implementation for multi-queue devices is known </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">as </span><a id="_idTextAnchor115"/></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.188.1">mq-deadline</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.190.1">The primary objective of the deadline scheduler is to ensure that a request has a designated start service time. </span><span class="koboSpan" id="kobo.190.2">This is accomplished by enforcing a deadline on all I/O operations, which helps prevent requests from being neglected. </span><span class="koboSpan" id="kobo.190.3">The deadline scheduler makes use of the </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">following queues:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.192.1">Sorted</span></strong><span class="koboSpan" id="kobo.193.1">: The read and write operations in this queue are sorted by the sector numbers they are </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">to access.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.195.1">Deadline</span></strong><span class="koboSpan" id="kobo.196.1">: The deadline queue is a standard </span><strong class="bold"><span class="koboSpan" id="kobo.197.1">First-In-First-Out</span></strong><span class="koboSpan" id="kobo.198.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.199.1">FIFO</span></strong><span class="koboSpan" id="kobo.200.1">) queue that contains requests sorted by their deadlines. </span><span class="koboSpan" id="kobo.200.2">To prevent starvation of requests, the deadline scheduler utilizes separate instances of the deadline queue for read and write requests, assigning an expiration time to each </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">I/O request.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.202.1">The deadline scheduler places each I/O request in both the sorted and deadline queues. </span><span class="koboSpan" id="kobo.202.2">Before deciding which request to serve, the deadline scheduler selects a queue from which to choose a read or write request. </span><span class="koboSpan" id="kobo.202.3">If there are requests in both the read and write queues, read queues are preferred. </span><span class="koboSpan" id="kobo.202.4">This is because write requests can starve read operations. </span><span class="koboSpan" id="kobo.202.5">This makes the deadline scheduler extremely effective for </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">read-heavy workloads.</span></span></p>
<p><span class="koboSpan" id="kobo.204.1">The operational logic of the deadline scheduler is depicted in the </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">following figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer056">
<span class="koboSpan" id="kobo.206.1"><img alt="Figure 6.7 – The MQ-deadline I/O scheduler" src="image/B19430_06_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.207.1">Figure 6.7 – The MQ-deadline I/O scheduler</span></p>
<p><span class="koboSpan" id="kobo.208.1">The I/O requests to be served are decided </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">as follows:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.210.1">Let’s say that the scheduler has decided to serve read requests. </span><span class="koboSpan" id="kobo.210.2">It will check the first request in the deadline queue. </span><span class="koboSpan" id="kobo.210.3">If the timer associated with that request has expired, it will be handed over to the dispatch queue and inserted at its tail end. </span><span class="koboSpan" id="kobo.210.4">The scheduler then turns its focus to the sorted queue and selects a batch of requests (16 requests by default) following the chosen request. </span><span class="koboSpan" id="kobo.210.5">This is done to increase the sequential operations. </span><span class="koboSpan" id="kobo.210.6">Think of how an elevator drops off people on different floors along the way to its final destination. </span><span class="koboSpan" id="kobo.210.7">The number of requests in a batch is a tunable parameter and can </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">be changed.</span></span></li>
<li><span class="koboSpan" id="kobo.212.1">It can also happen that there are no requests with expired deadlines in the deadline queue. </span><span class="koboSpan" id="kobo.212.2">In that case, the scheduler will examine the last request that was serviced from the sorted queue and choose the subsequent request in the sequence. </span><span class="koboSpan" id="kobo.212.3">The scheduler will then select a batch of 16 requests that follow the </span><span class="No-Break"><span class="koboSpan" id="kobo.213.1">chosen request.</span></span></li>
<li><span class="koboSpan" id="kobo.214.1">After processing each batch of requests, the deadline scheduler checks to see whether requests in the write deadline queue have been starved for too long, and then decides whether to start a new batch of read or </span><span class="No-Break"><span class="koboSpan" id="kobo.215.1">write operations.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.216.1">The following figure explains this process. </span><span class="koboSpan" id="kobo.216.2">If a read request for sector number 19 on the disk is received, it is assigned a deadline and inserted at the tail end of the deadline queue for read operations. </span><span class="koboSpan" id="kobo.216.3">Based on the sector number, this request is also placed in the sorted sector queue, just behind the request for sector 11. </span><span class="koboSpan" id="kobo.216.4">The operational flow of the deadline scheduler, regarding how requests are processed, is demonstrated in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.217.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.218.1">.8</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<span class="koboSpan" id="kobo.220.1"><img alt="Figure 6.8 – Request handling in the MQ-deadline I/O scheduler" src="image/B19430_06_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.221.1">Figure 6.8 – Request handling in the MQ-deadline I/O scheduler</span></p>
<p><span class="koboSpan" id="kobo.222.1">The following snippet code of mq-deadline in </span><strong class="source-inline"><span class="koboSpan" id="kobo.223.1">block/mq-deadline</span></strong><span class="koboSpan" id="kobo.224.1"> dictates some of the behavior illustrated in the preceding figure. </span><span class="koboSpan" id="kobo.224.2">The expiry deadline for read requests (HZ/2) is 500 milliseconds, whereas for writes, it is 5 seconds (5*HZ). </span><span class="koboSpan" id="kobo.224.3">This ensures that read requests have higher precedence. </span><span class="koboSpan" id="kobo.224.4">The term </span><strong class="source-inline"><span class="koboSpan" id="kobo.225.1">HZ</span></strong><span class="koboSpan" id="kobo.226.1"> represents the clock ticks generated per second. </span><span class="koboSpan" id="kobo.226.2">The definition of </span><strong class="source-inline"><span class="koboSpan" id="kobo.227.1">writes_starved</span></strong><span class="koboSpan" id="kobo.228.1"> indicates that reads can starve writes. </span><span class="koboSpan" id="kobo.228.2">The writes are only serviced once against two rounds of reads. </span><strong class="source-inline"><span class="koboSpan" id="kobo.229.1">fifo_batch</span></strong><span class="koboSpan" id="kobo.230.1"> sets the number of requests that can be </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">batched together:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.232.1">
[……….]
static const int read_expire = HZ / 2;
static const int write_expire = 5 * HZ;
static const int writes_starved = 2;
static const int fifo_batch = 16;
[……….]</span></pre>
<p><span class="koboSpan" id="kobo.233.1">To summarize, the deadline scheduler strives to reduce I/O latency by implementing start service times for every incoming request. </span><span class="koboSpan" id="kobo.233.2">Each new request is assigned a deadline timer. </span><span class="koboSpan" id="kobo.233.3">When the expiry time for a request is reached, the scheduler will forcefully service that request to prevent </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">request starvation.</span></span></p>
<h2 id="_idParaDest-105"><a id="_idTextAnchor116"/><span class="koboSpan" id="kobo.235.1">Budget fair queuing – providing proportional disk share</span></h2>
<p><span class="koboSpan" id="kobo.236.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.237.1">Budget Fair Queuing</span></strong><span class="koboSpan" id="kobo.238.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.239.1">BFQ</span></strong><span class="koboSpan" id="kobo.240.1">) scheduler is a relative newcomer in the world of disk schedulers, but it has gained considerable popularity. </span><span class="koboSpan" id="kobo.240.2">It is modeled after the </span><strong class="bold"><span class="koboSpan" id="kobo.241.1">Completely Fair Queuing</span></strong><span class="koboSpan" id="kobo.242.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.243.1">CFQ</span></strong><span class="koboSpan" id="kobo.244.1">) scheduler. </span><span class="koboSpan" id="kobo.244.2">It provides fairly good response times and is considered particularly suitable for slower devices. </span><span class="koboSpan" id="kobo.244.3">With its rich and comprehensive scheduling techniques, the BFQ is often thought to be one of the most complete disk schedulers, although its sophisticated design also makes it the most complex scheduler among </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">the lot.</span></span></p>
<p><span class="koboSpan" id="kobo.246.1">BFQ is a proportional share disk scheduler. </span><span class="koboSpan" id="kobo.246.2">The primary goal of BFQ is to be fair to all I/O requests. </span><span class="koboSpan" id="kobo.246.3">To achieve this fairness, it makes use of some intricate techniques. </span><span class="koboSpan" id="kobo.246.4">Internally, BFQ uses the </span><strong class="source-inline"><span class="koboSpan" id="kobo.247.1">Worst-case Fair Weighted Fair Queuing+ (B-WF2Q+)</span></strong><span class="koboSpan" id="kobo.248.1"> algorithm to aid in </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">scheduling decisions.</span></span></p>
<p><span class="koboSpan" id="kobo.250.1">The BFQ scheduler guarantees a proportional share of the disk resources to every process in the system. </span><span class="koboSpan" id="kobo.250.2">It collects the I/O requests in the following </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">two queues:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.252.1">Per-process queues</span></strong><span class="koboSpan" id="kobo.253.1">: The BFQ scheduler allocates a queue for every process. </span><span class="koboSpan" id="kobo.253.2">Each per-process queue contains synchronous </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">I/O requests.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.255.1">Per-device queue</span></strong><span class="koboSpan" id="kobo.256.1">: All the asynchronous I/O requests are collected in a per-device queue. </span><span class="koboSpan" id="kobo.256.2">This queue is shared </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">among processes.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.258.1">Whenever a new queue is created, it is assigned a variable budget. </span><span class="koboSpan" id="kobo.258.2">Unlike most schedulers, which allocate time slices, this budget is implemented as the number of sectors that each process is allowed to transfer when it is next scheduled to access the disk resources. </span><span class="koboSpan" id="kobo.258.3">The value of this budget is what ultimately determines the share of disk throughput for each process. </span><span class="koboSpan" id="kobo.258.4">As such, its calculation is complex and based on a multitude of factors. </span><span class="koboSpan" id="kobo.258.5">The major factors in this calculation are the I/O weight and the recent I/O activity of the process. </span><span class="koboSpan" id="kobo.258.6">Based on these observations, the scheduler assigns a budget that is proportional to a process’s I/O activity. </span><span class="koboSpan" id="kobo.258.7">The I/O weight of a process has a default value, but it can be changed. </span><span class="koboSpan" id="kobo.258.8">The assignment of the budget is such that a single process is not able to hog all the bandwidth of available storage resources. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.259.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.260.1">.9</span></em><span class="koboSpan" id="kobo.261.1"> shows the different queues used by the </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">BFQ scheduler:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<span class="koboSpan" id="kobo.263.1"><img alt="Figure 6.9 – The BFQ I/O scheduler" src="image/B19430_06_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.264.1">Figure 6.9 – The BFQ I/O scheduler</span></p>
<p><span class="koboSpan" id="kobo.265.1">When it comes to servicing I/O requests, some of the factors affecting scheduling decisions are described </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">as follows:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.267.1">The BFQ scheduler selects the queue to be served through the C-LOOK algorithm. </span><span class="koboSpan" id="kobo.267.2">It picks up the first request from the selected queue and hands it to the driver. </span><span class="koboSpan" id="kobo.267.3">The budget of the queue gets decremented by the size of the request This is explained in a bit more detail at the end of this discussion. </span><span class="koboSpan" id="kobo.267.4">BFQ exclusively serves one queue at </span><span class="No-Break"><span class="koboSpan" id="kobo.268.1">a time.</span></span></li>
<li><span class="koboSpan" id="kobo.269.1">The BFQ scheduler prioritizes scheduling processes that have smaller I/O budgets. </span><span class="koboSpan" id="kobo.269.2">Normally, these are the processes that have a small but random set of I/O requests. </span><span class="koboSpan" id="kobo.269.3">In contrast, I/O intensive processes with a large number of sequential I/O requests are assigned a larger budget. </span><span class="koboSpan" id="kobo.269.4">When selecting a process queue for servicing, the BFQ scheduler chooses the queue with the lowest I/O budget, granting exclusive access to the disk resources. </span><span class="koboSpan" id="kobo.269.5">This approach achieves two objectives. </span><span class="koboSpan" id="kobo.269.6">First, processes with smaller budgets receive prompt service and do not have to wait excessively. </span><span class="koboSpan" id="kobo.269.7">Second, I/O-bound processes with larger budgets receive a proportionately greater share of disk resources, promoting sequential I/O operations and thereby enhancing disk performance. </span><span class="koboSpan" id="kobo.269.8">The BFQ scheduler makes use of a slightly unorthodox approach to increase disk throughput – performing disk idling by checking for synchronous I/O requests. </span><span class="koboSpan" id="kobo.269.9">When an application generates synchronous I/O requests, it enters a blocking state and waits for the operation to complete. </span><span class="koboSpan" id="kobo.269.10">Mostly, these are read requests, as write operations are asynchronous and can be directly performed in cache. </span><span class="koboSpan" id="kobo.269.11">If the last request in the process queue is synchronous, the process goes into a waiting state. </span><span class="koboSpan" id="kobo.269.12">This request is not dispatched immediately to the disk, as the BFQ scheduler allows the process to generate another request. </span><span class="koboSpan" id="kobo.269.13">During this time frame, the drive remains idle. </span><span class="koboSpan" id="kobo.269.14">More often than not, the process generates another request, as it waits for the current synchronous request to complete before issuing new requests. </span><span class="koboSpan" id="kobo.269.15">The new request is normally adjacent to the last request, which improves the chance of sequential operations. </span><span class="koboSpan" id="kobo.269.16">At times, this approach can backfire and might not always have a positive impact </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">on performance.</span></span></li>
<li><span class="koboSpan" id="kobo.271.1">If two processes work on neighboring areas on a disk, it makes sense to combine their requests so that sequential operations can be increased. </span><span class="koboSpan" id="kobo.271.2">In this case, BFQ merges the queues of both processes to enable the consolidation of requests. </span><span class="koboSpan" id="kobo.271.3">The incoming requests are compared with the next request of the in-service process, and if the two requests are close, the request queues for both processes </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">are merged.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.273.1">In the event that an application executing read requests depletes its queue while still having a surplus budget, the disk will be idled briefly to give that process a chance to issue another </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">I/O request.</span></span></p>
<p><span class="koboSpan" id="kobo.275.1">The scheduler continues to serve the queue until one of the following </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">events occurs:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.277.1">The queue budget </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">is exhausted</span></span></li>
<li><span class="koboSpan" id="kobo.279.1">All queue requests have </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">been completed</span></span></li>
<li><span class="koboSpan" id="kobo.281.1">The idling timer expires while waiting for a new request from </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">the process</span></span></li>
<li><span class="koboSpan" id="kobo.283.1">Too much time has been spent while servicing </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">the queue</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.285.1">Upon examining the BFQ code found in </span><strong class="source-inline"><span class="koboSpan" id="kobo.286.1">block/bfq-iosched.c</span></strong><span class="koboSpan" id="kobo.287.1">, you will discover a notable concept known as the </span><strong class="bold"><span class="koboSpan" id="kobo.288.1">charge factor</span></strong><span class="koboSpan" id="kobo.289.1"> for </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">asynchronous requests:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.291.1">
static const int bfq_async_charge_factor = 3;</span></pre>
<p><span class="koboSpan" id="kobo.292.1">It was mentioned earlier that when a request to be serviced is selected from a queue, the budget of the queue is decremented by the size of the request – that is, the number of sectors in the request. </span><span class="koboSpan" id="kobo.292.2">This is true for synchronous requests, but for asynchronous requests, this cost is much higher. </span><span class="koboSpan" id="kobo.292.3">This is also one of the ways reads are prioritized over writes. </span><span class="koboSpan" id="kobo.292.4">For asynchronous requests, the queue is charged with the number of sectors in the request, multiplied by the value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.293.1">bfq_async_charge_factor</span></strong><span class="koboSpan" id="kobo.294.1">, which is three. </span><span class="koboSpan" id="kobo.294.2">According to the kernel documentation, the current value for the charge factor parameter was determined by following a tuning process that involved various hardware and </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">software configurations.</span></span></p>
<p><span class="koboSpan" id="kobo.296.1">In summary, the BFQ scheduler employs equitable queuing approaches by apportioning a proportion of the I/O throughput to each process. </span><span class="koboSpan" id="kobo.296.2">It makes use of per-process queues for synchronous requests and a per-device queue for asynchronous requests. </span><span class="koboSpan" id="kobo.296.3">It assigns a budget to each process. </span><span class="koboSpan" id="kobo.296.4">This budget is calculated based on the I/O priority and the number of sectors transferred by the process when it was scheduled the last time. </span><span class="koboSpan" id="kobo.296.5">Although the BFQ scheduler is complex and incurs a slightly larger overhead compared to other schedulers, it is widely used, as it improves system response times and minimizes latency for </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">time-sensitive applications.</span></span></p>
<h2 id="_idParaDest-106"><a id="_idTextAnchor117"/><span class="koboSpan" id="kobo.298.1">Kyber – prioritizing throughput</span></h2>
<p><span class="koboSpan" id="kobo.299.1">The Kyber scheduler is also a relatively newer entry in the disk scheduling world. </span><span class="koboSpan" id="kobo.299.2">Although the BFQ scheduler is older than the Kyber scheduler, both officially became a part of the kernel version 4.12. </span><span class="koboSpan" id="kobo.299.3">The Kyber scheduler is specifically designed for modern high-performing </span><span class="No-Break"><span class="koboSpan" id="kobo.300.1">storage devices.</span></span></p>
<p><span class="koboSpan" id="kobo.301.1">Historically, the ultimate goal of disk schedulers has been to reduce seek times for mechanical drives so that the overhead caused by random access operations can be decreased. </span><span class="koboSpan" id="kobo.301.2">Consequently, the different disk schedulers have used complex and sophisticated techniques to achieve this common goal. </span><span class="koboSpan" id="kobo.301.3">Each scheduler prioritizes certain aspects of performance in varying ways, which introduces an additional overhead while processing I/O requests. </span><span class="koboSpan" id="kobo.301.4">As modern drives, such as SSDs and NVMe, are not hampered by random access operations, some of the complicated techniques used by certain schedulers might not apply to these devices. </span><span class="koboSpan" id="kobo.301.5">For instance, the BFQ scheduler has a slightly </span><a id="_idTextAnchor118"/><span class="koboSpan" id="kobo.302.1">high overhead for each request, so it is not considered ideal for systems to have high throughput drives. </span><span class="koboSpan" id="kobo.302.2">This is where the Kyber scheduler comes </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">in handy.</span></span></p>
<p><span class="koboSpan" id="kobo.304.1">The Kyber scheduler doesn’t have complex internal scheduling algorithms. </span><span class="koboSpan" id="kobo.304.2">It is intended to be used in environments that comprise high-performing storage devices. </span><span class="koboSpan" id="kobo.304.3">It uses a very straightforward approach and implements some basic policies to marshal I/O requests. </span><span class="koboSpan" id="kobo.304.4">The Kyber scheduler splits the underlying device into multiple domains. </span><span class="koboSpan" id="kobo.304.5">The idea is to maintain a queue for the different types of I/O requests. </span><span class="koboSpan" id="kobo.304.6">Upon inspecting the code found in </span><strong class="source-inline"><span class="koboSpan" id="kobo.305.1">block/kyber-iosched.c</span></strong><span class="koboSpan" id="kobo.306.1">, we can observe the presence of the following </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">request types:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.308.1">
[…….]
static const char *Kyber_domain_names[] = {
        [KYBER_READ] = "READ",
        [KYBER_WRITE] = "WRITE",
        [KYBER_DISCARD] = "DISCARD",
        [KYBER_OTHER] = "OTHER",
};
[…….]</span></pre>
<p><span class="koboSpan" id="kobo.309.1">The Kyber scheduler categorizes the requests as follows – reads, writes, discard, and other requests. </span><span class="koboSpan" id="kobo.309.2">The Kyber scheduler maintains queues for these types of requests. </span><span class="koboSpan" id="kobo.309.3">The discard request is used for devices such as SSDs. </span><span class="koboSpan" id="kobo.309.4">The filesystem on top of the device can issue this request to discard blocks not in use by the filesystem. </span><span class="koboSpan" id="kobo.309.5">For the type of request mentioned previously, the scheduler implements a limit on the corresponding number of operations in the </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">device queue:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.311.1">
[…...]
static const unsigned int Kyber_depth[] = {
        [KYBER_READ] = 256,
        [KYBER_WRITE] = 128,
        [KYBER_DISCARD] = 64,
        [KYBER_OTHER] = 16,
};
[…...]</span></pre>
<p><span class="koboSpan" id="kobo.312.1">The crux of Kyber’s scheduling approach is to limit the size of dispatch queues. </span><span class="koboSpan" id="kobo.312.2">This directly correlates with the time spent waiting for I/O requests in the request queue. </span><span class="koboSpan" id="kobo.312.3">The scheduler only sends a limited number of operations to the dispatch queue, which ensures that the dispatch queue is not too crowded. </span><span class="koboSpan" id="kobo.312.4">This results in the swift processing of the requests in the dispatch queue. </span><span class="koboSpan" id="kobo.312.5">Consequently, the I/O operations in the request queues don’t have to wait too long to be serviced. </span><span class="koboSpan" id="kobo.312.6">This approach results in reduced latency. </span><span class="koboSpan" id="kobo.312.7">The following figure illustrates the logic of the </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">Kyber scheduler:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<span class="koboSpan" id="kobo.314.1"><img alt="Figure 6.10 – The Kyber I/O scheduler" src="image/B19430_06_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.315.1">Figure 6.10 – The Kyber I/O scheduler</span></p>
<p><span class="koboSpan" id="kobo.316.1">To determine the number of requests to be allowed in the dispatch queue, the Kyber scheduler uses a simple but effective approach. </span><span class="koboSpan" id="kobo.316.2">It calculates the completion time of each request, and based on this feedback, it adjusts the number of requests in the dispatch queue. </span><span class="koboSpan" id="kobo.316.3">Further, the target latencies for reads and synchronous writes are tunable parameters and can be changed. </span><span class="koboSpan" id="kobo.316.4">Based on their values, the scheduler will throttle requests in order to meet these </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">target latencies.</span></span></p>
<p><span class="koboSpan" id="kobo.318.1">The Kyber scheduler prioritizes requests in the read queue over those in the write queue, unless a write request has been outstanding for too long, meaning the target latency has </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">been breached.</span></span></p>
<p><span class="koboSpan" id="kobo.320.1">The Kyber scheduler is a performance powerhouse when it comes to modern storage devices. </span><span class="koboSpan" id="kobo.320.2">It is tailored for high-speed storage devices, such as SSDs and NVMe, and prioritizes low-latency I/O operations. </span><span class="koboSpan" id="kobo.320.3">This scheduler dynamically adjusts itself by scrutinizing I/O requests and enables the establishment of target latencies for both synchronous writes and reads. </span><span class="koboSpan" id="kobo.320.4">Consequently, it regulates I/O requests to meet the </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">specified objectives.</span></span></p>
<h2 id="_idParaDest-107"><a id="_idTextAnchor119"/><span class="koboSpan" id="kobo.322.1">None – minimal scheduling overhead</span></h2>
<p><span class="koboSpan" id="kobo.323.1">The scheduling of I/O requests is a multifaceted problem. </span><span class="koboSpan" id="kobo.323.2">The scheduler has to take care of several aspects, such as reordering requests in the queue, allocating a portion of disk shares to each process, controlling the execution duration of every request, and making sure that individual requests do not monopolize the available storage resources. </span><span class="koboSpan" id="kobo.323.3">Each scheduler assumes that the host itself cannot optimize requests. </span><span class="koboSpan" id="kobo.323.4">Therefore, it jumps in and applies complex techniques to try and make the most of the available storage resources. </span><span class="koboSpan" id="kobo.323.5">The more sophisticated the scheduling technique, the greater the processing overhead. </span><span class="koboSpan" id="kobo.323.6">While optimizing requests, the schedulers generally make some assumptions about the underlying device. </span><span class="koboSpan" id="kobo.323.7">This works well unless the lower layers in the stack have better visibility of the available storage resources and can handle making scheduling decisions themselves, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.325.1">In high-end storage settings, such as storage area networks, storage arrays frequently include their own scheduling logic, since they possess deeper insight into the nuances of the underlying devices. </span><span class="koboSpan" id="kobo.325.2">As a result, the scheduling of I/O requests typically transpires at the lower layer. </span><span class="koboSpan" id="kobo.325.3">When using raid controllers, the host system doesn’t have complete knowledge about the underlying disks. </span><span class="koboSpan" id="kobo.325.4">Even if the scheduler applies some optimizations to I/O requests, it might not make much of a difference, as the host system lacks the visibility to accurately re-order the requests to lower seek time. </span><span class="koboSpan" id="kobo.325.5">In such cases, it makes sense to simply dispatch the requests to the </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">raid controller.</span></span></li>
<li><span class="koboSpan" id="kobo.327.1">Most scheduler optimizations are directed toward slow mechanical drives. </span><span class="koboSpan" id="kobo.327.2">If the environment consists of SSDs and NVMe drives, the processing overhead associated with these scheduling optimizations may </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">seem excessive.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.329.1">In such cases, a unique but effective solution is to use the </span><em class="italic"><span class="koboSpan" id="kobo.330.1">none</span></em><span class="koboSpan" id="kobo.331.1"> scheduler. </span><span class="koboSpan" id="kobo.331.2">The none scheduler is the multi-queue </span><em class="italic"><span class="koboSpan" id="kobo.332.1">no-op I/O scheduler</span></em><span class="koboSpan" id="kobo.333.1">. </span><span class="koboSpan" id="kobo.333.2">For single-queue devices, the same functionality was achieved through </span><a id="_idTextAnchor120"/><span class="koboSpan" id="kobo.334.1">the </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.335.1">no-op</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.336.1"> scheduler.</span></span></p>
<p><span class="koboSpan" id="kobo.337.1">The none scheduler is the most straightforward of all schedulers, as it performs no scheduling optimizations. </span><span class="koboSpan" id="kobo.337.2">Every incoming I/O request is appended to a FIFO queue and delegated to the block device for handling. </span><span class="koboSpan" id="kobo.337.3">This strategy proves beneficial when it has been established that the host must not endeavor to rearrange requests according to their included sector numbers. </span><span class="koboSpan" id="kobo.337.4">The none scheduler has a single request queue that includes both read and write I/O requests. </span><span class="koboSpan" id="kobo.337.5">Due to its rudimentary approach, Although the none I/O scheduler imposes minimal overhead, it does not ensure any particular quality of service. </span><span class="koboSpan" id="kobo.337.6">The none scheduler also does not perform any reordering of requests. </span><span class="koboSpan" id="kobo.337.7">It only does request merging to reduce seek time and improve throughput. </span><span class="koboSpan" id="kobo.337.8">Unlike all the other schedulers, the none scheduler has no tunables or settings for optimization. </span><span class="koboSpan" id="kobo.337.9">The request merging operation is the entire extent of its complexity. </span><span class="koboSpan" id="kobo.337.10">Because of this, the none scheduler uses a minimal amount of CPU instructions per I/O request. </span><span class="koboSpan" id="kobo.337.11">The operation of the none scheduler is based on the assumption that devices at the lower layer, such as raid controllers or storage controllers, will optimize </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">I/O performance.</span></span></p>
<p><span class="koboSpan" id="kobo.339.1">The simple operational logic of the none scheduler is shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.340.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.341.1">.11</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer060">
<span class="koboSpan" id="kobo.343.1"><img alt="Figure 6.11 – The none I/O scheduler" src="image/B19430_06_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.344.1">Figure 6.11 – The none I/O scheduler</span></p>
<p><span class="koboSpan" id="kobo.345.1">Although every environment has a lot of variables, based on the mode of operation, the none scheduler seems to be the preferred scheduler for enterprise storage area networks, as it does not make any assumptions about the underlying physical devices, and it does not implement any scheduling decisions that can compete or clash with the logic of the lower level </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">I/O controllers.</span></span></p>
<p><span class="koboSpan" id="kobo.347.1">Given the profusion of options to choose from, it can be challenging to determine which scheduler is </span><a id="_idIndexMarker198"/><span class="koboSpan" id="kobo.348.1">most</span><a id="_idIndexMarker199"/><span class="koboSpan" id="kobo.349.1"> suitable for your needs. </span><span class="koboSpan" id="kobo.349.2">In the subsequent section, we will outline common usage scenarios for the schedulers we have covered in </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">this chapter.</span></span></p>
<h1 id="_idParaDest-108"><a id="_idTextAnchor121"/><span class="koboSpan" id="kobo.351.1">Discussing the scheduling conundrum</span></h1>
<p><span class="koboSpan" id="kobo.352.1">We’ve discussed and explained how the different I/O scheduling flavors go about their business, but the</span><a id="_idIndexMarker200"/><span class="koboSpan" id="kobo.353.1"> selection of a scheduler should always be accompanied by benchmark results gathered through real application workloads. </span><span class="koboSpan" id="kobo.353.2">As mentioned earlier, most of the time, default settings might be good enough. </span><span class="koboSpan" id="kobo.353.3">It’s only when you try to achieve peak efficiency, you try and tinker with the </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">default settings.</span></span></p>
<p><span class="koboSpan" id="kobo.355.1">The pluggable nature of these schedulers means that we can change the I/O scheduler for a block device on the fly. </span><span class="koboSpan" id="kobo.355.2">There are two ways to do this. </span><span class="koboSpan" id="kobo.355.3">The currently active scheduler for a particular disk device can be checked through </span><strong class="source-inline"><span class="koboSpan" id="kobo.356.1">sysfs</span></strong><span class="koboSpan" id="kobo.357.1">. </span><span class="koboSpan" id="kobo.357.2">In the following example, the active scheduler is set </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.359.1">mq-deadline</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.361.1">[root@linuxbox ~]# cat /sys/block/sda/queue/scheduler</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.362.1">[mq-deadline] none bfq kyber</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.363.1">[root@linuxbox ~]#</span></strong></pre>
<p><span class="koboSpan" id="kobo.364.1">To change the active scheduler, write the name of the desired scheduler to the scheduler file. </span><span class="koboSpan" id="kobo.364.2">For instance, to set the BFQ scheduler for </span><strong class="source-inline"><span class="koboSpan" id="kobo.365.1">sda</span></strong><span class="koboSpan" id="kobo.366.1">, use the </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">following command:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.368.1">
echo bfq &gt; /sys/block/sda/queue/scheduler</span></pre>
<p><span class="koboSpan" id="kobo.369.1">The preceding method will only set the scheduler temporarily and revert to default settings after a reboot. </span><span class="koboSpan" id="kobo.369.2">To make this change permanent, edit the </span><strong class="source-inline"><span class="koboSpan" id="kobo.370.1">/etc/default/grub</span></strong><span class="koboSpan" id="kobo.371.1"> file and add the </span><strong class="source-inline"><span class="koboSpan" id="kobo.372.1">elevator=bfq</span></strong><span class="koboSpan" id="kobo.373.1"> parameter to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.374.1">GRUB_CMDLINE_LINUX_DEFAULT</span></strong><span class="koboSpan" id="kobo.375.1"> line. </span><span class="koboSpan" id="kobo.375.2">Then, regenerate the </span><strong class="source-inline"><span class="koboSpan" id="kobo.376.1">GRUB</span></strong><span class="koboSpan" id="kobo.377.1"> configuration and reboot </span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">the system.</span></span></p>
<p><span class="koboSpan" id="kobo.379.1">Merely changing the scheduler will not result in two-fold performance gains. </span><span class="koboSpan" id="kobo.379.2">Usually, the improvement figure will be somewhere </span><span class="No-Break"><span class="koboSpan" id="kobo.380.1">between 10–20%.</span></span></p>
<p><span class="koboSpan" id="kobo.381.1">Although each environment is different and scheduler performance may vary depending upon several variables, as a baseline, the following are some of the use cases of the schedulers that we’ve discussed in </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">this chapter:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-5">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.383.1">Use case</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.384.1">Recommended </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.385.1">I/O scheduler</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.386.1">A desktop GUI, interactive applications, and soft real-time applications, such as audio and </span><span class="No-Break"><span class="koboSpan" id="kobo.387.1">video players</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.388.1">BFQ, as it guarantees good system responsiveness and low latency for </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">time-sensitive applications</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.390.1">Traditional </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">mechanical drives</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.392.1">BFQ or MQ-deadline – both are considered suitable for slower drives. </span><span class="koboSpan" id="kobo.392.2">Kyber/none are biased in favor of </span><span class="No-Break"><span class="koboSpan" id="kobo.393.1">faster disks.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.394.1">High-performing SSDs and NVMe drives as </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">local storage</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.396.1">Preferably none, but Kyber might also be a good alternative in </span><span class="No-Break"><span class="koboSpan" id="kobo.397.1">some cases</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.398.1">Enterprise </span><span class="No-Break"><span class="koboSpan" id="kobo.399.1">storage arrays</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.400.1">None, as most storage arrays have built-in logic to schedule I/Os </span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">more efficiently</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.402.1">Virtualized environments</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.403.1">MQ-deadline is a good option. </span><span class="koboSpan" id="kobo.403.2">If the hypervisor layer does its own I/O scheduling, then using the none scheduler might </span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">be beneficial.</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.405.1">Table 6.1 – Typical use cases for I/O schedulers</span></p>
<p><span class="koboSpan" id="kobo.406.1">Please note that these are not strict use cases, as often, several conditions might be overlapping. </span><span class="koboSpan" id="kobo.406.2">The type of application, workload, host system, and storage media are just some of the factors that must be kept in mind before deciding on a scheduler. </span><span class="koboSpan" id="kobo.406.3">Typically, the deadline scheduler </span><a id="_idIndexMarker201"/><span class="koboSpan" id="kobo.407.1">is regarded as a versatile choice, due to its modest CPU overhead. </span><span class="koboSpan" id="kobo.407.2">BFQ performs well in desktop environments, whereas none and Kyber are better suited for high-end </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">storage devices.</span></span></p>
<h1 id="_idParaDest-109"><a id="_idTextAnchor122"/><span class="koboSpan" id="kobo.409.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.410.1">This chapter provided an overview of I/O scheduling, which is a critical function of the block layer. </span><span class="koboSpan" id="kobo.410.2">When a read or write request passes through all the layers of the virtual filesystem, it eventually arrives at the block layer. </span><span class="koboSpan" id="kobo.410.3">The chapter explored the various types of I/O schedulers and their characteristics, including their advantages and disadvantages. </span><span class="koboSpan" id="kobo.410.4">The block layer includes multiple I/O schedulers that are suitable for particular use cases. </span><span class="koboSpan" id="kobo.410.5">The choice of an I/O scheduler plays a vital role in determining how I/O requests will be handled at the lower layer. </span><span class="koboSpan" id="kobo.410.6">To make more performance-oriented decisions, most schedulers employ some common techniques that aid in improving overall disk performance. </span><span class="koboSpan" id="kobo.410.7">The techniques that we discussed in this chapter are merging, coalescing, sorting, </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">and plugging.</span></span></p>
<p><span class="koboSpan" id="kobo.412.1">We also explained the different scheduling options available in the kernel. </span><span class="koboSpan" id="kobo.412.2">The kernel has a separate set of I/O schedulers for single- and multi-queue devices. </span><span class="koboSpan" id="kobo.412.3">The single-queue schedulers have been deprecated since kernel version 5.0. </span><span class="koboSpan" id="kobo.412.4">The multi-queue scheduling options include the multi-queue Deadline scheduler, BFQ, Kyber, and the none scheduler. </span><span class="koboSpan" id="kobo.412.5">Each of these schedulers is suited to specific use cases, and there is no single recommendation, which can be applied to all situations. </span><span class="koboSpan" id="kobo.412.6">The MQ-deadline scheduler has good all-around performance. </span><span class="koboSpan" id="kobo.412.7">The BFQ scheduler is more oriented toward interactive applications, while Kyber and None are geared toward high-end storage devices. </span><span class="koboSpan" id="kobo.412.8">To choose a scheduler, it is imperative to know details about the environment, which includes details such as the type of workload, application, host system, and backend </span><span class="No-Break"><span class="koboSpan" id="kobo.413.1">physical media.</span></span></p>
<p><span class="koboSpan" id="kobo.414.1">This chapter concludes part two of the book, in which we delved into the block layer. </span><span class="koboSpan" id="kobo.414.2">In the next chapter, we’ll see the different types of storage media available today and explain the differences </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">between them.</span></span></p>
</div>


<div class="Content" id="_idContainer062">
<h1 id="_idParaDest-110"><a id="_idTextAnchor123"/><span class="koboSpan" id="kobo.1.1">Part 3: Descending into the Physical Layer</span></h1>
<p><span class="koboSpan" id="kobo.2.1">This part will introduce you to the architecture and major components of the SCSI subsystem in the Linux kernel. </span><span class="koboSpan" id="kobo.2.2">You will also be introduced to the different types of physical storage media available today and the differences in </span><span class="No-Break"><span class="koboSpan" id="kobo.3.1">their implementation.</span></span></p>
<p><span class="koboSpan" id="kobo.4.1">This part contains the </span><span class="No-Break"><span class="koboSpan" id="kobo.5.1">following chapters:</span></span></p>
<ul>
<li><a href="B19430_07.xhtml#_idTextAnchor124"><em class="italic"><span class="koboSpan" id="kobo.6.1">Chapter 7</span></em></a><span class="koboSpan" id="kobo.7.1">, </span><em class="italic"><span class="koboSpan" id="kobo.8.1">The SCSI Subsystem</span></em></li>
<li><a href="B19430_08.xhtml#_idTextAnchor134"><em class="italic"><span class="koboSpan" id="kobo.9.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.10.1">, </span><em class="italic"><span class="koboSpan" id="kobo.11.1">Illustrating the Layout of Physical Media</span></em></li>
</ul>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer063">
</div>
</div>
<div>
<div id="_idContainer064">
</div>
</div>
</body></html>