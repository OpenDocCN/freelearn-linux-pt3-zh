- en: '18'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '18'
- en: Container Orchestration
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器编排
- en: In the previous chapter, we started learning concepts around containerization.
    We’ve learned what containers are and how they differ from **Virtual Machines**
    (**VMs**), as well as how to run two different types of containers (Docker and
    LXD). As you are now aware, containers are typically lightweight (which means
    you run a larger number of them than VMs on the same hardware) and are easy to
    manage with a command syntax that’s rather logical, such as docker run myapp to
    launch a container named myapp. Depending on the size of your organization, you
    may only need to run one or two containers to suit your needs, or perhaps you
    plan on scaling up to hundreds of them. While it’s rather simple to maintain a
    small number of containers, the footprint can quickly expand and become much harder
    to keep track of.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们开始学习关于容器化的概念。我们了解了容器是什么，它们与**虚拟机**（**VMs**）的区别，以及如何运行两种不同类型的容器（Docker
    和 LXD）。如你所知，容器通常较为轻量（这意味着你可以在同一硬件上运行更多的容器，而不是虚拟机），并且容易通过逻辑性较强的命令语法进行管理，例如使用 `docker
    run myapp` 启动一个名为 myapp 的容器。根据你的组织规模，你可能只需要运行一个或两个容器来满足需求，或者你计划扩展到数百个容器。虽然维护少量容器相对简单，但随着数量的增加，容器的管理难度也会急剧增加。
- en: 'In this chapter, we’ll start looking into the concept of **Container Orchestration**,
    which can help us to better maintain the containers that we run. Without such
    orchestration, the onus is on you, the administrator, to ensure your containers
    are running properly. While someone still needs to be responsible for mission-critical
    containers, orchestration provides us with tools we can use to manage them much
    more efficiently. In addition, orchestration allows us to create an entire cluster
    that’s easily scalable, so we’re better equipped to handle the demand of our users
    or clients. As we navigate this topic, we will work on:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将开始探讨**容器编排**的概念，它可以帮助我们更好地维护我们运行的容器。如果没有这种编排，责任就落在你这个管理员身上，确保你的容器正常运行。虽然仍然需要有人对关键任务容器负责，但编排为我们提供了可以用来更高效管理容器的工具。此外，编排允许我们创建一个易于扩展的集群，从而更好地应对用户或客户的需求。在探讨这一话题时，我们将着重于：
- en: Container orchestration
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器编排
- en: Preparing a lab environment for Kubernetes testing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 Kubernetes 测试准备实验环境
- en: Utilizing MicroK8s
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 MicroK8s
- en: Setting up a Kubernetes cluster
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置 Kubernetes 集群
- en: Deploying containers via Kubernetes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Kubernetes 部署容器
- en: Excited? I know I am—containerization can be a lot of fun to learn and work
    with. We’ll even create our very own cluster in this chapter! But before we can
    do that, let’s make sure we have an understanding of what container orchestration
    is.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 激动吗？我知道我很激动——容器化是一个非常有趣的学习和工作内容。在本章中，我们甚至会创建我们自己的集群！但在此之前，让我们先确保理解什么是容器编排。
- en: Container orchestration
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器编排
- en: In the last chapter, we covered the basics of running containers on your server.
    Of special note is the coverage of Docker, which will play a very important role
    in this chapter. We saw how to pull a Docker image as well as how to use such
    an image to create a container. There are many more advanced concepts we can learn
    when it comes to Docker, but understanding the essentials is good enough for the
    scope of this chapter. And now that we know how to run containers, looking further
    into how to more efficiently manage them is a logical next step.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了如何在服务器上运行容器的基础知识，特别提到了 Docker，它将在本章中发挥非常重要的作用。我们了解了如何拉取 Docker 镜像，以及如何使用镜像创建容器。关于
    Docker，还有许多更高级的概念可以学习，但理解基本内容已足够满足本章的范围。既然我们已经知道如何运行容器，那么接下来就逻辑地探讨如何更高效地管理它们。
- en: Traditionally, as an administrator, you’ll ensure the critical apps and services
    for your organization are always healthy and available. If a critical resource
    stops working for any reason, it falls on you to return it to a healthy state.
    Regardless of whether we’re utilizing applications on a physical server, or in
    a VM or container, this need doesn’t change—production apps need to be available
    at all times with minimal or no downtime. Specific to containers, what orchestration
    does for us is help us maintain them much more efficiently. Orchestration allows
    us to not only manage our containers in one place, but it also provides us with
    additional tooling we can use to more intelligently handle load and recover from
    faults.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，作为管理员，你需要确保组织中的关键应用程序和服务始终保持健康和可用。如果某个关键资源因任何原因停止工作，你需要负责将其恢复到健康状态。无论我们是在物理服务器、虚拟机（VM）还是容器中使用应用程序，这一需求都没有变化——生产应用程序必须始终可用，且停机时间要尽量减少或没有停机时间。针对容器来说，编排帮助我们更高效地管理它们。编排不仅让我们可以在一个地方管理容器，还提供了额外的工具，帮助我们更智能地处理负载并从故障中恢复。
- en: 'Consider this example: let’s assume you work at an organization that has an
    important website that needs to be available online at all times, and it’s currently
    set up inside a VM. As the administrator, you test the application by running
    it inside a Docker container and discover that it not only functions the same
    as in the VM, it also requires less of the server’s memory to run it in a container,
    and it’s even more responsive than before. Everyone at your company is impressed,
    and the project of converting your company’s site to run inside a container is
    a complete success.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子：假设你在一家组织工作，这个组织有一个重要的网站需要始终在线可用，且当前网站是部署在虚拟机中的。作为管理员，你通过将其运行在 Docker 容器中来测试应用，发现它不仅与在虚拟机中的功能相同，而且在容器中运行时需要的服务器内存更少，响应速度也比之前更快。你公司里的人都对这个结果印象深刻，将公司网站迁移到容器内运行的项目也圆满成功。
- en: Now, let’s assume your organization is getting ready to release a brand new
    version of your company’s product. It’s expected that the demand for your website
    will increase ten times for at least the first few weeks after the debut. To address
    this, you can launch however many additional containers you feel will handle the
    expected load, and then set up a load balancer to spread traffic evenly between
    them. When the excitement over the new release winds down, you can remove the
    newly added containers to return to your original population. We haven’t gone
    over load balancers yet, but these are useful for spreading traffic between multiple
    nodes. This feature is built into Kubernetes, so you won’t need to install anything
    extra to take advantage of this.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你的组织准备发布公司产品的全新版本。预计在新版本发布后的几周内，网站的访问需求将增加十倍。为了解决这个问题，你可以根据预计的负载，启动任意数量的额外容器，然后设置负载均衡器将流量均匀分配到这些容器之间。当新版本发布的热度平息后，你可以删除新增的容器，恢复到原来的容器数量。我们还没有讨论负载均衡器，但它们对在多个节点之间分配流量非常有用。这个功能已经内置于
    Kubernetes 中，因此你无需额外安装任何东西就能利用这一功能。
- en: If the launch of your organization’s newly updated product is expected to go
    live at 1:00am, you’d have to make sure you’re awake then and execute the necessary
    commands to launch the extra containers and deploy the load balancer. You would
    then watch the containers for a while and ensure they’re stable. Perhaps you’ve
    already tested this in a testing environment, so you have reasonable confidence
    that the maintenance will go smoothly. After you successfully launch the containers,
    you set a reminder for yourself in your calendar to log back in after two weeks
    to undo the changes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你组织的新产品更新计划在凌晨1:00上线，那么你需要确保在那个时间醒来，并执行必要的命令来启动额外的容器和部署负载均衡器。然后你需要观察这些容器一段时间，确保它们稳定运行。也许你已经在测试环境中进行过测试，所以你有足够的信心认为维护过程会顺利进行。在成功启动容器后，你在日历中设置了提醒，在两周后重新登录，撤销这些更改。
- en: While that approach can technically work and result in a successful rollout,
    it’s not very efficient. Sure, you *can* log in at 1:00am to launch the extra
    containers and deploy the load balancer, but is that an effective use of your
    time? What if you’re very sleepy at that time and make a mistake that results
    in a failure during an important launch? And when the launch window is over and
    the load returns to normal, you may or may not see the alert that you’ve intended
    to use to remind yourself and lower the container count.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方法在技术上可以工作并实现成功的部署，但它并不高效。当然，你*可以*在凌晨1点登录以启动额外的容器并部署负载均衡器，但这真的是时间的有效利用吗？如果你那时非常困倦，并犯了一个错误，导致在一个重要发布时出现故障怎么办？而当发布窗口结束，负载恢复正常时，你可能根本不会看到原本打算用来提醒自己并降低容器数量的警报。
- en: In that situation, you could end up with an expensive bill since your server
    would be using extra energy to run containers that were no longer needed. Even
    worse, manually managing your containers means that it can’t handle a situation
    where the load increases unexpectedly. Despite our best intentions, any process
    that is run manually may or may not work out well; we’re only human after all.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你可能会面临一笔昂贵的账单，因为你的服务器将使用额外的能量来运行那些已经不再需要的容器。更糟糕的是，手动管理容器意味着它无法应对负载意外增加的情况。尽管我们有最好的意图，但任何手动运行的过程都可能不顺利；毕竟我们只是人类。
- en: With container orchestration, we essentially delegate the process of running
    containers to an application that will automatically create additional containers
    as demand increases and remove unneeded containers when demand winds down. Orchestration
    also simplifies the process of setting up applications, by giving us tools we
    can use to ensure a particular number of containers are running at a minimum and
    we can set a maximum for when load and demand spikes. This empowers us to have
    infrastructure that grows and shrinks automatically to match the needs of our
    users. In addition, container orchestration allows us to automatically heal from
    failures. If a container runs into a problem and fails for some reason, it will
    be deleted and recreated from the image.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用容器编排，我们基本上将运行容器的过程委托给一个应用程序，该应用程序会根据需求增加额外的容器，并在需求减少时删除不需要的容器。编排还简化了应用程序的设置过程，通过提供我们可以使用的工具，确保一定数量的容器至少在最小限度内运行，并在负载和需求激增时设定最大容器数。这使得我们能够拥有一个能够自动增长和收缩的基础设施，以匹配用户的需求。此外，容器编排还允许我们在发生故障时自动修复。如果某个容器遇到问题并因某种原因失败，它将被删除并从镜像中重新创建。
- en: As you can see, orchestration gives us additional value, it can actually save
    you time and effort. To be fair, some of the features mentioned are part of containerization
    itself and not necessarily specific to orchestration, but the latter does give
    us the ability to manage these tools much more efficiently. Is container orchestration
    for everyone? No technology meets 100% of all use-cases, but it’s certainly something
    to consider. If you only run a single container and have no plans to run another,
    then a technology such as orchestration is overkill—it would take you more time
    to manage the cluster than it would to manage the container itself. Use your best
    judgment.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，编排为我们提供了额外的价值，它实际上可以节省时间和精力。公平地说，文中提到的一些功能是容器化本身的一部分，并不一定特定于编排，但后者确实让我们能够更高效地管理这些工具。容器编排适合每个人吗？没有技术能满足100%的使用场景，但它肯定值得考虑。如果你只运行一个容器，并且没有计划运行另一个，那么像编排这样的技术就显得过于复杂——管理集群所花的时间会比管理容器本身更多。请凭你的判断做出决定。
- en: If you do decide to implement containerization, **Kubernetes** (often abbreviated
    **K8s**) is a very popular solution for container orchestration and is what we’ll
    be exploring in this chapter. What Kubernetes allows us to do is create deployments
    for our applications, providing us with fine-tuned control we can leverage to
    determine the actual behavior of our applications. It can automatically re-spawn
    a container if it stops working for any reason, ensure the number of containers
    running meets the demand, and spread our workloads across many worker nodes so
    that no one server becomes overwhelmed with running too many containers. Kubernetes
    is very popular and is not specific to Ubuntu Server. However, utilizing a technology
    such as Kubernetes in Ubuntu is one of many ways that we can use to extend the
    platform.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你决定实施容器化，**Kubernetes**（通常缩写为**K8s**）是一个非常流行的容器编排解决方案，也是我们将在本章中探讨的内容。Kubernetes允许我们为应用程序创建部署，提供我们可以利用的精细控制，以决定应用程序的实际行为。如果容器因任何原因停止工作，它可以自动重新启动容器，确保运行的容器数量满足需求，并将我们的工作负载分布到多个工作节点上，从而避免任何一个服务器因运行过多容器而不堪重负。Kubernetes非常流行，且不仅限于Ubuntu
    Server。然而，像Kubernetes这样的技术在Ubuntu中的使用是我们可以扩展平台的许多方式之一。
- en: What do you need in order to set up a Kubernetes cluster? That’s likely a logical
    question to have at this point. In the next section, we’ll cover some of the considerations
    to make before deciding how to set it up.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要什么才能设置一个Kubernetes集群？这在此时可能是一个合乎逻辑的问题。在下一部分，我们将讨论在决定如何设置之前需要考虑的一些事项。
- en: Preparing a lab environment for Kubernetes testing
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Kubernetes测试准备实验环境
- en: In an organization, planning a roll-out of an entire Kubernetes cluster can
    be fairly involved—you may have to purchase hardware and also analyze your existing
    environment and understand how containerization will fit in. It’s possible that
    some applications you want to run aren’t a good fit for containers; some don’t
    support running in a container at all. Assuming you’ve already checked the documentation
    for the applications you are wanting to run in containers and came to the conclusion
    that such a technology is supported, the next step is procuring the hardware (if
    you don’t already have a place to run it) and then setting up the cluster.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个组织中，规划整个Kubernetes集群的部署可能相当复杂——你可能需要购买硬件，还需要分析现有的环境，了解容器化如何融入其中。你可能希望运行的一些应用程序不适合容器；有些根本不支持在容器中运行。假设你已经查看了你希望在容器中运行的应用程序的文档，并得出结论认为这种技术是被支持的，下一步就是采购硬件（如果你还没有可用的运行场所），然后设置集群。
- en: Specific to us in this book, we don’t need to contact a server vendor and submit
    a purchase order to simply test out the technology. If you are actually involved
    with the rollout of container orchestration at your organization, then it’s a
    fun project to work on. But for the purposes of this book, let’s discuss some
    of the details around what’s needed to set up a personal lab in order to set up
    Kubernetes and start learning the platform.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，针对我们来说，我们不需要联系服务器供应商并提交采购订单来简单地测试技术。如果你实际参与了容器编排在你组织中的部署，那么这是一个很有趣的项目。但是为了本书的目的，我们将讨论一些建立个人实验室所需的细节，以便设置Kubernetes并开始学习该平台。
- en: The best rule of thumb when setting up a lab for testing software is to try
    to use what you have available. To create a Kubernetes cluster, we’ll need one
    Ubuntu machine to act as the controller, and one or more additional servers to
    be used as worker nodes. As you’ll learn later in the book, the goal of Kubernetes
    is to schedule containers to run in **Pods** on worker nodes. Pods in Kubernetes
    are a collection of one or more containers, and every container is run in a pod.
    With more than one worker node, you can benefit from being able to run more pods
    (and as an extension, run more containers) and having load spread between multiple
    workers to have the most control over how your applications are served to the
    end-user.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 设置实验室以测试软件时，最好的经验法则是尽量使用现有的资源。为了创建一个Kubernetes集群，我们需要一台Ubuntu机器作为控制器，另外一台或多台服务器作为工作节点。正如你将在本书后续部分学到的，Kubernetes的目标是将容器调度到工作节点上的**Pod**中。Kubernetes中的Pod是一组一个或多个容器，每个容器都在一个Pod中运行。有了多个工作节点，你可以通过运行更多的Pod（从而运行更多的容器）并将负载分配到多个工作节点之间，从而获得对应用程序如何提供给最终用户的最大控制。
- en: But on what type of device should you run Kubernetes on in order to test it
    out and learn it? For this, we have the same possibilities as we discussed when
    installing Ubuntu Server back in *Chapter 1*, *Deploying Ubuntu Server*—we can
    use VMs, physical servers, spare desktops or laptops, as well as Raspberry Pi’s
    (or any combination of those). Again, use whatever you have available. For a rollout
    in an organization, you may end up using a virtualization server for the controller
    and worker nodes, or perhaps physical servers. One of my favorite platforms for
    Kubernetes is the Raspberry Pi, believe it or not. I’ve been running a Kubernetes
    cluster in production for several years that consists of only Raspberry Pi 4 units
    with complete success. If nothing else, purchasing a few Pi’s is a relatively
    low barrier to entry. You can even utilize a cloud provider if you’d like, though
    doing so goes beyond the scope of this chapter as cloud providers generally have
    their own tools in place to manage clusters.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，在什么类型的设备上运行 Kubernetes 进行测试和学习呢？对于这个问题，我们可以选择和 *第 1 章*、*部署 Ubuntu Server*
    中讨论的相同选项——可以使用虚拟机、物理服务器、备用台式机或笔记本电脑，也可以使用树莓派（或这些设备的任意组合）。再次强调，使用你现有的设备即可。对于组织的部署，你可能会选择使用虚拟化服务器作为控制器和工作节点，或者使用物理服务器。说实话，我最喜欢的
    Kubernetes 平台之一就是树莓派。我已经运行了一个生产环境中的 Kubernetes 集群，完全由树莓派 4 单元组成，而且取得了完全成功。如果没有其他选择，购买几台树莓派的成本相对较低。你甚至可以选择使用云服务提供商，尽管这样做超出了本章的范围，因为云服务提供商通常有自己的工具来管理集群。
- en: In general, it’s recommended to have a controller node and a handful of workers.
    A single worker will suffice, but in this chapter, I’ll show the process of setting
    up two workers to better understand how the platform scales. On your end, you
    can use a single controller and worker, or set up however many workers you’d like.
    One of the best things about Kubernetes is that you aren’t stuck with the number
    of workers you set up initially, you can add more nodes to your cluster as time
    goes on. An organization may start with just a few workers but add additional
    ones as the need arises.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，推荐拥有一个控制器节点和若干工作节点。一个工作节点就足够了，但在本章中，我将演示如何设置两个工作节点，以便更好地理解平台的扩展性。在你的环境中，你可以使用一个控制器和工作节点，或者根据需要设置任意数量的工作节点。Kubernetes
    最棒的地方之一就是你不必固定最初设置的工作节点数量，随着时间推移，你可以向集群中添加更多节点。一个组织可能一开始只会有几个工作节点，但随着需求的增加，可以逐步添加更多节点。
- en: As far as resources go, requirements for Kubernetes are relatively modest. The
    node that’s designated as the controller should have a minimum of two CPUs or
    one CPU with at least two cores. Obviously, it’s better if you have more than
    that, such as a quad-core CPU for the controller, but two cores are the minimum.
    The worker nodes can have a single CPU core each, but the more cores they have,
    the more Pods they’ll be able to run. When it comes to RAM, I recommend a minimum
    of 2 GB of memory on each, but again, if you have more than that on each node
    then that’s even better.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 就资源而言，Kubernetes 的要求相对较低。被指定为控制器的节点应至少具有两个 CPU 或一个 CPU，且至少有两个核心。显然，如果你有更多的 CPU，尤其是四核
    CPU 来作为控制器，那会更好，但两个核心是最低要求。工作节点每个可以有一个 CPU 核心，但它们的核心越多，能够运行的 Pods 就越多。至于 RAM，我建议每个节点至少
    2 GB 内存，但如果每个节点的内存更高，那会更好。
- en: It’s important that the IP addresses for the nodes in your cluster do not change.
    If an IP of a cluster node changes, it can cause the cluster nodes to be unable
    to find each other. In *Chapter 10*, *Connecting to Networks*, we learned how
    to set up a static IP address, which is a good solution for preventing IP addresses
    from changing. As an alternative, you can set up a static lease in your DHCP server
    if you wish. It doesn’t matter which solution you use, so long as you prevent
    the IP addresses of cluster nodes from changing.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，集群中节点的 IP 地址不能发生变化。如果集群节点的 IP 地址发生变化，可能会导致节点无法互相找到。在 *第 10 章*、*连接到网络* 中，我们学习了如何设置静态
    IP 地址，这是防止 IP 地址变化的好方法。作为替代方案，如果你愿意，可以在 DHCP 服务器中设置静态租约。无论你使用哪种解决方案，关键是要确保集群节点的
    IP 地址不发生变化。
- en: For some readers, a more accessible method of setting up comes in the form of
    **MicroK8s**, which allows you to even set up Kubernetes on a single machine.
    If your only goal is to set up a simple test installation, it’s one of the best
    and easiest methods of getting started. MicroK8s is not recommended for running
    a production cluster in an organization, but it’s definitely a great way to learn.
    I do recommend that you work through the standard Kubernetes procedure with multiple
    nodes if you can, but in the next section we’ll walk through setting up MicroK8s
    for those of you that would like to utilize that method.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些读者来说，更容易的设置方法是 **MicroK8s**，它甚至允许你在单台机器上设置 Kubernetes。如果你的唯一目标是设置一个简单的测试安装，它是最好的且最简单的入门方法之一。MicroK8s
    不推荐用于在组织中运行生产集群，但它绝对是学习的好方式。我确实建议如果可以的话，按照标准的 Kubernetes 程序进行多节点设置，但在下一节中，我们将讲解如何设置
    MicroK8s，供那些希望使用这种方法的你参考。
- en: Utilizing MicroK8s
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MicroK8s
- en: If you don’t have more than one machine or enough memory on your laptop or desktop
    to run multiple nodes inside virtualization software such as VirtualBox, MicroK8s
    is a simple way to set up a Kubernetes instance for testing the platform, as well
    as going through the examples in this chapter. MicroK8s is actually provided by
    Canonical, the makers of Ubuntu. That just goes to show you how important Kubernetes
    is to the Ubuntu distribution, its own creator is going the extra mile to contribute
    to the platform. MicroK8s is available for Linux, macOS, as well as Windows. So
    regardless of which operating system you’re running on your laptop or desktop,
    you should be able to install and use it. If nothing else, it gives you a great
    test installation of Kubernetes that will come in handy as you learn.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有多台机器，或者你的笔记本电脑或台式机内存不足以在虚拟化软件（如 VirtualBox）中运行多个节点，MicroK8s 是一个简单的方式来设置
    Kubernetes 实例，用于测试平台并通过本章的示例。MicroK8s 实际上是由 Ubuntu 的开发商 Canonical 提供的。这也说明了 Kubernetes
    对 Ubuntu 发行版的重要性，作为其创始人，Canonical 致力于为该平台做出贡献。MicroK8s 可用于 Linux、macOS 以及 Windows。因此，无论你在笔记本电脑或台式机上运行的是哪个操作系统，你都应该能够安装并使用它。如果没有其他目的，它至少能为你提供一个优秀的
    Kubernetes 测试安装，帮助你学习。
- en: To set it up, follow along with one of the subsections below that matches the
    operating system installed on your computer.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行设置，请按照下面与电脑操作系统相匹配的子章节操作。
- en: Installing MicroK8s on Linux
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Linux 上安装 MicroK8s
- en: 'When it comes to Linux, MicroK8s is distributed as a snap package. We covered
    snap packages back in *Chapter 3*, *Managing Software Packages*, and it’s a great
    solution for cross-distribution package management. If you run a recent version
    of Ubuntu on your computer, then you should already have support for snap packages
    and you can proceed to install MicroK8s. If you’re running a distribution of Linux
    on your computer other than Ubuntu, then you may not have access to the `snap`
    command by default. If in doubt, you can use the `which` to see if the command
    is available:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Linux，MicroK8s 作为 snap 包分发。我们在*第 3 章*《管理软件包》中介绍过 snap 包，它是一个很好的跨发行版软件包管理解决方案。如果你在电脑上运行的是较新的
    Ubuntu 版本，那么你应该已经支持 snap 包，可以继续安装 MicroK8s。如果你在电脑上运行的是 Ubuntu 之外的 Linux 发行版，那么默认情况下可能没有
    `snap` 命令。如果不确定，你可以使用 `which` 命令检查该命令是否可用：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you do have the ability to install snap packages, then your output should
    be similar to the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实能够安装 snap 包，则输出应该类似于以下内容：
- en: '![](img/B18425_18_01.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_01.png)'
- en: 'Figure 18.1: Checking if the snap command is available'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.1：检查 snap 命令是否可用
- en: If you see no output when you run `which snap`, then that means your distribution
    doesn’t have support for this package type installed. Canonical makes the `snap`
    command available to distributions outside of Ubuntu, so if you’re using a distribution
    other than Ubuntu, it’s usually just a matter of installing the required package.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行 `which snap` 时没有输出，说明你的发行版没有安装对这种包类型的支持。Canonical 将 `snap` 命令提供给了 Ubuntu
    之外的发行版，因此，如果你使用的是其他发行版，通常只需要安装所需的软件包。
- en: 'Canonical has additional information available on the following site, which
    shows the process of enabling `snap` for several distributions: [https://snapcraft.io/docs/installing-snapd](https://snapcraft.io/docs/installing-snapd).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Canonical 在以下网站上提供了更多信息，展示了如何为多个发行版启用 `snap` 的过程：[https://snapcraft.io/docs/installing-snapd](https://snapcraft.io/docs/installing-snapd)。
- en: 'For example, the documentation on that site gives the following command to
    install the required package for Fedora:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，该网站的文档提供了以下命令来安装 Fedora 所需的软件包：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Essentially, as long as you follow along with the instructions for setting up
    `snap` that are specific to the distribution of Linux you’re running, the process
    should be simple enough. If for some reason your distribution isn’t supported,
    you can simply use the same Ubuntu installation as you’ve been using during this
    book, which will have `snap` support built in.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，只要按照与你所使用的 Linux 发行版相关的 `snap` 设置说明操作，整个过程应该足够简单。如果出于某些原因你的发行版不支持，你可以使用本书中已经介绍的相同
    Ubuntu 安装版本，该版本已内置 `snap` 支持。
- en: 'Once you either confirm you already have support for `snap` on your computer,
    or you successfully enable the feature, you can install MicroK8s with the following
    command:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确认你的电脑已支持 `snap`，或者成功启用该功能，你可以使用以下命令安装 MicroK8s：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If successful, you should see a confirmation in your terminal that the process
    was successful:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果成功，你应该会在终端中看到确认消息，表明过程已成功完成：
- en: '![](img/B18425_18_02.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_02.png)'
- en: 'Figure 18.2: Setting up MicroK8s on a Linux installation'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.2：在 Linux 安装中设置 MicroK8s
- en: Now that we have MicroK8s installed on your Linux computer, we can proceed through
    the chapter. Or, you can check out the next section to see the installation process
    for macOS.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在你的 Linux 电脑上安装了 MicroK8s，可以继续本章内容。或者，你也可以查看下一部分，了解 macOS 的安装过程。
- en: Installing MicroK8s on macOS
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 macOS 上安装 MicroK8s
- en: On macOS, the installation process for MicroK8s is similar. The process for
    Mac will utilize **Homebrew**, which is an addon for macOS. Homebrew isn’t specific
    to Kubernetes or MicroK8s; it gives you the ability to install additional packages
    on your Mac that aren’t normally available, with MicroK8s being one of many. Homebrew
    is essentially a command-line utility with syntax similar to Ubuntu’s `apt` command.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 macOS 上，安装 MicroK8s 的过程类似。Mac 上的安装将使用 **Homebrew**，这是 macOS 的一个附加工具。Homebrew
    并不是 Kubernetes 或 MicroK8s 特有的，它让你能够在 Mac 上安装通常无法获得的额外软件包，MicroK8s 只是其中之一。Homebrew
    本质上是一个命令行工具，语法类似于 Ubuntu 的 `apt` 命令。
- en: 'To install Homebrew, visit [https://brew.sh](https://brew.sh) in your browser,
    and the command required to set it up will be right there on the site. I could
    insert the command to install Homebrew right here on this page, but the process
    may change someday, so it’s better to get the command right from the official
    website for the utility. At the time of writing, the page looks like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 Homebrew，请在浏览器中访问 [https://brew.sh](https://brew.sh)，所需的安装命令就在网站上。我可以在此页面直接插入安装
    Homebrew 的命令，但安装过程可能会有所变化，因此最好从官方网站获取最新的命令。写这篇文章时，页面如下所示：
- en: '![](img/B18425_18_03.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_03.png)'
- en: 'Figure 18.3: The Homebrew website'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.3：Homebrew 网站
- en: In the screenshot, you’ll notice the command with white text on a black highlight.
    It’s cut off a bit, due to the command being wider than this page. You should
    see the entire command on the site, so you can copy it from there and paste it
    into your Mac’s terminal.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在截图中，你会注意到命令以白色文字显示在黑色高亮的背景上。由于命令比这页宽，所以被截断了一些。你应该能在网站上看到完整的命令，可以从那里复制并粘贴到你的
    Mac 终端中。
- en: It’s becoming increasingly popular for application developers to provide a command
    on their website to install their application that you paste directly into your
    terminal. This is very convenient and allows you to set up an app quickly. But
    you should always research and inspect such commands before pasting them into
    your terminal (regardless of your operating system). It’s possible that an outside
    actor could hijack the command on a website to trick you into running something
    nefarious. You can use the `wget` command to download the script their command
    will end up running, so you can check it to ensure it’s not doing something evil.
    Since this method of deploying software is getting more and more common, I recommend
    getting into the habit of checking commands before running them (especially if
    they use `sudo`).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越多的应用开发者在其网站上提供直接复制到终端的命令来安装他们的应用程序。这非常方便，可以快速设置应用程序。但在将此类命令粘贴到终端之前，你应始终进行调查和检查（无论你的操作系统是什么）。有可能外部行为者劫持了网站上的命令，诱使你执行某些恶意操作。你可以使用
    `wget` 命令下载其命令将要运行的脚本，检查其内容，确保它没有做恶意的事。由于这种软件部署方式越来越常见，我建议养成在运行命令之前检查命令的习惯（尤其是当命令使用了
    `sudo` 时）。
- en: 'Once you have Homebrew installed on your Mac, you can proceed to install MicroK8s
    with Homebrew with the following command:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您在 Mac 上安装了 Homebrew，您可以使用以下命令继续通过 Homebrew 安装 MicroK8s：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Once that command finishes, you should have MicroK8s installed on your Mac.
    In the next sub-section, we’ll see the same process in Windows.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦该命令完成，您应该已经在您的 Mac 上安装了 MicroK8s。在下一个小节中，我们将看到 Windows 上相同的过程。
- en: Installing MicroK8s on Windows
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Windows 上安装 MicroK8s
- en: 'If you’d like to try out MicroK8s on a laptop or desktop computer running Windows
    10, there’s a specific installer available that will allow you to get it up and
    running. On the MicroK8s website, at [https://microk8s.io](https://microk8s.io),
    you should see a large green button labeled **Download MicroK8s for Windows**,
    and if you click on it, you’ll be able to download the installer:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在运行 Windows 10 的笔记本电脑或台式电脑上尝试 MicroK8s，可以使用一个专门的安装程序来帮助您安装和运行它。在 MicroK8s
    网站上，您应该会看到一个大大的绿色按钮，上面写着 **下载 MicroK8s for Windows**，点击它后，您就可以下载安装程序：
- en: '![](img/B18425_18_04.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_04.png)'
- en: 'Figure 18.4: The MicroK8s website, with a button to download the installer
    for Windows'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.4：MicroK8s 网站，包含下载 Windows 安装程序的按钮
- en: 'Once the download finishes, you can then launch the installer, which will have
    several different sections, all of which you can accept the defaults for. Click
    **Next** and then the **Install** button to begin the actual installation:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完成后，您可以启动安装程序，它包含多个不同的部分，所有部分都可以选择默认选项。点击 **下一步**，然后点击 **安装** 按钮开始实际安装：
- en: '![](img/B18425_18_05.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_05.png)'
- en: 'Figure 18.5: The MicroK8s installer for Windows'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.5：Windows 上的 MicroK8s 安装程序
- en: 'After the installation begins, another installation will also launch in parallel
    that will ask you to select a hypervisor:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 安装开始后，另一个安装程序也会同时启动，要求您选择一个虚拟化管理程序（hypervisor）：
- en: '![](img/B18425_18_06.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_06.png)'
- en: 'Figure 18.6: The MicroK8s installer for Windows, selecting a hypervisor'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.6：Windows 上的 MicroK8s 安装程序，选择虚拟化管理程序
- en: For this, you can leave the default selection on Microsoft Hyper-V, and click
    **Next**. You can keep the remaining options at their defaults and click **Next**
    through any remaining prompt that comes up. Depending on the setup of your computer,
    it may require you to reboot in order to finalize the required components before
    the installation can be completely finished. If you do see a prompt to reboot,
    do so, and then launch the installer again.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以保持默认选项为 Microsoft Hyper-V，然后点击 **下一步**。您可以保持其余选项为默认，并点击 **下一步**，直到出现任何剩余的提示。根据您的计算机配置，可能需要您重新启动才能完成所需组件的安装，然后才能完成安装过程。如果出现重新启动的提示，请按照提示操作，然后再次启动安装程序。
- en: 'You’ll see the following window appear, asking you to set up the parameters
    for MicroK8s, specifically how many virtual CPUs to utilize, how much RAM to provide,
    disk space, and so on:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下窗口，要求您设置 MicroK8s 的参数，具体包括使用多少虚拟 CPU、提供多少内存、磁盘空间等：
- en: '![](img/B18425_18_07.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_07.png)'
- en: 'Figure 18.7: The MicroK8s installer for Windows, allocating resources'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.7：Windows 上的 MicroK8s 安装程序，分配资源
- en: You can simply choose the defaults for this screen as well and click **Next**.
    Once the process is complete, you can click the **Finish** button to exit the
    installer.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以选择该页面的默认选项并点击 **下一步**。完成该过程后，点击 **完成** 按钮退出安装程序。
- en: Interacting with MicroK8s
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与 MicroK8s 进行交互
- en: At this point, if you’ve decided to utilize MicroK8s, you should have it installed
    on your computer. How you actually interact with it depends on your operating
    system. In each case, the `microk8s` command (which we’ll cover shortly) is used
    to control MicroK8s. Which app you use in order to enter `microk8s` commands differs
    from one platform to another.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，如果您决定使用 MicroK8s，您应该已经在您的计算机上安装了它。如何与它进行交互取决于您的操作系统。在每种情况下，`microk8s` 命令（我们稍后会介绍）用于控制
    MicroK8s。不同平台上用于输入 `microk8s` 命令的应用程序是不同的。
- en: 'On Windows, you can use the Command Prompt app, which is built into the operating
    system. The `microk8s` command is recognized and available for use after you install
    MicroK8s. When you enter the `microk8s` command by itself, it should display basic
    usage information:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，您可以使用操作系统内置的命令提示符应用程序。安装 MicroK8s 后，`microk8s` 命令可以被识别并使用。当您单独输入
    `microk8s` 命令时，它应该会显示基本的使用信息：
- en: '![](img/B18425_18_08.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_08.png)'
- en: 'Figure 18.8: Executing the microk8s command with no options in a Windows Command
    Prompt'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.8：在 Windows 命令提示符中执行没有选项的 microk8s 命令
- en: 'With macOS, you can use the built-in terminal app that’s provided with the
    operating system. You may have another step to complete though before you can
    actually use MicroK8s. If you enter the `microk8s` command, and you receive an
    error informing you that `support for multipass needs to be set-up`, then you
    can run the following command to fix it:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 macOS，你可以使用操作系统自带的终端应用程序。不过，在你实际使用 MicroK8s 之前，可能需要完成另一个步骤。如果你输入 `microk8s`
    命令并收到错误提示，说明 `multipass 支持需要设置`，你可以运行以下命令来修复它：
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you’re curious, **Multipass** is a technology that’s also created by Canonical
    that allows you to quickly set up an Ubuntu instance for testing. It’s not specific
    to MicroK8s or even Kubernetes, but in our case it’s used in the background to
    facilitate MicroK8s. Multipass is not covered in this book, but it’s worth taking
    a look at if you think you’ll benefit from the ability to quickly set up Ubuntu
    instances to test applications and configurations on. It’s available for all of
    the leading operating systems.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣，**Multipass** 是 Canonical 也创建的一项技术，它允许你快速设置一个 Ubuntu 实例进行测试。它并不特定于 MicroK8s
    或 Kubernetes，但在我们的案例中，它在后台用于促进 MicroK8s 的运行。Multipass 在本书中没有详细讲解，但如果你认为能从快速设置
    Ubuntu 实例以测试应用程序和配置中获益，值得了解一下。它适用于所有主流操作系统。
- en: When it comes to Linux, if you’ve already gone through the process of setting
    up MicroK8s, you should be ready to use it immediately. Open up your distribution’s
    terminal app and try the `microk8s` command to see if it’s recognized. If it is,
    you’re ready to move on.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Linux，如果你已经完成了设置 MicroK8s 的过程，你应该能够立即开始使用它。打开你发行版的终端应用程序，尝试输入 `microk8s`
    命令，看是否能被识别。如果可以，你就可以继续进行下一步了。
- en: To check the status of MicroK8s, the following command can be used to give you
    an overview of the various components. Before you run it, note the inclusion of
    `sudo` at the beginning. By default, this is required if your underlying operating
    system is Linux.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查 MicroK8s 的状态，可以使用以下命令来概览各个组件。在运行之前，请注意命令开头的 `sudo`。默认情况下，如果你的操作系统是 Linux，则需要使用
    `sudo`。
- en: 'If you’re running Windows 11 or macOS, you shouldn’t need `sudo`. This difference
    has to do with how the underlying operating system handles permissions, which
    is different from operating system to operating system. So, if you’re not using
    Linux on your PC, feel free to omit `sudo` from `microk8s` commands:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是 Windows 11 或 macOS，则不需要 `sudo`。这个差异与底层操作系统如何处理权限有关，不同操作系统的处理方式不同。因此，如果你不是在
    PC 上使用 Linux，完全可以省略 `microk8s` 命令中的 `sudo`：
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Don’t worry about the details regarding the individual components of Kubernetes
    at the moment, we’ll cover what you need to know as we go through the rest of
    the chapter. For now, so long as you don’t see errors when you run the previous
    command and check the status, you should be in good shape to continue.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 暂时不用担心 Kubernetes 中各个组件的细节，我们将在本章的后续部分介绍你需要了解的内容。目前，只要你在运行前面的命令并检查状态时没有出现错误，你就可以继续进行操作。
- en: 'By default, our MicroK8s installation comes with only the addons that are required
    for it to run. There are other addons we can enable, such as `storage`, which
    gives us the ability to expose a path on the host (the underlying operating system)
    to Kubernetes; `gpu`, which allows us to utilize NVIDIA GPUs within the containers;
    and others. We don’t need to worry about these for now, but we should at least
    enable the `dns` addon, which sets up DNS within our cluster. It’s not necessarily
    required, but not having it can create issues down the road when it comes to name
    resolution, so we may as well enable it now:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，我们的 MicroK8s 安装仅包括运行所需的插件。我们可以启用其他插件，例如 `storage`，它使我们能够将主机（底层操作系统）上的路径暴露给
    Kubernetes；`gpu`，它允许我们在容器中使用 NVIDIA GPU；还有其他插件。目前我们不需要担心这些插件，但至少应该启用 `dns` 插件，它会在我们的集群中设置
    DNS。它不是必需的，但如果没有它，在后续进行名称解析时可能会出现问题，因此我们现在最好启用它：
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should see output similar to the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到类似以下的输出：
- en: '![](img/B18425_18_09.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_09.png)'
- en: 'Figure 18.9: Enabling the DNS addon in MicroK8s on a Linux installation'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.9：在 Linux 安装中启用 MicroK8s 的 DNS 插件
- en: In my tests, I find that the command to enable the addon seems to stop responding
    for a while, with no output. Don’t close the window; it should catch up and then
    display information about the process of installing the addon eventually. If this
    happens, just wait it out a bit.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的测试中，我发现启用插件的命令似乎会暂停一段时间，且没有输出。不要关闭窗口；它应该会继续执行，并最终显示有关安装插件过程的信息。如果发生这种情况，只需稍等片刻。
- en: With the previous command, we’ve enabled the `dns` addon. As I’ve mentioned,
    there are other addons available, but that’s enough for now. At this point, just
    keep in mind that you can extend MicroK8s with addons, so it may be worth exploring
    in more detail later on if you wish. A list of addons is included in a link at
    the end of this chapter.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面的命令，我们已经启用了`dns`插件。正如我提到的，还有其他插件可用，但现在这些就足够了。在这一点上，请记住，你可以通过插件扩展MicroK8s，如果你愿意，可以在稍后深入探索。插件的列表会在本章末尾的链接中提供。
- en: 'As mentioned earlier, if you’re using Linux to run MicroK8s, then you would’ve
    used `sudo` with the `microk8s` command we used earlier. If you’d like to remove
    the requirement of using `sudo` on Linux, you can do so by adding your user to
    the `microk8s` group. That can be done with the following command:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，如果你正在使用Linux运行MicroK8s，那么你在之前使用的`microk8s`命令时需要使用`sudo`。如果你希望去掉Linux上使用`sudo`的要求，可以通过将你的用户添加到`microk8s`组来实现。你可以通过以下命令完成此操作：
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: After you log out and then log in again, you should be able to run `microk8s`
    commands without `sudo`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在你注销并重新登录后，你应该能够运行`microk8s`命令而无需使用`sudo`。
- en: As we’ll discover as we proceed through the rest of the chapter, the `kubectl`
    command is generally used to interact with a Kubernetes cluster and manage it.
    `kubectl`, short for **Kube Control**, is the standard utility you use to perform
    many tasks against your cluster. We’ll explore this more later on. But specific
    to MicroK8s, it’s important to understand that it uses its own version of `kubectl`
    that’s specific to it. So with MicroK8s, you would run `microk8s kubectl` instead
    of simply `kubectl` to interact with the cluster. Having a separate implementation
    of `kubectl` with MicroK8s allows you to target an actual cluster (the `kubectl`
    command by itself) or specifically your installation of MicroK8s (prefix `kubectl`
    commands with `microk8s`), so one won’t conflict with the other. As we work through
    the chapter, I’ll call out `kubectl` by itself when we get to the actual examples,
    so it will be up to you to remember to use `microk8s` in front of such commands
    as needed.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在接下来的章节中会发现的，`kubectl`命令通常用于与Kubernetes集群交互并管理它。`kubectl`，即**Kube Control**的缩写，是你用来执行许多集群任务的标准工具。我们稍后会进一步探讨它。但具体到MicroK8s，重要的是要理解它使用的是自己特定版本的`kubectl`。因此，在MicroK8s中，你需要运行`microk8s
    kubectl`而不是单纯的`kubectl`来与集群交互。MicroK8s有一个单独的`kubectl`实现，这让你可以针对实际的集群（直接使用`kubectl`命令）或专门针对你的MicroK8s安装（将`kubectl`命令前缀加上`microk8s`）进行操作，从而避免它们之间的冲突。在本章的实际示例中，我会单独提到`kubectl`，所以你需要记得在相应的命令前加上`microk8s`。
- en: Now that we have our very own installation of MicroK8s on our laptop or desktop,
    we can proceed through the examples in this book. You can skip ahead to the *Deploying
    containers via Kubernetes* section later in this chapter to begin working with
    Kubernetes. In the next section though, we’ll take a look at setting up a Kubernetes
    cluster manually without MicroK8s, which is closer to the actual process you’d
    use in an actual production implementation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在自己的笔记本电脑或台式机上安装了MicroK8s，我们可以继续本书中的示例。你可以跳到本章稍后的*通过Kubernetes部署容器*部分开始使用Kubernetes。不过，在下一节中，我们将看看如何手动设置Kubernetes集群，而不使用MicroK8s，这更接近实际生产环境中的操作流程。
- en: Setting up a Kubernetes cluster
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Kubernetes集群
- en: In the previous section, we set up MicroK8s, which provides us with a Kubernetes
    cluster on a single machine, which is great for testing purposes. That might even
    be all you need in order to learn Kubernetes and see how it works. If you can,
    I still recommend setting up a cluster manually, which will give you even more
    insight into how the individual components work together. That’s exactly what
    we’re going to do in this section.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们设置了MicroK8s，它为我们提供了一个在单台机器上运行的Kubernetes集群，这对于测试目的非常有用。这可能就是你学习Kubernetes并了解它如何工作的全部所需。如果可以的话，我仍然建议你手动设置一个集群，这样你能更深入地了解各个组件如何协同工作。这正是我们在本节中要做的事情。
- en: Before we do get started, it’s important to synchronize our mindset a bit. Of
    all of the activities we’ve worked through so far, setting up a Kubernetes cluster
    manually is easily the most complex. Kubernetes itself is made up of many components,
    as well as settings. If any one component is incorrect or a setting is misconfigured,
    the entire process can fail. In this section, a great deal of care and attention
    was spent to ensure (as much as possible) that the process works to the point
    where it’s completely reproducible and has been broken down to only the required
    components to simplify everything. However, if the process doesn’t work out well
    when you go to try it, don’t worry - it’s perfectly fine if we encounter an issue.
    We’re still learning, and fixing things is the best way to learn. So the bottom
    line is to have fun, and be patient.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，调整一下我们的思维状态是很重要的。在我们到目前为止的所有活动中，手动设置 Kubernetes 集群是最复杂的。Kubernetes 本身由许多组件和设置组成。如果任何一个组件不正确或设置错误，整个过程可能会失败。在这一节中，我们花了大量精力和注意力来确保（尽可能）该过程能够顺利进行，已经将其分解为只需的组件以简化一切。但是，如果在尝试时遇到问题，过程不顺利，不要担心——如果我们遇到问题，修复问题正是学习的最佳方式。所以最重要的是享受过程，保持耐心。
- en: What does a typical Kubernetes cluster look like? When it comes to a production
    installation in an actual data center, having Kubernetes installed on multiple
    servers is commonplace. Typically, one of them will act as the controller node,
    and then you can add as many worker nodes as you need.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的 Kubernetes 集群是什么样子？在实际的数据中心生产安装中，将 Kubernetes 安装在多台服务器上是司空见惯的。通常，其中一台将作为控制节点，然后你可以根据需要添加任意多的工作节点。
- en: As your needs expand, you can add additional servers to provide more worker
    nodes to your cluster. Setting up a controller Kubernetes node and then individual
    workers is a great way to see the actual relationship in action. And that’s exactly
    what we’re going to do in this section.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你的需求扩展，你可以添加更多的服务器来提供更多的工作节点给你的集群。设置一个控制器 Kubernetes 节点，然后单独设置工作节点是一个很好的方式来看到实际关系的运作。而这正是我们将在本节中做的事情。
- en: As I walk you through the process, I’m going to do so utilizing three VMs. The
    first will be the controller, and the remaining two will be workers. On your end,
    it doesn’t really matter how many workers you decide to go with. You can have
    a single worker, or a dozen—however many you’d like to set up is fine. If you
    do set up more nodes than I do, then you would simply repeat the commands in this
    section for the additional nodes. For the nodes on your end, feel free to use
    whatever combination of physical or VMs makes sense and fits within the resources
    of the equipment you have available.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当我指导你完成这个过程时，我会利用三个虚拟机来做这件事。第一个将是控制器，剩下的两个将是工作节点。在你那边，你决定使用多少个工作节点并不重要。你可以只有一个工作节点，也可以有十几个——你想设置多少个都可以。如果你设置的节点比我多，那么你只需为额外的节点重复本节中的命令即可。关于你那边的节点，可以随意使用物理机或虚拟机的任何组合，只要符合你可用设备的资源。
- en: Before we get started, you’ll want to have already installed Ubuntu Server on
    each machine and install all of the updates. It’s also a good idea for you to
    create a user for yourself if you haven’t already done so. The remainder of this
    section will assume you’ve already set up Ubuntu on each. After you’ve installed
    Ubuntu on everything, it’s a good idea to also configure the hostnames on each
    node as well to make it easier to tell them apart. For example, on the node that
    I’m intending to use as the controller, I’m going to set the hostname as `controller`.
    For the workers, I’ll name them `node-01` and `node-02` respectively. You can
    name yours in whatever theme makes sense, but the reason I specifically mention
    it is to make sure that you name them something, as by default they’ll each show
    the same hostname in the command prompt, and that may be confusing.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，你需要确保每台机器上都已经安装了 Ubuntu Server 并且安装了所有更新。如果你还没有为自己创建用户，现在也是个好时机。接下来的部分将假设你已经在每台机器上安装了
    Ubuntu。在你安装完 Ubuntu 后，还是将每个节点的主机名配置好会更方便区分它们。例如，我打算将作为控制器使用的节点命名为 `controller`。对于工作节点，我将分别命名为
    `node-01` 和 `node-02`。你可以根据自己的需求命名，但我特别提到这一点是为了确保你给它们起个名字，因为默认情况下它们在命令提示符中显示的主机名都一样，这可能会让人感到困惑。
- en: Now that you have everything you need, let’s set up Kubernetes!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经准备好了所有所需的东西，让我们来设置 Kubernetes 吧！
- en: Preliminary setup
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初步设置
- en: In this section, we’re going to complete some miscellaneous setup tasks before
    we actually start building our cluster. These are basically the prerequisites
    for our cluster to function.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将在实际开始构建集群之前完成一些杂项设置任务。这些基本上是集群正常运行的前置条件。
- en: We should first ensure that each of the servers we intend on using for the cluster
    has either a static lease, or a static IP that will not change. You can change
    your server’s IP address at any time, but with Kubernetes, there’s some additional
    steps involved if you do change the IP later. For this reason, I suggest setting
    your static lease or static IP right now, *before* we build the cluster. That
    way, you won’t have to worry about that later. The process was covered in *Chapter
    11*, *Setting Up Network Services*, so I won’t repeat that here. On your side,
    be sure to set up a static lease or static IP, and then continue further with
    our setup here.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要确保每台计划用于集群的服务器都有一个静态租约或静态 IP 地址，并且该地址不会发生变化。你可以随时更改服务器的 IP 地址，但在使用 Kubernetes
    时，如果你之后更改了 IP 地址，还需要执行一些额外的步骤。因此，我建议在我们构建集群之前，*先*设置静态租约或静态 IP 地址。这样，你以后就不需要担心这个问题了。这个过程在*第
    11 章*《设置网络服务》中有介绍，我在这里就不再重复了。请确保在你这一侧设置好静态租约或静态 IP 地址，然后继续我们的设置步骤。
- en: Next, if the devices you’ve selected for this exercise includes servers that
    are being built using the Raspberry Pi, then there are some special requirements
    that are specific to the Pi. If you are using one or more Raspberry Pi units,
    be sure to complete this step (otherwise, skip this if you’re NOT using the Raspberry
    Pi).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，如果你选择的设备中包括使用 Raspberry Pi 构建的服务器，那么有一些特定于 Pi 的特殊要求。如果你使用一个或多个 Raspberry
    Pi，请确保完成此步骤（如果你没有使用 Raspberry Pi，请跳过此步骤）。
- en: 'To set boot parameters specific to the Raspberry Pi, open up the following
    file in your editor of choice:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置 Raspberry Pi 特定的启动参数，请在你选择的编辑器中打开以下文件：
- en: '[PRE8]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'What you’re about to do in this file, is add some cgroup options to control
    how Kubernetes is able to interact with the hardware of your device. You’ll want
    to add the following options to the existing line within the file. Don’t create
    a new line. Instead, add these options to the very end of the first (and only)
    line within that file:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这个文件中将要做的，是添加一些 cgroup 选项来控制 Kubernetes 如何与设备的硬件交互。你需要将以下选项添加到文件中现有行的末尾。不要创建新行，而是将这些选项添加到该文件中第一行（且唯一一行）的末尾：
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Save and exit the file, and that should be the only change we’ll be making that’s
    specific to the Raspberry Pi.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 保存并退出文件，这应该是我们针对 Raspberry Pi 所做的唯一特定更改。
- en: In order to build a Kubernetes cluster, we’ll need to set up something called
    a **Container Runtime**. A Container Runtime is the means by which Kubernetes
    will run containers within the cluster. Without a runtime, there’s no ability
    for Kubernetes to run even a single container. While Kubernetes is a container
    orchestration solution, it doesn’t mandate which container runtime you use. The
    suggested runtime known as **containerd**, so that’s what we’ll use in our cluster.
    Other container runtimes include (but aren’t limited to) Docker, CRI-O, and there’s
    others. We’ve already worked with Docker in this book, but for our cluster, we’re
    going to deploy it with the suggested containerd runtime.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建 Kubernetes 集群，我们需要设置一个叫做 **容器运行时** 的东西。容器运行时是 Kubernetes 在集群内运行容器的方式。如果没有运行时，Kubernetes
    甚至无法运行一个容器。虽然 Kubernetes 是一个容器编排解决方案，但它并不强制要求你使用哪种容器运行时。推荐的运行时是 **containerd**，所以我们将在我们的集群中使用它。其他容器运行时包括（但不限于）Docker、CRI-O
    等。我们在本书中已经使用过 Docker，但对于我们的集群，我们将使用推荐的 containerd 运行时。
- en: When it comes to the containers we can run, there’s no difference - containerd
    for example can run Docker containers just like we’ve been doing. So even though
    we’re going to go with a different container runtime, it shouldn’t really make
    a difference at all when it comes to the end result.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 至于我们可以运行的容器，实际上没有区别——例如 containerd 可以像我们之前做的那样运行 Docker 容器。因此，尽管我们将选择不同的容器运行时，但最终结果应该不会有任何区别。
- en: In this section, the commands that I’m going to have you run should be executed
    on each of the instances you plan on using with Kubernetes, regardless of whether
    or not you’re working with the intended controller or a node; these commands need
    to be run on each. There will be commands specific to the controller and the nodes
    later on, but I’ll mention the intended target if it’s something I’d like you
    to do on specifically one or the other.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我将让你运行的命令应该在你计划与Kubernetes一起使用的每个实例上执行，无论你是在操作目标控制器还是节点；这些命令需要在每个实例上运行。后续会有针对控制器和节点的特定命令，但如果我希望你只对其中一个执行，我会提到目标。
- en: 'The first thing we’re going to do is install the `containerd` package:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的第一件事是安装`containerd`包：
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After the package is installed, we’ll check the status of it and ensure that
    it’s running:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 包安装完毕后，我们将检查它的状态，确保它正在运行：
- en: '[PRE11]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We should see that the unit is running:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该会看到单元正在运行：
- en: '![](img/B18425_18_10.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_10.png)'
- en: 'Figure 18.10: Checking the status of the containerd runtime'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.10：检查 containerd 运行时的状态
- en: 'We’re not quite done with `containerd`, though. It’s going to need some default
    configuration in order to function properly, but by default, there’s no sample
    config provided automatically. Let’s create that config, starting with adding
    a directory to our server to house the configuration file:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，我们还没完全完成`containerd`的配置。它需要一些默认配置才能正常工作，但默认情况下并不会自动提供示例配置。让我们从为服务器添加一个目录来存放配置文件开始，创建这个配置文件：
- en: '[PRE12]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, we’ll create the config file for `containerd` with the following command:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用以下命令为`containerd`创建配置文件：
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: That command will not only create the default configuration file for `containerd`,
    it also prints the configuration information to the screen as well so we can see
    what the default values are. However, while most of the default settings are fine,
    we’ll need to make some adjustments to this file. Open up the `/etc/containerd/config.toml`
    file in your editor of choice.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 那个命令不仅会为`containerd`创建默认配置文件，还会将配置内容打印到屏幕上，以便我们查看默认值是什么。然而，尽管大部分默认设置都可以使用，我们还是需要对这个文件做一些调整。打开你喜欢的编辑器，并编辑`/etc/containerd/config.toml`文件。
- en: 'The first change to make to this file, is to set the cgroup driver to `systemd`.
    To do so, look for the following line:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 对这个文件的第一个更改是将cgroup驱动程序设置为`systemd`。为此，查找以下行：
- en: '[PRE14]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Several lines below that, you’ll see the following line:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在几行之后，你会看到以下这一行：
- en: '[PRE15]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Change that line to `true` instead:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 将该行更改为`true`：
- en: '[PRE16]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: At this point, we’re done with `containerd` for now. Let’s move on and configure
    some important system tweaks. The first of these is disabling swap. Although it’s
    usually not a good idea to run a server without swap, setting up a Kubernetes
    cluster is the exception to this. In fact, when we go to initialize the cluster
    later, the process will actually abort if swap is enabled. So let’s take care
    of disabling it now.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们暂时完成了`containerd`的配置。接下来，让我们继续配置一些重要的系统调整。第一个调整就是禁用交换分区。虽然通常不建议在没有交换分区的情况下运行服务器，但设置Kubernetes集群是一个例外。事实上，当我们稍后初始化集群时，如果交换分区已启用，过程会中止。所以现在我们就来禁用它。
- en: 'First, we’ll run the following command to disable swap:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将运行以下命令来禁用交换分区：
- en: '[PRE17]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After doing this, if we run `free -m` we should see all zero’s for swap:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 做完这些之后，如果我们运行`free -m`，我们应该会看到交换分区的值全为零：
- en: '![](img/B18425_18_11.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_11.png)'
- en: 'Figure 18.11: Running the free -m command to check that swap is disabled'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.11：运行 free -m 命令检查交换分区是否已禁用
- en: However, the command that we’ve just run to disable swap was not a permanent
    change. When we reboot our server, swap will be automatically re-enabled. In order
    to disable swap for good, we’ll need to edit the `/etc/fstab` file and comment
    out the line that activates swap during boot.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们刚刚运行的禁用交换分区的命令并不是永久性的更改。当我们重启服务器时，交换分区会自动重新启用。为了彻底禁用交换分区，我们需要编辑`/etc/fstab`文件，并注释掉启用交换分区的那一行。
- en: 'The following screenshot shows an example configuration line for swap, but
    it’s been commented out by inserting the `#` character at the beginning of that
    line:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了交换分区的一个示例配置行，但它通过在该行前添加`#`字符被注释掉了：
- en: '![](img/B18425_18_12.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_12.png)'
- en: 'Figure 18.12: The /etc/fstab file, with the swap line commented out'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.12：`/etc/fstab`文件，交换分区行已被注释掉
- en: At this point, swap should be turned off, and considering we’ve commented out
    the swap line in the `/etc/fstab` file, swap won’t be re-enabled the next time
    we start our server.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，swap应该已关闭，考虑到我们已在`/etc/fstab`文件中注释掉了swap行，下一次启动服务器时swap将不会重新启用。
- en: 'Next, we’ll need to make a change to the `/etc/sysctl.conf` file to enable
    bridging. This is similar to what we worked through as we set up an internet gateway
    back in *Chapter 11*, *Setting Up Network Services*. Once we’ve opened up the
    `/etc/sysctl.conf` file in an editor, we’ll need to uncomment the following line:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要对`/etc/sysctl.conf`文件进行更改以启用桥接。这类似于我们在*第11章*，*设置网络服务*中配置互联网网关时所做的工作。一旦我们在编辑器中打开`/etc/sysctl.conf`文件，我们需要取消注释以下行：
- en: '[PRE18]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'It should now look like this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 它现在应该是这样的：
- en: '[PRE19]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: With that line uncommented, bridging should be enabled the next time we start
    our server.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在取消注释该行后，下一次启动服务器时应该启用桥接。
- en: 'Next, we’ll create the following file, which we’ll use to ensure a required
    kernel module is loaded when the server starts:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建以下文件，用于确保在服务器启动时加载必需的内核模块：
- en: '[PRE20]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Inside that file, we’ll add the following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在该文件内，我们将添加以下内容：
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: That’s actually it for that file, so save and exit the editor. The `br_netfilter`
    module assists with networking for our eventual Kubernetes cluster, and will need
    to be enabled in order for the cluster to function. By creating the `/etc/modules-load.d/k8s.conf`
    file, we’re ensuring this kernel module is loaded automatically when we start
    our server.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上就是这个文件的全部内容，所以保存并退出编辑器。`br_netfilter`模块有助于为我们最终的Kubernetes集群提供网络支持，并且需要启用才能使集群正常运行。通过创建`/etc/modules-load.d/k8s.conf`文件，我们确保在启动服务器时此内核模块会自动加载。
- en: 'Before we continue, further, let’s take a moment and ensure we’ve done everything
    we need to do up to now. At this point, on each of the servers you intend to use
    with Kubernetes (the controller as well as the nodes) you should’ve accomplished
    the following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，先花点时间确保到目前为止我们已完成所有需要做的事情。此时，在每台你打算与Kubernetes一起使用的服务器上（包括控制器和节点），你应该已经完成了以下工作：
- en: Installed all updates
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了所有更新
- en: Set a hostname
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置了主机名
- en: Set up a static IP or lease on each node
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个节点上设置静态IP或租约
- en: Set Raspberry Pi-specific boot options (if you’re using a Raspberry Pi)
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置特定于Raspberry Pi的启动选项（如果你使用的是Raspberry Pi）
- en: Installed `containerd`
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了`containerd`
- en: Created the `/etc/containerd/config.toml` file for `containerd` and also set
    the cgroup driver
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了`/etc/containerd/config.toml`文件用于`containerd`，并设置了cgroup驱动程序
- en: Disabled swap
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用了swap
- en: Added the `/etc/modules-load.d/k8s.conf` file with the `br_netfilter` module
    listed inside
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加了`/etc/modules-load.d/k8s.conf`文件，文件内列出了`br_netfilter`模块
- en: Edited the `/etc/sysctl.conf` file to enable bridging
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编辑了`/etc/sysctl.conf`文件以启用桥接
- en: 'All of the above should’ve been completed on every server you plan to use with
    your cluster. Once you’re sure that you’ve performed each of those tasks, we should
    reboot each of our nodes:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 上述所有内容应该在你计划用于集群的每台服务器上完成。一旦确认已经完成这些任务，我们应该重启每个节点：
- en: '[PRE22]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Once your nodes finish starting back up, we can proceed to actually install
    Kubernetes.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦节点完成重启，我们就可以继续安装Kubernetes了。
- en: Installing Kubernetes
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装Kubernetes
- en: 'Now it’s finally time to start building our cluster, and we’ll start by installing
    the required packages. To do so, we’ll need to add the appropriate repository
    so we can have access to the required packages for installing Kubernetes. To add
    the repository, we’ll first add the key for the repository so our server will
    accept it as a trusted resource:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在终于到了开始构建集群的时候，我们将首先安装所需的软件包。为此，我们需要添加适当的仓库，以便能够访问安装Kubernetes所需的软件包。要添加仓库，我们将首先添加仓库的密钥，以便我们的服务器将其视为受信资源：
- en: '[PRE23]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To add the actual repository itself, we will run the following command:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加实际的仓库，我们将运行以下命令：
- en: '[PRE24]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After adding the repository, we’ll update our local index:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 添加仓库后，我们将更新本地索引：
- en: '[PRE25]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: What you may notice is that the repository URL references `xenial` instead of
    the actual codename for Ubuntu 22.04, which is `jammy` (short for Jammy Jellyfish).
    At the time of writing, there is no dedicated Kubernetes repository for Ubuntu
    22.04 yet, but the process will still work just fine. It’s possible that by the
    time you’re reading this, there will be a dedicated repository for 22.04\. But
    for now, we can use the line mentioned above for our repository file.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，仓库的URL引用的是`xenial`，而不是Ubuntu 22.04的实际代号`jammy`（简写为Jammy Jellyfish）。在写这篇文章时，还没有专门为Ubuntu
    22.04提供的Kubernetes仓库，但这个过程依然可以顺利进行。可能在你读这篇文章时，已经会有专门为22.04提供的仓库了。但目前，我们可以在我们的仓库文件中使用上面提到的这一行。
- en: 'Next, we can install the packages required for Kubernetes:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以安装Kubernetes所需的包：
- en: '[PRE26]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We’re installing three packages, `kubeadm`, `kubectl`, and `kubelet`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在安装三个包，`kubeadm`、`kubectl`和`kubelet`：
- en: '**kubeadm**: The `kubeadm` package gives us tools we can use to “bootstrap”
    our cluster. We can use this tool to initialize a new cluster, join a node to
    an existing clusterand upgrade the cluster to a newer version.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kubeadm**：`kubeadm`包为我们提供了可以用来“引导”集群的工具。我们可以使用这个工具初始化一个新的集群，加入一个节点到现有的集群中，或者将集群升级到更新的版本。'
- en: '**kubectl**: This package provides us with the Kubernetes command-line tool,
    `kubectl`. We will use this tool to interact with our cluster and manage it.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kubectl**：这个包为我们提供了Kubernetes命令行工具`kubectl`。我们将使用这个工具与我们的集群进行交互和管理。'
- en: '**kubelet**: The Kubernetes `kubelet` acts as an agent that facilitates communication
    between nodes. It also exposes API endpoints that can be used to enable additional
    communication and features.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kubelet**：Kubernetes的`kubelet`作为一个代理，促进节点之间的通信。它还公开了可以用于启用额外通信和功能的API端点。'
- en: 'Unlike all of the previous commands we’ve run through so far while setting
    up our cluster, the following will be entered and ran only on the node that you’ve
    designated as the controller (before you run it, read the paragraph that follows
    to know how to customize the command):'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前我们在设置集群时执行的所有命令不同，以下命令将仅在你指定的控制节点上输入和运行（在运行之前，请阅读接下来的段落，了解如何自定义该命令）：
- en: '[PRE27]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The previous `kubeadm init` command should be customized a bit, before you run
    it. There’s a few things you should change to ensure they match your environment.
    In fact, I bolded the individual settings you should customize. I’ll also describe
    some additional details about those particular settings now.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的`kubeadm init`命令需要在执行之前稍作自定义。有几个地方需要你更改，以确保它们与你的环境匹配。实际上，我已经将你应该自定义的设置加粗了。我现在也将描述这些特定设置的更多细节。
- en: '`--control-plane-endpoint=172.16.250.216`: For this option, the IP address
    that is mentioned here should be the same IP address that’s assigned to your server.
    I filled in the value I used for my test server, but you should make sure this
    matches the actual IP on your side. Since this is a very specific setting, this
    is one of the reasons why I recommended you finalize your IP address for your
    nodes *before* you set them up in the cluster.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`--control-plane-endpoint=172.16.250.216`：对于这个选项，这里提到的IP地址应该与你的服务器分配的IP地址相同。我填入的是我测试服务器使用的值，但你应该确保这个值与你实际的IP地址匹配。由于这是一个非常具体的设置，这也是我建议你在将节点加入集群之前*先*确定好节点的IP地址的原因之一。'
- en: '`--node-name controller`: When I set up my test server, I simplified its hostname
    down to simply `controller`. On your side, you can set this to match your controller’s
    hostname as well.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`--node-name controller`：在设置我的测试服务器时，我将其主机名简化为`controller`。在你的环境中，你可以将其设置为与你的控制节点主机名匹配。'
- en: Note that I didn’t bold the second IP address in the command, `10.244.0.0/16`.
    The reason for this, is that you should not change that particular IP declaration.
    That’s actually the IP scheme for the **Pod Network**, which is an internal network
    to Kubernetes and is not accessible from the outside. You can actually customize
    this to your own scheme, but then you’d have to change other settings as well.
    Since this is a dedicated internal network, there shouldn’t be any need to change
    this so I recommend to leave it as-is.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我没有加粗命令中的第二个IP地址`10.244.0.0/16`。这样做的原因是，你不应更改这个特定的IP声明。它实际上是**Pod网络**的IP方案，这是Kubernetes的内部网络，外部无法访问。你当然可以将其自定义为自己的网络方案，但那样的话你还需要更改其他设置。由于这是一个专用的内部网络，通常不需要更改它，因此我建议保持原样。
- en: 'The `kubeadm init` command that I mentioned earlier, after you customize it,
    will initialize the cluster and assign it a Pod Network. If the initialization
    process is successful, you’ll see a `join` command printed to the terminal at
    the end. If you do see it, then congratulations! You’ve successfully set up a
    Kubernetes cluster. It’s not a very usable cluster yet, because we haven’t added
    any worker nodes to it at this point. But you do, by definition, have a Kubernetes
    cluster in existence at this point. On my controller node, I see the following
    output:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前提到的`kubeadm init`命令，在你自定义之后，将初始化集群并为其分配一个Pod网络。如果初始化过程成功，你会在终端的最后看到一个`join`命令。如果你看到了它，那么恭喜你！你已经成功搭建了一个Kubernetes集群。虽然它现在还不是一个非常可用的集群，因为此时我们还没有添加任何工作节点。但从定义上来说，现在你已经拥有了一个Kubernetes集群。在我的控制节点上，我看到以下输出：
- en: '![](img/B18425_18_13.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_13.png)'
- en: 'Figure 18.13: Successful initialization of a Kubernetes cluster, showing a
    join command'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.13：Kubernetes集群成功初始化，显示一个join命令
- en: The `join` command that’s shown to you after the process is complete is very
    special—you can copy that command and paste it into the command prompt of a worker
    node to join it to the cluster, but don’t do that just yet. For now, copy that
    command and store it somewhere safe. You don’t want to allow others to see it,
    because it contains a hash value that’s specific to your cluster and allows someone
    to join nodes to it. Technically, showing my `join` command with the hash value
    is the last thing I should do in a book that will be seen and read by many people,
    but since this is just a test cluster with no actual value, I don’t mind you seeing
    it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 过程完成后显示给你的`join`命令是非常特别的——你可以将这个命令复制并粘贴到工作节点的命令提示符中，以将其加入集群，但现在先不要这么做。此时，请复制这个命令并将其保存在一个安全的地方。你不希望其他人看到它，因为它包含一个特定于你集群的哈希值，允许他人将节点加入到该集群。技术上讲，显示我的`join`命令及哈希值是我在一本会被许多人看到和阅读的书中做的最后一件事，但由于这只是一个没有实际价值的测试集群，我不介意你看到它。
- en: 'Also, in the same output as the `join` command, are three additional commands
    we should run on the controller node. If you scroll up in your terminal window
    to before the `join` command, you should see output similar to the following:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在`join`命令的同一输出中，还有三个额外的命令，我们应该在控制节点上运行。如果你滚动终端窗口，回到`join`命令之前的位置，你应该看到类似以下的输出：
- en: '![](img/B18425_18_14.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_14.png)'
- en: 'Figure 18.14: Output of the initialization process for Kubernetes showing additional
    commands to run'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.14：Kubernetes初始化过程的输出，显示要运行的附加命令
- en: For those three commands, you can copy and paste them as-is right back into
    the terminal, one by one. Go ahead and do that. Essentially what you’re doing
    is creating a local config directory for `kubectl` right in your user’s home directory.
    Then, you’re copying the `admin.conf` file from `/etc/kubernetes` and storing
    it in the newly created `.kube` folder in your home directory with a new name
    of `config`. Finally, you’re changing ownership of the `.kube` directory to be
    owned by your user. This will allow your user account to manage Kubernetes with
    the `kubectl` command, without needing to be logged in as `root` or use `sudo`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这三个命令，你可以直接将它们逐个复制并粘贴回终端。请继续操作。实际上，你所做的事情是为`kubectl`创建一个本地配置目录，放在你的用户主目录下。然后，你会从`/etc/kubernetes`复制`admin.conf`文件，并将其存储在你主目录中新创建的`.kube`文件夹中，文件名改为`config`。最后，你会将`.kube`目录的所有权更改为你的用户账户所有。这将允许你的用户账户通过`kubectl`命令管理Kubernetes，而无需以`root`身份登录或使用`sudo`。
- en: 'Kubernetes itself consists of multiple **Pods**, within which your containers
    will run. We haven’t deployed any containers yet, we’ll do that later. But even
    though we didn’t deploy any containers ourselves, there are some that are actually
    running already. See for yourself:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes本身由多个**Pods**组成，你的容器将在其中运行。我们还没有部署任何容器，我们稍后会进行。但即便我们自己没有部署任何容器，实际上已经有一些容器在运行。你可以亲自验证一下：
- en: '[PRE28]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'On my end, I see the following:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的端，我看到以下内容：
- en: '![](img/B18425_18_15.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_15.png)'
- en: 'Figure 18.15: Checking the status of pods running in our Kubernetes cluster'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.15：检查我们Kubernetes集群中正在运行的Pods状态
- en: Notice that the namespace for each of these Pods is `kube-system`. This is a
    special namespace, where Pods related to the Kubernetes cluster itself will run.
    We didn’t explicitly ask for these to run, they’re run as part of the cluster
    and provide essential functionality. Another important column is `STATUS`. In
    the screenshot, we see that most of them are `Running`. The first two, though
    are in a state of`Pending`, which means that they’re not quite ready yet. This
    is actually expected, we haven’t deployed an overlay network yet, which is required
    for the `coredns` pods to function.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这些Pods的命名空间是`kube-system`。这是一个特殊的命名空间，其中运行与Kubernetes集群本身相关的Pods。我们并没有明确要求这些Pods运行，它们是作为集群的一部分运行，并提供必要的功能。另一个重要的列是`STATUS`。在截图中，我们看到大多数Pod处于`Running`状态。不过，前两个Pods处于`Pending`状态，这意味着它们还没有准备好。这其实是预期中的情况，因为我们还没有部署覆盖网络，而`coredns`
    Pods的运行需要这个网络。
- en: Overlay networks are virtual networks that are created to serve as a network
    on top of another network. The concept is not specific to Kubernetes, but when
    used in Kubernetes, the overlay network manages communication between nodes.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖网络是虚拟网络，它是在另一网络之上创建的，用作一个网络。这个概念不仅仅适用于Kubernetes，但在Kubernetes中，覆盖网络管理节点之间的通信。
- en: Other Pods may also show a status of `Pending`, and those should automatically
    switch to `Running` when they finish setting themselves up. How long this takes
    depends on the speed of your hardware, but it should only take a few minutes.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 其他Pods也可能显示为`Pending`状态，当它们完成设置后，应该会自动切换为`Running`状态。这个过程所需的时间取决于硬件的速度，但通常只需几分钟。
- en: The others will eventually change to a state of `Running` once their setup is
    finished – but they might also crash as well, and respawn. Since there’s no overlay
    network yet, the pods aren’t able to fully communicate yet. So if you see some
    errors, don’t worry about that yet.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 其他节点将在设置完成后最终变为`Running`状态——但它们也可能会崩溃并重新启动。由于还没有配置覆盖网络，Pods之间还无法完全通信。因此，如果看到一些错误，不用担心。
- en: 'Let’s deploy an overlay network so we can make the cluster more stable:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们部署一个覆盖网络，以便让集群更加稳定：
- en: '[PRE29]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'When we check the status again, we should see an additional Pod running (`kube-flannel-ds`),
    and the Pods that had a state of `Pending` previously should now be `Running`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们再次检查状态时，应该能看到一个额外的Pod在运行（`kube-flannel-ds`），之前处于`Pending`状态的Pods应该现在是`Running`状态：
- en: '![](img/B18425_18_16.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_16.png)'
- en: 'Figure 18.16: Checking the status of Pods running in our Kubernetes cluster
    again'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.16：再次检查Kubernetes集群中运行的Pods状态
- en: So, what exactly did we do? **Flannel** is a networking layer that can run on
    Kubernetes. Networking is required for Kubernetes to function, as Pods within
    the cluster need to be able to communicate with one another. There are multiple
    different types of networking models you can implement in Kubernetes, Flannel
    is just one available option. If you’re using a cloud provider, such as AWS, then
    the networking model is typically chosen for you. Since we’re building a cluster
    from scratch, we have to choose a networking model—Kubernetes itself doesn’t come
    with one.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们到底做了什么呢？**Flannel**是一个可以在Kubernetes上运行的网络层。网络是Kubernetes正常运行所必需的，因为集群中的Pods需要能够相互通信。Kubernetes中可以实现多种不同的网络模型，而Flannel只是其中一个可用的选项。如果你使用的是云服务提供商，如AWS，通常会为你选择网络模型。由于我们是从零开始构建集群，因此必须选择一个网络模型——Kubernetes本身并不附带网络模型。
- en: Setting up networking in a cluster that was manually created can be quite an
    involved task, Flannel is easy to set up (we simply deploy it) and its defaults
    meet the needs of Kubernetes and will get us up and running quickly. There are
    definitely some other options for the networking layer to consider for your cluster,
    but Flannel is good enough for us for what we need right now.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动创建的集群中设置网络可能是一个复杂的任务，Flannel的设置很简单（我们只需要部署它），而且它的默认配置能够满足Kubernetes的需求，并让我们快速启动。虽然还有其他网络层的选择，但Flannel对于我们当前的需求已经足够好了。
- en: 'Next, it’s time to watch the magic happen and join worker nodes to our cluster.
    We can check the status of all of our nodes with the following command:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，到了见证奇迹发生的时候，将工作节点加入集群。我们可以使用以下命令检查所有节点的状态：
- en: '[PRE30]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Right now though, we only have the controller showing up in the output since
    we haven’t yet added any nodes:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们输出中只显示了控制器，因为我们还没有添加任何节点：
- en: '![](img/B18425_18_17.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_17.png)'
- en: 'Figure 18.17: Checking the status of the nodes within the cluster'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.17：检查集群中节点的状态
- en: 'To add a worker to our cluster, we can enter the `join` command we saw earlier
    on a node designated as a worker. If you recall, the `join` command was shown
    in the terminal when we first initialized our cluster. The command will look something
    like the following, which I’ve shortened a bit to fit on this page (I’ve added
    `sudo` to the beginning):'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 要将一个工作节点添加到我们的集群中，我们可以在指定为工作节点的节点上输入我们之前看到的`join`命令。如果你还记得，在我们首次初始化集群时，终端会显示`join`命令。命令大致如下，我已稍微缩短以适应本页（在开头添加了`sudo`）：
- en: '[PRE31]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: You should consider the join command as private, and not show it to anyone,
    nor should you upload it to a Git repository or a documentation server. Reason
    being, it could be used by an outside actor to join something to your cluster.
    In my case, I truncated the hash so it’s impossible to reproduce, but keep this
    in mind going forward.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该将加入命令视为私密信息，不能展示给任何人，也不应将其上传到Git仓库或文档服务器。原因是，它可能会被外部人员用来将某些东西加入到你的集群中。就我而言，我截断了哈希值，因此无法复制，但请记住这一点。
- en: 'For you, the command will be very different. The IP address in the command
    is for the controller, which will no doubt be different on your end. The hash
    value will be different as well. Basically, just copy the `join` command you were
    provided while initializing the cluster on the controller and paste it into each
    of your worker nodes. You should see a message in the output that the node was
    successfully added to the cluster:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 对你来说，命令会非常不同。命令中的IP地址是控制节点的IP，显然你这边会有所不同。哈希值也会不同。基本上，只需复制你在初始化集群时在控制节点上获得的`join`命令，并将其粘贴到每个工作节点中。你应该能在输出中看到节点已成功添加到集群的消息：
- en: '![](img/B18425_18_18.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_18.png)'
- en: 'Figure 18.18: Successfully adding a worker node to the Kubernetes cluster'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.18：成功将一个工作节点添加到Kubernetes集群中
- en: 'After you’ve run the join command on each of your worker nodes (on however
    many you decided to create), you can run the `kubectl get nodes` command again
    on the controller and verify the new nodes appear on the list. I added two nodes,
    so I see the following output on my end:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在你在每个工作节点上运行了加入命令（无论你决定创建多少个工作节点）之后，你可以再次在控制节点上运行`kubectl get nodes`命令，验证新节点是否出现在列表中。我添加了两个节点，所以我在我的端看到以下输出：
- en: '![](img/B18425_18_19.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_19.png)'
- en: 'Figure 18.19: Output of kubectl showing worker nodes now added to the cluster'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.19：`kubectl`的输出显示工作节点已添加到集群中
- en: Once all of the nodes you plan on deploying show a `STATUS` of `Ready`, then
    your cluster setup is complete!
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你计划部署的所有节点都显示`STATUS`为`Ready`，那么你的集群设置就完成了！
- en: 'If you run into any trouble joining a node to the cluster, you can try to regenerate
    the join token. After a while, it’s possible the original could’ve expired and
    the certificates won’t be valid. To regenerate the join command, run the following
    from the controller node:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在将节点加入集群时遇到任何问题，可以尝试重新生成加入令牌。经过一段时间，原始令牌可能会过期，证书也将失效。要重新生成加入命令，可以从控制节点运行以下命令：
- en: '[PRE32]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This will print a brand new join command you can use in place of the original.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印一个全新的加入命令，你可以用它来替代原始命令。
- en: At this point, our cluster exists and has one or more worker nodes ready to
    do our bidding. The next step is to actually use the cluster and deploy a container.
    That’s exactly what we’ll do in the next section.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们的集群已存在，并且至少有一个工作节点准备好为我们服务。下一步是实际使用集群并部署一个容器。这正是我们将在下一节中做的。
- en: Deploying containers via Kubernetes
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Kubernetes部署容器
- en: 'Now it’s time to see our work pay off, and we can successfully use the cluster
    we’ve created. At this point, you should have either set up MicroK8s, or manually
    created a cluster as we’ve done in the previous section. In either case, the result
    is the same: we have a cluster available that we can use to deploy containers.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候看到我们的工作成果了，我们可以成功地使用我们创建的集群。在这一点上，你应该已经设置好了 MicroK8s，或者像我们在上一节中所做的那样手动创建了一个集群。无论哪种情况，结果是相同的：我们有了一个可以用来部署容器的集群。
- en: Keep in mind that if you’re using MicroK8s, you might need to prepend `microk8s`
    in front of `kubectl` commands, depending on how you set up MicroK8s. I’ll leave
    it up to you to add `microk8s` to the front of such commands as you go along,
    if you’re using MicroK8s and you don’t have it set up to simplify `microk8s kubectl`
    to `kubectl`.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，如果你使用的是MicroK8s，根据你设置MicroK8s的方式，可能需要在`kubectl`命令前添加`microk8s`。如果你使用MicroK8s且没有简化`microk8s
    kubectl`为`kubectl`，就需要自己加上`microk8s`。
- en: 'Kubernetes utilizes files created in the YAML format to receive instructions.
    Does that sound familiar? In *Chapter 15*, *Automating Server Configuration with
    Ansible*, we worked with YAML files as that’s the format that Ansible playbooks
    are written in. YAML isn’t specific to Ansible; it’s used with many different
    applications and services, and Kubernetes will also recognize the YAML format
    to contain instructions for how to deploy something. Here’s an example YAML file
    to get us started. This one in particular is intended to launch an NGINX container
    within our cluster:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用以 YAML 格式创建的文件来接收指令。这听起来熟悉吗？在 *第15章*，*使用 Ansible 自动化服务器配置* 中，我们使用了
    YAML 文件，因为 Ansible playbook 就是以这种格式编写的。YAML 并不局限于 Ansible，它被许多不同的应用和服务使用，Kubernetes
    也会识别 YAML 格式，以此作为部署指令的载体。下面是一个示例 YAML 文件，帮助我们入门。这个文件特别用于在集群中启动一个 NGINX 容器：
- en: '[PRE33]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Before I show you how to run it, let’s walk through the file and understand
    what’s going on.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在我展示如何运行之前，让我们先浏览一下这个文件，了解其中的内容。
- en: '[PRE34]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: First, we’re identifying the API version we intend to use, and then we’re setting
    the `kind` of deployment we intend to set up. In this case, we’re deploying a
    `pod`, which is what our containers run inside of in Kubernetes. One or more containers
    can run in a Pod, and a worker node can run one or more Pods at the same time.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们确定了我们打算使用的 API 版本，然后设置了我们要部署的 `kind` 类型。在这种情况下，我们部署的是一个 `pod`，即 Kubernetes
    中容器运行的环境。一个 Pod 可以运行一个或多个容器，而一个工作节点可以同时运行一个或多个 Pod。
- en: '[PRE35]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next, we add some metadata. Metadata allows us to set special parameters specific
    to our deployment. The first item of metadata we’re customizing is the `name`,
    we’re naming the Pod `nginx-example` in this case. We’re also able to set up labels
    with metadata, which is a “name: value” key pair that allows us to add additional
    values to our Pod that we can refer to later. In this case, we’re creating a label
    called `app` and setting it to `nginx`. This name is arbitrary; we could call
    it `potato` if we wanted to. Setting this to `nginx` is a descriptive label that
    makes it obvious to someone else what we are intending to run here.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们添加一些元数据。元数据使我们能够设置特定于部署的特殊参数。我们自定义的第一个元数据项是 `name`，在这种情况下，我们将 Pod 命名为
    `nginx-example`。我们还可以使用元数据设置标签，标签是一个“名称：值”键值对，它允许我们为 Pod 添加额外的值，以便稍后引用。在此情况下，我们创建了一个名为
    `app` 的标签，并将其设置为 `nginx`。这个名称是任意的；如果我们愿意，也可以将其命名为 `potato`。将其设置为 `nginx` 是一个描述性标签，能够让其他人清楚地知道我们打算在此运行什么。
- en: '[PRE36]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Moving on, the `spec` section allows us to specify what exactly we want to run
    in our Pod, and how we want it to run. We want to run a container in our Pod,
    and specifically a container that we’ll name `nginx`, which we’ll retrieve from
    a registry called `linuxserver`, and we’re requesting a container from that registry
    by the name of `nginx`.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`spec` 部分允许我们指定希望在 Pod 中运行的内容以及运行方式。我们希望在 Pod 中运行一个容器，具体来说是一个我们将命名为 `nginx`
    的容器，该容器来自名为 `linuxserver` 的镜像仓库，我们通过该仓库请求名为 `nginx` 的容器。
- en: The registry we’re fetching the container image from deserves some extra explanation.
    This registry in particular is located at [https://linuxserver.io](https://linuxserver.io),
    which is a special service that makes container images available for us to download
    and use. The site has a documentation section that gives us information about
    each of the container images they offer. Why use the [linuxserver.io](http://linuxserver.io)
    registry? The reason is that their service makes available various container images
    that support a variety of architectures, including x86 as well as ARM. The latter
    is especially important, because if you’re using Raspberry Pi units for your cluster,
    they won’t be able to utilize container images created for x86\. If you do attempt
    to run a container image that does not support ARM, then the container will fail
    to launch on a Pi. Since [linuxserver.io](http://linuxserver.io) makes container
    images available for multiple architectures, they should work fine regardless
    of the type of device you decided to use for your cluster. Whether you’re using
    an x86 physical server or VM for your worker node, the `nginx` container we’re
    retrieving from that registry should function just fine.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从中获取容器镜像的注册表值得额外说明一下。这个特别的注册表位于 [https://linuxserver.io](https://linuxserver.io)，它是一个专门的服务，提供可供我们下载和使用的容器镜像。该网站有一个文档部分，向我们提供关于他们提供的每个容器镜像的信息。为什么要使用
    [linuxserver.io](http://linuxserver.io) 注册表？原因是他们的服务提供了各种支持多种架构的容器镜像，包括 x86 和
    ARM。后者尤其重要，因为如果你使用的是 Raspberry Pi 单元作为集群节点，它们将无法使用为 x86 创建的容器镜像。如果你尝试运行不支持 ARM
    的容器镜像，那么容器将在 Pi 上启动失败。由于 [linuxserver.io](http://linuxserver.io) 提供支持多种架构的容器镜像，无论你决定使用哪种设备来构建集群，它们都应该可以正常工作。无论你是在使用
    x86 物理服务器还是虚拟机作为工作节点，我们从该注册表中获取的 `nginx` 容器应该都能正常运行。
- en: '[PRE37]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In the last few lines, we’re setting up a container port of `80`, which is the
    standard for a web server. This is the default port that NGINX listens on when
    it runs, and NGINX is what we’re intending to run inside our container. We’re
    applying a name to this port declaration, and calling it `nginx-http`. We can
    refer to that name in a subsequent YAML file (if we have more than one) and that
    works better than having to type the same port in each file. Referring to a port
    by name is not all that different from variables in scripting or programming languages.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几行中，我们正在设置一个 `80` 的容器端口，这是 Web 服务器的标准端口。当 NGINX 运行时，它会监听此端口，而 NGINX 就是我们打算在容器内运行的服务。我们给这个端口声明赋予了一个名称，叫做
    `nginx-http`。我们可以在随后的 YAML 文件中引用该名称（如果我们有多个文件），而这样比每个文件中都输入相同端口要更为高效。通过名称引用端口，与脚本或编程语言中的变量类似，并不算特别复杂。
- en: 'Before we continue, there’s a bit of difference regarding how you deploy resources
    to a cluster within MicroK8s compared to a cluster that was set up manually on
    actual servers. The commands going forward will assume you’ve set up a cluster
    manually. If you’re using MicroK8s on Windows or macOS, you’ll need to copy any
    deployment files you create into the MicroK8s VM that’s created as part of the
    installation of MicroK8s. If you try to save a file locally and deploy it as we’re
    about to do in the next paragraph, it will fail, because the file will not be
    found on the VM. To copy a deployment file to the MicroK8s VM to enable you to
    deploy it, you can use the following command to copy the file into the VM first:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，有一点关于如何在 MicroK8s 集群中部署资源与在实际服务器上手动设置的集群中部署资源的差异。接下来的命令假设你已经手动设置了集群。如果你在
    Windows 或 macOS 上使用 MicroK8s，你需要将任何你创建的部署文件复制到作为 MicroK8s 安装的一部分创建的 MicroK8s 虚拟机中。如果你试图将文件保存在本地并像接下来的段落中那样进行部署，操作将失败，因为该文件在虚拟机上无法找到。要将部署文件复制到
    MicroK8s 虚拟机并使其能够部署，你可以使用以下命令将文件先复制到虚拟机：
- en: '[PRE38]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: As we go along, keep in mind that whenever we’re deploying a file, you’ll have
    to make sure to transfer it first. Also, a manually created cluster uses the `kubectl`
    command, while MicroK8s requires you to prefix `kubectl` with `microk8s`, so such
    commands become `microk8s kubectl` instead of just `kubectl`.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进行操作时，请记住，每当我们部署文件时，首先需要确保将其传输过去。另外，手动创建的集群使用 `kubectl` 命令，而 MicroK8s 需要将
    `kubectl` 命令前缀加上 `microk8s`，因此此类命令应变为 `microk8s kubectl`，而不仅仅是 `kubectl`。
- en: 'Let’s go ahead and deploy the container to our cluster. Assuming you named
    the YAML file as `pod.yml`, you can deploy it with the following command on the
    controller node:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始将容器部署到集群中了。假设你将 YAML 文件命名为 `pod.yml`，你可以在控制节点上使用以下命令进行部署：
- en: '[PRE39]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: As mentioned previously, the `kubectl` command allows us to control our cluster.
    The `-f` option accepts a file as input, and we’re pointing it to the YAML file
    that we’ve created.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`kubectl`命令允许我们控制集群。`-f`选项接受文件作为输入，我们指向的是我们创建的YAML文件。
- en: 'Once you’ve run the command, you’ll be able to check the status of the deployment
    with the following command:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你运行了这个命令，你就可以使用以下命令检查部署的状态：
- en: '[PRE40]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'For me, I see the following when I run it:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，当我运行时，我看到如下内容：
- en: '![](img/B18425_18_20.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_20.png)'
- en: 'Figure 18.20: Checking the status of a container deployment'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.20：检查容器部署的状态
- en: 'From the output in my case, I can see that the process was successful. The
    `STATUS` is `Running`. What we don’t see is what worker node the Pod is running
    on. It’s nice to know that it’s `Running`, but where? We can get more information
    by adding the `-o wide` option to the end of the command:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 从我的输出中，我可以看到这个过程是成功的。`STATUS`显示为`Running`。我们没有看到的是Pod运行在哪个工作节点上。虽然知道它是`Running`很不错，但我们想知道它在哪儿运行？我们可以通过在命令末尾添加`-o
    wide`选项来获得更多信息：
- en: '[PRE41]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The output contains much more information, so much that a screenshot of it won’t
    fit on this page. The focus though, is that among the extra fields we have with
    this version of the command is the `node` field, which shows us which worker node
    is handling this deployment. We’ll even see an IP address assigned to the Pod
    as well.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 输出包含更多信息，信息量大到截图无法完全显示在这页上。不过，重点是，在这个命令版本的额外字段中，有一个`node`字段，它显示了哪个工作节点正在处理这个部署。我们还会看到分配给Pod的IP地址。
- en: 'We can use the IP address shown for the Pod to access the application running
    inside the container. In my case, my Pod was given an IP address of `10.244.1.2`,
    so I can use the `curl` command to access the default NGINX web page:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用显示的Pod的IP地址来访问运行在容器内的应用程序。在我的例子中，我的Pod被分配了`10.244.1.2`的IP地址，因此我可以使用`curl`命令访问默认的NGINX网页：
- en: '[PRE42]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output that’s shown in the terminal after running that command should be
    the HTML for the default NGINX web page. Note that the `curl` command may not
    be available in your Ubuntu installation, so you may need to install the required
    package first:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端运行命令后的输出应该是默认NGINX网页的HTML。请注意，`curl`命令可能在你的Ubuntu安装中不可用，因此你可能需要先安装所需的软件包：
- en: '[PRE43]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We have one potential issue though: if you want to be able to access an application
    running inside the cluster on a machine other than the controller or worker nodes,
    it won’t work. By default, there’s nothing in place to route traffic from your
    LAN to your cluster. This means that in my case, the IP address of `10.244.1.2`
    that was given to my Pod was provided to it by the Pod Network, the router on
    my network doesn’t understand that IP address scheme so trying to access it from
    another machine on the LAN will fail. What’s interesting is that you can access
    the application from any other node within the cluster. In my case, the NGINX
    Pod is running on the first worker node. However, I can actually run the previous
    `curl` command from worker #2 even though the Pod isn’t running there, and I’ll
    get the same exact output. This works because the Pod Network is cluster-wide;
    it’s not specific to any one node.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 不过我们有一个潜在的问题：如果你希望能够从集群外的机器访问运行在集群内部的应用程序，那是不行的。默认情况下，没有任何机制可以将来自你局域网的流量路由到你的集群。这意味着在我的例子中，我的Pod被分配的`10.244.1.2`的IP地址是由Pod网络提供的，而我网络中的路由器并不理解这个IP地址方案，所以试图从局域网的其他机器访问它将会失败。有趣的是，你可以从集群内的任何其他节点访问该应用程序。在我的例子中，NGINX
    Pod运行在第一个工作节点上。但是，即使Pod没有运行在那儿，我实际上也可以从工作节点#2运行先前的`curl`命令，而且我会得到完全相同的输出。这是因为Pod网络是集群范围的；它不是特定于某一个节点的。
- en: The IP address of `10.244.1.2` is unique to the entire cluster, so if I run
    another container it won’t receive that same IP address, and every node within
    the cluster knows how to internally route to IPs within that network.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '`10.244.1.2`的IP地址对于整个集群来说是唯一的，所以如果我运行另一个容器，它不会得到相同的IP地址，而且集群中的每个节点都知道如何将流量内部路由到该网络中的IP。'
- en: Not allowing outside devices to access applications within the cluster is great
    for security purposes. After all, a hacker can’t break into a container that they
    can’t even route to. But the entire point of running a Kubernetes cluster is to
    make applications available to our network, so how do we do that? This can be
    a very confusing topic for newcomers, especially when we’re setting up a cluster
    manually. If we’re using a cloud service such as AWS or Google Cloud, they add
    an additional layer on top of their Kubernetes implementation that facilitates
    routing traffic in and out of the cluster. Since we set up our cluster manually,
    we don’t have anything like that in place.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 不允许外部设备访问集群内的应用程序对安全性来说非常重要。毕竟，黑客无法侵入他们连路由都无法到达的容器。但是运行Kubernetes集群的主要目的是让应用程序可以在我们的网络上访问，那我们该怎么做呢？对于新手来说，这可能是一个非常混乱的话题，特别是当我们手动设置集群时。如果我们使用像AWS或Google
    Cloud这样的云服务，它们会在其Kubernetes实现上添加一层额外的功能，便于在集群内外路由流量。由于我们是手动搭建集群的，因此没有类似的机制。
- en: When it comes to building services and networking components designed to handle
    networking to bridge our LAN and Kubernetes cluster, that’s an expansive topic
    that can span a few chapters in and of itself. But a simple solution for us is
    to create a **NodePort Service**. These are two new concepts here, a Service as
    well as NodePort. When it comes to a Service, a Pod isn’t the only thing we can
    deploy within our cluster. There are several different things we can deploy, and
    a Service is a method of exposing a Kubernetes Pod, and a NodePort is a specific
    type of service that gives us a specific method for facilitating a way of accessing
    it. What NodePort itself does is expose a port running inside a Pod to a port
    on each cluster node.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到构建旨在处理我们局域网与Kubernetes集群之间网络连接的服务和网络组件时，这是一个广泛的话题，可能需要几章内容来讲解。但对于我们来说，一个简单的解决方案是创建一个**NodePort服务**。这里有两个新概念，一个是服务（Service），另一个是NodePort。对于服务（Service）来说，Pod并不是我们在集群中唯一可以部署的内容。我们可以部署几种不同的东西，而服务是一种暴露Kubernetes
    Pod的方法，NodePort则是一种特定类型的服务，它为我们提供了一种特定的方式来访问Pod。NodePort的作用是将Pod内部运行的端口暴露到每个集群节点上的端口。
- en: 'Here’s a file we can deploy to create a NodePort Service for our Pod:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可以部署的文件，用于为我们的Pod创建一个NodePort服务：
- en: '[PRE44]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: As you can see, the `kind` is `Service`; as this time, we’re deploying a service
    to our cluster to complement the Pod we’ve deployed previously. The `type` of
    service is `NodePort`, and we are mapping port `80` within the Pod to port `30080`
    in our cluster. I chose port `30080` arbitrarily. With NodePort, we can utilize
    ports `30000` through `32767`. The `selector` in this file is set to `nginx`,
    which is the same selector we used while creating the Pod. Selectors allow us
    to “select” Kubernetes resources via a name we assign them, to make it easier
    to refer to them later.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`kind`是`Service`；这次我们正在将服务部署到集群中，以补充我们之前部署的Pod。服务的`type`是`NodePort`，我们将Pod中的端口`80`映射到集群中的端口`30080`。我随意选择了端口`30080`。使用NodePort时，我们可以使用端口`30000`到`32767`。此文件中的`selector`设置为`nginx`，这与我们在创建Pod时使用的选择器相同。选择器允许我们通过给Kubernetes资源分配一个名称来“选择”它们，从而方便我们以后引用它们。
- en: 'Let’s deploy our service:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们部署我们的服务：
- en: '[PRE45]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Assuming we’ve typed everything in the YAML file for the service properly,
    we can retrieve the status of services running within our cluster with the following
    command:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已正确输入了YAML文件中的所有内容，可以使用以下命令检索在集群中运行的服务的状态：
- en: '[PRE46]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'If everything has gone well, you should see output similar to the following:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，你应该会看到类似以下的输出：
- en: '![](img/B18425_18_21.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_21.png)'
- en: 'Figure 18.21: Checking the status of a service deployment'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.21：检查服务部署的状态
- en: 'In the output, we should see the status of our `service` deployment, which
    is the second line in the screenshot. We can also see the port mapping for it,
    showing that port `30080` should be exposed to the outside. To test that it’s
    actually working, we can open a web browser on a machine that is within our LAN,
    and it should be able to access the controller’s IP address at port `30080`:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出中，我们应该看到`service`部署的状态，这是屏幕截图中的第二行。我们还可以看到它的端口映射，显示端口`30080`应该暴露到外部。为了测试它是否正常工作，我们可以在我们局域网中的一台机器上打开Web浏览器，它应该能够访问控制器的IP地址，并使用端口`30080`：
- en: '![](img/B18425_18_22.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18425_18_22.png)'
- en: 'Figure 18.22: Accessing a web page served by an NGINX container in a cluster
    from within a web browser'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.22：通过Web浏览器访问集群中NGINX容器提供的网页
- en: Another interesting benefit is that we didn’t actually have to use the IP address
    of our controller node, we can use the IP address of a worker node as well and
    see the same default page. The reason this works is that the mapping of port `30080`
    to port `80` inside the Pod is cluster-wide, just as the internal Pod Network
    is also cluster-wide. Accessing a resource on one is the same as accessing the
    same resource on any other, as the request will be directed toward whichever node
    is running the Pod that matches the request.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的好处是，我们实际上并不需要使用我们控制节点的IP地址，我们也可以使用工作节点的IP地址，并查看相同的默认页面。 这样做的原因是，Pod内部将端口`30080`映射到集群范围内的端口`80`，就像内部Pod网络也是集群范围的一样。
    访问一个资源与访问任何其他资源是一样的，因为请求将被定向到运行与匹配请求的Pod的任何节点。
- en: 'When it comes to removing a Pod or a Service, assuming you want to decommission
    something running in your cluster, the syntax for that is fairly straightforward.
    To remove our `nginx-example` Pod, for example, you can run this:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到移除Pod或服务时，假设您想要将运行在您集群中的某些东西下架，那么删除的语法相对来说非常简单。 例如，要删除我们的`nginx-example`
    Pod，您可以运行以下命令：
- en: '[PRE47]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Similarly, to delete our service, we can run this:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，要删除我们的服务，我们可以运行以下命令：
- en: '[PRE48]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: At this point, you not only have a working cluster, but you also have the ability
    to deploy containers to it and set them up to be accessible from outside the Pod
    Network. From here, I recommend you practice with this a bit and attempt to run
    additional containers and apps to have a bit of fun with it.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您不仅拥有一个工作的集群，还可以部署容器，并设置它们可以从Pod网络外部访问。 从这里开始，我建议您稍微练习一下，并尝试运行额外的容器和应用程序，以便稍微玩一下。
- en: Summary
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we took containerization to the next level and implemented
    Kubernetes. Kubernetes provides us with orchestration for our containers, enabling
    us to more intelligently manage our running containers and implement services.
    Kubernetes itself is a very expansive topic, and there are many additional features
    and benefits we can explore. But for the goal of getting set up on Kubernetes
    and running containers with it, we did what we needed to do. I recommend that
    you continue studying Kubernetes and expand your knowledge, as it’s a very worthwhile
    subject to dig deeper into.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将容器化提升到了一个新的水平，并实施了Kubernetes。 Kubernetes为我们的容器提供了编排功能，使我们能够更智能地管理我们运行的容器并实现服务。
    Kubernetes本身是一个非常广泛的主题，我们可以探索许多其他功能和优势。 但是，为了在Kubernetes上进行设置并运行容器的目标，我们做了我们需要做的事情。
    我建议您继续学习Kubernetes并扩展您的知识，因为这是一个非常值得深入挖掘的主题。
- en: Speaking of subjects that are worthwhile to learn, in the next chapter, we’re
    going to learn how to deploy Ubuntu in the cloud! Specifically, we’ll get started
    with Amazon Web Services, which is a very popular cloud platform.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到值得学习的主题，在下一章中，我们将学习如何在云中部署Ubuntu！ 具体来说，我们将开始使用Amazon Web Services，这是一个非常流行的云平台。
- en: Relevant videos
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关视频
- en: 'Setting up a Kubernetes Cluster (LearnLinuxTV): [https://linux.video/setup-k8s](https://linux.video/setup-k8s)'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Kubernetes集群（LearnLinuxTV）：[https://linux.video/setup-k8s](https://linux.video/setup-k8s)
- en: Further reading
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'MicroK8s website: [https://learnlinux.link/mk8s](https://learnlinux.link/mk8s)'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MicroK8s网站：[https://learnlinux.link/mk8s](https://learnlinux.link/mk8s)
- en: 'MicroK8s addons: [https://learnlinux.link/mk8s-addons](https://learnlinux.link/mk8s-addons)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MicroK8s插件：[https://learnlinux.link/mk8s-addons](https://learnlinux.link/mk8s-addons)
- en: Join our community on Discord
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/LWaZ0](https://packt.link/LWaZ0)'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/LWaZ0](https://packt.link/LWaZ0)'
- en: '![](img/QR_Code50046724-19558751561.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code50046724-19558751561.png)'
