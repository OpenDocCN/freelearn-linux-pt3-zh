<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer186" class="Basic-Text-Frame">
    <h1 class="chapterNumber"><a id="_idTextAnchor707"/>21</h1>
    <h1 id="_idParaDest-608" class="chapterTitle"><a id="_idTextAnchor708"/>Real-Time Programming</h1>
    <p class="normal">Much of the interaction between a computer system and the real world happens in real time, and so this is an important topic for developers of embedded systems. I have touched on real-time programming in several places so far: in <a href="Chapter_17.xhtml#_idTextAnchor542"><em class="italic">Chapter 17</em></a>, we looked at scheduling policies and priority inversion, and in <a href="Chapter_18.xhtml#_idTextAnchor581"><em class="italic">Chapter 18</em></a>, I described the problems with page faults and the need for memory locking. Now it is time to bring these topics together and look at real-time programming in some depth.</p>
    <p class="normal">In this chapter, I will begin with a discussion about the characteristics of real-time systems, and then consider the implications for system design, at both the application and kernel levels. I will describe the real-time <code class="inlineCode">PREEMPT_RT</code> kernel patch and show how to get it and apply it to a mainline kernel. The<a id="_idIndexMarker1544"/> final sections will<a id="_idIndexMarker1545"/> describe how to characterize system latencies using two tools: <strong class="keyWord">cyclictest</strong> and <strong class="keyWord">Ftrace</strong>.</p>
    <p class="normal">There are other ways to achieve real-time behavior on an embedded Linux device, for instance, using a dedicated microcontroller or a separate real-time kernel alongside the Linux kernel in the way that Xenomai and RTAI do. I am not going to discuss these here because the focus of this book is on using Linux as the core for embedded systems.</p>
    <p class="normal">In this chapter, we will cover the following topics:</p>
    <ul>
      <li class="bulletList">What is real time?</li>
      <li class="bulletList">Identifying sources of non-determinism</li>
      <li class="bulletList">Understanding scheduling latency</li>
      <li class="bulletList">Kernel preemption</li>
      <li class="bulletList">Preemptible kernel locks</li>
      <li class="bulletList">High-resolution timers</li>
      <li class="bulletList">Avoiding page faults</li>
      <li class="bulletList">Interrupt shielding</li>
      <li class="bulletList">Measuring scheduling latencies</li>
    </ul>
    <h1 id="_idParaDest-609" class="heading-1"><a id="_idTextAnchor709"/>Technical requirements</h1>
    <p class="normal">To follow along with the examples, make sure you have the following:</p>
    <ul>
      <li class="bulletList">An Ubuntu 24.04 or later LTS host system with at least 90 GB of free disk space</li>
      <li class="bulletList">Yocto 5.0 (Scarthgap) LTS release</li>
      <li class="bulletList">A microSD card reader and card</li>
      <li class="bulletList">balenaEtcher for Linux</li>
      <li class="bulletList">An Ethernet cable and router with an available port for network connectivity</li>
      <li class="bulletList">A BeaglePlay</li>
      <li class="bulletList">A 5 V USB-C power supply capable of delivering 3 A</li>
    </ul>
    <p class="normal">You should have already built the 5.0 (Scarthgap) LTS release of Yocto in <a href="Chapter_04.xhtml#_idTextAnchor110"><em class="italic">Chapter 6</em></a>. If you have not, then please refer to the <em class="italic">Compatible Linux Distribution</em> and <em class="italic">Build Host Packages</em> sections of the <em class="italic">Yocto Project Quick Build</em> guide (<a href="https://docs.yoctoproject.org/brief-yoctoprojectqs/"><span class="url">https://docs.yoctoproject.org/brief-yoctoprojectqs/</span></a>) before building Yocto on your Linux host according to the instructions in <a href="Chapter_04.xhtml#_idTextAnchor110"><em class="italic">Chapter 6</em></a>.</p>
    <h1 id="_idParaDest-610" class="heading-1"><a id="_idTextAnchor710"/>What is real time?</h1>
    <p class="normal">The nature of real-time programming<a id="_idIndexMarker1546"/> is one of the subjects that software engineers love to discuss at length, often giving a range of contradictory definitions. I will begin by setting out what I think is important about real time.</p>
    <p class="normal">A task is a real-time task if it has to be completed before a certain point in time, known as the <strong class="keyWord">deadline</strong>. The distinction between real-time and non-real-time tasks is shown by considering what happens when you play an audio stream on your computer while compiling the Linux kernel. The first is a real-time task because there is a constant stream of data arriving at the audio driver, and blocks of audio samples have to be written to the audio interface at the playback rate. Meanwhile, the compilation is not real time because there is no deadline. You simply want it to be completed as soon as possible; whether it takes 10 seconds or 10 minutes does not affect the quality of the kernel binaries.</p>
    <p class="normal">The other important thing to consider is the consequence of missing the deadline, which can range from mild annoyance to system failure or, in the most extreme cases, injury or death. Here are some examples:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Playing an audio stream</strong>: There is a deadline in the order of tens of milliseconds. If the audio buffer underruns, you will hear a click, which is annoying, but you will get over it.</li>
      <li class="bulletList"><strong class="keyWord">Moving and clicking a mouse</strong>: The deadline is also in the order of tens of milliseconds. If it is missed, the mouse moves erratically and button clicks will be lost. If the problem persists, the system will become unusable.</li>
      <li class="bulletList"><strong class="keyWord">Printing a piece of paper</strong>: The deadlines for the paper feed are in the millisecond range, which if missed may cause the printer to jam, and somebody will have to go and fix it. Occasional jams are acceptable, but nobody is going to buy a printer that keeps on jamming.</li>
      <li class="bulletList"><strong class="keyWord">Printing sell-by dates on bottles on a production line</strong>: If one bottle is not printed, the whole production line has to be halted, the bottle removed, and the line restarted, which is expensive.</li>
      <li class="bulletList"><strong class="keyWord">Baking a cake</strong>: There is a deadline of 30 minutes or so. If you miss it by a few minutes, the cake might be ruined. If you miss it by a lot, the house may burn down.</li>
      <li class="bulletList"><strong class="keyWord">Power-surge detection system</strong>: If the system detects a surge, a circuit breaker has to be triggered within 2 milliseconds. Failing to do so causes damage to the equipment and may injure or kill someone.</li>
    </ul>
    <p class="normal">In other words, there are many<a id="_idIndexMarker1547"/> consequences to missed deadlines. We often talk about these different categories:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Soft real-time</strong>: The deadline is desirable but is sometimes missed without the system being considered a failure. The first two examples in the previous list are examples of this.</li>
      <li class="bulletList"><strong class="keyWord">Hard real-time</strong>: Here, missing a deadline has a serious effect. We can further subdivide hard real-time into mission-critical systems, in which there is a cost to missing the deadline, such as the fourth example, and safety-critical systems, in which there is a danger to life and limb, such as the last two examples. I put in the baking example to show that not all hard real-time systems have deadlines measured in milliseconds or microseconds.</li>
    </ul>
    <p class="normal">Software written for safety-critical systems has to conform to various standards that seek to ensure that it is capable of performing reliably. It is very difficult for a complex operating system such as Linux to meet those requirements.</p>
    <p class="normal">When it comes to mission-critical systems, it is possible, and common, for Linux to be used for a wide range of control systems. The requirements of the software depend on the combination of the deadline and the confidence level, which can usually be determined through extensive testing.</p>
    <p class="normal">Therefore, to say that a system is real-time, you have to measure its response times under the maximum anticipated load and show that it meets the deadline for an agreed proportion of the time. As a rule of thumb, a well-configured Linux system using a mainline kernel is good for soft real-time tasks with deadlines down to tens of milliseconds, and a kernel with the <code class="inlineCode">PREEMPT_RT</code> patch is good for soft and hard real-time mission-critical systems with deadlines down to several hundreds of microseconds.</p>
    <p class="normal">The key to creating a real-time system is to reduce the variability in response times so that you have greater confidence that the deadlines will not be missed; in other words, you need to make the system more deterministic. Often, this is done at the expense of performance. For example, caches<a id="_idIndexMarker1548"/> make systems run faster by making the average time to access an item of data shorter, but the maximum time is longer in the case of a cache miss. Caches make a system faster but less deterministic, which is the opposite of what we want.</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">TIP</strong></p>
      <p class="normal">It is a myth of real-time computing that it is fast. This is not so; the more deterministic a system is, the lower the maximum throughput.</p>
    </div>
    <p class="normal">The remainder of this chapter is concerned with identifying the causes of latency and the things you can do to reduce it.</p>
    <h1 id="_idParaDest-611" class="heading-1"><a id="_idTextAnchor711"/>Identifying sources of non-determinism</h1>
    <p class="normal">Fundamentally, real-time programming is about making sure that the threads controlling the output in real time<a id="_idIndexMarker1549"/> are scheduled when needed and so can complete the job before the deadline. Anything that prevents this is a problem. Here are some problem areas:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Scheduling</strong>: Real-time threads must be scheduled before others, and so they must have a real-time policy, <code class="inlineCode">SCHED_FIFO</code> or <code class="inlineCode">SCHED_RR</code>. Additionally, they should have priorities assigned in descending order, starting with the one with the shortest deadline, according to the theory of rate monotonic analysis that I described in <a href="Chapter_17.xhtml#_idTextAnchor542"><em class="italic">Chapter 17</em></a>.</li>
      <li class="bulletList"><strong class="keyWord">Scheduling latency</strong>: The kernel must be able to reschedule as soon as an event such as an interrupt or timer occurs and not be subject to unbounded delays. Reducing scheduling latency is a key topic later on in this chapter.</li>
      <li class="bulletList"><strong class="keyWord">Priority inversion</strong>: This is a consequence of priority-based scheduling, which leads to unbounded delays when a high-priority thread is blocked on a mutex held by a low-priority thread, as I described in <a href="Chapter_17.xhtml#_idTextAnchor542"><em class="italic">Chapter 17</em></a>. User space has priority inheritance and priority ceiling mutexes; in kernel space, we have RT-mutexes, which implement priority inheritance, and I will talk about them in the section on the real-time kernel.</li>
      <li class="bulletList"><strong class="keyWord">Accurate timers</strong>: If you want to manage deadlines in the region of low milliseconds or microseconds, you need timers that match. High-resolution timers are crucial and are a configuration option on almost all kernels.</li>
      <li class="bulletList"><strong class="keyWord">Page faults</strong>: A page fault while executing a critical section of code will upset all timing estimates. You can avoid them by locking memory, as I shall describe later.</li>
      <li class="bulletList"><strong class="keyWord">Interrupts</strong>: They occur at unpredictable times and can result in an unexpected processing overhead if there is a sudden flood of them. There are two ways to avoid this. One is to run interrupts as kernel threads, and the other, on multi-core devices, is to shield one or more CPUs from interrupt handling. I will discuss both possibilities later.</li>
      <li class="bulletList"><strong class="keyWord">Processor caches</strong>: These provide a buffer between the CPU and the main memory and, like all caches, are a source of non-determinism, especially on multi-core devices. Unfortunately, this is beyond the scope of this book, but you may want to refer to the references at the end of the chapter for more details.</li>
      <li class="bulletList"><strong class="keyWord">Memory bus contention</strong>: When peripherals access memory directly through a DMA <a id="_idIndexMarker1550"/>channel, they use up a slice of memory bus bandwidth, which slows down access from the CPU core (or cores) and so contributes to the non-deterministic execution of the program. However, this is a hardware issue and is also beyond the scope of this book.</li>
    </ul>
    <p class="normal">I will expand on the most important problems and see what can be done about them in the next sections.</p>
    <h1 id="_idParaDest-612" class="heading-1"><a id="_idTextAnchor712"/>Understanding scheduling latency</h1>
    <p class="normal">Real-time threads <a id="_idIndexMarker1551"/>need to be scheduled as soon as they have something to do. However, even if there are no other threads of the same or higher priority, there is always a delay from the point at which the wakeup event occurs—an interrupt or system timer—to the time that the thread starts to run. This is called scheduling latency. It can be broken down into several components, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B18466_21_01.png" alt="Figure 21.1 – Scheduling latency" width="1212" height="563"/></figure>
    <p class="packt_figref">Figure 21.1 – Scheduling latency</p>
    <p class="normal">Firstly, there is the hardware interrupt latency from the point at which an interrupt is asserted until <a id="_idIndexMarker1552"/>the <strong class="keyWord">interrupt service routine</strong> (<strong class="keyWord">ISR</strong>) begins to run. A small part of this is the delay in the interrupt hardware itself, but the biggest problem is due to interrupts being disabled in software. Minimizing this <em class="italic">IRQ off time</em> is important.</p>
    <p class="normal">The next is interrupt latency, which is the length of time until the ISR has serviced the interrupt and woken up<a id="_idIndexMarker1553"/> any threads waiting on this event. It is mostly dependent on the way the ISR was written. Normally, it should take only a short time, measured in microseconds.</p>
    <p class="normal">The final delay is the preemption latency, which is the time from the point that the kernel is notified that a thread is ready to run to that at which the scheduler actually runs the thread. It is determined by whether the kernel can be preempted or not. If it is running code in a critical section, then the rescheduling will have to wait. The length of the delay is dependent on the configuration of kernel preemption.</p>
    <h1 id="_idParaDest-613" class="heading-1"><a id="_idTextAnchor713"/>Kernel preemption</h1>
    <p class="normal">Preemption latency <a id="_idIndexMarker1554"/>occurs because it is not always safe or desirable to preempt<a id="_idIndexMarker1555"/> the current thread of execution and call the scheduler. Mainline Linux has three settings for preemption, selected via the <strong class="screenText">Kernel Features</strong> | <strong class="screenText">Preemption Mode</strong>l menu:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">CONFIG_PREEMPT_NONE</code>: No preemption.</li>
      <li class="bulletList"><code class="inlineCode">CONFIG_PREEMPT_VOLUNTARY</code>: Enables additional checks for requests for preemption.</li>
      <li class="bulletList"><code class="inlineCode">CONFIG_PREEMPT</code>: Allows the kernel to be preempted.</li>
    </ul>
    <p class="normal">With preemption set to <code class="inlineCode">none</code>, kernel code will continue without rescheduling until it either returns via a <code class="inlineCode">syscall</code> back to user space, where preemption is always allowed, or it encounters a sleeping wait that stops the current thread. Since it reduces the number of transitions between the kernel and user space and may reduce the total number of context switches, this option results in the highest throughput at the expense of large preemption latencies. It is the default for servers and some desktop kernels where throughput is more important than responsiveness.</p>
    <p class="normal">The second option enables explicit preemption points, where the scheduler is called if the <code class="inlineCode">need_resched</code> flag is set, which reduces the worst-case preemption latencies at the expense of slightly lower throughput. Some distributions set this option on desktops.</p>
    <p class="normal">The third option makes the kernel preemptible, meaning that an interrupt can result in an immediate reschedule so long as the kernel is not executing in an atomic context, which I will describe in the following section. This reduces worst-case preemption latencies and, therefore, overall scheduling latencies to something in the order of a few milliseconds on typical embedded hardware.</p>
    <p class="normal">This is often described as a soft real-time option, and most embedded kernels are configured in this way. Of course, there is a small reduction in overall throughput, but that is usually less important than having more deterministic scheduling for embedded devices.</p>
    <h2 id="_idParaDest-614" class="heading-2"><a id="_idTextAnchor714"/>Real-time Linux kernel (PREEMPT_RT)</h2>
    <p class="normal">There <a id="_idIndexMarker1556"/>was a long-standing effort to reduce<a id="_idIndexMarker1557"/> latencies even further that goes by the name of the kernel configuration option for these features, <strong class="keyWord">PREEMPT_RT</strong>. The project was started by Ingo Molnar, Thomas Gleixner, and Steven Rostedt and has had contributions from many more developers over the years. The kernel patches are at <a href="https://www.kernel.org/pub/linux/kernel/projects/rt"><span class="url">https://www.kernel.org/pub/linux/kernel/projects/rt</span></a>, and there is a wiki at <a href="https://wiki.linuxfoundation.org/realtime/start"><span class="url">https://wiki.linuxfoundation.org/realtime/start</span></a>.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">IMPORTANT NOTE</strong></p>
      <p class="normal"><code class="inlineCode">PREEMPT_RT</code> was fully merged and enabled in the mainline Linux kernel on September 20, 2024. <code class="inlineCode">PREEMPT_RT</code> support for the x86, x86-64, arm64, and riscv architectures was included in the Linux 6.12 LTS release that happened on November 17, 2024.</p>
    </div>
    <p class="normal">The central plan was to reduce the amount of time the kernel spends running in an <strong class="keyWord">atomic context</strong>, which is where it is not safe to call the scheduler and switch to a different thread. Typical atomic contexts are when the kernel is in the following states:</p>
    <ul>
      <li class="bulletList">Running an interrupt or trap handler.</li>
      <li class="bulletList">Holding a spin lock or is in an RCU-critical section. Spin locks and RCU are kernel-locking primitives, the details of which are not relevant here.</li>
      <li class="bulletList">Between calls to <code class="inlineCode">preempt_disable()</code> and <code class="inlineCode">preempt_enable()</code>.</li>
      <li class="bulletList">Hardware interrupts are disabled (<strong class="keyWord">IRQs off</strong>).</li>
    </ul>
    <p class="normal">The changes that comprised <code class="inlineCode">PREEMPT_RT</code> had two main goals: one is to reduce the impact of interrupt handlers by turning them into kernel threads, and the other is to make locks preemptible so that a thread can sleep while holding one. It is obvious that there is a large overhead in these changes, which makes average-case interrupt handling slower but much more deterministic, which is what we are striving for.</p>
    <h2 id="_idParaDest-615" class="heading-2"><a id="_idTextAnchor715"/>Threaded interrupt handlers</h2>
    <p class="normal">Not all <a id="_idIndexMarker1558"/>interrupts are triggers for real-time tasks, but all interrupts steal cycles from real-time tasks. Threaded interrupt handlers allow a priority to be associated with the interrupt and for it to be scheduled at an appropriate time, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B18466_21_02.png" alt="Figure 21.2 – In-line versus threaded interrupt handlers" width="861" height="907"/></figure>
    <p class="packt_figref">Figure 21.2 – In-line versus threaded interrupt handlers</p>
    <p class="normal">If the <a id="_idIndexMarker1559"/>interrupt handler code is run as a kernel thread, there is no reason why it cannot be preempted by a user space thread of higher priority, and so the interrupt handler does not contribute toward scheduling latency of the user space thread. Threaded interrupt handlers have been a feature of mainline Linux since 2.6.30. You can request that an individual interrupt handler be threaded by registering it with <code class="inlineCode">request_threaded_irq()</code> in place of the normal <code class="inlineCode">request_irq()</code>. You can make threaded IRQs the default by configuring the kernel with <code class="inlineCode">CONFIG_IRQ_FORCED_THREADING=y</code>, which makes all handlers into threads unless they have explicitly prevented this by setting the <code class="inlineCode">IRQF_NO_THREAD</code> flag. When <code class="inlineCode">PREEMPT_RT</code> is enabled, interrupts are, by default, configured as threads in this way. Here is an example of what you might see:</p>
    <pre class="programlisting con"><code class="hljs-con"># ps -Leo pid,tid,class,rtprio,stat,comm,wchan | grep FF
  PID   TID CLS RTPRIO STAT COMMAND         WCHAN
   21    21 FF      99 S    migration/0     smpboot_thread_fn
<a id="_idTextAnchor716"/>   22    22 FF       1 S    irq_work/0      smpboot_thread_fn
<a id="_idTextAnchor717"/>   25    25 FF       1 S    irq_work/1      smpboot_thread_fn
<a id="_idTextAnchor718"/>   26    26 FF      99 S    migration/1     smpboot_thread_fn
<a id="_idTextAnchor719"/>   32    32 FF       1 S    irq_work/2      smpboot_thread_fn
<a id="_idTextAnchor720"/>   33    33 FF      99 S    migration/2     smpboot_thread_fn
<a id="_idTextAnchor721"/>   39    39 FF       1 S    irq_work/3      smpboot_thread_fn
<a id="_idTextAnchor722"/>   40    40 FF      99 S    migration/3     smpboot_thread_fn
<a id="_idTextAnchor723"/>   66    66 FF      50 S    watchdogd       kthread_worker_fn
<a id="_idTextAnchor724"/>   78    78 FF      50 S    irq/14-4d000000 irq_thread
  &lt;…&gt;
  103   103 FF      50 S    irq/256-8000000 irq_thread
  107   107 FF      50 S    irq/293-xhci-hc irq_thread
  111   111 FF      50 S    irq/294-mmc0    irq_thread
  112   112 FF      50 S    irq/294-s-mmc0  irq_thread
  119   119 FF      50 S    irq/346-User Ke irq_thread
  120   120 FF      50 S    irq/476-mmc1    irq_thread
  121   121 FF      50 S    irq/476-s-mmc1  irq_thread
  123   123 FF      50 S    irq/295-mmc2    irq_thread
  124   124 FF      50 S    irq/295-s-mmc2  irq_thread
  127   127 FF      50 S    irq/472-fa00000 irq_thread
</code></pre>
    <div class="note">
      <p class="normal"><strong class="keyWord">IMPORTANT NOTE</strong></p>
      <p class="normal">The interrupt threads have all been given the default <code class="inlineCode">SCHED_FIFO</code> policy and a priority of <code class="inlineCode">50</code>. It doesn’t make sense to leave them at the defaults, however; now is your chance to assign priorities according to the importance of the interrupts compared to real-time user space threads.</p>
    </div>
    <p class="normal">Here is a <a id="_idIndexMarker1560"/>suggested order of descending thread priorities:</p>
    <ul>
      <li class="bulletList">The POSIX timers thread, <code class="inlineCode">posixcputmr</code>, should always have the highest priority.</li>
      <li class="bulletList">Hardware interrupts associated with the highest-priority real-time thread.</li>
      <li class="bulletList">The highest-priority real-time thread.</li>
      <li class="bulletList">Hardware interrupts for the progressively lower-priority real-time threads, followed by the thread itself.</li>
      <li class="bulletList">The next highest priority real-time thread.</li>
      <li class="bulletList">Hardware interrupts for non-real-time interfaces.</li>
      <li class="bulletList">The soft IRQ daemon, <code class="inlineCode">ksoftirqd</code>, which on RT kernels is responsible for running delayed interrupt routines and, prior to Linux 3.6, was responsible for running the network stack, the block I/O layer, and other things.</li>
    </ul>
    <p class="normal">You may need to experiment with different priority levels to achieve a balance. You can change the priorities using the <code class="inlineCode">chrt</code> command as part of the boot script with a command like this:</p>
    <pre class="programlisting con"><code class="hljs-con"># chrt -f -p 90 `pgrep irq/293-xhci-hcd:usb1`
</code></pre>
    <p class="normal">The <code class="inlineCode">pgrep</code> command is part of the <code class="inlineCode">procps</code> package.</p>
    <p class="normal">Now that we’ve been introduced to the real-time Linux kernel by way of threaded interrupt handlers, let’s dig deeper into its implementation.</p>
    <h1 id="_idParaDest-616" class="heading-1"><a id="_idTextAnchor725"/>Preemptible kernel locks</h1>
    <p class="normal">Making the <a id="_idIndexMarker1561"/>majority of kernel locks preemptible is the most intrusive change that <code class="inlineCode">PREEMPT_RT</code> makes.</p>
    <p class="normal">The problem occurs with spin locks, which are used for much of the kernel locking. A spin lock is a busy-wait mutex that does not require a context switch in the contended case, and so it is very efficient as long as the lock is held for a short time. Ideally, they should be locked for less than the time it would take to reschedule twice. </p>
    <p class="normal">The following diagram shows threads running on two different CPUs contending the same spin lock. <strong class="keyWord">CPU 0</strong> gets it first, forcing <strong class="keyWord">CPU 1</strong> to spin, waiting until it is unlocked:</p>
    <figure class="mediaobject"><img src="../Images/B18466_21_03.png" alt="Figure 21.3 – Spin lock" width="776" height="364"/></figure>
    <p class="packt_figref">Figure 21.3 – Spin lock</p>
    <p class="normal">The thread that holds the spin lock cannot be preempted since doing so may make the new thread enter the same code and deadlock when it tries to lock the same spin lock. Consequently, in mainline Linux, locking a spin lock disables kernel preemption, creating an atomic context. This means that a low-priority thread that holds a spin lock can prevent a high-priority thread from being scheduled, a condition otherwise <a id="_idIndexMarker1562"/>known as <strong class="keyWord">priority inversion</strong>.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">IMPORTANT NOTE</strong></p>
      <p class="normal">The solution adopted by <code class="inlineCode">PREEMPT_RT</code> is to replace almost all spin locks with RT-mutexes. A mutex is slower than a spin lock, but it is fully preemptible. Not only that, but RT-mutexes implement priority inheritance and so are not susceptible to priority inversion.</p>
    </div>
    <p class="normal">We now have an idea of what’s in the <code class="inlineCode">PREEMPT_RT</code> patches. So, how do we go about getting them?</p>
    <h2 id="_idParaDest-617" class="heading-2"><a id="_idTextAnchor726"/>Getting the PREEMPT_RT patches</h2>
    <p class="normal">Historically, the<a id="_idIndexMarker1563"/> RT developers did not create patch sets for every kernel version because of the amount of porting effort involved. On average, they created patches for every other kernel. This practice changed beginning with kernel version 5.9, after which a patch was generated for every kernel version. The most recent kernels that are supported at the time of writing are as follows:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><a id="_idTextAnchor727"/>6.13-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.12-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.11-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.10-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.9-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.8-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.7-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.6-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.5-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.4-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.3-rt</code></li>
      <li class="bulletList"><code class="inlineCode">6.1-rt</code>
        <div class="note">
          <p class="normal"><strong class="keyWord">IMPORTANT NOTE</strong></p>
          <p class="normal">The patches are available at <a href="https://www.kernel.org/pub/linux/kernel/projects/rt"><span class="url">https://www.kernel.org/pub/linux/kernel/projects/rt</span></a>. From <code class="inlineCode">6.12-rt</code> onward, the patches contain features and optimizations that have yet to be merged into the official kernel.</p>
        </div>
      </li>
    </ul>
    <p class="normal">If you are<a id="_idIndexMarker1564"/> using The Yocto Project, there is an RT version of the kernel already. Otherwise, it is possible that the place you got your kernel from already has the <code class="inlineCode">PREEMPT_RT</code> patch applied. If not, you will have to apply the patch yourself. Firstly, make sure that the <code class="inlineCode">PREEMPT_RT</code> patch version and your kernel version match exactly; otherwise, you will not be able to apply the patches cleanly. Then, you apply it in the normal way, as shown in the following command lines. You will then be able to configure the kernel with <code class="inlineCode">CONFIG_PREEMPT_RT_FULL</code>:</p>
    <pre class="programlisting con"><code class="hljs-con">$ cd linux-6.6.74
$ zcat patch-6.6.74-rt48.patch.gz | patch -p1
</code></pre>
    <p class="normal">There is a problem in the previous paragraph. The <code class="inlineCode">RT</code> patch will only apply if you are using a compatible mainline kernel. You are probably not, because that is the nature of embedded Linux kernels. Therefore, you will have to spend some time looking at failed patches and fixing them and then analyzing the board support for your target and adding any real-time support that is missing. These details are, once again, outside the scope of this book. If you are not sure what to do, you should request support from the kernel vendor that you are using and on kernel developer forums.</p>
    <h2 id="_idParaDest-618" class="heading-2"><a id="_idTextAnchor728"/>The Yocto Project and PREEMPT_RT</h2>
    <p class="normal">The Yocto Project<a id="_idIndexMarker1565"/> supplies <a id="_idIndexMarker1566"/>two standard kernel recipes: <code class="inlineCode">linux-yocto</code> and <code class="inlineCode">linux-yocto-rt</code> with the real-time patches already applied. Assuming that your target is supported by the Yocto kernels, you just need to select <code class="inlineCode">linux-yocto-rt</code> as your preferred kernel and declare that your machine is compatible.</p>
    <p class="normal">Since we are using the <code class="inlineCode">meta-ti-bsp</code> layer to build a TI kernel for the BeaglePlay, add these two lines to your <code class="inlineCode">conf/local.conf</code> to build a real-time kernel:</p>
    <pre class="programlisting code"><code class="hljs-code">PREFERRED_PROVIDER_virtual/kernel = "linux-ti-staging-rt"
COMPATIBLE_MACHINE_beagleplay-ti = "beagleplay-ti"
</code></pre>
    <p class="normal">So, now that we know where to get a real-time Linux kernel, let’s switch gears and talk about timing.</p>
    <h1 id="_idParaDest-619" class="heading-1"><a id="_idTextAnchor729"/>High-resolution timers</h1>
    <p class="normal">Timer<a id="_idIndexMarker1567"/> resolution is<a id="_idIndexMarker1568"/> important if you have precise timing requirements, which is typical for real-time applications. The default timer in Linux is a clock that runs at a configurable rate, typically 100 Hz for embedded systems and 250 Hz for servers and desktops. The interval between two timer ticks is known as a <strong class="keyWord">jiffy</strong> and, in the examples given previously, is 10 milliseconds on an embedded SoC and 4 milliseconds on a server.</p>
    <p class="normal">Linux gained more accurate timers from the real-time kernel project in version 2.6.18, and now they are available on all platforms, provided that there is a high-resolution timer source and device driver for it—which is almost always the case. You need to configure the kernel with <code class="inlineCode">CONFIG_HIGH_RES_TIMERS=y</code>.</p>
    <p class="normal">With this enabled, all the kernel and user space clocks will be accurate down to the granularity of the underlying hardware. Finding the actual clock granularity is difficult. The obvious answer is the value provided by <code class="inlineCode">clock_getres(2)</code>, but that always claims a resolution of 1 nanosecond.</p>
    <p class="normal">The <code class="inlineCode">cyclictest</code> tool has an option to analyze the times reported by the clock to guess the resolution:</p>
    <pre class="programlisting con"><code class="hljs-con"># cyclictest -R
# /dev/cpu_dma_latency set to 0us
WARN: reported clock resolution: 1 nsec
WARN: measured clock resolution approximately: 60 nsec
</code></pre>
    <p class="normal">You can also look at the kernel log messages for clock-related strings like this:</p>
    <pre class="programlisting con"><code class="hljs-con"># dmesg | grep clock
[    0.000000] clocksource: arch_sys_counter: mask: 0x3ffffffffffffff max_cycles: 0x2e2049d3e8, max_idle_ns: 440795210634 ns60563 Min:     13 Act:   67 Avg:   67 Max:     241
[    0.000001] sched_clock: 58 bits at 200MHz, resolution 5ns, wraps every 4398046511102ns
[    0.028415] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns
[    0.058173] PTP clock support registered
[    0.060830] clocksource: Switched to clocksource arch_sys_counter
[    0.685471] clk: Disabling unused clocks
</code></pre>
    <p class="normal">The two <a id="_idIndexMarker1569"/>methods provide noticeably different numbers, both of which are below 1 microsecond. Kernel logs show the base resolution of a timer (e.g., jiffies, HPET, TSC) rather than the effective resolution after applying timekeeping adjustments. <code class="inlineCode">cyclictest</code> measures actual wakeup latencies, which depend on scheduler wakeup delays, IRQ latencies, and the accuracy of the timer hardware.</p>
    <p class="normal">High-resolution timers can measure variations in latency with sufficient accuracy. Now, let’s look at a couple of ways to mitigate such non-determinism.</p>
    <h1 id="_idParaDest-620" class="heading-1"><a id="_idTextAnchor730"/>Avoiding page faults</h1>
    <p class="normal">A page fault occurs <a id="_idIndexMarker1570"/>when an application reads or writes to memory that is not committed to physical memory. It is impossible (or very hard) to predict when a page fault will happen, so they are another source of non-determinism in computers.</p>
    <p class="normal">Fortunately, there is a function that allows you to commit all the memory used by the process and lock it down so that it cannot cause a page fault. It is <code class="inlineCode">mlockall(2)</code>. These are its two flags:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">MCL_CURRENT</code>: Locks all pages currently mapped.</li>
      <li class="bulletList"><code class="inlineCode">MCL_FUTURE</code>: Locks pages that are mapped in later.</li>
    </ul>
    <p class="normal">You usually call <code class="inlineCode">mlockall</code> during the startup of the application with both flags set to lock all current and future memory mappings.</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">TIP</strong></p>
      <p class="normal"><code class="inlineCode">MCL_FUTURE</code> is not magic, in that there will still be a non-deterministic delay when allocating or freeing heap memory using <code class="inlineCode">malloc()/free()</code> or <code class="inlineCode">mmap()</code>. Such operations are best done at startup and not in the main control loops.</p>
    </div>
    <p class="normal">Memory allocated on the stack is trickier because it is done automatically, and if you call a function that makes the stack deeper than before, you will encounter more memory management delays. A simple fix is to grow the stack to a size larger than you think you will ever need at startup. The code would look like this:</p>
    <pre class="programlisting code"><code class="hljs-code">#define MAX_STACK (512*1024)
static void stack_grow (void)
{
    char dummy[MAX_STACK];
    memset(dummy, 0, MAX_STACK);
    return;
}
int main(int argc, char* argv[])
{
    &lt;…&gt;
    stack_grow ();
    mlockall(MCL_CURRENT | MCL_FUTURE);
    &lt;…&gt;
</code></pre>
    <p class="normal">The <code class="inlineCode">stack_grow()</code> function<a id="_idIndexMarker1571"/> allocates a large variable on the stack and then zeroes it out to force those pages of memory to be committed to this process.</p>
    <p class="normal">Interrupts are another source of non-determinism we should guard against.</p>
    <h1 id="_idParaDest-621" class="heading-1"><a id="_idTextAnchor731"/>Interrupt shielding</h1>
    <p class="normal">Using threaded<a id="_idIndexMarker1572"/> interrupt handlers helps mitigate interrupt overhead by running some threads at a higher priority than interrupt handlers that do not impact real-time tasks. If you are using a multi-core processor, you can take a different approach and shield one or more cores from processing interrupts completely, allowing them to be dedicated to real-time tasks instead. This works either with a normal Linux kernel or a <code class="inlineCode">PREEMPT_RT</code> kernel.</p>
    <p class="normal">Achieving this is a question of pinning the real-time threads to one CPU and the interrupt handlers to a different one. You can set the CPU affinity of a thread or process using the taskset command-line tool, or you can use the <code class="inlineCode">sched_setaffinity(2)</code> and <code class="inlineCode">pthread_setaffinity_np(3)</code> functions.</p>
    <p class="normal">To set the affinity of an interrupt, first note that there is a subdirectory for each interrupt number in <code class="inlineCode">/proc/irq/&lt;IRQ number&gt;</code>. The control files for the interrupt are in there, including a CPU mask in <code class="inlineCode">smp_affinity</code>. Write a bitmask to that file with a bit set for each CPU that is allowed to handle that IRQ.</p>
    <p class="normal">Stack growing and interrupt shielding are nifty techniques for improving responsiveness, but how can you tell whether they are actually working?</p>
    <h1 id="_idParaDest-622" class="heading-1"><a id="_idTextAnchor732"/>Measuring scheduling latencies</h1>
    <p class="normal">All the <a id="_idIndexMarker1573"/>configuration and tuning you may do will be pointless if you cannot show that your device meets the deadlines. You will need your own benchmarks for the final testing, but I will describe here two important measurement tools: <code class="inlineCode">cyclictest</code> and <code class="inlineCode">Ftrace</code>.</p>
    <h2 id="_idParaDest-623" class="heading-2"><a id="_idTextAnchor733"/>cyclictest</h2>
    <p class="normal"><code class="inlineCode">cyclictest</code> was <a id="_idIndexMarker1574"/>originally written by Thomas Gleixner and is now available on most platforms in a package named <code class="inlineCode">rt-tests</code>.</p>
    <p class="normal">If you are building <a id="_idIndexMarker1575"/>a Yocto real-time kernel, you can create a target image that includes <code class="inlineCode">rt-tests</code> by building the real-time image recipe:</p>
    <pre class="programlisting con"><code class="hljs-con">$ bitbake core-image-rt
</code></pre>
    <p class="normal">If you are building a TI real-time kernel for the BeaglePlay, then configure the kernel with <code class="inlineCode">CONFIG_ARM_PSCI_IDLE=y</code> so that <code class="inlineCode">cyclictest</code> can write to the <code class="inlineCode">/dev/cpu_dma_latency</code> socket.</p>
    <p class="normal">If you are building a TI real-time kernel for the BeaglePlay, then append <code class="inlineCode">rt-tests</code> to your image by modifying <code class="inlineCode">conf/local.conf</code>:</p>
    <pre class="programlisting con"><code class="hljs-con">IMAGE_INSTALL:append = " rt-tests"
</code></pre>
    <p class="normal">Build the minimal image recipe to install <code class="inlineCode">rt-tests</code> onto an image for the BeaglePlay:</p>
    <pre class="programlisting con"><code class="hljs-con">$ bitbake core-image-minimal
</code></pre>
    <p class="normal">If you are using Buildroot, you need to add the <code class="inlineCode">BR2_PACKAGE_RT_TESTS</code> package in the <strong class="screenText">Target packages</strong> | <strong class="screenText">Debugging, profiling and benchmark</strong> | <strong class="screenText">rt-tests</strong> menu.</p>
    <p class="normal"><code class="inlineCode">cyclictest</code> measures scheduling latencies by comparing the actual time taken for sleeping to the requested time. If there was no latency, they would be the same, and the reported latency would be 0. <code class="inlineCode">cyclictest</code> assumes a timer resolution of less than 1 microsecond.</p>
    <p class="normal">It has a large number of command-line options. To start with, you might try running this command as <code class="inlineCode">root</code> on the target:</p>
    <pre class="programlisting con"><code class="hljs-con"># cyclictest -l 100000 -m -p 99
# /dev/cpu_dma_latency set to 0us
policy: fifo: loadavg: 0.00 0.00 0.00 1/119 430
T: 0 (  422) P:99 I:1000 C: 100000 Min:      5 Act:    7 Avg:    7 Max:      48
</code></pre>
    <p class="normal">The options selected are as follows:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">-l N</code>: Loops N times (the default is unlimited).</li>
      <li class="bulletList"><code class="inlineCode">-m</code>: Locks memory with <code class="inlineCode">mlockall</code>.</li>
      <li class="bulletList"><code class="inlineCode">-p N</code>: Uses the real-time priority N.</li>
    </ul>
    <p class="normal">The result line shows the following, reading from left to right:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">T: 0</code>: This was thread 0, the only thread in this run. You can set the number of threads with parameter <code class="inlineCode">-t</code>.</li>
      <li class="bulletList"><code class="inlineCode">( 422)</code>: This was PID 422.</li>
      <li class="bulletList"><code class="inlineCode">P:99</code>: The priority was 99.</li>
      <li class="bulletList"><code class="inlineCode">I:1000</code>: The interval between loops was 1,000 microseconds. You can set the interval with the <code class="inlineCode">-i N</code> parameter.</li>
      <li class="bulletList"><code class="inlineCode">C:100000</code>: The final loop count for this thread was 100,000.</li>
      <li class="bulletList"><code class="inlineCode">Min: 5</code>: The minimum latency was 5 microseconds.</li>
      <li class="bulletList"><code class="inlineCode">Act: 7</code>: The actual latency was 7 microseconds. The <em class="italic">actual latency</em> is the most recent latency measurement, which only makes sense if you are watching <code class="inlineCode">cyclictest</code> as it runs.</li>
      <li class="bulletList"><code class="inlineCode">Avg: 7</code>: The average latency was 7 microseconds.</li>
      <li class="bulletList"><code class="inlineCode">Max: 48</code>: The maximum latency was 48 microseconds.</li>
    </ul>
    <p class="normal">This<a id="_idIndexMarker1576"/> was obtained on an idle system running a <code class="inlineCode">linux-ti-staging-rt</code> kernel as a quick demonstration of the tool. To be of real use, you<a id="_idIndexMarker1577"/> would run tests over a 24-hour period or longer while running a load representative of the maximum you expect. <code class="inlineCode">cyclictest</code> is a standard metric for scheduling latencies. However, it cannot help you identify and resolve specific problems with kernel latency. To do that, you need Ftrace.</p>
    <h2 id="_idParaDest-624" class="heading-2"><a id="_idTextAnchor734"/>Using Ftrace</h2>
    <p class="normal">The kernel function<a id="_idIndexMarker1578"/> tracer has tracers to help track down kernel latencies—that is what it was originally written for, after all. These tracers <a id="_idIndexMarker1579"/>capture the trace for the worst-case latency detected during a run, showing the functions that caused the delay.</p>
    <p class="normal">The tracers of interest, together with the kernel configuration parameters, are as follows:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">irqsoff</code>: <code class="inlineCode">CONFIG_IRQSOFF_TRACER</code> traces code that disables interrupts, recording the worst case.</li>
      <li class="bulletList"><code class="inlineCode">preemptoff</code>: <code class="inlineCode">CONFIG_PREEMPT_TRACER</code> is similar to <code class="inlineCode">irqsoff</code> but traces the longest time that kernel preemption is disabled (only available on preemptible kernels).</li>
      <li class="bulletList"><code class="inlineCode">preemptirqsoff</code>: Combines the previous two traces to record the longest time either <code class="inlineCode">irqs</code> and/or preemption are disabled for.</li>
      <li class="bulletList"><code class="inlineCode">wakeup</code>: Traces and records the maximum latency that it takes for the highest priority task to get scheduled after it has been woken up.</li>
      <li class="bulletList"><code class="inlineCode">wakeup_rt</code>: This is the same as wakeup but only for real-time threads with the <code class="inlineCode">SCHED_FIFO</code>, <code class="inlineCode">SCHED_RR</code>, or <code class="inlineCode">SCHED_DEADLINE</code> policies.</li>
      <li class="bulletList"><code class="inlineCode">wakeup_dl</code>: This is the same but only for deadline-scheduled threads with the <code class="inlineCode">SCHED_DEADLINE</code> policy.</li>
    </ul>
    <p class="normal">Be aware that running Ftrace adds a lot of latency, in the order of tens of milliseconds, every time it captures a new maximum, which Ftrace itself can ignore. However, it skews the results of user space tracers such as <code class="inlineCode">cyclictest</code>. In other words, ignore the results of <code class="inlineCode">cyclictest</code> if you run it while capturing traces.</p>
    <p class="normal">Selecting<a id="_idIndexMarker1580"/> the tracer is the same as for the function tracer we looked at in <a href="Chapter_16.xhtml#_idTextAnchor538"><em class="italic">Chapter 20</em></a>. Here is an example of capturing a trace for the maximum <a id="_idIndexMarker1581"/>period with preemption disabled for a period of 60 seconds:</p>
    <pre class="programlisting con"><code class="hljs-con"># echo preemptoff &gt; /sys/kernel/debug/tracing/current_tracer
# echo 0 &gt; /sys/kernel/debug/tracing/tracing_max_latency
# echo 1 &gt; /sys/kernel/debug/tracing/tracing_on
# sleep 60
# echo 0 &gt; /sys/kernel/debug/tracing/tracing_on
</code></pre>
    <p class="normal">The resulting trace, heavily edited, looks like this:</p>
    <pre class="programlisting con"><code class="hljs-con"># cat /sys/kernel/debug/tracing/trace
# tracer: preemptoff
#
# preemptoff latency trace v1.1.5 on 3.14.19-yocto-standard
# -----------------------------------------------------------
# latency: 1160 us, #384/384, CPU#0 | (M:preempt VP:0, KP:0, SP:0 HP:0)
# ----------------
# | task: init-1 (uid:0 nice:0 policy:0 rt_prio:0)
# ----------------
# =&gt; started at: ip_finish_output
# =&gt; ended at: __local_bh_enable_ip
#
#
#           _------=&gt; CPU#
#          / _-----=&gt; irqs-off
#         | / _----=&gt; need-resched
#         || / _---=&gt; hardirq/softirq
#         ||| / _--=&gt; preempt-depth
#         |||| /     delay
# cmd pid |||||   time | caller
#   \ /   |||||      \ | /
 init-1   0..s.    1us+: ip_finish_output
 init-1   0d.s2   27us+: preempt_count_add &lt;-cpdma_chan_submit
 init-1   0d.s3   30us+: preempt_count_add &lt;-cpdma_chan_submit
 init-1   0d.s4   37us+: preempt_count_sub &lt;-cpdma_chan_submit
 &lt;…&gt;
 init-1   0d.s2 1152us+: preempt_count_sub &lt;-__local_bh_enable
 init-1   0d..2 1155us+: preempt_count_sub &lt;-__local_bh_enable_ip
 init-1   0d..1 1158us+: __local_bh_enable_ip
 init-1   0d..1 1162us!: trace_preempt_on &lt;-__local_bh_enable_ip
 init-1   0d..1 1340us : &lt;stack trace&gt;
</code></pre>
    <p class="normal">Here, you can see that the longest period with kernel preemption disabled while running the trace was <code class="inlineCode">1160</code> microseconds. This simple fact is available by reading <code class="inlineCode">/sys/kernel/debug/tracing/tracing_max_latency</code>, but the previous trace goes further and gives<a id="_idIndexMarker1582"/> you the sequence of kernel function calls that led up to that measurement. The column marked <code class="inlineCode">delay</code> shows the point on the trail <a id="_idIndexMarker1583"/>where each function was called, ending with the call to <code class="inlineCode">trace_preempt_on()</code> at <code class="inlineCode">1162us</code>, at which point kernel preemption is once again enabled. With this information, you can look back through the call chain and (hopefully) work out whether this is a problem or not.</p>
    <p class="normal">The other tracers mentioned work in the same way.</p>
    <h2 id="_idParaDest-625" class="heading-2"><a id="_idTextAnchor735"/>Combining cyclictest and Ftrace</h2>
    <p class="normal">If <code class="inlineCode">cyclictest</code> reports <a id="_idIndexMarker1584"/>unexpectedly long latencies, you can use the <code class="inlineCode">breaktrace</code> option to abort the program and trigger Ftrace to obtain more information.</p>
    <p class="normal">You<a id="_idIndexMarker1585"/> invoke <code class="inlineCode">breaktrace</code> using <code class="inlineCode">-b&lt;N&gt;</code> or <code class="inlineCode">--breaktrace=&lt;N&gt;</code>, where <code class="inlineCode">N</code> is the number of microseconds of latency that will trigger the trace. You select the Ftrace tracer using <code class="inlineCode">-T[tracer name]</code> or one of the following:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">-C</code>: Context switch</li>
      <li class="bulletList"><code class="inlineCode">-E</code>: Event</li>
      <li class="bulletList"><code class="inlineCode">-f</code>: Function</li>
      <li class="bulletList"><code class="inlineCode">-w</code>: Wakeup</li>
      <li class="bulletList"><code class="inlineCode">-W</code>: Wakeup-RT</li>
    </ul>
    <p class="normal">For example, this will trigger the Ftrace function tracer when a latency greater than <code class="inlineCode">100</code> microseconds is measured:</p>
    <pre class="programlisting con"><code class="hljs-con"># cyclictest -a -t -p99 -b100
</code></pre>
    <p class="normal">We now have two complementary tools for debugging latency issues. <code class="inlineCode">cyclictest</code> detects the pauses and Ftrace provides the details.</p>
    <h1 id="_idParaDest-626" class="heading-1"><a id="_idTextAnchor736"/>Summary</h1>
    <p class="normal">The term <em class="italic">real-time</em> is meaningless unless you qualify it with a deadline and an acceptable miss rate. When you have these two pieces of information, you can determine whether or not Linux is a suitable candidate for the operating system and, if so, begin to tune your system to meet the requirements. Tuning Linux and your application to handle real-time events means making it more deterministic so that the real-time threads can meet their deadlines reliably. Determinism usually comes at the price of total throughput, so a real-time system is not going to be able to process as much data as a non-real-time system.</p>
    <p class="normal">It is not possible to provide mathematical proof that a complex operating system such as Linux will always meet a given deadline, so the only approach is through extensive testing using tools such as <code class="inlineCode">cyclictest</code> and Ftrace and, more importantly, using your own benchmarks for your own application.</p>
    <p class="normal">To improve determinism, you need to consider both the application and the kernel. When writing real-time applications, you should follow the guidelines given in this chapter about scheduling, locking, and memory.</p>
    <p class="normal">The kernel has a large impact on the determinism of your system. Thankfully, there has been a lot of work on this over the years. Enabling kernel preemption is a good first step. If you still find that it is missing deadlines more often than you would like, then you might want to consider <code class="inlineCode">PREEMPT_RT</code>. It can certainly produce low latencies, but you may have problems integrating the <code class="inlineCode">PREEMPT_RT</code> kernel patch with an older (pre 6.12) vendor kernel for your particular board. You may instead, or in addition, need to embark on the exercise of finding the cause of the latencies using Ftrace and similar tools.</p>
    <p class="normal">That brings me to the end of this dissection of embedded Linux. Being an engineer of embedded systems requires a very wide range of skills, which includes a low-level knowledge of hardware and how the kernel interacts with it. You need to be an excellent system engineer who can configure user applications and tune them to work in an efficient manner. All of this has to be done with hardware that is, often, only just capable of carrying out the task. There is a quotation that sums this up: <em class="italic">An engineer can do for a dollar what anyone else can do for two</em>. I hope that you will be able to achieve this with the information I have presented during the course of this book.</p>
    <h1 id="_idParaDest-627" class="heading-1"><a id="_idTextAnchor737"/>Further study</h1>
    <ul>
      <li class="bulletList"><em class="italic">Hard Real-Time Computing Systems: Predictable Scheduling Algorithms and Applications</em>, by Giorgio Buttazzo</li>
      <li class="bulletList"><em class="italic">Multicore Application Programming: for Windows, Linux, and Oracle Solaris</em>, by Darryl Gove</li>
    </ul>
    <h1 id="_idParaDest-628" class="heading-1"><a id="_idTextAnchor738"/>Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the authors and other readers: <a href="https://packt.link/embeddedsystems"><span class="url">https://packt.link/embeddedsystems</span></a></p>
    <p class="normal"><img src="../Images/QR_Code12308107448340296.png" alt="" role="presentation" width="354" height="354"/></p>
  </div>
</div></div>
<div id="book-content"><div id="sbo-rt-content"><div id="_idContainer190">
    <p class="BM-packtLogo"><img src="../Images/Packt_Logo_New1.png" alt="" role="presentation" width="832" height="211"/></p>
    <p class="normal"><a href="https://www.packt.com"><span class="url">packt.com</span></a></p>
    <p class="normal">Subscribe to our online digital library for full access to over 7,000 books and videos, as well as industry leading tools to help you plan your personal development and advance your career. For more information, please visit our website.</p>
    <h1 class="heading-1"><a id="_idTextAnchor739"/>Why subscribe?</h1>
    <ul>
      <li class="bulletList">Spend less time learning and more time coding with practical eBooks and Videos from over 4,000 industry professionals</li>
      <li class="bulletList">Improve your learning with Skill Plans built especially for you</li>
      <li class="bulletList">Get a free eBook or video every month</li>
      <li class="bulletList">Fully searchable for easy access to vital information</li>
      <li class="bulletList">Copy and paste, print, and bookmark content</li>
    </ul>
    <p class="normal">At <a href="https://www.packt.com"><span class="url">www.packt.com</span></a>, you can also read a collection of free technical articles, sign up for a range of free newsletters, and receive exclusive discounts and offers on Packt books and eBooks.</p>
    <p class="eop"/>
    <h1 class="mainHeading"><a id="_idTextAnchor740"/>Other Books You May Enjoy</h1>
    <p class="normal">If you enjoyed this book, you may be interested in these other books by Packt:</p>
    <p class="BM-bookCover"><a href="https://www.packtpub.com/en-us/product/mastering-pytorch-9781801074308"><img src="../Images/B22104_Mockup_Cover_High_Res.png" alt="" role="presentation" width="510" height="629"/></a></p>
    <p class="normal"><strong class="keyWord">The Embedded Linux Security Handbook</strong></p>
    <p class="normal">Matt St. Onge</p>
    <p class="normal">ISBN: 978-1-83588-564-2</p>
    <ul>
      <li class="bulletList">Understand how to determine the optimal hardware platform based on design criteria</li>
      <li class="bulletList">Recognize the importance of security by design in embedded systems</li>
      <li class="bulletList">Implement advanced security measures such as TPM, LUKS encryption, and Secure Boot processes</li>
      <li class="bulletList">Discover best practices for secure life cycle management, including appliance update and upgrade mechanisms</li>
      <li class="bulletList">Create a secure software supply chain efficiently</li>
      <li class="bulletList">Implement childproofing by controlling access and resources on the appliance</li>
    </ul>
    <p class="eop"/>
    <p class="BM-bookCover"><a href="https://www.packtpub.com/en-us/product/building-llm-powered-applications-9781835462317"><img src="../Images/B17934.png" alt="" role="presentation" width="510" height="629"/></a></p>
    <p class="normal"><strong class="keyWord">Linux Device Driver Development, Second Edition</strong></p>
    <p class="normal">John Madieu</p>
    <p class="normal">ISBN: 978-1-80324-006-0</p>
    <ul>
      <li class="bulletList">Download, configure, build, and tailor the Linux kernel</li>
      <li class="bulletList">Describe the hardware using a device tree</li>
      <li class="bulletList">Write feature-rich platform drivers and leverage I2C and SPI buses</li>
      <li class="bulletList">Get the most out of the new concurrency managed workqueue infrastructure</li>
      <li class="bulletList">Understand the Linux kernel timekeeping mechanism and use time-related APIs</li>
      <li class="bulletList">Use the regmap framework to factor the code and make it generic</li>
      <li class="bulletList">Offload CPU for memory copies using DMA</li>
      <li class="bulletList">Interact with the real world using GPIO, IIO, and input subsystems</li>
    </ul>
    <p class="eop"/>
    <h1 class="heading-1"><a id="_idTextAnchor741"/>Packt is searching for authors like you</h1>
    <p class="normal">If you’re interested in becoming an author for Packt, please visit <a href="https://authors.packtpub.com"><span class="url">authors.packtpub.com</span></a> and apply today. We have worked with thousands of developers and tech professionals, just like you, to help them share their insight with the global tech community. You can make a general application, apply for a specific hot topic that we are recruiting an author for, or submit your own idea.</p>
  </div>
  <div id="_idContainer191" class="Basic-Text-Frame">
    <p class="eop"/>
    <h1 class="heading-1"><a id="_idTextAnchor742"/>Share your thoughts</h1>
    <p class="normal">Now you’ve finished <em class="italic">Mastering Embedded Linux Development, Fourth Edition</em>, we’d love to hear your thoughts! If you purchased the book from Amazon, please <a href="https://packt.link/r/1803232595"><span class="url">click here to go straight to the Amazon review page</span></a> for this book and share your feedback or leave a review on the site that you purchased it from.</p>
    <p class="normal">Your review is important to us and the tech community and will help us make sure we’re delivering excellent quality content.</p>
  </div>
</div></div></body></html>