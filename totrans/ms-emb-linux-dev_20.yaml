- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Container Images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, I will introduce the principles of the DevOps movement and
    demonstrate how to apply them to embedded Linux. First, we will learn how to use
    Docker to bundle a Python application together with its user-space environment
    inside a container image. Next, we will set up a Docker-based **continuous integration
    and continuous delivery** (**CI/CD**) pipeline for a Python Bluetooth server application.
    Then I will demonstrate how to quickly add Docker to a Yocto image for the Raspberry
    Pi 4\. Lastly, we will deploy a containerized software update to a Raspberry Pi
    4 running Docker.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is DevOps?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevOps and embedded Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Python applications with Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a CI/CD pipeline for a Python application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding Docker to a Yocto image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating software with Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To follow along with the examples, make sure you have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An Ubuntu 24.04 or later LTS host system with at least 90 GB of free disk space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A user account with admin or sudo privileges on the host system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yocto 5.0 (Scarthgap) LTS release
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A microSD card reader and card
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`balenaEtcher` for Linux'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Ethernet cable and router with an available port for network connectivity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Raspberry Pi 4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A 5 V USB-C power supply capable of delivering 3 A
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should have already built the 5.0 (Scarthgap) LTS release of Yocto in [*Chapter
    6*](Chapter_04.xhtml#_idTextAnchor110). If you have not, then please refer to
    the *Compatible Linux Distribution* and *Build Host Packages* sections of the
    *Yocto Project Quick Build* guide ([https://docs.yoctoproject.org/brief-yoctoprojectqs/](https://docs.yoctoproject.org/brief-yoctoprojectqs/))
    before building Yocto on your Linux host according to the instructions in [*Chapter
    6*](Chapter_04.xhtml#_idTextAnchor110).
  prefs: []
  type: TYPE_NORMAL
- en: 'The code used in this chapter can be found in the chapter folder in this book’s
    GitHub repository: [https://github.com/PacktPublishing/Mastering-Embedded-Linux-Development/tree/main/Chapter16](https://github.com/PacktPublishing/Mastering-Embedded-Linux-Development/tree/main/Chapter16).'
  prefs: []
  type: TYPE_NORMAL
- en: Getting Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To install Docker on Ubuntu 24.04 LTS:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the package repositories:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install Docker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the Docker daemon and enable it to start at boot time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add yourself to the `docker` group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Restart the Docker daemon:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Replace `<username>` in *step 4* with your username. I recommend creating your
    own Ubuntu user account rather than using the default `ubuntu` user account, which
    is supposed to be reserved for administrative tasks.
  prefs: []
  type: TYPE_NORMAL
- en: What is DevOps?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since its inception in 2009, the **DevOps movement** has taken the software
    industry by storm. Patrick Debois coined the term **DevOps** after seeing the
    2009 Velocity Conference presentation *10 Deploys per Day*. Patrick is one of
    the four co-authors of *The DevOps Handbook* along with Gene Kim, Jez Humble,
    and John Willis. The *DevOps Handbook* was first published in 2016 and codifies
    the principles of the movement. These ideas originate from the Lean manufacturing
    and Agile software development communities. DevOps practices are closely aligned
    with Agile methodologies like Scrum and Kanban. The goal of all these approaches
    is always to ship quality products to customers faster.
  prefs: []
  type: TYPE_NORMAL
- en: DevOps strives to integrate the development and operations teams within an organization.
    Historically, the people who operate software at a company are separate from the
    people who develop that same software. Sometimes there is a dedicated team of
    system administrators (IT) responsible for provisioning servers and deploying
    scheduled software releases. This separation of concerns combined with big bang
    deployments inevitably leads to lengthy delays and outages. The relationship between
    development and operations becomes adversarial as finger-pointing ensues amid
    failures. By contrast, DevOps encourages close collaboration, rapid iteration,
    and experimentation. Mistakes are how we learn.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous integration and continuous deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Two core concepts of Lean manufacturing are the notions of a **value stream**
    and the **lead time** associated with that. The Lean philosophy comes from the
    automotive industry, specifically the Toyota Production System. If a value stream
    is a factory assembly line, then the lead time is the time from when a customer
    request is submitted to when it is fulfilled. Lead time is one of the metrics
    by which the performance of a value stream is measured. Reducing lead time enables
    factories to build cars faster. The same idea applies to software.
  prefs: []
  type: TYPE_NORMAL
- en: In software, we can think of lead time as the time from when a feature request
    is submitted to when that finished feature is deployed to production. Every time
    a developer commits and pushes a change to the software an automated build is
    kicked off. A suite of unit tests is run against this newly changed code as part
    of the automated build. A code change can only be merged to the main branch if
    the build succeeds and the test suite passes. All these checks are scripted and
    performed automatically. The longer it takes to build the software and execute
    the tests, the longer the lead time is.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating code is only part of the value stream. To deliver value to customers,
    software must be deployed to production. That typically means tagging a release,
    spinning up servers in the cloud, and installing the new release onto those servers.
    There are several techniques to ensure deployments go smoothly. Run integration
    tests first. Roll releases out incrementally across your fleet of servers. Roll
    back to a prior release in the event of a bad software update. Maximum developer
    productivity can only be achieved when software is deployed to production multiple
    times a day. The value stream is the **CI/CD** pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure as code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need more than source code to build and deploy most software. Today, most
    modern software development involves Docker. An application typically requires
    a Dockerfile, makefile, and shell scripts to build and bundle the software for
    release. These items are invoked by a YAML file at different stages of the CI/CD
    pipeline. Since they aren’t part of the actual software, we may not think of these
    items as code per se. Still, they reside inside version control along with the
    source code and likewise need to be reviewed and maintained. Because the building
    and bundling of the software is entirely scripted, the task is easily repeatable.
  prefs: []
  type: TYPE_NORMAL
- en: The amount of YAML involved increases during deployment. Cloud-native tools
    like Terraform and CloudFormation are YAML-based. We provision cloud infrastructure
    and deploy software release artifacts onto it with these tools by applying declarative
    YAML files. Deployment is driven by the same top-level YAML file used for building
    and bundling. That way, the whole process is automated from end to end. While
    they may not look like it, YAML files are indeed code and should adhere to the
    same standards of quality as code written in high-level programming languages
    like Python.
  prefs: []
  type: TYPE_NORMAL
- en: Security is a shared responsibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When time to market is everything, security takes a back seat. Like deployments,
    security is often relegated to operations. High-profile incidents like the Log4j
    vulnerability of 2022 and the `xz` backdoor of 2024 demonstrate how critical security
    is to day-to-day business. DevOps argues that security is a concern at every stage
    of development, not an afterthought. Intellectual property and customer data are
    always encrypted. Secrets like keys and passphrases are stored safely outside
    of version control. Security best practices are everyone’s responsibility and
    need to be enforced from the outset.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and observability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Gathering telemetry in the form of system stats, logs, and traces provides us
    with visibility into the health and performance of our applications. Once we have
    telemetry, it can be displayed on a Grafana dashboard for analysis. That way,
    we can detect performance regressions, resource leaks, and other systemic problems
    before they result in a costly service outage. Real-time insights trigger rapid
    incident responses and resolutions. More importantly, telemetry gives us quick
    unfiltered feedback on how we are doing as developers so that we can learn and
    improve.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous improvement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lean manufacturing espouses short lead times, small changes, and rapid iteration.
    *The Lean Startup* by Eric Ries popularized the notion of a **minimum viable product**
    (**MVP**). An MVP is a version of a product with just enough functionality that
    initial customers can offer feedback on said product. This feedback is reviewed,
    and improvements are made to the next version in rapid succession. A software
    CI/CD pipeline cranks out MVPs faster than a factory assembly line.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous feedback incentivizes developers to ship small incremental improvements
    with greater frequency. An MVP approach enables teams to see what works and what
    doesn’t before committing more time and resources. This way, adjustments can be
    made so that more value is delivered to users. DevOps argues that integrating
    small changes sooner results in better outcomes. This is in stark contrast to
    having a lone developer toil away on a long-lived feature branch without any feedback
    from users.
  prefs: []
  type: TYPE_NORMAL
- en: Transparency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Collaboration is unlikely if an organization’s culture discourages it. Fear
    pervades dysfunctional organizations. Individuals act strategically by hiding
    information away from others who could benefit from it. This behavior leads to
    silos where all communication happens in private meetings and chats on a need-to-know
    basis. Mistakes are hidden for fear of punishment (e.g., leadership “shoots the
    messenger”). The DevOps mindset is one of openness. Successes, failures, and ideas
    are shared across the organization to promote best practices. If you are struggling
    with a task, then you ask your team for help.
  prefs: []
  type: TYPE_NORMAL
- en: DevOps and Embedded Linux
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hardware is hard. PCB layout, contract manufacturing, and board revisions cost
    time and money. The risks are bigger than with software. Lead times are longer,
    and mistakes can be catastrophic. Embedded Linux forms the bridge between hardware
    and software.
  prefs: []
  type: TYPE_NORMAL
- en: Embedded Linux engineers work closely with electrical engineers during board
    bring-up, troubleshooting issues as they arise. It’s not uncommon to ask an electrical
    engineer to rewire a component or add a pull-up resistor. PCB layout is extremely
    complex. Nobody is perfect, so a new board rarely ever boots the first time around.
  prefs: []
  type: TYPE_NORMAL
- en: With such high stakes, it might seem like DevOps principles are a bad fit for
    hardware products. Industry trends like **test-driven development** (**TDD**)
    are often dismissed as impractical by experienced embedded developers. Automated
    testing is harder when dealing with real hardware but not impossible. Investing
    time and energy in establishing a CI/CD pipeline pays dividends once features
    begin landing in rapid succession. Management may question why you are doing so
    much process work up front, but their tune will change when new products begin
    to be delivered ahead of schedule.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous integration and cross-compilation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linux and much of the middleware on top of it is written mostly in C. This means
    it must be compiled natively for the target’s **instruction set architecture**
    (**ISA**). In the cloud, that ISA is usually x86-64 running on Intel or AMD CPUs.
    On embedded devices capable of running Linux, it is increasingly 64-bit Arm. Since
    most cloud infrastructure runs on Intel and AMD CPUs, building software for embedded
    Linux requires a cross-compiling toolchain. However, cross-compilation is not
    a common use case for cloud-based CI/CD services like GitHub Actions or GitLab
    CI.
  prefs: []
  type: TYPE_NORMAL
- en: Buildroot and Yocto are both designed to cross-compile embedded Linux images,
    but running these tools in the cloud can be challenging. They require lots of
    disk space and the extended build times are prohibitive. Build times can be improved
    by employing incremental builds and intelligent caching (e.g., Yocto’s shared
    `sstate-cache`). Alternatively, you can use Docker in conjunction with QEMU to
    cross-compile container images for 64-bit Arm. This containerized approach works
    great for user space but emulating the target architecture slows down compilation.
  prefs: []
  type: TYPE_NORMAL
- en: Automated testing on real hardware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the biggest challenges involved in shipping hardware is implementing
    **hardware-in-the-loop** (**HIL**) testing. Like cross-compilation, automated
    testing can be done easily in the cloud with QEMU, but there is no substitute
    for testing software on its intended hardware. When safety is a concern, HIL testing
    is an obligation, not a cautionary measure. The challenge is in how to automate
    it. This is why HIL testing often requires as much effort as coding the software.
  prefs: []
  type: TYPE_NORMAL
- en: The most effective form of HIL testing is to simulate the real world. Hardware
    interacts with the real world through sensors and actuators. It receives input
    from sensors and sends output to actuators via communications interfaces like
    I2C, SPI, and CAN. We simulate the real world by modeling it with software. This
    software model runs on a separate Linux machine. It sends and receives messages
    over the various comms interfaces just like the sensors and actuators in the actual
    system. For example, to test an EV charger we would connect a PCB on a test bench
    to a mock battery running our model.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous delivery and OTA updates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When a deployment fails in the cloud, we simply delete the problem servers and
    spin up new instances. We don’t need to worry about bricking servers because we
    can always just start over from scratch. Reprovisioning servers is relatively
    quick and painless to do in the cloud. The same cannot be said for consumer devices
    out in the field. If a device cannot boot, then it is useless. Similarly, if a
    connected device suddenly becomes disconnected from the internet, then it cannot
    receive critical OTA updates.
  prefs: []
  type: TYPE_NORMAL
- en: OTA updates are how the continuous delivery of software happens in embedded
    systems. OTA updates need to be fail-safe in the face of accidental power loss.
    A failed OTA update cannot result in a partial or unknown flash image. Otherwise,
    the device may be rendered unbootable. Buildroot and Yocto support fail-safe OTA
    update solutions like Mender, RAUC, and SWUpdate. Even though these tools will
    save you from bricking your fleet, you should still test your software releases
    thoroughly before a full rollout. Nothing sinks a new product launch quicker than
    a bad user experience.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure as code and build systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Buildroot relies on makefiles. Yocto consists of BitBake recipes. Like the YAML
    files that define your cloud infrastructure, this build metadata also qualifies
    as code and should be kept in version control. That includes board defconfigs
    and package definitions for Buildroot. For Yocto, the build metadata is comprised
    of BSP and distro layers. It also pays to containerize your embedded Linux build
    environment by defining a Dockerfile for it. This makes it easier to spin up a
    CI/CD pipeline to build images for your target device. It also makes it easier
    for others to reproduce your build environment so that they can develop locally
    on their machines.
  prefs: []
  type: TYPE_NORMAL
- en: Securing edge devices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The internet is full of danger. The infamous Mirai botnet was started by kids
    wanting to knock out rival Minecraft servers. The idea evolved into large-scale
    **distributed denial-of-service** (**DDoS**) attacks. Mirai hijacks consumer IoT
    devices like webcams and home routers and points them at selected websites. Securing
    the boot and OTA update processes prevents malware like Mirai from running on
    users’ devices. The mechanisms for securing the boot and OTA update processes
    are described in [*Chapter 10*](Chapter_10.xhtml#_idTextAnchor341). Security is
    table stakes at the edge because once your fleet is hijacked, you can’t get it
    back.
  prefs: []
  type: TYPE_NORMAL
- en: Secure boot means that a device will only boot from an image that has been cryptographically
    signed by the device manufacturer. A signature verification step is inserted at
    boot time to ensure the authenticity of the latest image applied by an OTA update.
    Users also expect all data to be encrypted on their devices for privacy. Auto-unlocking
    an encrypted volume requires a passphrase on startup. Any keys or passphrases
    needed by a device at runtime should be stored safely inside a TPM or secure element.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and observability of edge devices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Gathering telemetry from consumer devices is difficult because they are deployed
    in people’s homes and offices. Like all other devices connected to the internet,
    any new product that wants to stream telemetry up to the cloud will need to get
    past the firewall. This typically requires a user to open an outgoing port on
    their Wi-Fi router. Users may not be network savvy enough or object to doing this
    for privacy. While standard IoT protocols for telemetry like MQTT exist, they
    are not always a good fit for every application. There is still much room for
    innovation in this space by startups like Golioth and Memfault.
  prefs: []
  type: TYPE_NORMAL
- en: Enough theory and rationale. Let’s put these principles into practice. We’ll
    start by performing a containerized software deployment. You should have already
    installed Docker on your Linux host according to the instructions in the *Getting
    Docker* section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Python applications with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker offers another way to bundle Python code with software written in other
    languages. The idea behind Docker is that instead of packaging and installing
    your application onto a preconfigured server environment, you build and ship a
    container image with your application and all its runtime dependencies. A container
    image is more like a virtual environment than a virtual machine. A virtual machine
    is a complete system image including a kernel and an operating system. A container
    image is a minimal user-space environment that only comes with the binaries needed
    to run your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Virtual machines run on top of a hypervisor that emulates hardware. Containers
    run directly on top of the host operating system. Unlike virtual machines, containers
    are able to share the same operating system and kernel without the use of hardware
    emulation. Instead, they rely on two special features of the Linux kernel for
    isolation: namespaces and cgroups. Docker did not invent container technology,
    but they were the first to build tooling that made them easy to use. The tired
    excuse of “works on my machine” no longer flies now that Docker makes it so simple
    to build and deploy container images.'
  prefs: []
  type: TYPE_NORMAL
- en: Anatomy of a Dockerfile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **Dockerfile** describes the contents of a Docker image. Every Dockerfile
    contains a set of instructions specifying what environment to use and which commands
    to run. Instead of writing a Dockerfile from scratch, we will use an existing
    Dockerfile for a project template. This Dockerfile generates a Docker image for
    a very simple Flask web application that you can extend to fit your needs. The
    Docker image is built on top of Debian Bookworm. Besides Flask, the Docker image
    also includes uWSGI and Nginx for better performance.
  prefs: []
  type: TYPE_NORMAL
- en: Start by pointing your web browser at the `uwsgi-nginx-flask-docker` project
    on GitHub ([https://github.com/tiangolo/uwsgi-nginx-flask-docker](https://github.com/tiangolo/uwsgi-nginx-flask-docker)).
    Then, click on the link to the `python-3.12` Dockerfile from the `README.md` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, look at the first line in that Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This `FROM` command tells Docker to pull an image named `uwsgi-nginx` from
    the `tiangolo` namespace with `python3.12` from Docker Hub. Docker Hub is a public
    registry where people publish their Docker images for others to fetch and deploy.
    You can set up your own image registry using a service such as AWS ECR or Quay
    if you prefer. You will need to insert the name of your registry service in front
    of your namespace like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Otherwise, Docker defaults to fetching images from Docker Hub. `FROM` is like
    an `include` statement in a Dockerfile. It inserts the contents of another Dockerfile
    into yours so that you have something to build on top of. I like to think of this
    approach as layering images. Debian Bookworm is the base layer, followed by Python
    3.12, then uWSGI plus Nginx, and finally your Flask application. You can learn
    more about how image layering works by digging into the `python3.12` Dockerfile
    at [https://hub.docker.com/r/tiangolo/uwsgi-nginx](https://hub.docker.com/r/tiangolo/uwsgi-nginx).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the next line of interest in the Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: A `RUN` instruction runs a command. Docker executes the `RUN` instructions contained
    in the Dockerfile sequentially in order to build the resulting Docker image. If
    you look at the `requirements.txt` file in the Git repo, you will see that this
    `RUN` instruction installs Flask in the system `site-packages` directory. We know
    that `pip` is available because the `uwsgi-nginx` base image also includes Python
    3.12.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s skip over Nginx’s environment variables and go straight to copying:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This particular Dockerfile is located inside a Git repo along with several other
    files and subdirectories. The `COPY` instruction copies a directory from the host
    Docker runtime environment (usually a Git clone of a repo) into the container
    being built.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `python3.12.dockerfile` file you are looking at resides in a `docker-images`
    subdirectory of the `tiangolo/uwsgi-nginx-flask-docker` repo. Inside that `docker-images`
    directory is an `app` subdirectory containing a Hello World Flask web application.
    This `COPY` instruction copies the `app` directory from the example repo into
    the root directory of the Docker image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `WORKDIR` instruction tells Docker which directory to work from inside the
    container. In this example, the `/app` directory that it just copied becomes the
    working directory. If the target working directory does not exist, then `WORKDIR`
    creates it. Any subsequent non-absolute paths that appear in this Dockerfile are
    hence relative to the `/app` directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s see how an environment variable gets set inside the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`ENV` tells Docker that what follows is an environment variable definition.
    `PYTHONPATH` is an environment variable that expands into a list of colon-delimited
    paths where the Python interpreter looks for modules and packages.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s jump a few lines down to the second `RUN` instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `RUN` instruction tells Docker to run a command from the shell. In this
    case, the command being run is `chmod`, which changes file permissions. Here,
    it renders the `/entrypoint.sh` executable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next line in this Dockerfile is optional:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`ENTRYPOINT` is the most interesting instruction in this Dockerfile. It exposes
    an executable to the Docker host command line when starting the container. This
    lets you pass arguments from the command line down to the executable inside the
    container. You can append these arguments after `docker run` `<image>` on the
    command line. If there is more than one `ENTRYPOINT` instruction in a Dockerfile,
    then only the last `ENTRYPOINT` is executed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The last line in the Dockerfile is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Like `ENTRYPOINT` instructions, `CMD` instructions execute at container start
    time rather than build time. When an `ENTRYPOINT` instruction is defined in a
    Dockerfile, a `CMD` instruction defines default arguments to be passed to that
    `ENTRYPOINT`. In this instance, the `/start.sh` path is the argument passed to
    `/entrypoint.sh`. The last line in `/entrypoint.sh` executes `/start.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `/start.sh` script comes from the `uwsgi-nginx` base image. `/start.sh`
    starts Nginx and uWSGI after `/entrypoint.sh` has configured the container runtime
    environment for them. When `CMD` is used in conjunction with `ENTRYPOINT`, the
    default arguments set by `CMD` can be overridden from the Docker host command
    line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most Dockerfiles do not have an `ENTRYPOINT` instruction, so the last line
    of a Dockerfile is usually a `CMD` instruction that runs in the foreground instead
    of default arguments. You can use this Dockerfile trick to keep a general-purpose
    Docker container running for development:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Except for `ENTRYPOINT` and `CMD`, all of the instructions in this example `python-3.12`
    Dockerfile only execute when the container is being built.
  prefs: []
  type: TYPE_NORMAL
- en: Building a Docker image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we can build a Docker image, we need a Dockerfile. You may already have
    some Docker images on your system.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see a list of Docker images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s fetch and build the Dockerfile we just dissected:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone the repo containing the Dockerfile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Switch to the `docker-images` subdirectory inside the repo:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Copy `python3.12.dockerfile` to a file named `Dockerfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build an image from the Dockerfile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the image is done building, it will appear in your list of local Docker
    images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The newly built my-image should appear in the list.
  prefs: []
  type: TYPE_NORMAL
- en: Running a Docker image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now have a Docker image built that we can run as a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a list of running containers on your system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'To run a container based on `my-image`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'If the preceding command fails because port `80` is busy, then substitute port
    `8080` for `80`. Now observe the status of your running container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: You should see a container named `my-container` based on an image named `my-image`
    in the list. The `-p` option in the `docker run` command maps a container port
    to a host port. So, container port `80` maps to host port `80` in this example.
    This port mapping allows the Flask web server running inside the container to
    service HTTP requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'To stop `my-container`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now check the status of your running container again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '`my-container` should no longer appear in the list of running containers. Is
    the container gone? No, it is only stopped. You can still see `my-container` and
    its status by adding the `-a` option to the `docker` `ps` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We’ll look at how to delete containers we no longer need a bit later.
  prefs: []
  type: TYPE_NORMAL
- en: Fetching a Docker image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier in this section, I touched on image registries such as Docker Hub, AWS
    ECR, and Quay. As it turns out, the Docker image that we built locally from a
    cloned Git repo is already published on Docker Hub. It is much quicker to fetch
    the prebuilt image from Docker Hub than to build it yourself on your system. The
    Docker images for the project can be found at [https://hub.docker.com/r/tiangolo/uwsgi-nginx-flask](https://hub.docker.com/r/tiangolo/uwsgi-nginx-flask).
  prefs: []
  type: TYPE_NORMAL
- en: 'To pull the same Docker image that we built as `my-image` from Docker Hub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now look at your list of Docker images again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: You should see a new `uwsgi-nginx-flask` image in the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this newly fetched image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: You can substitute the full image name (`repo:tag`) in the preceding `docker
    run` command with the corresponding image ID (hash) from `docker images` if you
    prefer not to type out the full image name.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing a Docker image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To publish a Docker image to Docker Hub, you must first have an account and
    log in to it. You can create an account on Docker Hub by going to the [https://hub.docker.com](https://hub.docker.com)
    website and signing up. Once you have an account, then you can push an existing
    image to your Docker Hub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to the Docker Hub image registry from the command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Enter your Docker Hub username and password when prompted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Tag an existing image with a new name that starts with the name of your repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Replace `<repository>` in the preceding command with the name of your repository
    (the same as your username) on Docker Hub. You can also substitute the name of
    another existing image you wish to push for `my-image:latest`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Push the image to the Docker Hub image registry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Again, make the same replacements as you did for *step 3*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Images pushed to Docker Hub are publicly available by default. To visit the
    web page for your newly published image, go to [https://hub.docker.com/repository/docker/<repository>/my-image](https://hub.docker.com/repository/docker/repository/my-image).
    Replace `<repository>` in the preceding URL with the name of your repository (the
    same as your username) on Docker Hub. You can also substitute the name of the
    actual image you pushed for `my-image:latest` if different. If you click on the
    **Tags** tab on that web page, you should see the `docker pull` command for fetching
    that image.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We know that `docker images` lists images and `docker ps` lists containers.
    Before we can delete a Docker image, we must first delete any containers that
    reference it. To delete a Docker container, you first need to know the container’s
    name or ID:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the target Docker container’s name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Stop the container if it is running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Delete the Docker container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Replace `flask-container` in the two preceding commands with the container name
    or ID from *step 1*. Every container that appears under `docker ps` also has an
    image name or ID associated with it. Once you have deleted all the containers
    that reference an image, you can then delete the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker image names (`repo:tag`) can get quite long (for example, `tiangolo/uwsgi-nginx-flask:python3.12`).
    For that reason, I find it easier to just copy and paste an image’s ID (hash)
    when deleting:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the Docker image’s ID:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Delete the Docker image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Replace `<image-ID>` in the preceding command with the image ID from *step 1*.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you simply want to blow away all the containers and images that you are
    no longer using on your system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '`docker system prune` deletes all stopped containers and dangling images.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve seen how `pip` can be used to install a Python application’s dependencies.
    You simply add a `RUN` instruction that calls `pip install` to your Dockerfile.
    Because containers are sandboxed environments, they offer many of the same benefits
    that virtual environments do. But unlike `conda` and `venv` virtual environments,
    Buildroot and Yocto both have support for Docker containers. Buildroot has the
    `docker-engine` and `docker-cli` packages. Yocto has the `meta-virtualization`
    layer. If your device needs isolation because of Python package conflicts, then
    you can achieve that with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: The `docker run` command provides options for exposing operating system resources
    to containers. Specifying a bind mount allows a file or directory on the host
    machine to be mounted inside a container for reading and writing. By default,
    containers publish no ports to the outside world. When you ran your `my-container`
    image, you used the `-p` option to publish port `80` from the container to port
    `80` on the host. The `--device` option adds a host device file under `/dev` to
    an unprivileged container. If you wish to grant access to all devices on the host,
    then use the `--privileged` option.
  prefs: []
  type: TYPE_NORMAL
- en: What containers excel at is deployment. Being able to push a Docker image that
    can then be easily pulled and run on any of the major cloud platforms has revolutionized
    the DevOps movement. Docker is also making inroads in the embedded Linux space
    thanks to OTA update solutions such as balena. One of the downsides of Docker
    is the storage footprint and memory overhead of the runtime. The Go binaries are
    a bit bloated, but Docker runs on quad-core 64-bit Arm SBCs like the Raspberry
    Pi 4 and BeaglePlay just fine. If your target device has enough power, then run
    Docker on it. Your software development team will thank you.
  prefs: []
  type: TYPE_NORMAL
- en: '**IMPORTANT NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: Podman is an alternative to Docker that offers a lighter, daemonless architecture.
    Unlike Docker, Podman does not require a service to be continuously running in
    the background, making it more resource-efficient. Its support for rootless containers
    enhances security and its compatibility with OCI standards ensures flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a CI/CD pipeline for a Python application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker is not just for deploying software to the cloud. Cloud-based CI/CD services
    can build and publish 64-bit Arm container images for deploying to edge devices.
    Containerized software updates are less disruptive than full A/B image updates
    because they don’t require a reboot. Users get nervous when they see their devices
    fall offline even if just for a moment.
  prefs: []
  type: TYPE_NORMAL
- en: Containerized software updates are also less risky than full A/B image updates
    because they don’t include a Linux kernel. An edge device may fail to boot because
    of a bad kernel update. Unless there is a fail-safe mechanism in place, the device
    is effectively bricked. Upstream kernel modules fall into disrepair as hardware
    ages out. Kernel upgrades are especially dangerous because they can introduce
    kernel panics.
  prefs: []
  type: TYPE_NORMAL
- en: Back in the *Building on top of an existing BSP* section of [*Chapter 7*](Chapter_05.xhtml#_idTextAnchor151),
    we added a custom layer for a Python Bluetooth server application to a Yocto image
    for the Raspberry Pi 4\. We can deploy the same application to a fleet of Raspberry
    Pi 4s using Docker.
  prefs: []
  type: TYPE_NORMAL
- en: The source code for the Python Bluetooth server resides in a public Git repo
    ([https://github.com/fvasquez/gattd](https://github.com/fvasquez/gattd)). GitHub
    Actions can attempt to build and publish a container image every time a commit
    is pushed to the repo.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Dockerfile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To run `gattd` inside a container, we first need a Dockerfile. Since `gattd`
    is a **Bluetooth Low Energy** (**BLE**) GATT server, it depends on working Bluetooth
    hardware and software being available at runtime. Fortunately, the Raspberry Pi
    4 comes with Bluetooth built in, so there is robust kernel support for BLE already
    in place. Our `gattd` container image needs to include the BlueZ software stack
    to take advantage of all this Bluetooth support. BlueZ in turn requires D-Bus
    so that must be included in our image as well. **D-Bus** is message-based middleware
    that enables communication between multiple processes running on the same computer.
    The *D* in D-Bus stands for *desktop* but servers also rely on it for inter-process
    communication. D-Bus supports both request-response and publish/subscribe messaging
    and is deeply integrated into `systemd`.
  prefs: []
  type: TYPE_NORMAL
- en: Since `gattd` is a Python application, the Dockerfile does not have a compilation
    step. The Python distribution is not compiled by Yocto. It is part of the underlying
    Linux distribution or base layer specified at the top of the Dockerfile. I chose
    Ubuntu as my base layer because Ubuntu LTS releases are tested thoroughly against
    real hardware like the Raspberry Pi 4.
  prefs: []
  type: TYPE_NORMAL
- en: Relying on Ubuntu for user space eliminates the need to build your own distro
    and perform all the testing that goes along with that. Why go through all the
    trouble of maintaining a Linux distro layer when Canonical already does that for
    you? Choosing Ubuntu saves precious development time. The rest of your software
    team does not need to get up to speed on Yocto or install the eSDK. Ubuntu is
    a known entity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the Dockerfile I committed to the root level of the `gattd` repo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '**Docker Official Images** (**DOI**) are hosted on Docker Hub. One of the primary
    goals of the DOI program is to publish container images for architectures other
    than amd64\. One of the architectures DOI supports is arm64v8, which is the ISA
    for the Raspberry Pi 4\. The Docker Hub `arm64v8` organization publishes and maintains
    scores of container images on behalf of the DOI program. These include official
    arm64v8 container images for Debian, Ubuntu, and Python. 24.04 was the most recent
    LTS release of Ubuntu when I wrote this Dockerfile.'
  prefs: []
  type: TYPE_NORMAL
- en: The `gattd` application relies primarily on the Python standard library. The
    only other Python package dependencies are bindings for D-Bus and bindings for
    the GObject introspection libraries. These two packages do not justify an additional
    `pip install` step since there are Ubuntu packages readily available for both.
    Unlike JavaScript, which has a very limited standard library, Python ships with
    “batteries included” so your application may not need another package manager
    besides `apt`.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the `COPY` instruction copies source files from the Git repo into
    the container being built. I will talk about the `entrypoint.sh` script after
    I explain how container images are published for `gattd`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a GitHub Actions workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GitHub Actions is the free CI/CD service offered by GitHub. GitHub Actions can
    build a container image and publish it to **GitHub Container Registry** (**GHCR**)
    whenever a change is pushed to the `gattd` repo. **GitHub Packages** is GitHub’s
    software package hosting service for software releases. GHCR is part of GitHub
    Packages so no additional steps are needed to access GHCR other than using a repo
    owned by you or your organization. I own the `gattd` repo, which I forked from
    [https://github.com/Jumperr-labs/python-gatt-server](https://github.com/Jumperr-labs/python-gatt-server).
    The Python code was written by Dan Shemesh and dates back to 2017.
  prefs: []
  type: TYPE_NORMAL
- en: Like most CI/CD services, GitHub Actions workflows are defined as YAML files.
    The default workflow file is named `main.yml`. Changes to workflow files are committed
    to the `.github/workflows` directory of the repo. Since these files reside in
    version control along with the source code they build and deploy, workflow files
    constitute infrastructure as code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the contents of the `main.yml` workflow file I defined for the `gattd`
    repo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: This `main.yml` file is also included in the `Chapter16` folder of the book’s
    Git repo.
  prefs: []
  type: TYPE_NORMAL
- en: A simple three-step workflow is all that is needed to publish a container image
    to GHCR. The workflow is triggered every time a commit is pushed to the `master`
    branch of the repo.
  prefs: []
  type: TYPE_NORMAL
- en: '**IMPORTANT NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to replace `master` with `main` in the `branches` list of your `main.yml`
    file when creating a GitHub Actions workflow for one of your own repos. Otherwise,
    the workflow will fail if no branch named `master` exists. Even though `main`
    is now the name of the default branch on GitHub, `master` is still the name of
    the default branch in Git when you create a new repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another point of interest is `runs-on: ubuntu-24.04-arm`, which instructs GitHub
    Actions to leverage arm64-hosted runners for this workflow. This means that any
    hosted runners GitHub spins up for this workflow will run on real 64-bit Arm CPU
    cores, eliminating the need for cross-compilation or emulation.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 3* of the workflow builds and pushes the container image defined by the
    repo’s Dockerfile. Notice that only `linux/arm64` is specified for `platforms`.
    The `platforms` element is for building multi-platform container images using
    Docker `buildx`. Docker `buildx` leverages QEMU to compile container images for
    non-native architectures, aka “platforms.” Since `gattd` is targeted at the Raspberry
    Pi 4, a container image only needs to be built for the native `linux/arm64` platform.
    Docker `buildx` is under active development. Learn more about the plugin and building
    multi-platform images at [https://github.com/docker/buildx](https://github.com/docker/buildx).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a GitHub Actions workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: From your repo, click on the **Actions** icon in the top bar.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Below **Get started with GitHub Actions**, click **Skip this and set up a workflow
    yourself**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste the contents of `main.yml` into the **Edit** window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the green **Commit changes...** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the **Commit changes** dialog, click the green **Commit changes** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.1 – Commit changes](img/B18466_16_01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.1 – Commit changes
  prefs: []
  type: TYPE_NORMAL
- en: Clicking the green **Commit changes** button triggers the GitHub Actions workflow.
    GitHub then spins up a hosted runner to build the repo’s Dockerfile and push any
    resulting container image to GHCR. If everything goes as planned, you will see
    a status of **Success** for the commit and a white check mark inside of a green
    circle next to the **build-and-push** job. This workflow took 58 seconds to complete
    the first time I ran it and now triggers every time a commit is pushed to the
    `master` branch.
  prefs: []
  type: TYPE_NORMAL
- en: Pulling and running the latest image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker needs space to write the container images that it pulls. Most embedded
    Linux filesystems are either read-only or too small to store container images
    like `gattd:latest`. That is why you want to install a general-purpose Linux distribution
    like Ubuntu Server on your Raspberry Pi 4 for this exercise. The easiest way to
    do that is with the official Raspberry Pi Imager available from raspberrypi.org.
  prefs: []
  type: TYPE_NORMAL
- en: First, download and install the Raspberry Pi Imager onto your Linux host. Directions
    on how to do that can be found online at raspberrypi.com.
  prefs: []
  type: TYPE_NORMAL
- en: 'To download and install Ubuntu Server onto a microSD card:'
  prefs: []
  type: TYPE_NORMAL
- en: Insert a microSD card into your Linux host machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch Raspberry Pi Imager.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Raspberry Pi 4** as your **Raspberry Pi Device**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Other general-purpose OS** as your operating system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the **Operating System** menu, select **Ubuntu**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then select **Ubuntu Server 24.04.1 LTS** (64-bit) or the closest available
    equivalent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Edit Settings** button when asked **Would you like to apply OS customization
    settings?**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter a username and password on the **GENERAL** page as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.2 – GENERAL](img/B18466_16_02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.2 – GENERAL
  prefs: []
  type: TYPE_NORMAL
- en: Replace `frank` with your desired username.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check **Enable SSH** on the **SERVICES** page as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.3 – SERVICES](img/B18466_16_03.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.3 – SERVICES
  prefs: []
  type: TYPE_NORMAL
- en: Click the red **SAVE** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the microSD card as your storage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the Ubuntu Server image to the microSD card. This takes several minutes
    because Raspberry Pi Imager formats all the available space on the microSD card.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eject the microSD card when Raspberry Pi Imager is done writing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Insert the microSD card into your Raspberry Pi 4.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply power to the Raspberry Pi 4 by way of its USB-C port.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To SSH into the Raspberry Pi 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Replace `<username>` with the username for the account you created when installing
    Ubuntu Server. Log in with the password you created with that account when prompted.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install and configure Docker on the Raspberry Pi 4:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the package metadata:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the Docker daemon:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Configure the system to start the Docker daemon on power up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the user to the `Docker` group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Replace `<frank>` with the username for the account you created when installing
    Ubuntu Server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Restart the Docker daemon:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Close the session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: SSH into the Raspberry Pi 4 again.
  prefs: []
  type: TYPE_NORMAL
- en: 'To pull the latest `gattd` container image from GHCR:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the latest `gattd` container image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the `entrypoint.sh` script that executes when the `gattd` container
    image is run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This `entrypoint.sh` file comes from a Medium blog post that Thomas Huffert
    wrote on how to run containerized Bluetooth applications with BlueZ. A link to
    his original post is included in the *Further study* section at the end of the
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Adding Docker to a Yocto image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We don’t need to install Ubuntu on a Raspberry Pi 4 to take advantage of Docker.
    Buildroot and Yocto are both able to build Docker for embedded targets. Adding
    Docker to a Yocto image is straightforward. Simply append the package to an existing
    image. We will leverage the `rpi-test-image` from the *Building on top of an existing
    BSP* section of [*Chapter 7*](Chapter_05.xhtml#_idTextAnchor151).
  prefs: []
  type: TYPE_NORMAL
- en: Adding the meta-virtualization layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Yocto’s `meta-virtualization` layer contains recipes to enable support for cloud
    tooling. Over time, the project’s emphasis has moved away from virtualization
    technologies like Xen, KVM, and libvirt to more popular containerization tools.
    Bruce Ashfield has led the maintenance of `meta-virtualization` for more than
    a decade, working tirelessly to stay abreast of the latest innovations in cloud
    computing.
  prefs: []
  type: TYPE_NORMAL
- en: There are so many competing containerization tools to choose from, it’s hard
    to know where to start. The `meta-virtualization` layer is agnostic with respect
    to the choice of container runtime in that Docker, Podman, containerd, and Kubernetes
    are all fully supported. I made the conscious decision to focus on Docker because
    it remains the most popular tool for deploying container images.
  prefs: []
  type: TYPE_NORMAL
- en: The following exercises assume you have already completed the *Building an existing
    BSP* exercise from [*Chapter 7*](Chapter_05.xhtml#_idTextAnchor151) and the directory
    where `poky` was cloned is in your home directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add the `meta-virtualization` layer:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, navigate one level above the directory where you cloned `poky`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, set up your BitBake work environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This sets up a bunch of environment variables and puts you back in the `build-rpi`
    directory where you previously built `rpi-test-image`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, add the `meta-virtualization` layer to your image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This command will clone the `meta-virtualization` layer and all its dependency
    layers into your home directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Verify that all the necessary layers have been added to the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the command should look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If your output is missing layers from `meta-raspberrypi` upwards, then return
    to [*Chapter 7*](Chapter_05.xhtml#_idTextAnchor151)and repeat the *Building an
    existing BSP* exercise before reattempting to add the `meta-virtualization` layer.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `meta-virtualization` layer contains the recipes needed to build and install
    Docker. Once the layer has been added, we can then append the `docker` package
    to a Yocto image. There are several ways to achieve this goal, including creating
    a custom image recipe or distro layer. I chose to piggyback on top of `rpi-test-image`
    and modify the `conf/local.conf` file in the `build-rpi` directory. I did this
    solely for expediency. Changing `conf/local.conf` is not maintainable.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker daemon relies on SSL certificates to verify the authenticity of image
    registries. SSL certificates have set lifespans, so some measure of accurate time
    is needed. Most computers update their system clocks on startup according to time
    received from the internet via **Network Time Protocol** (**NTP**). So, not only
    do you need to install Docker on your target, but you also need some way to synchronize
    the system clock before you can pull a container image.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Docker on `rpi-test-image`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following line to your `conf/local.conf` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following lines to your `conf/local.conf` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Step 2* creates a group named `docker` and adds the `root` user to that group.
    This allows us to run Docker commands when we log in as `root`. The `rpi-test-image`
    permits `root` logins via SSH. There is no password required. This image is for
    demonstration only.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the image has finished building, there should be a file named `rpi-test-image-raspberrypi4-64.rootfs.wic.bz2`
    in the `tmp/deploy/images/raspberrypi4-64` directory. Write that image to a microSD
    card using Etcher and boot it on your Raspberry Pi 4:'
  prefs: []
  type: TYPE_NORMAL
- en: Insert a microSD card into your host machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch Etcher.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Flash from file** from Etcher.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Locate the `wic.bz2` image that you built for the Raspberry Pi 4 and open it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Select target** from Etcher.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the microSD card that you inserted in *step 1*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Flash** from Etcher to write the image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eject the microSD card when Etcher is done flashing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Insert the microSD card into your Raspberry Pi 4.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply power to the Raspberry Pi 4 by way of its USB-C port.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Confirm that your Pi 4 booted successfully by plugging it into your Ethernet
    and observing that the network activity lights blink.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying the Docker daemon is running
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous exercise, we built a bootable image for the Raspberry Pi 4
    that includes Docker. Now that the device has booted and connected to your local
    network via Ethernet, let’s verify the Docker daemon is running. Follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The image we built has a hostname of `raspberrypi4-64`, so you should be able
    to SSH into the device as `root`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Enter `yes` when asked if you want to continue connecting. You will not be prompted
    for a password. If no host is found at `raspberrypi4-64.local`, use a tool such
    as `arp-scan` to locate the IP address of your Raspberry Pi 4 and SSH into that
    instead of doing so by hostname.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To list information about the version of Docker that is running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To update the system clock:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To pull and run a `hello-world` container image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Most modern Linux distributions rely on `systemd-timesyncd` to update the system
    clock automatically. This eliminates the need to install and run `ntp-utils`.
    Yocto’s Poky reference distro defaults to SysVinit as its init system. To take
    advantage of `systemd-timesyncd`, we need to switch from SysVinit to `systemd`
    for startup. If you want to use systemd with Poky, then select `"poky-altcfg"`
    as your distro in `conf/local.conf`.
  prefs: []
  type: TYPE_NORMAL
- en: There are more reasons to switch from `SysVinit` to `systemd` than just time
    synchronization. Since it was designed for process supervision, `systemd` is well-suited
    to monitoring microservices. A microservice is typically deployed as a container.
    It makes sense to use `systemd` together with Docker to start, stop, and restart
    containers on a Linux system. Alternatively, you can also use Docker Compose to
    run multi-container applications, but that requires adding another tool to your
    Yocto image.
  prefs: []
  type: TYPE_NORMAL
- en: Updating software with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Balena uses Docker containers to deploy software updates. Devices run balenaOS,
    a Yocto-based Linux distribution that comes with balenaEngine, balena’s Docker-compatible
    container engine. OTA updates occur automatically by way of releases pushed from
    balenaCloud, a hosted service for managing fleets of devices. Balena can also
    operate in **local mode** so that updates originate from a server running on your
    local host machine rather than the cloud. We will stick to local mode for the
    following exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Balena is written and supported by balena.io ([https://balena.io](https://balena.io)).
    Like Mender, balenaCloud is a paid OTA update service. Your first ten devices
    are free, but you must adopt a monthly or yearly billing plan for anything beyond
    that. There is much more information about the software in the **Reference** section
    of the online docs at balena.io. We won’t dig into how balena works since our
    goal is to deploy and automatically update software on a small fleet of devices
    for fast development.
  prefs: []
  type: TYPE_NORMAL
- en: Balena provides prebuilt balenaOS images for popular dev boards such as the
    Raspberry Pi 4 and BeaglePlay. Downloading these images requires a balenaCloud
    account.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an account
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first thing you need to do even if you only intend to operate in local
    mode is to sign up for a balenaCloud account. You do this by visiting [https://dashboard.balenacloud.com/signup](https://dashboard.balenacloud.com/signup)
    and entering your email address and a password, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.4 – balenaCloud signup](img/B18466_16_04.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.4 – balenaCloud signup
  prefs: []
  type: TYPE_NORMAL
- en: Click the **Submit** button to submit the form and once it is done processing,
    you will be prompted to enter your profile details. You may choose to skip this
    form, at which point you will enter the **balenaCloud** dashboard under your new
    account.
  prefs: []
  type: TYPE_NORMAL
- en: If you sign out or your session expires, you can log back in to the dashboard
    by navigating to [https://dashboard.balena-cloud.com/login](https://dashboard.balena-cloud.com/login)
    and entering the email address and password you signed up with.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we can add a Raspberry Pi 4 to a balenaCloud account, we first need to
    create a fleet.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.5 – Create fleet](img/B18466_16_05.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.5 – Create fleet
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps for creating a fleet for the Raspberry Pi 4 on balenaCloud:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the **balenaCloud** dashboard with your email address and password.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Create fleet** button in the upper-left corner, next to **Fleets**,
    to open the **Create fleet** dialog.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter a name for your new fleet and select **Raspberry Pi 4 (using 64bit OS)**
    for **Default device type**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Create new fleet** button in the **Create fleet** dialog to submit
    the form.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your new fleet should appear in the **balenaCloud** dashboard on the **Fleets**
    page.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a device
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have a fleet on balenaCloud, let’s add a Raspberry Pi 4 to it:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the **balenaCloud** dashboard with your email address and password.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the new fleet we created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Add device** button from the fleet **Summary** page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clicking on the button will bring up the **Add new device** dialog.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that **Raspberry Pi 4 (using 64bit OS)** is the selected device type.
    That option should already be selected since you created the application with
    **Raspberry Pi 4 (using 64bit OS)** as the default device type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that **balenaOS** is the selected OS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the selected version of balenaOS is the latest. That option should
    already be selected since **Add new device** defaults to the latest available
    version of balenaOS, which it designates as **RECOMMENDED**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Development** as the edition of balenaOS. A development image is required
    to enable local mode for better testing and troubleshooting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.6 – Add new device](img/B18466_16_06.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.6 – Add new device
  prefs: []
  type: TYPE_NORMAL
- en: Select **Wifi + Ethernet** for **Network**. You could choose **Ethernet only**
    but auto-connecting to Wi-Fi is a very convenient feature.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter your Wi-Fi router’s SSID and passphrase in their respective fields. Replace
    **ATTCXR2Xjn** in the following screenshot with your Wi-Fi router’s SSID:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.7 – Wifi + Ethernet](img/B18466_16_07.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.7 – Wifi + Ethernet
  prefs: []
  type: TYPE_NORMAL
- en: Click the down arrow on the **Flash** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the zipped image file to your host machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We now have a microSD card image we can use to provision any number of Raspberry
    Pi 4s for your test fleet.
  prefs: []
  type: TYPE_NORMAL
- en: The steps for provisioning a Raspberry Pi 4 from your host machine should be
    familiar by now. Locate the balenaOS `img.zip` file that you downloaded from balenaCloud
    and use Etcher to write it to a microSD card. Insert the microSD card into your
    Raspberry Pi 4 and power it up by way of the USB-C port.
  prefs: []
  type: TYPE_NORMAL
- en: 'It will take a minute or two for the Raspberry Pi 4 to appear on the **Devices**
    page of your balenaCloud dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.8 – Devices](img/B18466_16_08.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.8 – Devices
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have connected a Raspberry Pi 4 to a balena application, we need
    to enable local mode so that we can deploy OTA updates to it from a nearby host
    machine rather than the cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on your target Raspberry Pi 4 from the **Devices** page of your balenaCloud
    dashboard. My device is named **evil-tree**. Yours will have a different name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Settings** for your Raspberry Pi 4.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enable **Local mode** from the **Settings** page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.9 – Enable local mode](img/B18466_16_09.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.9 – Enable local mode
  prefs: []
  type: TYPE_NORMAL
- en: Once local mode is enabled, the **Logs** panel is no longer available on the
    device **Summary** page.
  prefs: []
  type: TYPE_NORMAL
- en: With local mode now enabled on our target device, we are almost ready to deploy
    some code to it. Before we can do that, we need to install the balena CLI.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the CLI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are the instructions for installing the balena CLI on a Linux host machine:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a web browser and navigate to the latest balena CLI release page at [https://github.com/balena-io/balena-cli/releases/latest](https://github.com/balena-io/balena-cli/releases/latest).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the latest ZIP file for Linux to download it. Look for a filename of
    the form `balena-cli-vX.Y.Z-linux-x64-standalone.zip`, substituting major, minor,
    and patch version numbers for X, Y, and Z.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Extract the ZIP file contents to your home directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The extracted contents are enclosed in a `balena-cli` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the `balena-cli` directory to your `PATH` environment variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Add a line like this to the `.bashrc` file in your home directory if you want
    these changes to your `PATH` variable to persist.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Verify that the installation was successful:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The latest version of the balena CLI at the time of writing was 20.2.9.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we have a working balena CLI, let’s scan the local network for the
    Raspberry Pi 4 we provisioned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Notice the hostname of `bf04eba.local` and the IP address of `192.168.1.83`
    in the scan output. The hostname and IP address of your Raspberry Pi 4 will vary.
    Record these two pieces of information because we will need them for the remaining
    exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Pushing a project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s push a Python project to the Raspberry Pi over the local network:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone a project for a simple “Hello World!” Python web server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Navigate into the project directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Push the code to your Raspberry Pi 4:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Substitute your device’s IP address for the `192.168.1.183` argument.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wait for the Docker image to finish building and starting and let the application
    run in the foreground so that it logs to `stdout`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Issue a request to the web server at `http://192.168.1.183` from a web browser.
    Substitute your device’s IP address for `192.168.1.183`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The web server running on the Raspberry Pi 4 should display a splash page with
    **Welcome to balena** and a line like the following should appear in the live
    output from `balena push`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: The IP address in the log entry should be that of the machine from which you
    issued the web request. A new log entry should appear every time you refresh the
    web page. To stop tailing the logs and return to the shell, enter *Ctrl + C*.
    The container will continue running on the target device and the web server will
    continue to service requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can restart tailing the logs at any time by issuing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Substitute your device’s IP address for the `192.168.1.183` argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'The HTML for this simple web server can be found in a file named `index.html`
    within the project directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s make a slight modification to the project source code and redeploy:'
  prefs: []
  type: TYPE_NORMAL
- en: Open `views/index.html` in your favorite editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace `Welcome to balena!` with `Welcome to banana!` and save your changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following `git diff` output captures the changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Push the new code to your Raspberry Pi 4:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Substitute your device’s IP address for the `192.168.1.183` argument.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wait for the Docker image to update. The process should be much quicker this
    time around because of an intelligent caching feature called **Livepush** that
    is unique to local mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Issue a request to the web server at `http://192.168.1.183` from a web browser.
    Substitute your device’s IP address for `192.168.1.183`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The web server running on the Raspberry Pi 4 should display **Welcome to banana!**
  prefs: []
  type: TYPE_NORMAL
- en: 'We can SSH into a local target device by IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: Substitute your device’s IP address for `192.168.1.183`. This is not especially
    useful because the application is running inside a Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: 'To SSH into the container where the Python web server is running and observe
    what it’s doing, we need to include the service name in the `balena` `ssh` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The service name for this starter application is `balena-hello-world` as seen
    in the live logs output.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have successfully created a balenaOS image and host development
    environment that you and your team can use to iterate on project code and quickly
    redeploy to a target device. This is no small feat. Pushing code changes in the
    form of a Docker container is a common development workflow that full-stack engineers
    are very accustomed to. With balena, they can now use the techniques they are
    familiar with to develop embedded Linux applications on actual hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We accomplished a lot in this chapter. You now know how to create Dockerfiles
    and YAML workflows for your software projects. CI/CD pipelines use this infrastructure
    as code to automatically build and push containerized software updates out to
    edge devices. You also leveraged containers to develop locally on real hardware
    before pushing your changes out to the rest of the world. Modern DevOps practices
    like these enable software teams to move faster without breaking things.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look in detail at the Linux process model and describe
    what a process really is, how it relates to threads, how they cooperate, and how
    they are scheduled. Understanding these things is important if you want to create
    a robust and maintainable embedded system.
  prefs: []
  type: TYPE_NORMAL
- en: Further study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*The DevOps Handbook, Second Edition*, by Gene Kim, Jez Humble, Patrick Debois,
    and John Willis'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Docker Docs*, Docker Inc. – [https://docs.docker.com/reference/cli/docker/](https://docs.docker.com/reference/cli/docker/%0D%0A)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*How to run containerized Bluetooth applications with BlueZ*, by Thomas Huffert
    – [https://medium.com/omi-uulm/how-to-run-containerized-bluetooth-applications-with-bluez-dced9ab767f6](https://medium.com/omi-uulm/how-to-run-containerized-bluetooth-applications-with-bluez-dced9ab767f6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
