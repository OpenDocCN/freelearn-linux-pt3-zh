- en: Building a Standard Operating Environment on Linux
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provides a detailed exploration of the **Standard Operating Environment**
    (henceforth, **SOE** for short) concept in Linux. Although we will go into much
    greater detail later, in short, an SOE is an environment where everything is created
    and modified in a standard way. For example, this would mean that all Linux servers
    are built in the same way, using the same software versions. This is an important
    concept because it makes managing the environment much easier and reduces the
    workload for those looking after it. Although this chapter is quite theoretical
    in nature, it sets the groundwork for the rest of this book.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by looking at the fundamental definition of such an environment,
    and then proceed to explore why it is desirable to want to create one. From there,
    we will look at some of the pitfalls of an SOE to give you a good perspective
    on how to maintain the right balance in such an environment, before finally discussing
    how an SOE should be integrated into day-to-day maintenance processes. The effective
    application of this concept enables efficient and effective management of Linux
    environments at very large scales.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the challenges of Linux environment scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is an SOE?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring SOE benefits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Knowing when to deviate from standards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ongoing maintenance of SOEs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the challenges of Linux environment scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we delve into the definition of an SOE, let's explore the challenges
    of scaling a Linux environment without standards. An exploration of this will
    help us to understand the definition itself, as well as how to define the right
    standards for a given scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of non-standard environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is important to consider that many challenges experienced by enterprises
    with technology estates (whether Linux or otherwise) do not start out as such.
    In the early stages of growth, in fact, many systems and processes are entirely
    sustainable, and in the next section, we will look at this early stage of environment
    growth as a precursor to understanding the challenges associated with large-scale
    growth.
  prefs: []
  type: TYPE_NORMAL
- en: Early growth of a non-standard environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a surprisingly large number of companies, Linux environments begin life without
    any form of standardization. Often, they grow organically over time. Deployments
    start out small, perhaps just covering a handful of core functions, and as time
    passes and requirements grow, so does the environment. Skilled system administrators
    often make changes by hand on a per-server basis, deploying new services and growing
    the server estate as business demands dictate.
  prefs: []
  type: TYPE_NORMAL
- en: This organic growth is the path of least resistance for most companies—project
    deadlines are often tight and in addition both budget and resource are scarce.
    Hence, when a skilled Linux resource is available, that resource can assist in
    just about all of the tasks required, from simple maintenance tasks to commissioning
    complex application stacks. It saves a great deal of time and money spent on architecture
    and makes good use of the skillset of staff on hand as they can be used to address
    immediate issues and deployments, rather than spending time on architectural design.
    Hence, quite simply, it makes sense, and the author has experienced this at several
    companies, even high-profile multi-national ones.
  prefs: []
  type: TYPE_NORMAL
- en: Impacts of non-standard environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a deeper look at this from a technical standpoint. There are numerous
    flavors of Linux, numerous applications that perform (at a high level) the same
    function, and numerous ways to solve a given problem. For example, if you want
    to script a task, do you write it in a shell script, Perl, Python, or Ruby? For
    some tasks, all can achieve the desired end result. Different people have different
    preferred ways of approaching problems and different preferred technology solutions,
    and often it is found that a Linux environment has been built using a technology
    that was *the flavor of the month* when it was created or that was a favorite
    of the person responsible for it. There is nothing wrong with this in and of itself,
    and initially, it does not cause any problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'If organic growth brings with it one fundamental problem, it is this: scale.
    Making changes by hand and always using the latest and greatest technology is
    great when the environment size is relatively small, and often provides an interesting
    challenge, hence keeping technical staff feeling motivated and valued. It is vital
    for those working in technology to keep their skills up to date, so it is often
    a motivating factor to be able to employ up-to-date technologies as part of the
    day job.'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling up non-standard environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the number of servers enters the hundreds, never mind thousands (or even
    greater!), this whole *organic* process breaks down. What was once an interesting
    challenge becomes laborious and tedious, even stressful. The learning curve for
    new team members is steep. A new hire may find themselves with a disparate environment
    with lots of different technologies to learn, and possibly a long period of training
    before they can become truly effective. Long-serving team members can end up being
    silos of knowledge, and should they depart the business, their loss can cause
    continuity issues. Problems and outages become more numerous as the non-standard
    environment grows in an uncontrolled manner, and troubleshooting becomes a lengthy
    endeavor—hardly ideal when trying to achieve a 99.99% service uptime agreement,
    where every second of downtime matters! Hence, in the next section, we will look
    at how to address these challenges with an SOE.
  prefs: []
  type: TYPE_NORMAL
- en: Addressing the challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From this, we realize our requirement for standardization. Building a suitable
    SOE is all about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Realizing economies of scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being efficient in day-to-day operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making it easy for all involved to get up to speed quickly and easily
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being aligned with the growing needs of the business
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After all, if an environment is concise in its definition, then it is easier
    for everyone involved in it to understand and work with. This, in turn, means
    tasks are completed quicker and with greater ease. In short, standardization can
    bring cost savings and improved reliability.
  prefs: []
  type: TYPE_NORMAL
- en: It must be stressed that this is a concept and not an absolute. There is no
    right or wrong way to build such an environment, though there are best practices.
    Throughout this chapter, we will explore the concept further and help you to identify
    core best practices associated with SOEs so that you can make informed decisions
    when defining your own.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s proceed to explore this in more detail. Every enterprise has certain
    demands of their IT environments, whether they are based on Linux, Windows, FreeBSD,
    or any other technology. Sometimes, these are well understood and documented,
    and sometimes, they are simply implicit—that is to say, everyone assumes the environment
    meets these *standards*, but there is no official definition. These requirements
    often include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reliability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Longevity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supportability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ease of use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These, of course, are all high-level requirements, and very often, they intersect
    with each other. Let's explore these in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Security in an environment is established by several factors. Let''s look at
    some questions to understand the factors involved:'
  prefs: []
  type: TYPE_NORMAL
- en: Is the configuration secure?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have we allowed the use of weak passwords?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the superuser, root, allowed to log in remotely?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are we logging and auditing all connections?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, in a non-standard environment, how can you truly say that these requirements
    are all enforced across all of your Linux servers? To do so requires a great deal
    of faith they have all been built the same way, that they had the same security
    parameters applied, and that no-one has ever revisited the environment to change
    anything. In short, it requires fairly frequent auditing to ensure compliance.
  prefs: []
  type: TYPE_NORMAL
- en: However, where the environment has been standardized, and all servers have been
    built from a common source or using a common automation tool (we shall demonstrate
    this later in this book), it is much easier to say with confidence that your Linux
    estate is secure.
  prefs: []
  type: TYPE_NORMAL
- en: A standards-based environment isn't implicitly secure, of course—if there is
    an issue that results in a vulnerability in the build process for this environment,
    automation means this vulnerability will be replicated across the entire environment!
    It is important to be aware of the security requirements of your environment and
    to implement these with care, maintaining and auditing your environment continuously
    to ensure security levels are maintained.
  prefs: []
  type: TYPE_NORMAL
- en: Security is also enforced by patches, which ensure you are not running any software
    with vulnerabilities that could allow an attacker to compromise your servers.
    Some Linux distributions have longer lives than others. For example, Red Hat Enterprise
    Linux (and derivatives such as CentOS) and the Ubuntu LTS releases all have long,
    predictable life cycles and make good candidates for your Linux estate.
  prefs: []
  type: TYPE_NORMAL
- en: As such, they should be part of your standards. By contrast, if a *bleeding
    edge* Linux distribution such as Fedora has been used because, perhaps, it had
    the latest packages required at the time, you can be sure that the life cycle
    will be short, and that updates would cease in the not too distant future, hence
    leaving you open to potential unpatched vulnerabilities and the need to upgrade
    to a newer release of Fedora.
  prefs: []
  type: TYPE_NORMAL
- en: Even if the upgrade to a newer version of Fedora is performed, sometimes packages
    get *orphaned—*that is to say, they do not get included in the newer release.
    This might be because they have been superseded by a different package. Whatever
    the cause, upgrading one distribution to another could cause a false sense of
    security and should be avoided unless thoroughly researched. In this way, standardization
    helps to ensure good security practices.
  prefs: []
  type: TYPE_NORMAL
- en: Reliability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many enterprises expect their IT operations to be up and running 99.99% of the
    time (or better). Part of the route to achieving this is robust software, application
    of relevant bug fixes, and well-defined troubleshooting procedures. This ensures
    that in the worst case scenario of an outage, the downtime is as minimal as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Standardization again helps here*—*as we discussed in the preceding section
    on security, a good choice of underlying operating system ensures that you have
    ongoing access to bug fixes and updates, and if you know that your business needs
    a vendor backup to ensure business continuity, then the selection of a Linux operating
    system with a support contract (available with Red Hat or Canonical, for example)
    makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: Equally, when servers are all built to a well-defined and understood standard,
    making changes to them should yield predictable results as everyone knows what
    they are working with. If all servers are built slightly differently, then a well-meaning
    change or update could have unintended consequences and result in costly downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Again with standardization, even if the worst-case scenario occurs, everyone
    involved should know how to approach the problem because they will know that all
    servers have been built on a certain base image and have a certain configuration.
    This knowledge and confidence reduce troubleshooting times and ultimately downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All enterprises desire their business to grow and most times, this means that
    IT environments need to scale up to deal with increased demand. In an environment
    where the servers are built in a non-standard manner, scaling up an environment
    becomes more of a challenge.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if scaling horizontally (adding more identical servers to an existing
    service), the new servers should all have the same configuration as the existing
    ones. Without standards, the first step is to work out how the initial set of
    servers was built and then to clone this and make the necessary changes to produce
    more unique servers.
  prefs: []
  type: TYPE_NORMAL
- en: This process is somewhat cumbersome whereas, with a standardized environment,
    the investigative step is completely unnecessary, and horizontal scaling becomes
    a predictable, repeatable, *business-as-usual* task. It also ensures greater reliability
    as there should be no unintended results from the new servers in the case that
    a non-standard configuration item was missed. Human beings are incredible, intelligent
    beings capable of sending a man to the moon, and yet they are equally capable
    of overlooking a single line in a configuration file. The idea of standardization
    is to mitigate this risk, and hence make it quick and efficient to scale an environment
    either up or out using a well-thought-out operating system template, the concept
    of which we will explore as we proceed through this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Longevity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes when deploying a service, a particular software version is needed.
    Let's take the example of a web application that runs on PHP. Now, suppose that
    your particular enterprise has, for historical reasons, standardized on CentOS
    6 (or RHEL 6). This operating system only ships with PHP 5.3, meaning that if
    you suddenly take on an application that only supports PHP 7.0 and above, you
    need to figure out how to host this.
  prefs: []
  type: TYPE_NORMAL
- en: One apparently obvious solution to this would be to roll out a Fedora virtual
    machine image. After all, it shares similar technologies to CentOS and RHEL and
    has much more up-to-date libraries included with it. The author has direct experience
    of this kind of solution in several roles! However, let's take a look at the bigger
    picture.
  prefs: []
  type: TYPE_NORMAL
- en: RHEL (and CentOS, which is based upon this) has a lifespan of around 10 years,
    depending on the point at which you purchased it. In an enterprise, this is a
    valuable proposition*—*it means that you can guarantee that any servers you build
    will have patches and support for up to 10 years (and possibly longer with extended
    life cycle support) from the point at which you built them. This ties in nicely
    with our previous points around security, reliability, and supportability (in
    the following section).
  prefs: []
  type: TYPE_NORMAL
- en: However, any servers that you build on Fedora will have a lifespan of somewhere
    in the region of 12-18 months (depending on the Fedora release cycle)*—*in an
    enterprise setting, having to redeploy a server after, say, 12-18 months is a
    headache that is not needed.
  prefs: []
  type: TYPE_NORMAL
- en: This is not to say there is never a case for deploying on Fedora or any other
    fast-moving Linux platform*—*it is simply to state that in an enterprise where
    security and reliability are vitally important, you are unlikely to want a Linux
    platform with a short life cycle as the short term gain (newer library support)
    would be replaced in 12-18 months with the pain of a lack of updates and the need
    to rebuild/upgrade the platform.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this does depend very much on your approach to your infrastructure*—*some
    enterprises take a very container-like approach to their servers and re-deploy
    them with every new software release or application deployment. When your infrastructure
    and build standards are defined by code (such as Ansible), then it is entirely
    possible to do this with a fairly minimal impact on your day-to-day operations,
    and it is unlikely that any single server would be around for long enough for
    the operating system to become outdated or unsupported.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the day, the choice is yours and you must establish which path
    you feel provides you with the most business benefit without putting your operations
    at risk. Part of standardization is to make sound, rational decisions on technology
    and to adopt them wherever feasible, and your standard could include frequent
    rebuilds such that you can use a fast-moving operating system such as Fedora.
    Equally, you might decide that your standard is that servers will have long lives
    and be upgraded in place, and in this case, you would be better choosing an operating
    system such as an Ubuntu LTS release or RHEL/CentOS.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will look in greater detail at how an SOE benefits the
    concept of supportability in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Supportability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have already discussed, having a standardized environment brings with
    it two benefits. The first is that a well-chosen platform means a long vendor
    support life cycle. This, in turn, means long support from either the vendor (in
    the case of a product such as RHEL) or the community (in the case of CentOS).
    Some operating systems such as Ubuntu Server are available with either community
    support or a paid contract directly from Canonical.
  prefs: []
  type: TYPE_NORMAL
- en: Supportability doesn't just mean support from the vendor or the Linux community
    at large, however. Remember that, in an enterprise, your staff is your front line
    support before anyone external steps in. Now, imagine having a crack team of Linux
    staff, and presenting them with a server estate comprised of Debian, SuSe, CentOS,
    Fedora, Ubuntu, and Manjaro. There are similarities between them, but also a huge
    number of differences. Across them, there are four different package managers
    for installing and managing software packages, and that's just one example.
  prefs: []
  type: TYPE_NORMAL
- en: Whilst entirely supportable, it does present more of a challenge for your staff
    and means that, for anyone joining the company, you require both a broad and a
    deep set of Linux experience*—*either that or an extensive on-boarding process
    to get them up to speed.
  prefs: []
  type: TYPE_NORMAL
- en: With a standardized environment, you might end up with more than one operating
    system, but nonetheless, if you can meet all of your requirements with, say, CentOS
    7 and Ubuntu Server 18.04 LTS (and know that you are covered for the next few
    years because of your choices), then you immediately reduce the workload on your
    Linux team and enable them to spend more time creatively solving problems (for
    example, automating solutions with Ansible!) and less time figuring out the nuances
    between operating systems. As we have also discussed, in the event of an issue,
    they will be more familiar with each OS and hence need to spend less time debugging,
    reducing downtime.
  prefs: []
  type: TYPE_NORMAL
- en: This brings us nicely into the subject of ease of use at scale, and we will
    provide an overview of this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Ease of use
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This final category overlaps heavily with the last two—that is to say that,
    quite simply, the more standardized your environment, the easier it is for a given
    set of employees to get to grips with it. This automatically promotes all of the
    benefits we have discussed so far around reducing downtime, easier recruitment
    and on-boarding of staff, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Having set out the challenges that an SOE helps to address, we will proceed
    in the next section to look at the anatomy of such an environment to understand
    it from a technical standpoint.
  prefs: []
  type: TYPE_NORMAL
- en: What is an SOE?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we've explored the reasons why an SOE is important to the enterprise
    and understood at a high level the solutions for these problems, let's look in
    detail at an SOE. We will begin by defining the SOE itself.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the SOE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a quick look at this from a more practical standpoint. As we have
    already said, an SOE is a concept, not an absolute. It is, at its simplest level,
    a common server image or build standard that is deployed across a large number
    of servers throughout a company. Here, all required tasks are completed in a known,
    documented manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, there is the base operating system—and, as we have discussed,
    there are hundreds of Linux distributions to choose from. Some are quite similar
    from a system administration perspective (for example, Debian and Ubuntu), whilst
    some are markedly different (for example, Fedora and Manjaro). By way of a simple
    example, let''s say you wanted to install the Apache Web Server on Ubuntu 18.04
    LTS—you would enter the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if you wanted to do the same thing but on CentOS 7, you would enter the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, there is nothing in common between these commands—not even the
    name of the package, even though the end result in both cases is an installation
    of Apache. On a small scale, this is not an issue, but when servers are numerous
    and as server count goes up, so does the complexity of managing such an environment.
  prefs: []
  type: TYPE_NORMAL
- en: The base operating system is just the start. Our example above was installing
    Apache, yet we could also install nginx or even lighttpd. They are, after all,
    also web servers.
  prefs: []
  type: TYPE_NORMAL
- en: Then, there is configuration. Do you want users to be able to log in as root over
    SSH? Do you need a certain level of logging for audit or debug purposes? Do you
    need local or centralized authentication? The list is myriad, and as you can see,
    if left unchecked could grow into a massive headache.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where the SOE comes in. It is effectively a specification, and at a
    high level, it might say the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Our standard base operating system is Ubuntu 18.04 LTS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our standard web server will be Apache 2.4.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SSH logins are enabled, but only for users with SSH keys and not root.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All user logins must be logged and archived for audit purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Except for a few local *break glass* accounts, all accounts must be centrally
    managed (for example, by LDAP or Active Directory).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our corporate monitoring solution must be integrated (for example, the Nagios
    NCPA agent must be installed and configured to communicate with our Nagios server).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All system logs must be sent to the corporate central log management system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security hardening must be applied to the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding is simply an example, and it is by no means complete; however,
    it should begin to give you an idea of what an SOE looks like at a high level.
    As we proceed through this chapter, we will delve deeper into this subject and
    give more examples to build up a clear definition.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing what to include
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we proceed, let's take a look in a little more detail at what to include
    in the environment. We have outlined in the previous section a very simplistic
    definition for an SOE. Part of any good SOE operating process is to have a pre-defined
    operating system build that can be deployed at a moment's notice. There are multiple
    ways this might be achieved and we will discuss these later in this book—however,
    for the time being, let's assume that a base image of Ubuntu 18.04 LTS as suggested
    previously has been built. What do we integrate into this *standard* build?
  prefs: []
  type: TYPE_NORMAL
- en: We know, for example, that our login policy is going to be applied throughout
    the organization—hence, when the build is created, `/etc/ssh/sshd_config` must
    be customized to include `PermitRootLogin no` and `PasswordAuthentication no`.
    There is no point in performing this step in the post-deployment configuration,
    as this would have to be performed on each and every single deployment. Quite
    simply, this would be inefficient.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also important automation considerations for our operating system
    image. We know that Ansible itself communicates over SSH, and so we know that
    we are going to require some kind of credentials (it is quite likely this will
    be SSH key-based) for Ansible to run against all of the deployed servers. There
    is little point in having to manually roll out Ansible credentials to every single
    machine before you can actually perform any automation, and so it is important
    to consider the kind of authentication you want Ansible to use (for example, password-
    or SSH key-based), and to create the account and corresponding credentials when
    you build the image. The exact method for doing this will depend upon your corporate
    security standards, but I would advocate as a potential solution the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a local account on the standard image for Ansible to authenticate against
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Giving this account appropriate sudo rights to ensure all desired automation
    tasks can be performed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting the local password for this account, or adding the SSH public key from
    an Ansible key-pair to the `authorized_keys` file for the local Ansible account
    you created
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing this, of course, does present some security risks. It is most likely that
    Ansible will need full access to root on your servers for it to effectively perform
    all of the automation tasks you might ask of it, and so this Ansible account could
    become a backdoor if the credentials were ever compromised. It is recommended
    that as few people as possible have access to the credentials and that you make
    use of a tool such as AWX or Ansible Tower (which we shall explore in [Chapter 3](b0c37bde-4b12-4619-94f1-dd14ae0c96ff.xhtml),
    *Streamlining Infrastructure Management with AWX*) to manage your credentials,
    hence preventing people from getting hold of them inappropriately. You will also
    almost certainly want to enable auditing of all activities performed by the Ansible
    account and have these logged to a central server somewhere so that you can inspect
    them for any suspicious activity and audit them as required.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on from user accounts and authentication, consider also **Nagios Cross-Platform
    Agent** (**NCPA**). We know in our example that all deployed servers are going
    to need to be monitored, and so it is a given that NCPA agent must be installed,
    and the token defined such that it can communicate with the Nagios server. Again,
    there is no point doing this on every single server after the standard image is
    deployed.
  prefs: []
  type: TYPE_NORMAL
- en: What about the web server though? It is sensible to have a standard, as it means
    all who are responsible for the environment can become comfortable with the technology.
    This makes administration easier and is especially beneficial for automation,
    as we shall see in the next section. However, unless you only ever deploy web
    servers running on Linux, this probably shouldn't be included as part of the standard
    build.
  prefs: []
  type: TYPE_NORMAL
- en: As a sound principle, the standard builds should be as simple and lightweight
    as possible. There is no point in having additional services running on them,
    taking up memory and CPU cycles, when they are redundant. Equally, having unconfigured
    services increases the attack surface for any potential attacker and so for security
    reasons, it is advisable to leave them out.
  prefs: []
  type: TYPE_NORMAL
- en: In short, the standard build should only include configuration and/or services
    that are going to be common to every server deployed. This approach is sometimes
    referred to as **Just enough Operating System** or **JeOS** for short, and it
    is the best starting point for your SOE.
  prefs: []
  type: TYPE_NORMAL
- en: Having understood the basic principles of an SOE, we will proceed in the next
    section to look in more detail at the benefits an SOE brings to your enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring SOE benefits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, you should have some idea of what an SOE is, and how it brings economies
    of scale and greater efficiency to a Linux environment. Now, let's build on that
    and look in more detail at an example of the importance of standardization.
  prefs: []
  type: TYPE_NORMAL
- en: Example benefits of an SOE in a Linux environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To say that there are commonalities in a Linux environment is to say that the
    servers that comprise it all share attributes and features. For example, they
    might all be built upon Ubuntu Linux, or they might all have Apache as their web
    server.
  prefs: []
  type: TYPE_NORMAL
- en: We can explore this concept with an example. Suppose that you have 10 Linux
    web servers behind a load balancer and that they are all serving simple static
    content. Everything is working fine, but then a configuration change is mandated.
    Perhaps this is to change the document root of each web server to point to a new
    code release that has been deployed to them by another team.
  prefs: []
  type: TYPE_NORMAL
- en: As the person responsible, you know that because the overall solution is load
    balanced, all servers should be serving the same content. Therefore, the configuration
    change is going to be required on each and every one. That means 10 configurations
    changes to make if you do it by hand.
  prefs: []
  type: TYPE_NORMAL
- en: You could, of course, do this by hand, but this would be tedious and certainly
    isn't the best use of time for a skilled Linux admin. It is also error-prone—a
    typo could be made on one of the 10 servers and not spotted. Or the admin could
    be interrupted by an outage elsewhere and only a subset of the server configurations
    changed.
  prefs: []
  type: TYPE_NORMAL
- en: The better solution would be to write a script to make the change. This is the
    very basis of automation and it is almost certainly going to be a better use of
    time to run a single script once against 10 servers than to manually make the
    same change 10 times over. Not only is it more efficient, but if the same change
    became required in a month, the script could be reused with just minimal adjustment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s throw a spanner into the works. What if, for reasons unknown, someone
    built five of the web servers using Apache on CentOS 7, and the other five using
    nginx on Ubuntu 18.04 LTS? The end result would, after all, be the same—at a basic
    level, they are both web servers. However, if you want to change the document
    root in Apache on CentOS 7, you would need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Locate the appropriate configuration file in `/etc/httpd/conf.d`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make the required change to the `DocumentRoot` parameter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reload the web server with `systemctl reload httpd.service`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you had to do the same thing for nginx on Ubuntu 18.04 LTS, you would do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Locate the correct configuration file in `/etc/nginx/sites-available`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make the required change to the `root` parameter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the site configuration file is enabled using the `a2ensite` command—otherwise,
    Apache will not actually see the configuration file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reload the web server with `systemctl reload apache2.service`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As you can see from this rather simplistic (albeit contrived) example, a lack
    of commonality is the enemy of automation. To cope with the case, you would need
    to do as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Detect the operating system on each server. This in itself is non-trivial—there
    is no one way to detect a Linux operating system, so your script would have to
    walk through a series of checks, including the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The contents of `/etc/os-release`, if it exists
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The output of `lsb_release`, if it is installed
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The contents of `/etc/redhat-release`, if it exists
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The contents of `/etc/debian_version`, if it exists
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Other OS-specific files as required, if none of the preceding produce meaningful
    results
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run different modification commands in different directories to effect the change
    as discussed previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run different commands to reload the web server, again as detailed previously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hence, the script becomes complex, more difficult to write and maintain, and
    certainly more difficult to make reliable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although this particular example is unlikely to occur in real life, it does
    serve to make an important point—automation is much easier to implement when the
    environment is built to a given standard. If a decision is made that all web servers
    are to be based on CentOS 7, to run Apache 2, and have the site configuration
    named after the service name, then our automation becomes so much easier. In fact,
    you could even run a simple `sed` command to complete the change; for example,
    suppose the new web application was deployed to `/var/www/newapp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: No environment detection was necessary at all—just two simple shell commands.
    This could be the basis of a really simple automation script to be run either
    on each of the 10 servers in turn or remotely over SSH. Either way, our automation
    task is now very simple and shows how important commonality is. Importantly, an
    SOE by its very nature provides this commonality. Lack of commonality doesn't
    just make automation difficult though—it also hampers testing, often distorting
    test results as they may not be representative if environments are different.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section of this chapter, we will build on this knowledge to demonstrate
    how an SOE benefits the process of software testing.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of SOE to software testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common problem I have seen in many environments is that of a new software
    deployment having been successfully tested in an isolated pre-production environment
    and yet not working correctly when it is released into the production environment.
    More often than not, this problem is traced back to fundamental differences between
    the production and pre-production environments, and so it is clear that for testing
    to be valid, both environments must be as similar as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, one of the problems containerization platforms such as Docker set out
    to solve was exactly this, and hence portability is a core feature of container
    environments. Code deployed on Docker is built on top of a container image that
    is, in simple terms, a stripped-down operating system image (remember JeOS?).
    This, in effect, is a really tiny SOE, just running in a container rather than
    on a bare metal server or virtual machine. However, it is worth considering that
    if portability through environment standardization is a key feature of container
    technology, then should we not try to achieve this across the board regardless
    of our infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: After all, if the configuration of the production servers is different from
    the pre-production ones, then how valid is the testing? If the pre-production
    environment was built on CentOS 7.6, but the production environment lags behind
    it on CentOS 7.4, then can you really ensure that a successful test result in
    one environment will guarantee it in the other? On paper, it should work, but
    with fundamental differences in software and library versions between the environments,
    this can never be guaranteed. This is before we even consider possible differences
    in configuration files and installed software.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, SOEs can help here—if all environments are built to the same standards,
    then in theory, they should all be identical. Those of you who are eagle-eyed
    will notice the use of the word *should* in the previous sentence and it is there
    for a good reason. SOEs are a great step forward in defining the solution for
    testing failures, but they are not the whole story.
  prefs: []
  type: TYPE_NORMAL
- en: An environment is only standard as long as no-one modifies it, and if all users
    have administration-level privileges, then it is very easy for someone (well-meaning
    or otherwise) to log in and make changes that mean the environment deviates from
    the standard.
  prefs: []
  type: TYPE_NORMAL
- en: The answer to this issue is automation—not only do SOEs promote and enable automation,
    they also rely on it to maintain the level of standardization that they were required
    for in the first place. The two support each other directly and should ideally
    be inseparable partners—the SOE being the definition for the environment itself,
    and the automation providing the implementation, enforcement, and auditing of
    the standard. Indeed, this is the very premise of this book—that environments
    should be standardized as far as possible, and that as many changes as possible
    should be automated.
  prefs: []
  type: TYPE_NORMAL
- en: The focus of this book will be on the automation aspect of this equation, as
    other than adhering to the principles outlined in this chapter, the standards
    adopted will be unique for every environment and it is not the goal of this book
    to determine them at a low level. Working with our earlier example, both Apache
    and nginx have their benefits, and what fits one use case may not fit another.
  prefs: []
  type: TYPE_NORMAL
- en: The same is true with operating systems—some organizations may rely on the support
    package provided with Red Hat Enterprise Linux, whilst others don't need this
    but need the bleeding edge technologies provided by, say, Fedora. There is no
    right or wrong way to define a standard, as long as it meets the needs of the
    services it underpins. So far, we have focused very much on commonality and standards;
    however, there will always be edge cases where an alternative solution is required.
    In the next section, we will establish how to know when you should deviate from
    your standards.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing when to deviate from standards
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It would be easy to oversell the benefits of standardization, and they are certainly
    a requirement for automation to be effective. However, like anything, it can be
    taken too far. There is no point, for example, building servers on top of Red
    Hat Enterprise Linux 5.7 in 2019 simply because this was once defined as a standard
    (it is now End of Life and no longer supported or updated). Similarly, from time
    to time, software vendors will have qualified their product on certain specific
    Linux distributions or application stacks and will not provide support unless
    their software is run within that ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: These are cases when deviations from the SOE are necessary, but they should
    be performed in a controlled manner. For example, if a business has built up its
    Linux server estate on Ubuntu 18.04 LTS, and then a new software stack is purchased
    that is only qualified on RHEL 7, it is clear that builds of RHEL 7 are going
    to be required. These should, however, be part of a new set of standards if possible
    and become a secondary SOE.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if the CIS security hardening benchmark is applied to the Ubuntu
    SOE, then the equivalent one should be applied to the RHEL too. Similarly, if
    the business has standardized on nginx, then this should be used on the environment
    unless there is a compelling reason not to (hint: a compelling reason is not that
    it''s new and sexy—it is that it solves a real problem or somehow improves something
    in a tangible way).'
  prefs: []
  type: TYPE_NORMAL
- en: This results in the business going from one Linux SOE to two, which is still
    entirely manageable and certainly better than returning to organic growth methodologies
    that hamper effective automation.
  prefs: []
  type: TYPE_NORMAL
- en: In short, expect deviations, and don't fear them. Instead, handle them and use
    the requirements to expand your standards, but stick with them where you can.
    SOEs present a balancing act for everyone—on the one hand, they bring advantages
    of scale, make automation easier, and reduce the training time for new staff (as
    all servers are more or less the same in build and configuration), but if applied
    too rigidly, they could hamper innovation. They must not be used as an excuse
    to do things a certain way *because that's how it has always been done*.
  prefs: []
  type: TYPE_NORMAL
- en: There will always be a good reason to deviate from a standard; simply look for
    the business benefit it brings, whether it's vendor support, lower resource requirements
    (hence saving power and money), a longer support window, or otherwise. Try and
    avoid doing so just because a new technology is *shiny*. As long as you are mindful
    of this fact, you will make good decisions regarding deviation from your standards.
    In the next section of this chapter, we will explore the ongoing maintenance of
    SOEs.
  prefs: []
  type: TYPE_NORMAL
- en: Ongoing maintenance of SOEs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although we will look at patching and maintenance in much greater detail later
    in this book, it deserves a mention here as it dovetails nicely into the discussion
    on commonality and deviations.
  prefs: []
  type: TYPE_NORMAL
- en: If nothing else, you are going to have to patch your Linux environment. For
    security reasons alone, this is a given and good practice, even in an air-gapped
    environment. Let's say that your environment is made up entirely of virtual machines
    and that you decided to standardize on CentOS 7.2 some time ago. You built a virtual
    machine, performed all of the required configuration steps to turn it into your
    SOE image, and then converted it into a template for your virtualization environment.
    This becomes your *gold build*. So far, so good.
  prefs: []
  type: TYPE_NORMAL
- en: However, CentOS 7.2 was released in December 2015, nearly 4 years ago at the
    time of writing, and if you were to deploy such an image today, the first thing
    you would have to do is patch it. This would, depending on the build definition
    (and the number of packages included in it), possibly involve downloading a gigabyte
    or more of packages to bring it up to the latest standard and ensure you were
    running with all discovered vulnerabilities patched, and all of the requisite
    bug fixes in place.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, if you are doing this at scale, this is inefficient—each new server
    is going to pull all that data down over the network (or worse, the internet,
    if you don't have an internal mirror), and then consume a great deal of I/O time
    and CPU time applying the patches, during which the server can't be used for anything
    meaningful. If you only deploy one server every few months, you can probably put
    up with this. If you deploy them on a more regular basis, then this is going to
    waste a lot of valuable time and resources.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, as well as performing ongoing maintenance of your environment itself,
    it is important to perform ongoing maintenance of your standards. In 2019, it
    makes sense to update your CentOS build to 7.6\. At the very least, your ongoing
    maintenance schedule should involve updating the *gold build* regularly.
  prefs: []
  type: TYPE_NORMAL
- en: We will go into much greater detail on how this might be performed later in
    this book. However, for those who are eager to know now, this might be as simple
    as booting the virtual machine image up, performing the updates, sanitizing it
    (for example, removing SSH host keys that would be duplicated when the template
    is cloned), and then creating a new template from it. Obviously, if any other
    changes to the SOE have been made since the last maintenance cycle, then these
    can be incorporated too.
  prefs: []
  type: TYPE_NORMAL
- en: You should expect your SOE to evolve over time—it would be easy perhaps to labor
    this point—but there is an important balance between creating and maintaining
    standards, and being overly rigid with them. You must accept that there are times
    when you will need to deviate from them as we discussed in the previous section
    and that, over time, they will evolve.
  prefs: []
  type: TYPE_NORMAL
- en: In short, SOEs should become a part of your regular IT processes; if employed
    correctly, they don't hinder innovation— instead, they actively support it by
    giving back time to those working with them and ensuring they spend less time
    performing mundane, repetitive tasks and hence have more time for evaluating new
    technologies and finding better ways of doing things. This, after all, is one
    of the key benefits of automation, which SOEs support directly.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SOEs are a valuable addition to technology processes in almost any environment.
    They require some time to be spent upfront on design work and defining standards,
    but this time is more than offset later on as it supports efficient and effective
    automation of the environments, and in this manner, actually gives time back to
    those responsible for the environment, giving them more time to work on evaluating
    new technologies, finding more efficient ways to do things, and being innovative in
    general.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned the fundamental definition of an SOE. You explored
    the benefits that they bring to just about any Linux environment where scale is
    important, how they support automation, and when and how to make deviations from
    the standards to ensure that they do not become overly rigid and hamper growth.
    Finally, you learned about the importance of ongoing maintenance, including maintenance
    of your standards as part your ongoing maintenance cycles.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore how to make use of Ansible as an effective
    automation framework for your Linux environment.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What does the acronym SOE stand for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why would you choose an operating system with a long support cycle, such as
    CentOS, rather than one with a more rapid release cycle, such as Fedora?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should you ever deviate from the standards you have defined for your environment?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List three challenges of scaling Linux environments up to enterprise scale.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name three benefits that SOEs bring to Linux in the enterprise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does an SOE help to reduce the training requirements in an enterprise?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why does an SOE benefit the security of your Linux environment?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To learn more about SOEs from a Red Hat perspective, refer to this article: [https://servicesblog.redhat.com/2016/11/03/standard-operating-environment-part-i-concepts-and-structures/](https://servicesblog.redhat.com/2016/11/03/standard-operating-environment-part-i-concepts-and-structures/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
