

# 负载均衡与 HTTP

本章我们将采取一种稍微不同的方式，因此请系好安全带。一方面，我们将回顾一些关于**超文本传输协议**（**HTTP**）的背景知识，并重点讨论一些常见的误解，这些误解常常让许多开发人员在实际工作中踩坑。

另一方面，我们将保持实用，讲解一个在命令行上非常强大的标准 HTTP 工具——`curl`。具体来说，我们将教授你在使用 `curl` 排查常见的 web 应用问题时的基础知识。

我们假设你作为 web 开发者，已经对 HTTP 有一定了解。所以，虽然本章的目标不是教授你这一协议的基础知识，但我们会回顾一些基本内容，帮助你尽快跟上进度，特别是如果你有一段时间没接触过它。如果你*完全*不懂 HTTP，网上有很多优秀的文档可以帮助你。至于推荐，我们强烈建议你参考 Mozilla 提供的 MDN 文档。

其实，我们更希望聚焦在 HTTP 的常见误解和在实际应用中的陷阱，这些问题常常会让人吃惊。这些误解通常源于这样一个事实：作为开发者，你在非常简单的本地环境中编写 web 应用，但在复杂的生产环境中运行它们，这些环境与用于构建和测试的笔记本电脑大不相同。

开发环境中应用与本地机器的交互方式与应用在部署到暂存或生产环境后的基础设施之间的差异，是许多混淆和细微错误的源头。

在本章中，我们将讨论这些差异中最重要的内容：你将了解网关、上游服务器以及与现代网站或 web 应用的基础设施层交叉的其他概念。然后我们将讲解一些关于 HTTP 的常见错误，这些错误通常会导致调试困难的头部、状态码等问题。我们还会介绍一些现代安全功能，例如**跨域资源共享**（**CORS**），以及 HTTP 的历史和你可能会遇到的版本。最后，你将学习负载均衡的基本概念：了解这些基础知识能帮助你避免对客户端请求路径的错误理解，这是应用程序/基础设施边界处常见的设计问题源。

你将学习：

+   理解本章后续讨论的更复杂的 web 基础设施所需的一些基本术语。

+   关于 HTTP 状态码的常见误解，充分理解这些误解有助于你编写更简洁、更准确的状态处理代码。

+   HTTP 头部，以及你在自己的网站应用中可能遇到的一些相关问题。

+   你在实际使用中可能遇到的不同 HTTP 版本。

+   了解负载均衡是如何工作的，以及作为开发者为什么即使你从不打算接触应用程序基础设施，也需要理解它。

+   如何使用名为 `curl` 的工具，通过命令行排查与所有这些主题相关的 Web 问题。

本章唯一的前提知识是对 HTTP 请求工作原理的基本了解，以及对 Web 应用程序开发工具的基本认识（例如，你应该知道如何使用浏览器的控制台和其他开发工具来调试基本的 HTTP 问题）。

让我们从一些基本术语开始，这些术语在我们进行故障排除时会派上用场。

# 基本术语

后续章节将使用一些你可能不熟悉的术语，所以我们在这里快速覆盖一下这些术语。

## 网关

在当今的世界中，网关通常是一个 HTTP 反向代理、负载均衡器，或者两者的组合。这可以是一个 HTTP 服务器，如 nginx 或 Apache，一个传统意义上的物理负载均衡器，或是这种思路的云变体。它也可以是一个**内容分发网络**（**CDN**）。所以，当你收到一个 HTTP 状态码，提到与网关相关的错误时，就是这些网关设备或应用程序在与你通信。

## 上游

上游是指应用程序代理的服务。在大多数情况下，这将是实际的应用程序或服务，例如，你编写的 HTTP 服务。需要记住的是，代理可以级联或层叠，因此，可能在第一个代理和实际 Web 应用程序之间还有一个中间代理。例如，在许多云基础设施中，有一个入口负载均衡器负责处理和过滤传入流量，后面则是一个应用负载均衡器，实际上检查 HTTP 流量并将其路由到正确的应用服务器池。

现在，我们已经介绍了一些超越 HTTP 的术语，你已经为本章后续的内容做好了准备。接下来，让我们更详细地了解一些 HTTP 中常见的误解部分，并开始使用 `curl` 工具来练习常见的 CLI 排查命令。

# 关于 HTTP 的常见误解

在开发 Web 应用程序和 HTTP API 时，了解一些很多开发者容易忽略的细节是很有价值的。让我们来看一下几个关键领域，掌握这些额外的知识对你所创建的应用程序的可靠性非常有帮助。本章中我们介绍的 `curl` 技能，也将使你能够从命令行开始排查像“网站无法访问”这样模糊的问题。

## HTTP 状态码

在接下来的章节中，我们将介绍一些你可能会遇到的常见 HTTP 状态码。我们还将讨论一些关于这些状态码的重要信息和误解，你需要牢记这些内容。

### 不要只检查 200 OK

检查错误的常见方法是只检查 200 或整个 2xx 范围的状态码，以确定请求是否成功。然而，进行此操作时需要注意一些陷阱。

200 范围（2xx，即 200 到 299 之间的每个状态码）通常表示成功，许多 API 返回 204 No Content 来表示操作成功，尤其是当 API 通常返回已创建或已修改的资源时，但在某些场景下，例如 DELETE 请求，或者当返回资源会浪费资源时，则不会返回。

检查响应状态是否在 2xx 范围内，对于某些应用来说可能足够，但重要的是要理解像“如果不是 200，记录错误”这样的应用逻辑是错误的。1xx 范围和 3xx 范围都不表示错误，即使它们不是 200。

1xx 范围的状态码在没有预期的情况下出现是相对罕见的，因为涉及 100 的最常见情况是切换到 WebSocket，但这并不意味着它们是错误。3xx 状态码经常被返回，用于通知客户端重定向，虽然它可能表示需要某些操作——例如更新已移动内容的路径——但它本身绝对不是失败。

3xx 范围中一个在生产环境中比开发环境中更常见的状态码是 304 Not Modified。在开发时，这个状态码很容易被忽视，也可能由于基础设施变化或库更新，改进或引入了新的缓存行为。这个状态码在客户端（如浏览器或 HTTP 库）发送带有 If-Not-Modified 头的请求时使用，特别是为了利用缓存。

因此，通常只将以 400 开头的状态码视为任何潜在错误，而不是仅仅将 2xx 状态码视为成功。这仍然有助于应用程序内部保持简洁的逻辑：检查状态码是否大于或等于 400，与检查其是否在 2xx 范围内一样简洁。

### 404 Not Found

需要记住的一点是，Not Found 状态码根据应用程序的不同可能意味着不同的事情。404 可以由（文件）服务器和网关返回，也可以由应用程序返回。它可以表示某个路由不存在，也可以表示某个特定资源（例如，帖子或评论）因某种原因（例如被删除）而不存在。

这就是为什么 404 常常是健康应用正常响应集的一部分，且该应用按设计工作。在某些情况下，客户端甚至可能依赖这种行为，例如在创建某个资源之前或在告诉用户某个资源或资源名称是否已被占用时，验证某个内容是否不存在。

换句话说，单独的 404 状态码（没有关于应用程序和请求的更多上下文）不足以表明一个问题。正如你刚刚看到的，它可能在多个层面和层次上表示成功。有时可以通过在应用层避免使用它，并以不同的方式表示“未找到”情况，例如仍然返回 200 状态码，来避免这种情况。正确的做法取决于应用程序、团队或标准的约定，以及你应用程序使用的架构风格。

### 502 错误网关

这个状态码意味着网关没有理解上游返回的内容；换句话说，网关转发请求的响应不是一个完整且有效的 HTTP 响应。这通常表示上游服务有问题。

### 503 服务不可用

503 通常意味着上游服务在网关配置的端口上无法访问。实际上，这意味着 Web 应用程序可能崩溃了，或者它没有监听 HTTP 请求，或者它监听的是错误的端口，或者它被防火墙规则或破损的路由规则阻止，或者有其他无数原因。

### 504 网关超时

当网关与上游建立连接时，这个连接会在某个时刻超时。这一点很重要，因为挂起的进程会消耗双方的资源；无论是网关*还是*服务。通常，只有在这种情况出乎意料且没有字节被写入或读取时，才会发生这种超时。

如果上游服务有一个需要长时间运行的请求（例如等待计算等），一种选择是增加请求的超时时间。然而，通常建议采取不同的方法。例如，可以将该端点改为异步，或者通过提前开始写入字节（例如通过数据流式传输）来帮助解决问题。

这样做的原因是，在超时之前，资源会被消耗，而请求方并不知道应用程序是否会返回响应。因此，如果 Web 服务出现故障，网关和客户端都不会知道。这可能还会导致网关认为故障的服务仍在运行，而不是快速检测问题并切换到服务的其他实例。

### curl 简介：检查 HTTP 响应状态

如果你只学习一个命令行工具来帮助你排查 HTTP 问题，`curl`是一个不错的选择。当我们继续深入讨论 HTTP 的各个方面时，我们会添加类似这样的章节，展示你可以在排查与 HTTP 相关的常见问题时使用的实用`curl`命令。

最简单的`curl`调用如下所示：

```
curl https://tutorialinux.com/ 
```

这就像将 URL 粘贴到浏览器中——只是它跳过了浏览器，直接返回 web 服务器的响应到命令行。虽然这并不是浏览网页最激动人心的方式，但它更适合你下一个故障排除脚本的需求：检查 HTTP 响应的状态！

Curl 可以轻松地用来检查一个 web 服务器是否正常运行并响应请求：

```
curl -IsS https://tutorialinux.com/ | head -n 1
HTTP/2 200 
```

根据这个输出，我们知道 web 服务器已经启动，并且 `/` 路由正在响应 200 OK 状态。你还可以看到这里的 HTTP 版本（HTTP/2），我们稍后会讨论。具体来说，这个命令发出了一个 HEAD 请求（`-I` 或 `--head`），静默了 curl 的进度和错误信息（`-s` 或 `--silent`）。

然而，通过 `-S`（或 `--show-error`）选项，你仍然会看到错误信息，当出现问题时：

```
curl -IsS https://tutoriajsdkfksjdhfkjshdflinux.com/ | head -n 1
curl: (6) Could not resolve host: tutoriajsdkfksjdhfkjshdflinux.com 
```

最后，我们将截取大部分头部，只查看状态码，这是第一行（`| head -n 1`）。

然而，在故障排除时，你通常需要查看头部信息。让我们看几个与头部相关的 HTTP 陷阱，然后尝试使用 `curl` 检查头部。

## HTTP 头部

### 头部不区分大小写

HTTP 中的头部是不区分大小写的。某些软件依赖于这一点，结果某些网关可能会修改并“规范化”这些头部。幸运的是，开发人员在编写 web 应用程序时很少直接与原始头部值交互。相反，他们使用 web 库，这些库会将大部分复杂性抽象化，并处理这些细节。然而，你仍然应该确保这一点，并规范化它们，例如通过将你 web 应用程序设置的头部转换为小写。这样也可以防止响应头部因字母大小写不同而被意外添加多次。

### 自定义头部

当你为应用程序创建自定义 HTTP 头部时，要注意你决定使用的前缀。过去，通常会使用 `X-` 作为自定义头部的前缀，例如 `X-My-Header`。这种做法现在已被认为是不好的（参见 RFC 6648，已经弃用该做法）。相反，更合适的是创建一个自定义前缀，例如项目、产品或公司名称，或者它的缩写。这可以避免其他开发人员误将这个头部当作 HTTP 标准的一部分而重复使用。

### 使用 curl 查看 HTTP 头部

我们在前面的 `curl` 示例中介绍的 `-I` 选项对于查看响应头非常有用，这可以帮助发现缓存问题、内容类型不匹配以及其他问题。让我们看看 tutorialinux 服务器的头部信息：

```
curl -I https://tutorialinux.com/
HTTP/2 200
server: nginx/1.24.0
date: Sat, 21 Oct 2023 16:37:12 GMT
content-type: text/html; charset=UTF-8
vary: Accept-Encoding
x-powered-by: PHP/8.2.11
link: <https://tutorialinux.com/wp-json/>; rel="https://api.w.org/"
strict-transport-security: max-age=31536000; includeSubdomains; preload 
```

目前服务器没有问题，但这些头部信息已经给了我一些如何改进 nginx 配置的想法：从安全角度来看，泄露软件名称和版本号通常是不好的做法，而没有人需要知道从这个服务器接收 HTML 或 JSON 的用户，后台正在使用 PHP。

## HTTP 版本

为了说明一些你将看到的新 HTTP 特性，我们将简要回顾一下这个协议的历史。HTTP 已经存在一段时间，并且发生了很多变化，特别是在近年来，随着 Web 应用的流行，变化尤为显著。自 HTTP 起源以来，主要的概念和原语基本保持不变，然而，一些技巧、优化和行为已经发生了变化。了解协议版本有助于调试或预防问题，并减少不必要或适得其反的优化和变通方法。

### HTTP/0.9

你不太可能再遇到这个版本的 HTTP 它是一个极简的 HTTP 版本。HTTP/0.9 允许向服务器发送一个 `GET` 请求并接收我们现在称之为 HTTP 请求 *主体* 的内容。没有发送或返回头部，甚至没有版本头或状态码。

### HTTP/1.0 和 HTTP/1.1

HTTP/1.0，特别是 HTTP/1.1，离人们今天对 HTTP 的理解更近了。虽然 HTTP/1.0 添加了版本号和头部，但 HTTP/1.1 为方法和大量扩展（通常以头部的形式）铺平了道路。

HTTP/1.1 还增加了（并默认启用）管道化。这意味着多个请求可以通过同一个 TCP 连接发送。另一个广泛使用的新增功能是 `Host` 头，它允许同一服务器或 IP 使用多个主机名。

例如，Web 服务器现在可以配置为响应 `http://example.org/`、`http://www.example.org/`、`http://forum.example.org/` 和 `http://blog.example.org/` 的请求，而无需为每一个请求使用单独的 IP 地址。

HTTP/1.1 还启用了许多扩展：缓存、压缩、各种身份验证方案、内容协商，甚至是像 WebSockets 这样的功能。所有这些在今天的 Web 中被广泛使用。

### HTTP/2

有很多文章赞扬 HTTP/2 的优点。它是 HTTP 向新方向迈出的巨大且具有争议的一步。虽然 HTTP/1.1 是一个基于文本的协议，允许任何人在终端或文本编辑器中创建完整有效的请求，但 HTTP/2 是一个二进制协议，它还处理流，这是创建轻量级 TCP 连接变体的一种机制。

二进制格式和头部压缩意味着现在需要专用工具来与 HTTP 服务器（或客户端）进行通信。然而，整体概念与早期版本的 HTTP 保持一致，因此作为一名 Web 开发者，你只会在特定情况下注意到差异。

虽然 HTTP/2 也增加了许多全新的功能，但其中许多在面向用户的 Web 应用中很少使用，甚至可能没有被浏览器实现。

虽然这在技术上并不是官方标准的一部分，但在浏览器中，HTTP/2 通常仅限于 HTTPS。

在大多数情况下，Web 应用将从增强功能中受益，例如使用单个 TCP 连接并进行多个流传输，尤其是在许多请求（如静态文件和 AJAX 请求）并行发出时。这可以使某些优化方法（如精灵图或将多个文件合并为一个文件）变得不再必要。当这些优化导致冗余数据传输时，甚至可能适得其反。

一些为 HTTP/1.1 设计的应用在切换到 HTTP/2 时可能需要进行修改，因为像保持连接活动这样的操作可能会产生不可预测的副作用。基于这一点和其他原因，建议在将应用程序转换为 HTTP/2 前进行测试。有时，甚至会发现将应用程序切换到 HTTP/2 会增加页面加载时间或增加资源使用。

这意味着进行实际测试和监控，以比较 HTTP 协议之间的差异是一个好主意。由于 HTTP/2 的许多优点针对的是 Web 浏览器的实际使用，简单的命令行负载测试可能无法与真实用户访问 Web 应用时的结果相同。例如，一个常见的错误是不考虑 HTTP/1.1 的流水线功能。

然而，对于大多数现实生活中的网站来说，HTTP/2 将带来好处。对于微服务中的内部 HTTP API，许多公司选择继续使用 HTTP/1.1 或 gRPC。

### HTTP/3 和 QUIC

HTTP/3 基于 HTTP/2 的发展，并将其概念迁移到一种基于 UDP 的传输协议 QUIC（而不是其他 HTTP 版本使用的 TCP）。

像之前版本的 HTTP 一样，HTTP/3 使用流作为建立新 TCP 连接的轻量级替代方案。与 HTTP/2 不同，HTTP/3 并不是通过在现有的 TCP 连接内启动流来实现，而是通过使用 QUIC，它是一个专门为支持此类流而设计的协议。

QUIC 在常见的 HTTP 使用场景中相比于 TCP 有一些优势。例如，由于 QUIC 基于 UDP——UDP 是用户数据报协议，一种比 TCP 更简化但更快速的替代方案——它可以防止因单个数据包尚未到达（即便该数据包是传输给不同流的）而导致整个连接停滞的情况。QUIC 还针对快速建立初始连接进行了优化，包括启动 TLS 以确保客户端与服务器之间的连接安全。QUIC 本身是为了支持未来版本的扩展性而创建的，在标准化后不久，许多此类扩展已经开始标准化。

由于 HTTP/3 基于 UDP 并旨在避免 *协议僵化*，许多传统的中间节点和网关形式变得过时。

**注意**

协议僵化指的是当中间节点（或任何与协议交互的部分）要求协议保持某种形式时，导致协议的持续开发和更改变得困难（例如，添加扩展）。

让我们看看这些基本的 HTTP 概念如何融入大多数 Web 应用程序所运行的更大基础设施中。在这样的架构中，通常不仅仅是一个单独的 Web 服务器和客户端（像你的 Web 浏览器或`curl`）：通常会有几个 HTTP 通信层次，简单的问题可能会累积并变得难以排查。

如常，我们将为你提供你需要理解的最重要概念，随后是一些使用`curl`命令行工具排查更复杂 Web 基础设施问题的实用技巧。

## 负载均衡

负载均衡是一种将目标服务的负载分散到该服务的多个实例上的方法。虽然这并不仅限于 HTTP 和 Web 服务，但 HTTP 是目前负载均衡最常见的应用场景之一。

了解 Web 应用负载均衡的工作原理非常重要，因为它会影响在生产环境中如何出现错误和问题。例如，在本地开发环境中，你通常只处理单一客户端（你的浏览器或其他 API 消费者）和单一服务器（你正在开发的 Web 应用或服务）。但在真实世界中，客户端和应用之间通常会有多个服务器层，每一层都负责转发 HTTP 流量，并可能在流量中引入自己的问题或错误。

本节材料将帮助你高层次地理解那些虽然不属于你编写的应用代码，但却成为整个应用一部分的活动组件。

HTTP 负载均衡通常是通过在应用前面放置一层基础设施来代理 HTTP 请求；通常有以下几种方式：

1.  网关服务，例如支持的 HTTP 服务器（如 nginx 或 Apache）

1.  专用服务（如 HAProxy 或 relayd）

1.  云服务（如 GCP 的负载均衡器、AWS 的 ELB 或 ALB 等）

1.  硬件负载均衡器

有时，工程师选择使用自定义服务或基于 DNS 的解决方案，尤其是在区域性负载均衡的场景中，这通常作为前置层添加在上述提到的其他方法之前。容器编排工具和专用的服务发现机制通常也提供另一种负载均衡的方式。

引入负载均衡器会涉及到理解一些其他概念——尤其是如何将来自客户端的请求映射到正在运行你精心设计的 Web 应用实例的服务器上。

会话和 cookie 管理变得复杂，因为长期运行的会话不再保证每次都会命中相同的服务器。应用池中的一台服务器出现故障会成为问题 —— 用户体验会中断吗？他们会丢失数据吗？作为工程师的你在排查自己 web 应用程序的问题时，是否无法重现问题，因为它只发生在数十台或数百台服务器中的一台上？

了解现代负载均衡是如何工作的，对于避免应用设计缺陷或类似这种排查困难的麻烦至关重要，接下来的几节将为你提供一个基本的思维模型，帮助你避免这些问题。

### 粘性会话、cookies 和确定性哈希

在为 HTTP 服务设置负载均衡时，第一个需要问的问题是该服务是否需要粘性会话。粘性会话是一种将客户端与特定应用服务器绑定在一起的机制，通常对于那些将会话状态保存在应用服务器上的应用程序是必须的。

这也是为什么设计“无状态”应用程序的最佳实践之一，因为这些应用程序将状态写入共享数据层 —— 在这些应用程序中，客户端的第一次请求是否由不同的服务器处理与第二次请求无关。幸运的是，在今天的世界中，尤其是在依赖基于云的基础设施时，通常不需要粘性会话。然而，这一点值得记住，特别是在排查只在负载均衡的生产环境中神秘出现的问题时。

尽管有许多方法可以在 HTTP 中创建粘性会话，但最常见的方法是通过 cookies。这可以通过负载均衡器可以识别的应用程序 cookies（如会话 cookies）来实现，也可以通过负载均衡器自己管理的专用 cookies 来实现。

然而，通过在负载均衡器上存储额外的状态来实现粘性会话本身也存在一些问题。如果负载均衡器必须保持 IP 地址到应用服务器的内部映射，那么如果该负载均衡器崩溃并被替换，导致状态丢失，会发生什么？你会发现，我们只是将状态问题从应用服务器转移到了负载均衡器上，并希望那里不会发生任何不好的事情。然而，正如俗话所说，希望并不是一种可行的策略。

实现粘性会话的一个巧妙方法是通过使用 IP 哈希进行负载均衡，而不需要处理在负载均衡器上存储状态的问题。为了实现这一点，会创建客户端 IP 的哈希值，并用于将请求的 IP 映射到服务实例上。只要客户端的 IP 不变，会话就会对该特定的应用实例保持“粘性”。

现在，一个或多个负载均衡器将确定性地将 IP 地址与应用服务器匹配，无需通信或共享状态。服务器可以随意进出，每个新服务器都会做出与其他服务器相同的匹配决定，因为它们都使用相同的哈希算法，并且始终将给定的 IP 地址匹配到相同的应用服务器。

### 轮询负载均衡

如果不需要粘性会话，最常见的负载均衡机制是轮询。这意味着每个新的连接或请求都会被路由到下一个实例。从数学角度来看，这意味着实例是通过`request_count % instance_count`（%表示取余）来选择的。

### 其他机制

你现在对 HTTP 负载均衡在现实世界中的工作原理有了一个高层次的概览。当然，还有许多其他的机制可以选择，例如基于资源使用情况的负载分配，但你应该小心真正理解增加复杂性所带来的影响——许多“聪明”的负载均衡算法并非没有重大陷阱。

例如，基于资源利用率的负载均衡器在处理短暂的负载峰值时可能会遇到问题，这可能导致一个实例的利用率不足而另一个实例的利用率过高，因为服务实际处理的工作负载具有波动性，而负载测量的时间不合适，未能平衡这些峰值。

为了平衡这样的负载峰值，可能会增加额外的复杂性，这也可能带来其他问题，比如这些峰值会堆叠在一起。如果你发现自己偏离了更为成熟的负载均衡机制，确保你的团队已经充分考虑了架构和实际应用及其使用场景的技术细节。

### 高可用性

虽然负载均衡的主要目标可能是确保快速响应，但负载均衡器通常会跟踪哪些服务是可达的。它可能会使用健康检查来验证它发送请求的服务器是否完全正常。这意味着负载均衡也是实现高可用性的一种方式，通常也是零停机架构的一个组成部分，在这种架构中，服务可以被替换（例如，当部署新版本时），而客户端不会察觉。

这可以通过允许实例以某种形式优雅地关闭来实现，其中与客户端的连接不会被简单地断开，而是保持活跃直到完全处理完毕，而新的连接只会被路由到已更新的实例。当最后一个会话结束时，过时的实例可以完全关闭。

健康检查使负载均衡器能够判断服务是否完全正常运行。当然，最基本的检查是是否能够建立连接。然而，在微服务架构中，无法访问外部依赖（比如另一个服务）可能会阻止服务正确响应请求。这也可以通过一个专门的状态端点来指示。

许多应用程序和基础设施团队会达成一致，使用像 `/healthcheck` 这样的路由，其状态码指示请求是否应路由到该服务。在一些更复杂的环境中，这样的路由甚至可能指示可以路由到实例的*请求类型*。

当熟练的应用开发人员和平台/SRE 团队聚集在一起时，健康检查路由甚至可以构建为在基础设施需要采取行动时发出信号，比如实例出现严重故障需要替换。如果这些路由设计得当，通常也会提供关于问题的额外上下文和信息，以便简化生产环境中的调试工作。

随着支撑 web 应用的基础设施变得越来越大和复杂，可能出现的问题也呈指数级增加，并且高度依赖于具体的架构和应用程序。一类问题是在 web 基础设施拥有更多代理和路由层时更容易出现的，即重定向循环和一般的重定向错误。

幸运的是，像 `curl` 这样的命令行工具正好可以用来排查这个问题。

### 使用 curl 排查重定向问题

正如我们刚刚提到的，重定向可以是 web 应用及其周边基础设施中的常见故障、问题，甚至是一些意外行为的表现。使用 curl 的 `-L`（或 `--location`）选项来跟踪它们：

```
curl -IL http://www.tutorialinux.com/
HTTP/1.1 301 Moved Permanently
Server: nginx/1.24.0
Date: Sun, 22 Oct 2023 22:58:02 GMT
Content-Type: text/html
Content-Length: 169
Connection: keep-alive
Location: https://tutorialinux.com/

HTTP/2 200
server: nginx/1.24.0
date: Sun, 22 Oct 2023 22:58:02 GMT
content-type: text/html; charset=UTF-8
vary: Accept-Encoding
x-powered-by: PHP/8.2.11
link: <https://tutorialinux.com/wp-json/>; rel="https://api.w.org/"
strict-transport-security: max-age=31536000; includeSubdomains; preload 
```

你会看到服务器返回 `301`（永久移动）和正确的位置，[`tutorialinux.com/`](https://tutorialinux.com/)。`curl` 跟踪该重定向并向新位置发起请求，在那里它得到了一个 200（OK）状态。

这个重定向按预期工作，但你可以使用这个 `curl` 命令来做一些事情，例如识别应用程序中的重定向循环，或者排查多层负载均衡设置中的缓存和路由问题。

然而，有时你需要深入并向 web 应用发送数据来进行故障排除。`curl` 也可以帮助解决这个问题！

### 使用 curl 作为 API 测试工具

拥有一个快速的 `curl` 命令用于 API 测试，比你想象的更有用。特别是在处理接受 POST 数据的 JSON API 时，通常会希望向某个端点发送一些测试数据，以确保后端返回了你期望的内容：

```
curl --header "Content-Type: application/json" \
     --request POST \
     --data '{"some":"JSON","goes":"here"}' \
     http://localhost:4000/api/v1/endpoint 
```

该命令使用了一些你需要记住的标志。首先，`--header` (`-H`) 参数允许你指定一个头部字符串（你可以通过重复此参数来提供多个头部）。接下来，`--request`（或 `-X`）标志允许你指定 HTTP 请求类型（默认情况下，`curl` 执行 GET 请求，但使用此标志可以改变请求类型）。当你进行 POST 或 PATCH 数据请求时，如本例所示，你需要使用 `--data`（或 `-d`）参数，这样可以发送数据。

在使用 `--data` 时，记住 bash 转义字符在这里发挥作用，因此对于复杂的数据，你可能会发现使用 `--data` 选项会更方便，如下所示：

```
curl -X POST --data "@my/data/file" https://localhost/api/v1/endpoint 
```

记得在文件路径前添加 `@` 字符。如果你发送的是复杂数据，也可以查阅 `--data-raw`、`--data-binary` 和 `--data-urlencode`。根据你的 web 应用程序的要求，你可能还需要发送额外的头部。

你现在已经了解了如何通过 `curl` 向你正在故障排除的 web 应用程序发送自定义数据，使其更具互动性。但我们还想展示最后一个 `curl` 技巧：TLS（传输层安全性，HTTPS 中加密现代 Web 流量的方式）不一定是 web 应用程序中一个“被误解”的方面，但它是一个常见的故障点，`curl` 可以帮助解决。

### 使用 `curl` 接受并显示无效的 TLS 证书

`curl` 为我们提供了 `--insecure` 选项，允许它接受来自服务器的无效 TLS 证书并继续请求。在故障排除配置错误的服务器时，这非常有用：

```
curl --insecure -v https://www.tutorialinux.org/ 
```

`--insecure` (`-k`) 选项会让 `curl` 假装 TLS 证书是有效的，即使它实际上无效。显然，这是一个安全隐患，仅应在故障排除时使用，但它可以让 `curl` 在 TLS 证书验证失败并且 `curl` 通常会中止请求的情况下继续执行。

让我们快速了解一下最后一部分关于 HTTP 的内容，如果你从事构建或故障排除 web 应用程序的工作，这部分内容值得学习：CORS。

## CORS

CORS 代表跨源资源共享。这个术语是用来表示资源，例如图片、视频、HTML、JavaScript，甚至是**异步 JavaScript 和 XML**（**AJAX**）响应将来自不同的主机名。为了防止从第三方加载资源的情况，浏览器首先会询问该第三方是否允许这么做。这被称为预检请求。

预检请求是一个 `OPTIONS` 请求，期望得到一个包含 HTTP 头部的响应，告知请求是否被允许。这样的响应通常会有一个 204（无内容）状态码，并且只包含头部。如果没有找到这样的头部，或者头部没有指示该请求被允许，则不会触发对资源的后续请求。

下面是这样的交换可能是什么样的例子。

浏览器打开[`www.example.org/`](https://www.example.org/)时，会询问是否允许向`api.example.org`的`/api/test`进行 POST 请求：

```
OPTIONS /api/test
Origin: https://www.example.org
Access-Control-Request-Method: POST
Access-Control-Request-Headers: X-Custom-Header, Content-Type 
```

一个接受的响应应该是这样的：

```
HTTP/1.1 204 No Content
Access-Control-Allow-Origin: https://www.example.org
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: X-Custom-Header, Content-Type
Access-Control-Allow-Max-Age: 3600 
```

由于这表示请求被允许，浏览器随后可以发送原始请求，这时请求已获得授权：

```
POST /api/test
Origin: https://www.example.org
Content-Type: application/json
X-Custom-Header: foobarbaz 
```

对于不被允许的请求，并没有通过错误状态返回信号来表示拒绝——只是缺少预期的`Access-Control-Allow-Origin`头信息。在这种情况下，客户端会看到请求未被授权并记录错误。

你可以在浏览器的开发者控制台中看到类似的错误。它们会像这样显示：

```
Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at https://not-allowed. (Reason: something). 
```

这只是对 CORS 的简要介绍，因为它是 Web 开发者必须理解的重要主题。尽管它与命令行无关，但开发者理解这些概念并检查 Web 客户端中这些错误日志是很常见的。想要深入了解该主题，我们推荐 MDN 上的相关文章，链接是[`developer.mozilla.org/en-US/docs/Web/HTTP/CORS`](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS)。

# 结论

在本章中，你学习了避免一些常见误解、bug 和令人沮丧的设计缺陷所需的知识，这些问题通常出现在 Web 应用程序从开发者的笔记本电脑中走出来，通过复杂的基础设施开始与现实世界互动时。你了解了调解访问你应用程序的一些基础设施，如网关和上游服务。

你还看到了一些我们常见的开发者在使用 HTTP 时犯的错误，你将能利用这些知识避免一些难以调试的头信息问题、不正确或模糊的状态码等问题。你了解了**跨域资源共享**（**CORS**）以及 HTTP 是如何发展成现在的形式。

或许最重要的是，你看到如何通过学习像`curl`这样的命令行工具并将其与 HTTP 的理论知识结合起来，从而提升你作为开发者的能力。

本章中你学到的内容使你能够快速且准确地排查 Web 应用程序问题，无论是识别损坏的 WordPress 网站中的重定向循环，通过检查 Ruby-on-Rails 应用程序返回的头信息定位微妙的缓存问题，还是在凌晨四点通过向开发服务器 POST 特定的 JSON 数据来重现生产环境中的 bug（并验证修复）。

# 在 Discord 上了解更多

要加入本书的 Discord 社区——在这里你可以分享反馈、向作者提问并了解新版本——请扫描下面的二维码：

[`packt.link/SecNet`](https://packt.link/SecNet)

![](img/QR_Code1768422420210094187.png)
