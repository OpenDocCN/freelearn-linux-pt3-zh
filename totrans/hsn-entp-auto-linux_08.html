<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Custom Builds with PXE Booting</h1>
                </header>
            
            <article>
                
<p class="mce-root">When <span>working with physical hardware, it is not a given that you could simply clone a virtual machine template to the hard drive and expect it to work. It is, of course, entirely possible to do this with the right tools, but it is tricky, and there is no guarantee the resulting system will run.</span></p>
<p>For example, cloud-ready images will only have the kernel modules installed for the common virtualized network adapters, and so, may not run (or not have network connectivity) when installed on a modern piece of hardware.</p>
<p>In spite of this, it is still entirely possible to perform automated, standardized builds on physical hardware, and this chapter provides a complete hands-on approach to doing so. In conjunction with the preceding chapter, by the end of this one, you will have practical experience of the automated build process for standardizing images for all your platforms, whether they are virtual, cloud-based, or physical.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>PXE booting basics</li>
<li>Performing unattended builds</li>
<li>Adding custom scripts to unattended boot configurations</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>In this chapter, we are going to look at the process of PXE booting, for physical and virtual servers. You will require two servers on the same network, and it is recommended that the network be isolated, as some of the steps performed in this chapter could be disruptive and, even, destructive if performed in a live operational network.</p>
<p>You will need one server (or virtual machine) to be pre-installed with your choice of Linux distribution—in our examples, we will use Ubuntu Server 18.04 LTS. The other server (or virtual machine) should be blank, and suitable for reinstalling.</p>
<p><span>All example code discussed in this chapter is available from GitHub at: </span><a href="https://github.com/PacktPublishing/Hands-On-Enterprise-Automation-on-Linux/tree/master/chapter06">https://github.com/PacktPublishing/Hands-On-Enterprise-Automation-on-Linux/tree/master/chapter06</a>.</p>
<p> </p>
<p> </p>
<p> </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">PXE booting basics</h1>
                </header>
            
            <article>
                
<p>Before the widespread adoption of virtualization and cloud platforms, there was a requirement to generate a standardized operating system build on physical servers, without the need to visit a data center and insert some form of installation media. PXE booting was created, as one of the common solutions to this requirement, and the name comes from the <strong>Pre-eXecution</strong> <strong>Environment</strong> (think of a tiny, minimal operating system) that is loaded so that an operating system installation can occur. </p>
<p>At a high level, when we talk about the PXE build of a given server, <span>the following process is occurring</span>:</p>
<ol>
<li>The server must be configured to use one (or all) of its network adapters for network booting. This is commonly a factory default setting for most new hardware.</li>
<li>Upon power-up, the server brings up the network interfaces, and on each, in turn, attempts to contact a DHCP server.</li>
<li>The DHCP server sends back IP address configuration parameters, along with further information on where the pre-execution environment should be loaded from.</li>
<li>The server then retrieves the pre-execution environment, typically, using the <strong>Trivial File Transfer Protocol</strong> (<strong>TFTP</strong>). </li>
</ol>
<ol start="5">
<li>The PXE environment runs and looks in a known, well-defined location on the TFTP server for configuration data.</li>
<li>The configuration data is loaded, and instructs the PXE environment how to proceed. Normally, with Linux, this involves loading a kernel and initial RAMDisk image from the TFTP server, which contains just enough Linux to proceed with the installation, and pulling further installation sources from another network service (often HTTP).</li>
</ol>
<p>Although this all sounds rather complex, it is, in fact, quite straightforward when broken down into a step-by-step process. As we proceed through this chapter, we will walk through the process of building out a PXE boot server that is capable of performing an unattended installation of either CentOS 7 or Ubuntu 18.04 Server. This will serve as a good hands-on example, and also demonstrates how we can script our build processes even on physical hardware, where the VM template processes we discussed in the last chapter are not readily available.</p>
<p>Before any process of PXE booting can commence, we must first set up some supporting services that provide the necessary network services. In the next section, we will look at how these may be set up and configured.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing and configuring PXE-related services</h1>
                </header>
            
            <article>
                
<p>As with just about any Linux setup, the exact way to do this will depend upon the Linux distribution on which you are performing the installation, and also, the software packages you are going to use. Here, we are going to make use of the ISC DHCP server, the venerable TFTP daemon, and nginx. However, you could just as feasibly use dnsmasq and Apache.</p>
<p>In many enterprises, these decisions will have already been made—most will have some form of DHCP infrastructure already in place, and many businesses with IP telephony systems will have a TFTP server too. Thus, this chapter serves to provide an example only—real-world implementations will likely be driven by long-established corporate standards.</p>
<div class="packt_infobox">There is no safety mechanism to prevent you from running two DHCP servers on the same network. DHCP relies on broadcast messages, and so any DHCP clients on the network will receive an answer from whichever server answers them faster. As a result, it is entirely possible to stop a network from functioning by setting up a second DHCP server. If you follow the process outlined in this chapter, be sure you are performing it on an isolated network, suitable for testing.</div>
<p class="mce-root"/>
<p>For this setup, we are going to assume that we have an isolated network. Our PXE server will have the IP address<span> </span><kbd>192.168.201.1</kbd>, and the subnet mask will be<span> </span><kbd>255.255.255.0</kbd>. These details will be important in setting up our DHCP server. Let's now walk through the process of setting up your server to support PXE booting:</p>
<ol>
<li>We need to install the following list of required packages:
<ul>
<li>DHCP server</li>
<li>TFTP server</li>
<li>Web server</li>
</ul>
</li>
</ol>
<p style="padding-left: 60px">Assuming an Ubuntu 18.04 host, as discussed earlier, run this command to install the packages we will need for this part of the chapter:</p>
<pre style="padding-left: 60px"><strong>$ apt-get install isc-dhcp-server tftpd-hpa nginx</strong></pre>
<ol start="2">
<li>With these installed, the next step is to configure our DHCP server, <span>with</span> which the preceding package is configured through the <kbd>/etc/dhcp/dhcpd.conf</kbd> file. The configuration file shown in the following code block is a good, if basic, example for our PXE boot network, though naturally, you'll need to edit the subnet definition to match your own test network. The first part of the file contains some important global directives and the subnet definition for the network:</li>
</ol>
<pre style="padding-left: 60px">allow bootp;<br/># https://www.syslinux.org/wiki/index.php?title=PXELINUX#UEFI<br/># This one line must be outside any bracketed scope<br/>option architecture-type code 93 = unsigned integer 16;<br/><br/><br/>subnet 192.168.201.0 netmask 255.255.255.0 {<br/>  range 192.168.201.51 192.168.201.99;<br/>  option broadcast-address 192.168.201.255;<br/>  option routers 192.168.201.1;<br/>  option domain-name-servers 192.168.201.1;</pre>
<p style="padding-left: 60px">The next part of the file then contains configuration directives, to ensure that we load the correct pre-execution binary, depending on the type of system being used. It is common at the time of writing to find a mix of both BIOS- and UEFI-based systems, so the following configuration is important:</p>
<pre style="padding-left: 60px">  class "pxeclients" {<br/>     match if substring (option vendor-class-identifier, 0, 9) = "PXEClient";<br/><br/>     if option architecture-type = 00:00 {<br/>         filename "BIOS/pxelinux.0";<br/>     } else if option architecture-type = 00:09 {<br/>         filename "EFIx64/syslinux.efi";<br/>     } else if option architecture-type = 00:07 {<br/>         filename "EFIx64/syslinux.efi";<br/>     } else if option architecture-type = 00:06 {<br/>         filename "EFIia32/syslinux.efi";<br/>     } else {<br/>         filename "BIOS/pxelinux.0";<br/>     }<br/>  }<br/>}</pre>
<p style="padding-left: 60px">Most of this is fairly self-explanatory if you have worked with DHCP servers before. However, the block of text headed<span> </span><kbd>class "pxeclients"</kbd><span> </span>deserves a special mention. Some years ago, server hardware relied on the BIOS to boot, and thus PXE boot configurations were simple, as there was only one pre-boot environment that you needed to load. Most new server hardware now is configured with firmware that can operate in either <em>Legacy BIOS</em> or <em>UEFI modes</em>, and most default to UEFI, unless configured otherwise. The pre-execution binary is different, depending on the type of firmware in use, and hence, the<span> </span><kbd>if</kbd><span> </span>statements in this block make use of a DHCP<span> </span><kbd>option</kbd><span>, </span>returned to the server when the client makes its DHCP request. </p>
<ol start="3">
<li>With this configuration in place, enable the DHCP server, and restart it, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ systemctl enable isc-dhcp-server.service</strong><br/><strong>$ systemctl restart isc-dhcp-server.service</strong></pre>
<ol start="4">
<li>The default configuration for the TFTP server will suffice for this example, so, let's also enable this and ensure it is running as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ systemctl enable tftpd-hpa.service</strong><br/><strong>$ systemctl restart tftpd-hpa.service</strong></pre>
<ol start="5">
<li>Finally, we'll use the default configuration of nginx, and serve all the files we need from<span> </span><kbd>/var/www/html</kbd><span>—</span>obviously, in an enterprise environment, you would want to do something a bit more advanced, but for the following practical example here, this will suffice:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ systemctl enable nginx.service</strong><br/><strong>$ systemctl restart nginx.service</strong></pre>
<p>That's our server infrastructure configured, but one last task remains. We need the pre-execution environment binaries for our TFTP server, to send to the clients.</p>
<p>Although these are readily available for most Linux distributions (and Ubuntu 18.04 is no exception), these packages are often quite old (the last stable release of PXELINUX was in 2014), and I have run into known bugs with these, especially when working with UEFI hardware. Although you are welcome to try newer snapshots, the author has achieved the most success with the release tagged 6.04-pre2, and so, we will explain how to build this and copy the files into the correct places for our TFTP server, as follows:</p>
<ol>
<li>First of all, download and unpack the required release of SYSLINUX (which contains the PXELINUX code) by entering the following code:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ wget https://www.zytor.com/pub/syslinux/Testing/6.04/syslinux-6.04-pre2.tar.gz</strong><br/><strong>$ tar -xzf syslinux-6.04-pre2.tar.gz</strong><br/><strong>$ cd syslinux-6.04-pre2/</strong></pre>
<ol start="2">
<li>Next, we need to install a few build tools to successfully compile the code, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ sudo apt-get install nasm uuid-dev g++-multilib</strong></pre>
<ol start="3">
<li>Finally, we'll make sure the build directory is clean, and then build the code, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ make spotless</strong><br/><strong>$ make</strong></pre>
<p>When the build is complete, the final step is to copy the files into the correct places. Recalling our DHCP server configuration from earlier, we know that we need to separate out the files related to Legacy BIOS boots, and those released to newer UEFI boots. Here, we will step through the process of setting up your server for both BIOS and UEFI network boots:</p>
<ol>
<li>The default root directory for the TFTP server is<span> </span><kbd>/var/lib/tftpboot</kbd><span> </span>on Ubuntu 18.04. Under this path, we will create the two directories referenced by the DHCP server configuration, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ mkdir -p /var/lib/tftpboot/{EFIx64,BIOS}</strong></pre>
<ol start="2">
<li>Then, we will run this set of commands, to gather up and copy all BIOS-related boot files into the newly created<span> </span><kbd>BIOS</kbd> directory:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ cp bios/com32/libutil/libutil.c32 bios/com32/elflink/ldlinux/ldlinux.c32 bios/core/pxelinux.0 /var/lib/tftpboot/BIOS</strong><br/><strong>$ mkdir /var/lib/tftpboot/BIOS/pxelinux.cfg</strong><br/><strong>$ mkdir /var/lib/tftpboot/BIOS/isolinux</strong><br/><strong>$ find bios -name *.c32 -exec cp {} /var/lib/tftpboot/BIOS/isolinux \;</strong></pre>
<ol start="3">
<li>We then repeat this step, except this time, we specify the UEFI-related boot files, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ cp efi64/com32/elflink/ldlinux/ldlinux.e64 efi64/com32/lib/libcom32.c32 efi64/com32/libutil/libutil.c32 efi64/efi/syslinux.efi /var/lib/tftpboot/EFIx64 </strong><br/><strong>$ mkdir /var/lib/tftpboot/EFIx64/pxelinux.cfg </strong><br/><strong>$ mkdir /var/lib/tftpboot/EFIx64/isolinux</strong><br/><strong>$ find efi64/ -name *.c32 -exec cp {} /var/lib/tftpboot/EFIx64/isolinux \;</strong></pre>
<p>With those steps completed, we now have a completed, functional PXE server. We have not downloaded any operating system images yet, so the boot process wouldn't proceed very far, but if you were to execute a test at this point, your server firmware should report that it has obtained an IP address from the DHCP server, and should present you with some boot-related messages. However, we will build this out further before going into any detailed testing in this book, and, in the next section, we will look at how to obtain the correct network installation images for your chosen Linux distribution.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Obtaining network installation images</h1>
                </header>
            
            <article>
                
<p>The next step in our PXE boot setup process is to build out the images required. Luckily, obtaining the boot images is quite easy—the kernel and packages are normally contained on the DVD ISO images for your chosen Linux distribution. Obviously, this can vary from distribution to distribution, so you will need to check this. In this chapter, we will show examples for Ubuntu Server and CentOS 7—these principles could also be applied to many Debian derivatives, Fedora, and Red Hat Enterprise Linux.</p>
<div class="packt_tip">The installation images required for network booting, along with the required installation packages, are normally found on the full DVD images—<em>live</em> images are often not sufficient because they lack either a sufficiently complete set of packages to perform the installation, or the network boot-capable kernel is missing.</div>
<p>Let's make a start with the CentOS 7 image, as follows: </p>
<ol>
<li>First of all, download the latest DVD image from your nearest mirror—for example, the one shown in the following code block:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ wget http://mirror.netweaver.uk/centos/7.6.1810/isos/x86_64/CentOS-7-x86_64-DVD-1810.iso</strong></pre>
<ol start="2">
<li>Once downloaded, mount the ISO image to a suitable location so that the files can be copied from it, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ mount -o loop CentOS-7-x86_64-DVD-1810.iso /mnt</strong></pre>
<ol start="3">
<li>Now, the network boot-capable kernel and initial RAMDisk image should be copied to a location of our choosing, under the TFTP server root.</li>
</ol>
<div class="packt_infobox">Note that in the following example, we are only doing this for UEFI booting. To set up for <strong>Legacy BIOS booting</strong>, follow exactly the same process, but place all files to be served by TFTP in <kbd>/var/lib/tftpboot/BIOS</kbd><span> </span>instead. This applies throughout the rest of this chapter.</div>
<p style="padding-left: 60px">The commands to achieve this on our test system are as follows:</p>
<pre style="padding-left: 60px"><strong>$ mkdir /var/lib/tftpboot/EFIx64/centos7</strong><br/><br/><strong>$ cp /mnt/images/pxeboot/{initrd.img,vmlinuz} /var/lib/tftpboot/EFIx64/centos7/</strong></pre>
<ol start="4">
<li>Finally, we need the web server we installed earlier to serve out the files for the installer—once the kernel and initial RAMDisk environment load, the rest of the environment will be served over HTTP, which is better suited to large data transfers. Again, we'll create a suitable subdirectory for our CentOS content, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ mkdir /var/www/html/centos7/</strong><br/><br/><strong>$ cp -r /mnt/* /var/www/html/centos7/</strong><br/><br/><strong>$ umount /mnt</strong></pre>
<p>That's all there is to it! Once these steps have been completed, we'll repeat this process for our Ubuntu 18.04 Server boot image, as follows:</p>
<pre style="padding-left: 60px"><strong>$ wget http://cdimage.ubuntu.com/releases/18.04/release/ubuntu-18.04.2-server-amd64.iso</strong><br/><br/><strong>$ mount -o loop ubuntu-18.04.2-server-amd64.iso /mnt</strong><br/><br/><strong>$ mkdir /var/lib/tftpboot/EFIx64/ubuntu1804</strong><br/><br/><strong>$ cp /mnt/install/netboot/ubuntu-installer/amd64/{linux,initrd.gz} /var/lib/tftpboot/EFIx64/ubuntu1804/</strong><br/><br/><strong>$ mkdir /var/www/html/ubuntu1804</strong><br/><br/><strong>$ cp -r /mnt/* /var/www/html/ubuntu1804/</strong><br/><br/><strong>$ umount /mnt</strong></pre>
<p><span>With these steps complete, we just have one more configuration stage to go before we can perform a network boot of our chosen operating system.</span></p>
<div class="packt_tip">The process is almost identical—the only difference is that the NetBoot-capable kernel and RAMDisk were sourced from a different directory on the ISO image.</div>
<p class="mce-root">In the next section, we will configure the PXE boot server we have built so far, so as to boot from these installation images.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performing your first network boot</h1>
                </header>
            
            <article>
                
<p>Thus far, we have configured our server to give our clients an IP address on boot, and have even built two installation trees, such that we can install either CentOS 7 or Ubuntu 18.04 Server, without the need for any physical media. However, when our target machine boots over the network, how does it know what to boot?</p>
<p>The answer to this comes in the form of the PXELINUX configuration. This is very similar in nature to the <strong>GRand Unified Bootloader</strong> (<strong>GRUB</strong>) configuration that most Linux installations use, to define their boot options and parameters when they boot from disk. Using the installation we have built so far, these configuration files are expected to be in<span> </span><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg</kbd><span> </span>(or <kbd>/var/lib/tftpboot/BIOS/pxelinux.cfg</kbd><span> </span>for Legacy BIOS machines).</p>
<p>Now, a word on file naming. You might want all devices that boot off a network interface to perform a network boot. However, consider a server where a valid Linux installation is on the local disk, but through some error (perhaps misconfiguration of the boot order in the firmware, or a missing boot loader), it boots from the network interface instead of the local disk. If you have a full, unattended installation configured on your PXE server, this would wipe the local disks, with potentially disastrous consequences. </p>
<p>If you want all servers to perform a network boot regardless, you create a special configuration file, called<span> </span><kbd>default</kbd>. </p>
<p>However, if you want to be more targeted, you instead create a configuration file with the name based on the MAC address. Suppose we have a server with the MAC address<span> </span><kbd>DE:AD:BE:EF:01:23</kbd>, and our DHCP server is going to assign it the IP address<span> </span><kbd>192.168.10.101/24</kbd><span> </span>(this would most likely be through a static DHCP mapping so that we can ensure that this server always gets this IP address). When this server network boots using UEFI, it will look initially for <kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/01-de-ad-be-ef-01-23</kbd>.</p>
<p>If this file is not present, it will look for a file named after the hex-encoded IP address. If this does not exist, it then takes one digit off the hexadecimal IP address at a time, until it finds a matching file. In this manner, our server would look for <kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0A80A65</kbd>. If it doesn't find it, it cycles through the ever-shortening IP address representations, until it runs out of options. If no appropriately named file is found, it finally reverts to the<span> </span><kbd>default</kbd><span> </span>file, and if that file isn't present, a boot failure is reported by the client.</p>
<p>Thus, the full search sequence for configuration files is as follows:</p>
<ol>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/01-de-ad-be-ef-01-23</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0A80A65</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0A80A6</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0A80A</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0A80</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0A8</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0A</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C</kbd></li>
<li><kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/default</kbd></li>
</ol>
<p>The idea of shortening the IP address filename is to enable you to create a subnet-wide configuration—for example, if all machines in the <kbd>192.168.10.0/24</kbd> subnet needed the same boot configuration, you could create a single file called <kbd>/var/lib/tftpboot/EFIx64/pxelinux.cfg/C0A80A</kbd>. Pay special attention to the case of the letters in the filename—the MAC address-based filename requires lowercase letters, while the IP address requires uppercase letters.</p>
<p>There are numerous permutations of configuration for the contents of this configuration file, and looking into all the possibilities for this is left as an exercise for the reader—there is ample documentation, and examples, available for PXELINUX. However, with the specific aim of booting our network install images, let's consider the following file. Initially, we define the header for the menu, with a simple title and timeout, as follows:</p>
<pre>default isolinux/menu.c32<br/>prompt 0<br/>timeout 120<br/><br/>menu title --------- Enterprise Automation Boot Menu ---------</pre>
<p>We then proceed to define the entries for our two operating system install images that we have built, as follows:</p>
<pre>label 1<br/>menu label ^1. Install CentOS 7.6 from local repo<br/>kernel centos7/vmlinuz<br/>append initrd=centos7/initrd.img method=http://192.168.201.1/centos7 devfs=nomount ip=dhcp inst.vnc inst.vncpassword=password<br/><br/>label 2<br/>menu label ^2. Install Ubuntu Server 18.04 from local repo<br/>kernel ubuntu1804/linux<br/>append initrd=ubuntu1804/initrd.gz vga=normal locale=en_US.UTF-8 mirror/country=manual mirror/http/hostname=192.168.201.1 mirror/http/directory=/ubuntu1804 mirror/http/proxy="" live-installer/net-image=http://192.168.201.1/ubuntu1804/install/filesystem.squashfs </pre>
<p>As with other examples in this book, these are real-world, tested examples that will work in their own right. However, they should be customized to your own requirements, and you should endeavor to read and understand the code before applying it in a production environment.</p>
<div class="packt_tip">In these preceding examples,<span> </span><kbd>192.168.201.1</kbd><span> </span>is the IP address of my PXE server in my test setup. Be sure to replace this wherever you see it with the IP address of your PXE server.</div>
<p>This is, in fact, a very simple example—here, we are defining a simple text mode menu with two entries, one for each of our operating systems. Each menu entry has a<span> </span><kbd>label</kbd>, a title that appears in the menu, and then, a<span> </span><kbd>kernel</kbd><span> </span>and<span> </span><kbd>append</kbd><span> </span>line. The<span> </span><kbd>kernel</kbd><span> </span>line tells the client from where to source the kernel on our TFTP server, while the<span> </span><kbd>append</kbd><span> </span>line is used to specify the path of the RAMDisk image and all supplementary boot parameters. </p>
<p>These boot parameters, as you can see, are greatly different for different Linux distributions, as are the capabilities of the installers. For example, the CentOS 7 installer is graphical (though a text mode option is available) and supports a VNC server, which we are configuring in the first menu item, enabling a remote installation using a VNC console, using the parameters<span> </span><kbd>inst.vnc</kbd><span> </span>and<span> </span><kbd>inst.vncpassword=password</kbd>. The other parameters used are the following:</p>
<ul>
<li><kbd>method=http://192.168.201.1/centos7</kbd>: Sets the address from where our CentOS 7 repo will be served</li>
<li><kbd>devfs=nomount</kbd>: Tells the kernel not to mount the devfs filesystem</li>
</ul>
<ul>
<li><kbd>ip=dhcp</kbd>: Tells the pre-boot environment to obtain an IP address using DHCP, to then be able to reach the HTTP server</li>
</ul>
<p>The Ubuntu installer is, by contrast, normally run in text mode, and so does not support a VNC server, so a different remote access technology would be required to perform an interactive installation, such as <strong>Serial-Over-LAN</strong> (<strong>SOL</strong>). Nonetheless, this menu file would be sufficient for us to perform an interactive installation of either OS as we choose, and is provided as a template for the reader to build on and develop, as they see fit. The parameters in use are the following:</p>
<ul>
<li><kbd>vga=normal</kbd><span>:</span> Tells the installer to use the standard VGA mode</li>
<li><kbd>locale=en_US.UTF-8</kbd><span>:</span> Sets the locale—adjust this to suit your environment</li>
<li><kbd>mirror/country=manual</kbd><span>:</span> Tells the installer we are manually defining the repository mirror</li>
<li><kbd>mirror/http/hostname=192.168.201.1</kbd><span>:</span> Sets the hostname of the repository mirror we created previously</li>
<li><kbd>mirror/http/directory=/ubuntu1804</kbd>: Sets the path on the repository mirror host that is serving the repository content</li>
<li><kbd>mirror/http/proxy=""</kbd><span>:</span> Tells the installer we are not using a proxy</li>
<li><kbd>live-installer/net-image=http://192.168.201.1/ubuntu1804/install/filesystem.squashfs</kbd><span> :</span> The URL from where the installer disk image can be downloaded</li>
</ul>
<p>Of course, in an unattended boot scenario, you would not want to present the server with a choice of operating system—you simply want it to boot the one you want to install. In this instance, simply remove the menu items that are not needed.</p>
<p>Let's take a look at this in action. Upon a successful network boot of a test machine, we should be presented with the following menu, as defined previously:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ac03916d-46c7-4467-94e3-b09a390877f1.png" style="width:39.42em;height:26.25em;"/></p>
<ol>
<li>If we select the CentOS image as our boot target, you will see the kernel and base system load, and then ultimately, a screen asking you to connect to the installer using a VNC client, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4a2416cf-e10d-4b1e-a7e2-2aa8ed6550a7.png" style="width:44.67em;height:19.33em;"/></p>
<ol start="2">
<li>Connecting with a VNC viewer, as instructed, yields the familiar interactive CentOS 7 graphical installer, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/724b5e2a-7b6a-4709-b383-1d80a753e19d.png" style="width:42.00em;height:31.50em;"/></p>
<ol start="3">
<li>Thus, a complete remote installation is possible, without the need to visit the location of the server, or connect a keyboard and mouse! The same is almost true if we boot our Ubuntu Server image, only this time, the console is on the host screen, rather than available over VNC, as can be seen in the following screenshot: </li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c07c98c2-85f3-41b2-af42-e0ffbad7f5e3.png" style="width:40.67em;height:10.50em;"/></p>
<p>This lends itself well to either redirecting the console over an SOL implementation or a remove KVM option. Neither of these is particularly convenient, especially as the goal of this book is automation!</p>
<p>Thus, in the next section, we will look at performing automated installations, using the concept of <em>unattended builds</em>—that is to say, builds where no human needs to intervene for the installation to take place.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performing unattended builds</h1>
                </header>
            
            <article>
                
<p>The ultimate goal of this process is to have a server boot over the network and configure itself completely, rather than having to have someone interact with it. Although this is not a process controlled by Ansible, it is still a vital component in our <strong>Standard Operating Environment</strong> (<strong>SOE</strong>) architecture to ensure consistency of builds, and that build standards can be well documented and version controlled.</p>
<p>Fortunately, both CentOS (Red Hat-based) and Ubuntu (Debian-based) installers provide the capability for unattended installs to be completed in a programmatic manner. Sadly, there is no common standard for this process and, as you will see in this section, the language used for this process is wholly different between the two Linux types we are discussing here. Nevertheless, by covering off these two technologies, we are giving a good grounding that will enable you to perform remote, unattended installations on a wide variety of Linux systems.</p>
<p>Note that the examples in this chapter are complete and working, and thus are provided as hands-on examples—however, they are really just scratching the surface in terms of what these unattended installation technologies can do. It is left as an exercise for you to expand on these examples, and build them out to your own requirements.</p>
<p>Let's get started by looking in the next section at how we perform unattended builds on Red Hat-based platforms such as CentOS using kickstart files.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performing unattended builds with kickstart files</h1>
                </header>
            
            <article>
                
<p>The Red Hat installer, Anaconda, uses a scripting language called <strong>kickstart</strong> to define unattended builds. This is well documented, and there are many examples available on the internet for you to work from—in fact, when you manually install a Red Hat derivative such as CentOS 7, you will find a kickstart file in<span> </span><kbd>/root/anaconda-ks.cfg</kbd><span>, </span>which could be employed to automate future builds! In the following, we will build up our own simple kickstart file, based loosely on a minimal install of CentOS 7 from the interactive installer.</p>
<ol>
<li>Let's start building up our example kickstart file for use in this chapter. Consider this block of code:</li>
</ol>
<pre style="padding-left: 60px">auth --enableshadow --passalgo=sha512<br/>url --url="http://192.168.201.1/centos7/"<br/>graphical<br/>firstboot --enable<br/>ignoredisk --only-use=sda<br/>keyboard --vckeymap=gb --xlayouts='gb'<br/>lang en_GB.UTF-8 <br/>reboot</pre>
<p class="mce-root" style="padding-left: 60px">Much of the kickstart file is very readable—in the preceding code block, you can see the following: we are defining<span> </span><kbd>sha512</kbd><span> </span>for the password hashing algorithm; our repository server is available at <kbd>http://192.168.201.1/centos7/</kbd>; we are performing a<span> </span><kbd>graphical</kbd><span> </span>install, using only<span> </span><kbd>/dev/sda</kbd>, and with some<span> </span><kbd>GB</kbd><span> </span>specific locale settings. We also tell the installer to<span> </span><kbd>reboot</kbd><span> </span>automatically once the install completes successfully.</p>
<ol start="2">
<li class="mce-root">We then build on this by setting up the network (note that you must know the network device name in advance of creating this file, so you might find it useful to boot into a live environment to check this first) by running the following code:</li>
</ol>
<pre style="padding-left: 60px">network --bootproto=dhcp --device=ens33 --ipv6=auto --activate<br/>network --hostname=ksautomation</pre>
<p style="padding-left: 60px">This sets the hostname of our newly built server to<span> </span><kbd>ksautomation</kbd>, and enables IPv6 and IPv4 DHCP on the network device called<span> </span><kbd>ens33</kbd>.</p>
<ol start="3">
<li>We then define the root account password, and—optionally—any additional accounts we want to be added as part of the build, by running the following code:</li>
</ol>
<pre style="padding-left: 60px">rootpw --iscrypted $6$cUkXdOxB$o8uxoU6arUj0g9SXqMGnigBYDH4rCkkQt9z/qYPm.lUYNwaZChCz2epQMUlbHUg8IVzN9lei9i/rschw1HydU.<br/>user --groups=wheel --name=automation --password=$6$eCIJyrjn$Vu30KX//UntsM0h..MLT6ik.m1GL8ayILBFWjbDrKSXowli5/hycMaiFzGI926YXEMfXXjAuwOFLIdANZ09/g1 --iscrypted --gecos="Automation User"</pre>
<p style="padding-left: 60px">Note that the password hashes must be used in this file—there are many ways to generate these. I used the following snippet of Python to generate unique hashes for the <kbd>password</kbd><span> string (</span>you would obviously want to choose a more secure password!):</p>
<pre style="padding-left: 60px"><strong>$ python -c "import random,string,crypt;</strong><br/><strong>pwsalt = ''.join(random.sample(string.ascii_letters,8));</strong><br/><strong>print crypt.crypt('password', '\$6\$%s\$' % pwsalt)"</strong></pre>
<p style="padding-left: 60px">Running the preceding three lines of code in the shell of any Linux server that has Python installed will generate the password hash needed for your kickstart file, which you can copy and paste into your installation.</p>
<div class="packt_tip">The preceding code is used only to generate the password hashes—do not include it in your kickstart file!</div>
<ol start="4">
<li>Finally, we set the time zone appropriately, and enable the<span> </span><kbd>chrony</kbd><span> </span>time synchronization service. We initialize the disk label on our chosen boot device,<span> </span><kbd>sda</kbd>, and make use of Anaconda's automated partitioning (designated by the<span> </span><kbd>autopart</kbd><span> </span>directive), to set up the disk.</li>
</ol>
<p>Note that<span> </span><kbd>clearpart --none</kbd><span> </span>does not actually clear the partition table—and if you run through this example with the kickstart file as defined here, the installation will only complete if there is space on the target disk to install CentOS 7. To have the kickstart file wipe the target disk and perform a fresh installation of CentOS 7 (which may be desirable to avoid having to manually wipe old machines before reuse), perform the following changes to the kickstart file:</p>
<ol>
<li>Insert the<span> </span><kbd>zerombr</kbd><span> </span>directive above the<span> </span><kbd>clearpart</kbd><span> </span>statement to ensure the boot sector is cleared.</li>
<li>Change the<span> </span><kbd>clearpart</kbd><span> </span>line to read <kbd>clearpart --drives=sda --initlabel --all</kbd><span>—</span>be sure to only specify the drives you want clearing in the<span> </span><kbd>--drives=</kbd><span> </span>parameter!</li>
</ol>
<p style="padding-left: 60px">The fragment of following code does not include these changes as they are destructive—however, you are free to experiment with them as you wish in your test environment:</p>
<pre style="padding-left: 60px">services --enabled="chronyd"<br/>timezone Europe/London --isUtc<br/><br/>bootloader --location=mbr --boot-drive=sda<br/>autopart --type=lvm<br/>clearpart --none --initlabel</pre>
<p>We then define our packages to be installed by default. Here, we are installing the<span> </span><kbd>core</kbd><span> </span>package group, the<span> </span><kbd>minimal</kbd><span> </span>system package set, and the<span> </span><kbd>chrony</kbd><span> </span>package. We are also disabling<span> </span><kbd>kdump</kbd><span> </span>for our test server, as shown in the following code block:</p>
<pre style="padding-left: 60px">%packages<br/>@^minimal<br/>@core<br/>chrony<br/><br/>%end<br/><br/>%addon com_redhat_kdump --disable --reserve-mb='auto'<br/><br/>%end</pre>
<p>Finally, we can perform additional customization, such as setting a strong password policy—the following lines are actually the defaults from the interactive installer, and should be customized to your requirements:</p>
<pre style="padding-left: 60px">%anaconda<br/>pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty<br/>pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok<br/>pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty<br/>%end</pre>
<p>When you have built your complete kickstart file, it's time to test the boot process. Remember the PXELINUX boot configuration we used in the last section? Well, that is reused almost in its entirety, except this time, we need to tell it where to find the kickstart file. I am storing the file we have just created in<span> </span><kbd>/var/www/html/centos7-config/centos7unattended.cfg</kbd>—thus, it can be downloaded from our HTTP server, just like with the packages for the installer. In this case, our PXELINUX configuration would look like this:</p>
<pre style="padding-left: 60px">default isolinux/menu.c32<br/>prompt 0<br/>timeout 120<br/><br/>menu title --------- Enterprise Automation Boot Menu ---------<br/><br/>label 1<br/>menu label ^1. Install CentOS 7.6 from local repo<br/>kernel centos7/vmlinuz<br/>append initrd=centos7/initrd.img method=http://192.168.201.1/centos7 devfs=nomount ip=dhcp inst.vnc inst.vncpassword=password inst.ks=http://192.168.201.1/centos7-config/centos7unattended.cfg</pre>
<p><span>Let's run through the installation process, and see what happens. Initially, the process will look identical to the interactive installation we performed earlier in this chapter.</span></p>
<div class="packt_tip"><span>The preceding PXE boot configuration shown is identical to before, save for the</span><span> </span><kbd>inst.ks</kbd><span> </span><span>parameter at the end, telling Anaconda where to download our kickstart file from.</span></div>
<p><span>Indeed, when you connect to the VNC console of your machine as it is being built, things will initially look the same—the graphical installer for CentOS 7 loads, as shown in the following screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/dd4b86f0-8388-482e-858d-de5c83874658.png" style="width:44.08em;height:33.08em;"/></p>
<p><span>So far, everything looks like an ordinary interactive installation. However, once the installer finishes the various tasks listed (for example,</span> <span class="packt_screen"><span>Saving storage configuratio</span>n...</span><span>), you will note that you are presented with a screen that looks complete, save for the</span> <span class="packt_screen">Begin Installation</span> <span>button being grayed out (as shown in the following screenshot):</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d56b8cad-7d41-4d05-b9dc-1e72ce64ce97.png" style="width:52.42em;height:39.17em;"/></p>
<p>Note the differences here—the installation source has now been set to the HTTP server we set up for our installation process. All other items that are usually completed manually, such as disk selection, have been completed automatically, using the configuration in our kickstart script. In fact, if we wait a short while longer, you will see that the installation commences automatically, without the need to click the <span class="packt_screen">Begin Installation</span> button, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/565adc47-7510-44cb-b64d-5bd5597746ba.png" style="width:56.50em;height:42.33em;"/></p>
<p>The installation now proceeds, using the parameters from our kickstart file. Note that the root password and initial user account creation has been completed, using the parameters from the kickstart script, and so, these buttons are again grayed out. In short, although the installation process appears very similar to a normal interactive installation, the user is not able to interact with the process in any way.</p>
<p>There are only two times when a user will be expected to interact with a kickstart installation, as follows:</p>
<ol>
<li>A configuration is incomplete or incorrect—in this instance, the installer will pause and expect the user to intervene, and (if possible) correct the issue.</li>
<li>If the <kbd>reboot</kbd> keyword has not been specified in the kickstart file.</li>
</ol>
<p>In the latter case, the installation will complete, but the installer will wait for the <span class="packt_screen">Reboot</span> button to be clicked, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/294e8549-4fb9-4db9-abbb-0ef895fbf6c3.png" style="width:53.67em;height:45.83em;"/></p>
<p>Rebooting automatically at the end of a kickstart installation is often desirable, as it saves the need to connect to the console. However, there are times when it is not—perhaps you don't actually want the newly built server to be running on the network at the present time. Or, perhaps you are building an image for templating purposes, and so don't want the first boot to complete, as it will mean log files and other data that subsequently need to be cleaned up. </p>
<p>The exact path the installation takes is up to you—the important thing to note is that you can connect to the VNC console, as shown in the preceding screenshots, and see exactly how the installation is going. If there are any errors or issues, you will be alerted.</p>
<p><span>Test this out, and see how the build performs for you. In the event of any issues, the installer runs up several consoles on the physical server that contain logging information—you can switch between these using</span> <em>Alt</em> + <em>Tab</em><span>, or</span> <em>Alt</em> + <em>F&lt;n&gt;</em><span>, where</span> <em>F&lt;n&gt;</em> <span>is one of the function keys—each of the first six corresponds to a different console, which will contain useful logging information. These can be queried, to debug any issues that might arise. The instructions are actually shown at the bottom of the text mode console screen—see the following screenshot for an example:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/97a127c9-5481-4cda-85a6-27da340fd7f7.png" style="width:36.00em;height:15.08em;"/></p>
<p>In the preceding screenshot, we can see we are on console <kbd>1</kbd>, entitled <kbd>main</kbd>. Console <kbd>2</kbd> has a <kbd>shell</kbd> for debugging purposes, and consoles <kbd>3</kbd> through <kbd>5</kbd> show <kbd>log</kbd> files specific to the installation process.</p>
<p>However, if all of this goes well, you will see the installer run without any intervention required, and then, the server will reboot and present you with a login prompt. From there, you should be able to log in, using the password you defined via the password hash earlier.</p>
<p>That concludes the process of building a CentOS 7 server over the network using a kickstart file. The same high-level process can be followed for Ubuntu and other Debian derivatives through the use of pre-seed files, as we shall explore in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performing unattended builds with pre-seed files</h1>
                </header>
            
            <article>
                
<p>Broadly speaking, Ubuntu Server builds (and indeed, other Debian derivative operating systems) function exactly the same way. You specify a script file to tell the installer what actions to take, in place of a human being selecting options. With Ubuntu Server, this is called a pre-seed file. Let's go through this now, and build one up.</p>
<p>The pre-seed files are very powerful, and there is lots of documentation around—however, they can sometimes appear more complex to the naked eye. Starting with the following lines of code, we set the appropriate locale and keyboard layout for our server:</p>
<pre>d-i debian-installer/locale string en_GB<br/>d-i console-setup/ask_detect boolean false<br/>d-i keyboard-configuration/xkb-keymap select gb</pre>
<p>We then configure the following network parameters:</p>
<pre>d-i netcfg/choose_interface select auto<br/>d-i netcfg/get_hostname string unassigned-hostname<br/>d-i netcfg/get_domain string unassigned-domain<br/>d-i netcfg/hostname string automatedubuntu<br/>d-i netcfg/wireless_wep string</pre>
<p>Here, you will note that we don't actually need to know the interface name in advance—rather, we can get Ubuntu to guess it, using its automated detection algorithm. We are setting the hostname to<span> </span><kbd>automatedubuntu</kbd>; however, note that the other parameters are used to prevent the installer from prompting for a hostname from the user, thus meaning the installation is not truly unattended. Next, we add some details about where the installer can download its packages from, as shown in the following code block:</p>
<pre>d-i mirror/country string manual<br/>d-i mirror/http/hostname string 192.168.201.1<br/>d-i mirror/http/directory string /ubuntu1804<br/>d-i mirror/http/proxy string</pre>
<p>These should naturally be adjusted to suit your network, HTTP server setup on your PXE server, and so on.</p>
<div class="packt_tip packt_infobox">Many of these are also set in the kernel parameters, as we saw in our PXELINUX configuration earlier—we just need to confirm a few of them here.</div>
<p>We then set up the root account password, and any additional user accounts, as follows:</p>
<pre>d-i passwd/root-password password password<br/>d-i passwd/root-password-again password password<br/>d-i passwd/user-fullname string Automation User<br/>d-i passwd/username string automation<br/>d-i passwd/user-password password insecure<br/>d-i passwd/user-password-again password insecure<br/>d-i user-setup/allow-password-weak boolean true<br/>d-i user-setup/encrypt-home boolean false</pre>
<p>Note here that I have specified the passwords in plain text, to highlight the possibility to do this here—there are alternative parameters you can specify that will accept a password hash, which is far more secure when creating configuration files. Here, the root password is set to<span> </span><kbd>password</kbd>, and a user account called<span> </span><kbd>automation</kbd><span> </span>is set up, with the password<span> </span><kbd>insecure</kbd>. As before, our password policy is quite weak and could be strengthened here, or later, using Ansible. We then set the time zone as appropriate, and turn on NTP synchronization, as follows:</p>
<pre>d-i clock-setup/utc boolean true<br/>d-i time/zone string Etc/UTC<br/>d-i clock-setup/ntp boolean true</pre>
<p>The most complex block of code in our otherwise simplistic example is the following one, which is used to partition and set up the disk:</p>
<pre>d-i partman-auto/disk string /dev/sda<br/>d-i partman-auto/method string lvm<br/>d-i partman-lvm/device_remove_lvm boolean true<br/>d-i partman-md/device_remove_md boolean true<br/>d-i partman-lvm/confirm boolean true<br/>d-i partman-lvm/confirm_nooverwrite boolean true<br/>d-i partman-auto-lvm/guided_size string max<br/>d-i partman-auto/choose_recipe select atomic<br/>d-i partman/default_filesystem string ext4<br/>d-i partman-partitioning/confirm_write_new_label boolean true<br/>d-i partman/choose_partition select finish<br/>d-i partman/confirm boolean true<br/>d-i partman/confirm_nooverwrite boolean true<br/>d-i partman-md/confirm boolean true<br/>d-i partman-partitioning/confirm_write_new_label boolean true<br/>d-i partman/choose_partition select finish<br/>d-i partman/confirm boolean true<br/>d-i partman/confirm_nooverwrite boolean true</pre>
<p>Although verbose, this section of the file basically says to automatically partition the disk<span> </span><kbd>/dev/sda</kbd>, set up LVM, use automated calculations to determine the filesystem layout, and then create<span> </span><kbd>ext4</kbd><span> </span>filesystems. As you can see, there are many safeguards and confirmation prompts that we have flagged as<span> </span><kbd>true</kbd><span> </span>as otherwise, the installer would stop and wait for user input to proceed. If this were to happen, our installation would again not be truly unattended. From here, we specify the package set we want to be installed, as follows:</p>
<pre>tasksel tasksel/first multiselect standard<br/>d-i pkgsel/include string openssh-server build-essential<br/>d-i pkgsel/update-policy select none</pre>
<p>The preceding lines of code essentially set up a minimal server build with the<span> </span><kbd>openssh-server</kbd><span> </span>package and<span> </span><kbd>build-essential</kbd><span> </span>packages on it. The automated update policy is configured to not automatically update. Finally, to finish off the file, we tell it where to install the boot loader, and to reboot upon successful completion, as follows:</p>
<pre>d-i grub-installer/only_debian boolean true<br/>d-i grub-installer/with_other_os boolean true<br/>d-i finish-install/reboot_in_progress note</pre>
<p>As with our CentOS example, we will serve this file from our web server, and thus, the PXELINUX boot configuration needs adjusting, to make sure we incorporate this file—an appropriate example is shown as follows:</p>
<pre>default isolinux/menu.c32<br/>prompt 0<br/>timeout 120<br/><br/>menu title --------- Enterprise Automation Boot Menu ---------<br/><br/>label 1<br/>menu label ^1. Install Ubuntu Server 18.04 from local repo<br/>kernel ubuntu1804/linux<br/>append initrd=ubuntu1804/initrd.gz url=http://192.168.201.1/ubuntu-config/ubuntu-unattended.txt vga=normal locale=en_US.UTF-8 console-setup/ask_detect=false console-setup/layoutcode=gb keyboard-configuration/layoutcode=gb mirror/country=manual mirror/http/hostname=192.168.201.1 mirror/http/directory=/ubuntu1804 mirror/http/proxy="" live-installer/net-image=http://192.168.201.1/ubuntu1804/install/filesystem.squashfs netcfg/get_hostname=unassigned-hostname</pre>
<p>Note the following new options in use this time:</p>
<ul>
<li><kbd>url</kbd><span>:</span> Tells the installer from where to obtain our pre-seed file.</li>
<li><kbd>console-setup/layoutcode</kbd><span> </span>and<span> </span><kbd>keyboard-configuration/layoutcode</kbd><span>:</span> Prevents the installer from asking about keyboard settings when it is first run.</li>
<li><kbd>netcfg/get_hostname</kbd><span>:</span> Although we have set the hostname in the pre-seed file, we have to specify this parameter here, otherwise the installer will stop, and prompt the user to enter a hostname.</li>
</ul>
<p>Again, if you test this by booting a server over the network using the preceding configuration, you should see the server build complete. Unlike the CentOS 7 installation, you will not see any menu options—these will only be presented to you if your pre-seed configuration file is incorrect, or is missing some important details. Instead, you will simply see a series of progress bars flash by, as the various stages of the installation are completed. For example, the following screenshot shows that the base system is installed to the disk after the partitions and logical volumes have been set up:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/abe7682b-af5d-4a53-b371-71d3bed0a352.png" style="width:36.08em;height:8.08em;"/></p>
<p>Assuming all goes well, this process will continue until you are presented with a final progress bar, which shows the final tidy-up being completed before the server is rebooted. In the following screenshot, the filesystems are being unmounted, in preparation for a reboot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/fcb62dcc-1ca4-486b-9153-adf3c47e3d6a.png" style="width:36.17em;height:8.42em;"/></p>
<p>When this final progress bar completes, your server will reboot, and you will be presented with a login prompt, from where you can log in with the credentials specified in the pre-seed file <kbd>d-i passwd</kbd> parameters shown previously. Note that if you use different credentials for your build, you must use these here, and not those specified previously.</p>
<p>At this stage, you should be able to perform an unattended build of either CentOS or Ubuntu Server over the network and perform basic changes, such as selecting the required packages and setting credentials. In the next section, we will explore methods of additional bespoke customization, beyond the original OS.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding custom scripts to unattended boot configurations</h1>
                </header>
            
            <article>
                
<p>As you will have seen from the examples in this chapter, the kickstart and pre-seed files are quite prescriptive in what they can do. For most purposes, they should be perfectly adequate, allowing you to build a machine suitable for further customization with Ansible. Indeed, much of the rest of this book is dedicated to how you would manage and automate configuration management across an estate of servers, built per the details in this and the preceding chapters.</p>
<p>However, what if your enterprise has a task (or tasks) that absolutely has to be performed at build time—perhaps for security compliance (which we shall explore in <a href="3d4a9c0a-452f-4fbb-85c8-372149303613.xhtml" target="_blank">Chapter 13</a>, <em>Using CIS Benchmarks</em>), for example? Luckily, both of the technologies we have discussed here provide an option for that. Let's first take a look at how you might perform custom commands in a kickstart-unattended installation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Customized scripting with kickstart</h1>
                </header>
            
            <article>
                
<p>As discussed previously, it is recommended for most tasks that you perform the post-build configuration with Ansible. However, let's take a simple and hypothetical example—suppose that, for security reasons, you need to disable root SSH logins immediately when the server is built, for security compliance. There is no directive in kickstart that can perform this task, and leaving the server with this enabled while it waits for Ansible to run against it may not be acceptable to a corporate security team, as there is a window of opportunity for a potential attacker. Luckily, at the bottom of our kickstart file, we can put a<span> </span><kbd>%post</kbd><span> </span>block in that runs any shellcode you put into it. Thus, we could run the<span> </span><kbd>sed</kbd><span> </span>utility from within the following code block: </p>
<pre>%post --log=/root/ks.log<br/><br/>/bin/sed -i 's/#PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config<br/><br/>%end</pre>
<p>This very simple block of code runs after the installation process has finished (but before the reboot), and logs its output into<span> </span><kbd>/root/ks.log</kbd>. You could customize this as you see fit—however, here, for the sake of our simple example, we are performing a search and replace operation on the default SSH daemon configuration, to ensure that even on first boot, root logins over SSH are disabled.</p>
<p>In the next section, we'll see how the same thing is achieved in an Ubuntu pre-seed file.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Customized scripting with pre-seed</h1>
                </header>
            
            <article>
                
<p>Suppose we want to perform the same customization with Ubuntu. Ubuntu pre-seed files run a single line of commands rather than a block as used in kickstart; hence, they lend themselves better to either simple tasks, or indeed to downloading a script for more complex operations. We could embed the <kbd>sed</kbd> command in our pre-seed file by adding the following line at the bottom:</p>
<pre>d-i preseed/late_command string in-target /bin/sed -i 's/#PermitRootLogin.*/PermitRootLogin no/' /etc/ssh/sshd_config</pre>
<p>Suppose, however, we have a much more complex script to run, and that trying to write it all on one line would make it difficult both to read and manage—instead, we could change the preceding command, to download a script from a chosen place and run it, as follows:</p>
<pre>d-i preseed/late_command string in-target wget -P /tmp/ http://192.168.201.1/ubuntu-config/run.sh; in-target chmod +x /tmp/run.sh; in-target sh -x /tmp/run.sh</pre>
<p>Note here that we are using <kbd>wget</kbd> (which was installed earlier in the build process) to download a file called<span> </span><kbd>run.sh</kbd><span> </span>from the<span> </span><kbd>/ubuntu-config/</kbd><span> </span>path on our web server. We then make it executable and run it. In this way, far more complex command sequences can be run at the end of the build process, just prior to the first reboot.</p>
<p>In this manner, incredibly complex, bespoke operating system builds can be installed remotely, over the network, without any human intervention at all. The use of kickstart and pre-seed files also means that the process is scripted and repeatable, which is an important principle for us to adhere to.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Even when using bare-metal servers (and some virtualization platforms), it is entirely possible to script the installation process, to ensure that all builds are consistent and thus adhere to the SOE principle we set out earlier in this book. By following the processes set out in this chapter, you will ensure that all your servers are built in a consistent manner, regardless of the platform on which they are running.</p>
<p>Specifically, you gained<span> experience of performing an interactive Linux installation environment, using PXE network booting. You then learned how to fully automate the build process, using kickstart and pre-seed scripts, to ensure that builds are completely unattended (and, hence, automated). Finally, you learned how to further customize the builds, by adding custom scripts to the build definition.</span></p>
<p>In the next chapter, we will proceed to look at the use of Ansible to customize servers, both when they are newly built, and on an ongoing basis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>What does PXE stand for?</li>
<li>Which basic services are required for a PXE boot?</li>
<li>Where would you obtain the installation sources for a network boot?</li>
<li>What is an unattended installation?</li>
<li>What is the difference between a kickstart file and a pre-seed file?</li>
<li>Why would you need to use a <kbd>%post</kbd> block in a kickstart file?</li>
<li>What is the purpose of the <kbd>BIOS</kbd> and <kbd>EFIx64</kbd> directories under the TFTP server root?</li>
<li>How would you create a separate partition for <kbd>/home</kbd> in a pre-seed file?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li>To see all the possible pre-seed file options, please visit <a href="https://help.ubuntu.com/lts/installation-guide/example-preseed.txt">https://help.ubuntu.com/lts/installation-guide/example-preseed.txt</a>.</li>
<li>To learn more about kickstart files (also works on CentOS), please visit <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/installation_guide/sect-kickstart-howto">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/installation_guide/sect-kickstart-howto</a>.</li>
<li>To see a syntax reference for kickstart file commands, please visit <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/installation_guide/sect-kickstart-syntax#sect-kickstart-commands">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/installation_guide/sect-kickstart-syntax#sect-kickstart-commands</a>.</li>
</ul>


            </article>

            
        </section>
    </body></html>