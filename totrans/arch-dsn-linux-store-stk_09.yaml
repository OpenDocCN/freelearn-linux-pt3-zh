- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analyzing Physical Storage Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*"*When you have eliminated the impossible, whatever remains, however improbable,
    must be the truth." — Sir Arthur Conan Doyle'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’re done with understanding the nitty gritty of the storage landscape
    in Linux, we can put that understanding to practical use. I always like to compare
    the I/O stack with the OSI model in networking, where each layer has a dedicated
    function and uses a different data unit for communication. Over the course of
    the *first eight chapters*, we’ve increased our understanding of the layered hierarchy
    of the storage stack and its conceptual model. If you are still following along,
    you may have gained some understanding of how even the most basic requests from
    an application have to navigate through numerous layers before being processed
    by the underlying disks.
  prefs: []
  type: TYPE_NORMAL
- en: Being the good folks that we are, when we work with someone, we can be too willing
    to be captious and tend to enjoy nitpicking. This leads us to the next phase in
    our journey – how do we gauge and measure the performance of our storage? There
    is always going to be a significant performance gap between the compute and storage
    resources, as a disk is orders of magnitude slower than a processor and memory.
    This makes performance analysis a very broad and complex domain. How do you determine,
    how much is too much, and how slow is too slow? A set of values might be perfectly
    suitable for an environment, while the same set would ring alarm bells elsewhere.
    Depending upon workloads, these variables differ in every environment.
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of tools and tracing mechanisms available in Linux that can
    assist in identifying potential bottlenecks in overall system performance. We’re
    going to keep our focus on the storage subsystem in particular and use these tools
    to get a sense of what is happening behind the scenes. Some of the tools are available
    by default in most Linux distributions, which serve as a good starting point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a summary of what we’ll cover in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: How do we gauge performance?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding storage topology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing physical storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using disk I/O analysis tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter is a lot more hands-on and requires prior experience with the
    Linux command line. Most of the readers might already be aware of some of the
    tools and technologies discussed in this chapter. Having basic system administration
    skills will be helpful, as these tools deal with resource monitoring and analysis.
    It would be best to have the required privileges (root or sudo) to run these tools.
    Depending upon the Linux distribution of your choice, you’ll need to install the
    relevant packages. To install `iostat` and `iotop` on Debian/Ubuntu, use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To install `iostat` and `iotop` on Fedora/Red Hat, use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To install Performance Co-Pilot, you can refer to the installation instructions
    in their official documentation at the following link: [https://pcp.readthedocs.io/en/latest/HowTos/installation/index.html](https://pcp.readthedocs.io/en/latest/HowTos/installation/index.html).'
  prefs: []
  type: TYPE_NORMAL
- en: The usage of these commands is the same on all Linux distributions.
  prefs: []
  type: TYPE_NORMAL
- en: How do we gauge performance?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are different lenses through which we can assess the performance of a
    system. A common approach is to equate the overall system performance with the
    speed of the processor. If go back to simpler times when single-processor systems
    were the order of the day and compare them with modern multi-socket, multi-core
    systems, we’ll see that the processor performance has increased by, to put it
    simply, an epic proportion. If we compare the improvement factor for processor
    performance with that of a disk, the processor is a runaway winner.
  prefs: []
  type: TYPE_NORMAL
- en: The response times for storage devices are usually measured in milliseconds.
    For processors and memory, that value is in nanoseconds. This results in a state
    of incongruity between the application requirements and what the underlying storage
    can actually deliver. The performance of the storage subsystem has not progressed
    at the same rate. Therefore, the argument about equating system performance with
    processor performance has faded away. Just like a chain is only as strong as its
    weakest link, the overall system performance is also dependent on its slowest
    component.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most tools and utilities tend to focus solely on disk performance and do not
    give much insight into the performance of the higher layers. As we’ve discovered
    on this journey, there’s a whole plethora of operations happening behind the scenes
    when an application sends an I/O request to the storage device. Keeping this in
    mind, we will divide our performance analysis into the following two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: An analysis of physical storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An analysis of higher layers in the I/O stack such as filesystems and block
    layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For both cases, we’re going to explain the relevant metrics and how they can
    affect performance. An analysis of filesystems and the block layer will be covered
    in [*Chapter 10*](B19430_10.xhtml#_idTextAnchor184). We’ll also see how we can
    check these metrics through the available tools in Linux distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding storage topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most enterprise environments usually contain a mix of the following types of
    storage.
  prefs: []
  type: TYPE_NORMAL
- en: '**Direct Attached Storage (DAS)**: This is the most common type of storage
    and is attached directly to a system, such as the hard drive in your laptop. Since
    data center environments need to have a certain level of redundancy at every layer,
    the directly attached storage in enterprise servers consists of several disks
    that are grouped in a RAID configuration to improve performance and data protection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fibre Channel storage area network**: This is a block-level storage protocol
    that makes use of fibre channel technology and allows servers to access storage
    devices. It offers extremely high performance and low response times compared
    to traditional DAS and is used to run mission-critical applications. It is also
    far more expensive than other options, as it requires specialized hardware, such
    as fibre channel adapters, fibre channel switches, and storage arrays.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**iSCSI SAN**: This is also a block storage protocol that can use the existing
    network infrastructure and allow hosts to access storage devices. iSCSI SANs utilize
    the TCP/IP network as a means to transport SCSI packets between the source and
    target block storage. As it doesn’t make use of a dedicated network such as FC
    SAN, it has a lower performance than FC SAN. However, it is far easier and inexpensive
    to implement iSCSI SAN, as it doesn’t require specialized adapters or switches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network-Attached Storage (NAS)**: NAS is a file-level storage protocol. Like
    iSCSI SANs, NAS arrays also rely on the existing network infrastructure and do
    not require any additional hardware. However, since the storage is accessed through
    file-level mechanisms, the performance is on the lower side. Nevertheless, NAS
    arrays are the most inexpensive of the lot and are usually used to store long-term
    backups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A simplified comparison of these technologies is shown in *Figure 9**.1*. To
    focus solely on the differences involved in accessing each type of storage, the
    additional details in the higher layers have been left out:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – The different storage topologies](img/B19430_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – The different storage topologies
  prefs: []
  type: TYPE_NORMAL
- en: We’re not going to include fibre switches or any SAN arrays in our discussion.
    However, keep in mind that there are a lot of components involved in accessing
    the different types of storage technologies. Every layer warrants careful examination,
    and as such, you should always have a topology map in mind when diagnosing storage
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing physical storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance defines how well a disk drive functions when accessing, retrieving,
    or saving data. There are quite a few yardsticks that can help to define the performance
    of the disk subsystem. For those of you who have worked with storage vendors while
    evaluating and purchasing high-end storage arrays, IOPS will be a very familiar
    term. Vendors like to throw this acronym around a lot and cite a storage system’s
    IOPS as one of its main selling points.
  prefs: []
  type: TYPE_NORMAL
- en: '**Input Output Operations per Second** (**IOPS**) might very well be an entirely
    useless figure, unless it is coupled with other capabilities of a storage system,
    such as the response time, the read and write ratio, throughput, and block size.
    The IOPS figure is usually referred to as *hero numbers*, and it rarely provides
    any insight into the capabilities of the system unless it is coupled with other
    metrics. When you purchase a vehicle, you need to know the intricate details,
    such as its acceleration, fuel economy, and how well it will handle bends and
    corners. You rarely think about its top speed. Similarly, you need to know all
    the capabilities of the storage system.'
  prefs: []
  type: TYPE_NORMAL
- en: Keeping our focus on the physical disk, we’ll first define the **time-based
    performance metrics**, since they are the ones that explain how and where time
    is spent. Any time you hear the word **latency** or **delay** while analyzing
    performance, that usually is an indication of *lost time*. It is the time that
    could have been spent while working on something, but instead, it was spent waiting
    for something to happen.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding disk service time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us first develop an understanding of the time-dependent metrics that we
    need to look for when analyzing physical disks. Once we’ve gained a conceptual
    understanding, we’ll use specific tools to look for potential bottlenecks. The
    following figure represents the most common *time-centered* metrics to gauge disk
    performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Disk service times](img/B19430_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Disk service times
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to state here that the aforementioned metrics do not account
    for the time spent going through the kernel’s I/O hierarchy, such as filesystems,
    the block layer, and scheduling. We’re going to take a look at them separately.
    For now, we’re only going to focus on the physical layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The terms used in *Figure 9**.2* are explained here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**I/O wait**: An I/O request can either wait in a queue or be actively served.
    An I/O request is inserted into the disk’s queue before being dispatched for servicing.
    The amount of time spent waiting in the queue is quantified as I/O wait.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I/O service time**: The I/O service time amounts to the time during which
    the disk controller actively serviced the I/O request. In other words, it is the
    amount of time an I/O request was not waiting in a queue. The servicing time includes
    the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *disk seek time* is the time taken to move the disk read-write head, with
    radial movement, to the specified track.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the read-write head is placed on the correct track, the platter surface
    rotates to move the exact sector (from where data is to be read from or written
    to) and line it up with the read-write head. The amount of time spent here is
    known as *rotational latency*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the read-write head is positioned over the correct sector, the actual I/O
    operation is performed. This amounts to the *transfer time*. Transfer time is
    the time taken to transfer data to/from the disk from/to the host system.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response time**: The response time or latency is the aggregate of service
    and wait times and can be thought of as the *round trip time* of an I/O request.
    It is expressed in milliseconds and is the most consequential term when working
    with storage devices, as it denotes the entire time from the issuance of an I/O
    request to its actual completion, as depicted in *Figure 9**.3*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Disk latency](img/B19430_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Disk latency
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in *Figure 9**.4*, storage vendors usually mention the following seek
    time specifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Full stroke**: This represents the time taken by the read write head to move
    from the innermost to the outermost track on the disk'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Average**: This is the average time taken by the read write head to move
    from one random track to another'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Track to track**: This is the time taken by the read write head to move between
    two adjacent tracks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The disk seek time specifications are shown in *Figure 9**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – The disk seek time specifications](img/B19430_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – The disk seek time specifications
  prefs: []
  type: TYPE_NORMAL
- en: 'The transfer rate can be broken down into internal and external transfer rates:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Internal transfer rate**: This is the speed at which data is transferred
    from the disk’s platter surface to its internal cache or buffer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External transfer rate**: Once the data has been fetched in the buffer, it
    is then transferred to the host bus adapter controller via the disk’s supported
    interface or protocol. As highlighted in *Figure 9**.5*, the speed at which data
    is transferred from the buffer to the host bus adapter determines the external
    transfer rate:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 9.5 – The disk transfer rates](img/B19430_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – The disk transfer rates
  prefs: []
  type: TYPE_NORMAL
- en: As we explained in [*Chapter 8*](B19430_08.xhtml#_idTextAnchor134), unlike mechanical
    drives, SSDs do not use any mechanical components. Therefore, concepts such as
    rotational latency and seek time do not apply to them. The *response time* encapsulates
    all the time-related aspects, and it is the term that is most frequently used
    when checking for performance-related issues.
  prefs: []
  type: TYPE_NORMAL
- en: Disk access patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The mechanical drives are most affected by the I/O access patterns. The I/O
    pattern generated by an application can be a combination of sequential and random
    operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sequential I/O**: Sequential I/O operations refer to I/O requests that read
    from or write data to consecutive or contiguous disk locations. For mechanical
    drives, this results in a major performance boost, as this requires a very small
    movement from the read write head. This reduces the disk seek time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random I/O**: Random I/O requests are performed on non-contiguous locations
    on the disk, and as you can guess, this results in longer disk seek times, which
    has a negative impact on disk performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Again, the random I/O operations impact the rotating mechanical drives and do
    not affect the SSDs as such. Although, since reading adjacent bytes on a disk
    requires a much smaller effort from the controller, sequential operations on SSDs
    are faster than random operations. However, this difference is much smaller compared
    to mechanical drives.
  prefs: []
  type: TYPE_NORMAL
- en: Determining reads/writes ratio and I/O size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IOPS alone do not paint the full picture of the disk’s performance and should
    always be taken with a grain of salt. It is important to look at the size of I/O
    requests and the ratio of read and write operations. For instance, complex storage
    systems are designed for specific read-write ratios and I/O sizes, such as `70/30
    read write` or `32 KB` block sizes.
  prefs: []
  type: TYPE_NORMAL
- en: Different applications have different requirements and expectations from the
    underlying drives. It is important to have a rough estimate of the percentage
    of types of I/O operations that will be performed on a storage device. For instance,
    online transaction processing applications usually consist of the `70/30 read
    write` ratio. On the other hand, a logging application might always be busy writing
    and might require fewer reads.
  prefs: []
  type: TYPE_NORMAL
- en: The size of the I/O request by an application also varies, depending upon the
    type of the application. In some cases, it is a far more effective approach to
    transmit larger blocks. The time required to process such a request is longer
    than a single smaller request. On the other hand, considering the same amount
    of data, the combined processing and response time of many smaller requests might
    be greater than a single larger request.
  prefs: []
  type: TYPE_NORMAL
- en: Disk cache
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Modern drives come with an onboard **disk cache** or **buffer**. The disk buffer
    is the embedded memory in a disk drive that acts as a buffer between the **host
    bus adapter** (**HBA**) and the disk platter or flash memory that is used for
    storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table highlights the effect of cache on different types of I/O
    patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **I/O type** | **Read** | **Write** |'
  prefs: []
  type: TYPE_TB
- en: '| Random | This is difficult to cache and pre-fetch, as a pattern cannot be
    predicted. | Caching is extremely effective, as random writes require a lot of
    disk seek time. |'
  prefs: []
  type: TYPE_TB
- en: '| Sequential | Caching is extremely effective, as data can be easily pre-fetched.
    | Caching is effective and can be flushed quickly, as data is to be written to
    contiguous locations. |'
  prefs: []
  type: TYPE_TB
- en: Table 9.1 – The effect of a cache on read/writes
  prefs: []
  type: TYPE_NORMAL
- en: The use of a cache speeds up the process of storing and accessing data from
    the hard disk. Enterprise storage arrays usually have a huge amount of cache available
    for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: IOPS and throughput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Along with latency, IOPS and throughput define the fundamental characteristics
    of physical storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '**IOPS**: IOPS represent the rate at which I/O operations can take place within
    a specific time period. The measurement of IOPS will give you the operations per
    second that the storage system currently delivers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throughput**: Throughput refers to the volume of data that is transferred
    from or to the disk drive – in other words, the amount of pizza that you can eat
    at once. This is also referred to as bandwidth. As throughput measures the actual
    amount of data transfer, it is expressed in MB or GB per second.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are a couple of important things to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: The IOPS figure should always be correlated with latency, read-write ratios,
    and the I/O request size. When used independently, it does not have much value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When processing large amounts of data, the bandwidth statistics might be more
    relevant than IOPS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Queue depth
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **queue depth** dictates the number of I/O requests that can be concurrently
    handled at one time. In general, this value will not need to be altered. For large-scale
    SAN environments, in which hosts are connected to storage arrays using Fibre channel
    HBAs, this becomes a significant value. In that case, there are separate queue
    depth values for disks, HBAs, and the storage array ports.
  prefs: []
  type: TYPE_NORMAL
- en: If the number of issued I/O requests exceeds the supported queue depth, any
    new requests will not be entertained by the storage device. Instead, it will return
    a “queue full” message to the host. Once there is room in the queue, the host
    will have to resend the failed I/O request. The queue depth settings can impact
    both mechanical drives and SSDs. Mechanical drives and SSDs that use SATA and
    SAS interfaces only support a single queue, with 32 and 256 commands. Conversely,
    NVMe drives have 64,000 queues and 64,000 commands per queue.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, the default settings for queue depth might be sufficient. Each
    component in a storage environment has some queue depth settings. For instance,
    a RAID controller also has its own queue depth, which can be larger than the combined
    queue depth of the individual disks.
  prefs: []
  type: TYPE_NORMAL
- en: Determining disk busyness
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are a couple of concepts that determine how much the disk is actually
    used. They are described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Utilization**: Disk utilization is a fairly common metric that you’ll see
    being reported by various tools. Utilization means that the disk was actively
    used for a given interval. This value is represented as a percentage of time.
    For example, a 70% utilization value indicates that if the kernel looked up the
    disk 100 times, on 70 occasions, it was busy while performing some I/O request.
    Similarly, a disk that is being 100% utilized means that it constantly serves
    I/O requests. Again, a fully utilized disk may or may not become a bottleneck.
    This value needs to be correlated with a few other metrics, such as the associated
    latency and queue depth. It could be that, although the I/O requests are issued
    continuously, they’re fairly small and sequential; hence, the disk is able to
    serve them in a timely manner. Similarly, RAID arrays have the ability to handle
    requests in parallel, and as such, a 100% utilized disk might not be problematic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Saturation**: Saturation means that the amount of requests issued to a disk
    might be more than what it can actually deliver. This means that we’re trying
    to exceed its rated capacity. When saturation happens, the applications have to
    wait before being able to read from or write data to disk. Saturation will result
    in increased response times and impact the overall performance of a system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I/O wait
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Quite understandably, **I/O wait** is often the most misunderstood metric when
    checking for performance issues. Although it has an *I/O* in name, I/O wait time
    is actually a CPU metric, but it doesn’t indicate issues with CPU performance.
    Get it?
  prefs: []
  type: TYPE_NORMAL
- en: 'I/O wait time is the percentage of time that a CPU was idle, during which the
    system had pending disk I/O requests. What makes this difficult to comprehend
    is that it is possible to have a healthy system with a high I/O wait percentage,
    and it is also possible to have a slow-performing system without a low I/O wait
    percentage. A high I/O wait means that the CPU is idle while waiting for disk
    requests to be completed. Let’s explain this with a couple of examples:'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if a process has sent some I/O requests and the underlying disk
    is unable to immediately fulfill that request, the CPU is said to be in a waiting
    state, as it is waiting for the request to be completed. Here, the waiting indicates
    that CPU cycles are wasted and the underlying disk might be slow to respond to
    I/O requests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, there’s the opposite case. Let’s say that process A is extremely CPU-intensive
    and constantly keeps the CPU busy. Another process running on the system, process
    B is I/O-intensive and occupies the disk. Even if the disk is slow to respond
    to requests of process B and becomes a source of a bottleneck for the system,
    the I/O wait value will be very low in this case. Why? Because the CPU is not
    idle, as it is wrapped up while serving process A. Therefore, although the I/O
    wait is on the low side, there could be a potential bottleneck with the storage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'High I/O wait values can be caused by anyone or a combination of the following
    factors:'
  prefs: []
  type: TYPE_NORMAL
- en: Bottlenecks in the physical storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large queue of I/O requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disks nearing saturation or fully saturated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processes in an uninterruptible sleep state, known as the `D` state (this is
    fairly common when storage is accessed through **network** **filesystem** (**NFS**))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slow network speed in the case of NFS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High swapping activity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I think we’ve covered quite a few things to watch out for when doing an analysis
    of storage devices. Again, if your storage environment contains all the components
    in a traditional SAN environment, then you need to look for a few more things,
    such as **fibre channel** (**FC**) switches and any potential bottlenecks on the
    storage array. To troubleshoot FC switches, you need to establish a basic understanding
    of the FC protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how we can identify these red flags using the available tools.
  prefs: []
  type: TYPE_NORMAL
- en: Using disk I/O analysis tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now have developed a basic understanding of what to look for when diagnosing
    problems with the underlying storage. Most of the time, the problematic behavior
    is first reported at the application layer, and multiple layers are checked before
    the actual identification of the issue. The problematic scenario can also be intermittent
    in nature, which could make it even more difficult to detect. Fortunately, Linux
    has a broad range of utilities in its toolbox that can be used to identify such
    problematic behavior. We’ll take a look at them one by one and highlight the things
    of value to look for when troubleshooting performance.
  prefs: []
  type: TYPE_NORMAL
- en: Establish a baseline using top
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`top` is one of the most frequently used commands when troubleshooting performance
    issues. What makes it so effective is that it can quickly give you the current
    status of a system and possibly give you a hint about the potential problem. Although
    most people use it for CPU and memory analysis, there is one particular field
    that can indicate a problem with underlying storage. As shown in the following
    output, the `top` command can quickly provide a summarized view of the current
    system state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As we discussed earlier, a high I/O wait is an indication of a bottleneck at
    the storage layer. The `wa` field is the wait average and indicates the potion
    of time that the CPU had to wait because of the disk. High wait averages mean
    that the disk does not respond in a timely manner. Although not discussed here,
    load averages can also increase because of higher wait averages. This is because
    load averages include disk waiting activity.
  prefs: []
  type: TYPE_NORMAL
- en: The top utility has several options that can provide insight into CPU and memory
    consumption, but we’re not going to focus on them. As our primary concern here
    is storage, we need to watch out for high values in the `wa` column and the load
    averages.
  prefs: []
  type: TYPE_NORMAL
- en: The iotop utility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `iotop` command is a `top`-like utility to monitor disk-related activity.
    The `top` command, by default, sorts output on the basis of CPU usage. Similarly,
    the `iotop` command sorts processes by the amount of data read and written by
    each process. It displays columns that highlight the top disk bandwidth consumers
    in your system. Additionally, it also displays the proportion of time that the
    thread/process was engaged in swapping and waiting for I/O operations. The I/O
    priority, both in terms of class and level, is indicated for each process.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s better to run `iotop` with the `-o` flag, as it will show processes that
    currently write to disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`iotop` command shows the amount of data being read from or written to the
    disk by a process. Check the supported disk read and write speeds, and compare
    them with the throughput of the top processes. This can also help to identify
    unusual disk activity by applications and determine whether any process can read
    or write an abnormal amount of data to underlying disks.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, the `iotop` command might complain that delay accounting is not
    enabled in the kernel. This can be fixed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sysctl kernel.task_delayacct = 1`'
  prefs: []
  type: TYPE_NORMAL
- en: The iostat utility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `iostat` command is the most popular tool for disk analysis, as it displays
    a wide variety of information that can be of help to analyze performance issues.
    Most of the metrics that were explained earlier, such as disk saturation, utilization,
    and I/O wait, can be analyzed through `iostat`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first line of the output in `iostat`’s disk statistics is a summary since
    the most recent boot, which shows the mean for the entire time the system has
    been up. Subsequent lines are displayed as per-second statistics, calculated using
    the interval specified on the command line, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – The iostat command](img/B19430_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – The iostat command
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what to look for:'
  prefs: []
  type: TYPE_NORMAL
- en: The first line, `avg-cpu`, shows the percentage of CPU utilization that occurred
    while executing in each state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `r/s` and `w/s` numbers give a breakdown of the number of read and write
    requests issued to the device per second.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `avgqu-sz` represents the count of operations that were in either a queued
    state or actively being serviced. The `await` value corresponds to the average
    duration between placing a request in a queue and its completion. The `r_await`
    and `w_await` columns show the average wait time for read and write operations.
    If you see consistently high values here, the device might be nearing saturation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `%util` column shows the amount of time during which the disk was busy serving
    at least one I/O request. The utilization value might be misleading if the underlying
    storage is a RAID-based volume.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The general assumption is that as a device’s utilization approaches 100%, it
    becomes more saturated. This holds true when referring to a storage device that
    represents a single disk. However, SAN arrays or RAID volumes consist of multiple
    drives and can serve multiple requests simultaneously. The kernel does not have
    direct visibility on how the I/O device is designed, which makes this a dubious
    figure in some cases.
  prefs: []
  type: TYPE_NORMAL
- en: Performance Co-Pilot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`sysstat` package. The PCP tools also include a GUI application to create graphs
    from the generated metrics and have the ability to save historical data for later
    viewing. A couple of tools that can assist in storage analysis are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pcp atop`: This provides information similar to both the `iotop` and `atop`
    commands. The command lists the processes that perform I/O, along with the disk
    bandwidth they use. Like `ioto` and `top`, `pcp atop` is a good tool for quickly
    grasping changes occurring on a system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pcp iostat`: The `pcp iostat` command reports live disk I/O statistics, much
    like the `iostat` command we saw earlier. As shown in *Figure 9**.7*, the columns
    in the output are similar to that of `iostat`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 9.7 – pcp iostat](img/B19430_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – pcp iostat
  prefs: []
  type: TYPE_NORMAL
- en: When troubleshooting disk performance or resource-related issues, `vmstat` can
    provide valuable information, as it can help to identify disk I/O congestion,
    excessive paging, or swapping activity.
  prefs: []
  type: TYPE_NORMAL
- en: The vmstat command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `vmstat` command, derived from “virtual memory statistics,” is a native
    monitoring utility included in nearly all Linux distributions. As shown in *Figure
    9**.8*, it reports information about processes, memory, paging, disks, and processor
    activity:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8 – The vmstat command](img/B19430_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 – The vmstat command
  prefs: []
  type: TYPE_NORMAL
- en: '`b` column in the output shows the number of processes blocked while waiting
    for a resource, such as disk I/O. Additional information most useful for troubleshooting
    I/O issues is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`si`: This field represents the amount of memory, in kilobytes, that is swapped
    in from the swap space on the disk to the system’s memory per second. A higher
    value in the `si` field indicates increased swapping activity, suggesting that
    the system frequently retrieves data from the swap space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`so`: This field represents the amount of memory, in kilobytes, that is swapped
    out from the system’s memory to the swap space on disk per second. A higher value
    in the `so` field indicates increased swapping activity, which can occur when
    the system is under memory pressure and needs to free up physical memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bi`: This field specifically refers to the data transfer rate from disk to
    memory. A higher value in the `bi` field indicates increased disk read activity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bo`: This reflects the output activity or the amount of data written from
    the system’s memory to the disk. A higher value in the `bo` field suggests increased
    disk write activity, indicating that data is written from memory to the disk frequently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`wa`: This field represents the percentage of time that the CPU is idle while
    the system waits for I/O operations to complete. A higher value in the `wa` field
    suggests that the system experiences I/O bottlenecks or delays, with the CPU frequently
    waiting for I/O operations to complete.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pressure Stall Index
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Pressure Stall Index** (**PSI**) is a relatively new addition to the troubleshooting
    toolset in Linux and offers a new way to obtain utilization metrics for memory,
    CPU, and disk I/O. Latency spikes can occur when there is contention for CPU,
    memory, or I/O devices, resulting in increased waiting times for workloads. The
    PSI feature identifies this and prints a summarized view of this information in
    real time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The PSI values are accessed through the `/proc pseudo` filesystem. The raw
    global PSI values appear in the `/proc/pressure` directory in files called `cpu`,
    `io`, and `memory`. Let’s take a look at the `io` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`avg` fields represent the *percentage* of time in the last 10, 60, and 300
    seconds, respectively, that processes were starved of disk I/O. The line prefixed
    with `some` represents the portion of time during which one or more tasks were
    delayed due to insufficient resources. The line prefixed with `full` represents
    the percentage of time when all tasks were delayed due to resource constraints,
    indicating the extent of unproductive time.This is a bit similar to the load averages
    in `top`. The output here shows high values for the `10`-, `60`- and `300`-second
    interval averages, which indicates that processes are being stalled.'
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, Linux offers a plethora of utilities to analyze the performance
    of your system. The tools that we covered here are not only used for storage analysis
    but also to establish an overall picture of a system, including its processor
    and memory subsystem. Every tool offers a wide range of options that can be used
    if we want to analyze a particular aspect. We highlighted the major indicators
    to look for when using each of these tools, but since every environment consists
    of different variables, there is no *fixed* approach to troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Troubleshooting performance issues is a complex matter, as it can take a long
    time to diagnose and analyze them. Of the three major components in an environment
    – storage, compute, and memory – storage is the slowest. There is always going
    to be a mismatch in their performance, and any degradation in disk performance
    can impact the overall operation of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping this objective in mind, we divided this chapter into two sections. In
    the first section, we explained the most important metrics that you should understand
    before troubleshooting any issues. We discussed the time-related metrics related
    to storage devices, CPU wait averages, disk saturation, and disk utilization,
    and the different access patterns when reading from or writing to physical disks.
  prefs: []
  type: TYPE_NORMAL
- en: In the second part, we saw the different ways in which we can analyze the metrics
    highlighted in the first section. There are a lot of mechanisms available in Linux
    that can assist to identify potential bottlenecks in overall system performance.
    We used tools such as `top`, `PSI`, `iostat`, `iotop`, and `vmstat` to analyze
    disk performance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will continue our analysis of the storage stack and
    focus on the higher layers, such as the block layer and filesystems. For this
    purpose, we’ll make use of the different tracing mechanisms available in Linux.
  prefs: []
  type: TYPE_NORMAL
