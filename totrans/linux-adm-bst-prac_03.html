<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer010">
			<h1 id="_idParaDest-32"><em class="italic"><a id="_idTextAnchor030"/>Chapter 2</em>: Choosing Your Distribution and Release Model</h1>
			<p>When we talk about <strong class="bold">Linux system administration</strong>, we probably jump quickly to wondering what flavor of Linux we are going to be talking about. This is typically the first topic that pops into our minds when having even a casual conversation with a business owner or someone in another, non-technical department. What we rarely spend much time thinking about is release and support models and how these play into our planning, risk, and expenditure models.</p>
			<p>A quarter century ago we used to be educated regularly about the merits, caveats, and machinations of different software licensing models. Today terms such as <em class="italic">open-source</em> are used constantly and no one is surprised to hear them but like with all things technical as the adoption rate of a term increases the general understanding of it likely decreases. Therefore, we need to investigate some nuances of licensing as this plays a role in how an operating system will interact with the outside world, at least from a legal perspective.</p>
			<p>In this chapter we are going to cover the following main topics:</p>
			<ol>
				<li>Understanding Linux in Production</li>
				<li>Linux Licensing</li>
				<li>Getting to Know Key Vendors and Products</li>
				<li>Grokking Releases and Support Models: Rapid, Long Term, and Rolling</li>
				<li>Choosing Your Distribution</li>
			</ol>
			<h1 id="_idParaDest-33"><a id="_idTextAnchor031"/>Understanding Linux in production</h1>
			<p><strong class="bold">Linux</strong> is used in <a id="_idIndexMarker070"/>every aspect of business and production <a id="_idIndexMarker071"/>systems today. Simply by being a Linux-based system actually tells us incredibly little about what a device might be doing or how it might be used. Unlike macOS, which essentially guarantees that the use case is either a desktop or a laptop end user device, or Windows Server, which all but assures us that a system is an infrastructure or line of business (LOB) server. Having a system be built on Linux gives us very little to go on when looking to determine the intended use of that system. Linux is used on servers, in virtualization, in desktops, laptops, tablets, routers, firewalls, phones, IoT devices, appliances, and more. Linux is everywhere. And Linux is doing just about everything that there is to do. There are almost no roles that Linux does not cover, at least some of the time.</p>
			<p>For the context of a book on <strong class="bold">Linux Administration</strong>, we are going to assume that we are talking about Linux in the standard <em class="italic">GNU</em>/<em class="italic">Linux</em> vein using the industry standard set of baseline tools, and in multi-user environments. We will focus almost entirely on the idea of Linux on servers but will consider that end user devices such as desktops and laptops are valid hardware candidates as well. Much of what we discuss will, of course, apply to things such as Android devices or even to non-Linux systems. Linux itself is an almost unlimitedly large topic, but there is a generally accepted <em class="italic">this is what people mean by Linux</em> idea<a id="_idIndexMarker072"/> that we will work with. So, we aren't talking about<a id="_idIndexMarker073"/> Android, Chrome OS, and so on.</p>
			<p>Linux itself is a <em class="italic">kernel</em>, not an operating system. But as a kernel, it has formed the backbone (and only a small overall common component) of several related <strong class="bold">UNIX</strong> operating systems.</p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor032"/>Is Linux UNIX?</h1>
			<p>You'll likely<a id="_idIndexMarker074"/> hear<a id="_idIndexMarker075"/> people say that Linux isn't UNIX at some point in your Linux career. And to some degree, they are correct, but not in the way that they likely mean. Linux is only a kernel, one piece of a UNIX operating system. But operating systems built on Linux are, by and large, UNIX - at least according to the most definitive possible source, Dennis Ritche, one of the creators of UNIX. Linux implements both the UNIX approach and ecosystem, as well as the UNIX interfaces. It is a UNIX, just as FreeBSD and others are. UNIX is both a standard and a trademark. But the two are not necessarily maintained together. The waters are a bit muddy here. But standard Linux systems, any that we will be discussing in this book, implement the UNIX standard (known as POSIX originally and now a super set of POSIXs, known as SUS). So, they are a UNIX variant or derivative, just as Dennis Ritchie said that they were way back in 1999. He said the same thing about the BSD operating system family, as well.</p>
			<p>But the story is a little better than that. While most operating systems built from Linux have never bothered to pay for any kind of UNIX certification, one of them recently did: EulerOS by Huawei which is built from CentOS, which in turn, is built from Fedora. Only EulerOS as a product officially carries the UNIX trademark designation, but it shows that the broader ecosystem is meeting the specifications. The nature of the certification process is that it makes it easy and obvious to certify large, proprietary, commercially backed UNIX projects such AIX or macOS. But in the Linux space where each distribution counts as a unique operating system and often defining exactly which OS is unique from another is a bit of a gray area (Is Kubuntu covered under Ubuntu? Is Ubuntu covered under Debian?) and where projects are often volunteer efforts that have no revenue source to cover a meaningless certification process it would be all but impossible to certify them through a complicated and expensive certification process, especially when that process has no value. In reality, the Linux and BSD ecosystems have demonstrated that the <a id="_idIndexMarker076"/>utility<a id="_idIndexMarker077"/> of the UNIX certification process has run its course and the process is now detrimental to the industry and serves no purpose. At the end of the day, being compatible with UNIX is worthless, it is Linux and BSD that other systems want to maintain compatibility with.</p>
			<p>Microsoft demonstrated this last point beautifully in the last few years when their traditional UNIX compatibility layer called Windows SFU (Windows Subsystem for UNIX) was rebuilt and renamed WSL (Windows Subsystem for Linux) and intentionally made fully compatible with Linux in order to be able to run Linux-based operating systems on top of the Windows kernel. Microsoft, once the largest maker of traditional UNIX systems with their Xenix product now sees only Linux compatibility as valuable.</p>
			<p>If there ever truly was an operating system war, UNIX won through and through. And within UNIX, Linux won. </p>
			<p>So, we are continuously challenged to define exactly what we mean by Linux. Everyone has their own definition whether intentionally or simply by not understanding either the relationship between a kernel and an operating system, or by not understanding the role of Linux distributions. It does not take too long working with Linux in business before you will get a feel for what people mean when they are discussing it, however. Somehow while not having any formal definition we have managed to arrive at some sort of standard in the industry. When saying a system is or is not Linux, we know not to include <em class="italic">Android</em> or <em class="italic">Chrome OS</em> when talking about administration, but to include them when we are talking about Linux adoption on the desktop. There is a lot of nuance and there is no reliable way to know completely for sure when someone means one thing or another and we can assume that over time these definitions will morph as they are not actually based on anything solid and are not accurate.</p>
			<p>Because of this strange approach to Linux naming conventions where nothing is formal and we use contextual clues to determine what is meant, we actually use phrases such as <em class="italic">switching from Chrome OS to a Linux desktop</em>, which should make no sense as Chrome OS is as much Linux as any other Linux-based operating system is.</p>
			<p>Now, at the highest level, we should have a decent idea of what Linux is and, more importantly, what most people mean when they talk about something being Linux or even being a<a id="_idIndexMarker078"/> UNIX <a id="_idIndexMarker079"/>system. We are also ready to defend why Linux is absolutely a true member of the UNIX family at our next system administration cocktail reception! Next up is licensing, but don't worry because the Linux universe makes licensing as easy as<a id="_idTextAnchor033"/> it gets.</p>
			<h1 id="_idParaDest-35"><a id="_idTextAnchor034"/>Linux licensing</h1>
			<p>Few discussions of<a id="_idIndexMarker080"/> Linux happen without the topic of <strong class="bold">licensing</strong> being mentioned. Mostly this happens for a few reasons: because <strong class="bold">Linux licensing</strong> is so different from nearly all of its competitors that it plays a significant role in business decisions, because it is the largest and most prominent open-source product on the market regardless of category, and because it arose in popularity in conjunction with the rise of the open-source software movement and quickly became its poster child. Most people instantly connect (and sometimes even confuse) Linux with any mention of open-source software, which leads to a lot of confusion as there are millions of other equally open-source software packages out there and when mentioning closed source software, no one jumps to any one comparable poster-child software package and assumes that that is what we are talking about. Linux, for whatever reason, gets treated differently than pretty much any other product on the market in how people talk, name, and think about it.</p>
			<p>Linux itself is licensed <a id="_idIndexMarker081"/>under the <strong class="bold">GNU General Public License</strong> (aka <strong class="bold">GPL</strong>) also known <a id="_idIndexMarker082"/>as a <strong class="bold">CopyLeft</strong> which is the best known of all open-source licenses. This license provides us with many advantages in the use of Linux. </p>
			<p>Being the best-known open-source license alone is a significant benefit. Understanding of how this license applies to organizations is extensive and licensing resources abound. Applying this license to organizations is standard industry knowledge and because essentially all companies globally use software licensed under the GPL at least a little, if not extensively, any concerns about the license must be addressed for myriad reasons. While other open-source licenses, such as BSD or MIT licenses, might be seen as superior from an end user IT department perspective, they are certainly less well known.</p>
			<p>The GPL guarantees that access to the source code for Linux is available to everyone, always, for free. This gives organizations important protections. It increases security by allowing for code reviews by anyone who is interested, and with a product like Linux the number of governments, large businesses, security research firms, and interested developers who<a id="_idIndexMarker083"/> try to do so is extremely large. Linux is easily the most reviewed code in history. Open-source software of this nature retains every security advantage of closed source software while adding the extremely critical options for public review and, perhaps even more importantly, public accountability. </p>
			<p>Freely available source code also guarantees companies using Linux that any vendor disruptions that might occur, which might include a bankruptcy, or a vendor suddenly deciding to change strategy and dropping a product or taking a product in an unwanted direction, can be mitigated in several ways such as another vendor taking up the product on their own and providing an alternative support and production path, or even the customer themselves doing so. Most importantly, an original vendor does not retain the power to hold customers truly hostage through a change in pricing, licensing, or product availability. The customer, and the market, always retain options should the product have value.</p>
			<p>A great feature of open-source software of this nature is that every customer benefit from the protections, security, and flexibility of the license even if they do not do things like review the code themselves or fork the product to make their own release.</p>
			<p>It is critical to understand, however, that open source does not mean nor imply free. Famously in the open-source community the expression <em class="italic">free as in freedom, not free as in beer</em> is used to explain this. Meaning that the code is free, but products made from the code may or may not be free. You are totally allowed under the license, as a vendor, to use the free and open-source code to compile a resulting product that is not free to purchase. There are Linux operating system vendors who take this approach. This doesn't remove the benefits of the code being open source, it simply means that you have to track licensing and costs the same as you work with many other operating systems such as Windows or AIX.</p>
			<p>Most Linux derived operating systems are completely free, though, and this is a very big deal in the industry. Being completely free has obvious benefits, but these can be misleading as the lack of upfront cost makes for an easy target for salespeople to prey on the emotionally confusing saying <em class="italic">you get what you pay for</em>, which we all know intrinsically is untrue and has no foundation in reality or logic, but it's oft repeated and easy to make sound plausible. We can instantly counter this with the option to pay as much as you want for Linux, no vendor will turn down the option of a donation and one must wonder <em class="italic">does the value then increase because you voluntarily paid more for it?</em> Of course not, the entire notion is nonsensical. And yet this is a common argument made that simply throwing money at products is its own reward.</p>
			<p>Beyond avoiding up front purchase costs, freely available software, especially operating system software, can do a lot for a business. Probably the biggest<a id="_idIndexMarker084"/> benefit is <strong class="bold">flexibility</strong>. With a free Linux option, you can deploy software as needed anywhere in the organization without managing licenses, getting budgetary approval, or trying to figure out how to <a id="_idIndexMarker085"/>coordinate with vendors to purchase. It's actually not uncommon for licensing overhead to actually exceed technology overhead in the deployment of non-free operating systems! This becomes even more exacerbated in the <em class="italic">cloud</em> and <em class="italic">DevOps</em> world when deployments may become automated, transparent, and unpredictable.</p>
			<p>Free also means that staff, subsidiaries, employee candidates, partner companies, customers, or anyone really, is free to deploy the same systems for compatibility, education, standardization, testing, staging, and on and on. In some cases, proprietary licensing doesn't even allow for desired scenarios or, when it does, can be cumbersome or onerous. Not in all cases, of course, but in most of the key real-world scenarios this is the case. With the notable exception of the <strong class="bold">BSD</strong> family of operating systems which are also open <a id="_idIndexMarker086"/>source and<a id="_idIndexMarker087"/> generally <a id="_idIndexMarker088"/>free (e.g., <strong class="bold">FreeBSD</strong>, <strong class="bold">NetBSD</strong>, <strong class="bold">OpenBSD</strong>, and <strong class="bold">Dragonfly BSD</strong>) no <a id="_idIndexMarker089"/>other market competitor of the Linux distributions is available in a form that allows it to be easily used in home labs, testing, or partner environments nor on a range of varying hardware platforms. macOS, for example, is only available on the very limited range of <em class="italic">Apple Mac</em> end user hardware. Windows is limited to <em class="italic">AMD64 architecture hardware</em> in any meaningful way and licensing for it is complex, confusing, and expensive. <em class="italic">AIX</em> and <em class="italic">Solaris</em> are limited to extremely niche, high end server hardware from only a tiny selection of vendors and require expensive licensing. Linux and BSD families are unique in their ability to be deployed, potentially for free, in essentially any conceivable scenario.</p>
			<p>And there we go, Linux licensing in a nutshell. At this point you should have the confidence to be able to deploy Linux solutions in your business and understand how licensing affects you, when you need to pay, and for what it is that you might decide to pay. You are prepared to separate concepts like licensing and support and invest where it makes sense for you. </p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If you find this topic to be really interesting, I recommend some classic books that delve into the topic of open-source licensing more thoroughly such as <em class="italic">Free as in Freedom</em> by Sam Williams (2002) and <em class="italic">The Cathedral &amp; the Bazaar</em> by Eric S. Raymond (2001). These titles were key tomes from the height of the open-source revolution and are considered nearly canon in the Linux Administration space. Well worth reading to gain better insight into the club to which Linux Administrators belong.</p>
			<p>Now that we have gone over concepts at the Linux level itself, we need to start coming down for the fifty <a id="_idIndexMarker090"/>thousand foot view to a closer ten thousand foot view and start talking about real world vendors and tangible products in the Linux space.</p>
			<h1 id="_idParaDest-36"><a id="_idTextAnchor035"/>Key vendors and products</h1>
			<p>Unlike key competitors to<a id="_idIndexMarker091"/> Linux, such as Windows by <em class="italic">Microsoft</em>, macOS by <em class="italic">Apple</em>, Solaris by <em class="italic">Oracle</em>, or AIX by <em class="italic">IBM</em>, Linux has no single vendor representing it, but rather has quite a few vendors each providing their own products, support, and approach to Linux. This, of course, makes discussing Linux exceedingly difficult because Linux isn't a single thing, but more of a concept: <em class="italic">a family of related things that often share many commonalities, but don't necessarily have to</em>.</p>
			<p>Describing the Linux family of operating systems is a rather daunting task as it is far more complex than just half a dozen sibling operating systems. In reality, Linux is a complex tree of root and derivative distributions with derivatives of derivatives and operating systems from all levels of the tree gaining and losing prominence over time. Thankfully, we can ignore the far more confusing and convoluted UNIX family tree of which Linux is just one branch! Analyzing the entire UNIX pedigree would require an entire book of its own and quite honestly a lot more research than I think would be prudent. Suffice it to say that UNIX is a huge topic and primarily historical interest that would not provide<a id="_idIndexMarker092"/> us with a lot of value to get too deeply into.</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>What about BSD?</h2>
			<p>Any mention <a id="_idIndexMarker093"/>of the Linux family of operating systems in<a id="_idIndexMarker094"/> the context of system administration will also require us to address the spiritual sibling family of operations systems: BSD. BSD is like Linux in many ways. Like Linux, BSD is open source. Like Linux, BSD represents a family of similar and closely related, but ultimately unique, operating systems. Like Linux, BSD is nearly always free. And like Linux, at least one member of the BSD family has been fully certified as a UNIX, while all members are UNIX in any meaningful way.</p>
			<p>Almost everything that we will be covering in this book is equally applicable to both Linux and BSD families, and in many cases even more broadly than that. BSD is not exactly the same as Linux and does have its differences, as would any other operating system. Some key differences at a high level include licensing with BSD being licensed under the BSD license instead of under the GPL like Linux, and BSD referring to the <em class="italic">ecosystem around the kernel</em> rather than the kernel itself, and Linux referring to the kernel regardless of the ecosystem around it. So truly opposite terms in that regard. BSD is actually analogous to the term GNU rather than to Linux.</p>
			<p>BSD truly represents a Linux alternative that shares no code and no licensing, yet is spiritually related in nearly every sense. Both were started from around the same time period, both to replicate UNIX at a time when UNIX was dominant, but expensive and very difficult to obtain access to without either academic access or large corporate access. And today both run nearly all the same applications, in extremely similar ways, and are often seen as direct alternatives to each other in nearly all arenas included cloud, servers, virtualization, desktops, laptops, mobile devices, and even IoT!</p>
			<p>Also, like Linux, BSD splintered or <em class="italic">forked</em> into many products. Four key BSD family members exist in the server world: FreeBSD, OpenBSD, NetBSD, and DragonFly BSD with FreeBSD being by far the most dominant. In the desktop and mobile world BSD looks very different from Linux with the key products being non-free and almost entirely from a single vendor, Apple. Apple's macOS, iOS, iPadOS, and others are all derived from FreeBSD and remain commercial members of the BSD family giving BSD far more visibility and utility than people realize.</p>
			<p>While tracking and understanding market dominance for any operating system is extremely difficult as there is no certain means of knowing what operating systems are truly deployed in the wild, let alone which ones are getting use or how new deployments compare to old ones, how to count primary devices against shelved tertiary devices and so forth, it is generally considered that Linux is the overall dominant operating system family today, and likely, but less broadly accepted, that BSD is in second place mostly because of mobile end user devices, but with a very strong server presence as well and macOS suddenly representing a major desktop presence as well. At this point, Microsoft's Windows NT family is the only serious competitor with Linux and BSD overall in the market, although it is still very much dominant on the desktop and laptop.</p>
			<p>At the base of the <strong class="bold">Linux family tree</strong> there are several roots. These are operating system distributions built with a Linux kernel and all of the accouterments surrounding it to be assembled into a full operating system. There are probably hundreds of distributions at this level, but only a few that truly matter and that we will mention. These are <strong class="bold">Debian</strong>, <strong class="bold">Red Hat</strong>, and <strong class="bold">Slackware</strong>. Each of these represents its own base level operating system that you can deploy, each also represents a family of hundreds, or thousands of operating system derivatives based on the core work of the initial operating system.</p>
			<p>We are only going to dig into server operating system choices. If we began listing important<a id="_idIndexMarker095"/> desktop Linux distributions our list would more than triple, and <a id="_idIndexMarker096"/>it would move from a stable list of <strong class="bold">vendors</strong> and <strong class="bold">products</strong> that changes very slowly over the years to a list that is disrupted every year or two with key products entering and exiting the market. Selecting an appropriate desktop operating system is a far more personal choice compared to the <em class="italic">purely business-focused decision process</em> of server selection. What looks and feels good to the end users or management is what often matters most, because it's an end user interface system. Servers, however, have no user interfaces so our decisions are very different.</p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor037"/>Debian</h2>
			<p>Let us look first at <a id="_idIndexMarker097"/>Debian. This is the largest and most interesting <a id="_idIndexMarker098"/>family of <strong class="bold">Linux distributions</strong>, as well as one of the oldest having first released in 1993. Debian is very well known on its own and a great number of IT departments use Debian as their primary server distribution and many applications are developed with it as their primary target. Debian is famous for its openness and lack of commercial oversight. It is often considered the <em class="italic">most free</em> of the large distributions. Because of this, Debian has found a place less as a distribution to be deployed in its own right, but more so as a distribution used as a starting point for building other distributions. More of the Linux world is built from a starting point of Debian than from any other source.</p>
			<p>Debian is completely free, to the point that they do not even offer any paid services, nor do they include any proprietary components or drivers. This makes it an ideal base or <em class="italic">seed</em> system for building another distribution, but often means that companies are wary of choosing Debian as their directly installed operating system of choice as original vendor support options do not exist. So, gauging the popularity of Debian is convoluted because as a base it is nearly everywhere, but installed natively it is rare.</p>
			<p>Debian is<a id="_idIndexMarker099"/> famously light, stable, and conservative. It is not the most popular system to deploy but is a solid choice to consider.</p>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor038"/>Ubuntu</h2>
			<p>Debian's best<a id="_idIndexMarker100"/> known derivative distribution, and the single most<a id="_idIndexMarker101"/> deployed Linux based distribution on servers, is <strong class="bold">Ubuntu</strong>. Ubuntu could be described as little less than an industry juggernaut having come to the Linux world late in the game, first providing a release in 2004 long after nearly everyone else on this list was well established. Ubuntu moved to desktop dominance, practically defining what Linux on the desktop looked like, in just a few years and today has sat for some time as the most popular, most broadly deployed flavour of Linux with no signs of slowly down. If anything, Ubuntu adoption rates continue to increase both as Linux itself continues to grow in absolute terms and as Ubuntu continues to grow inside of the Linux space in relation to other Linux distributions.</p>
			<p>Ubuntu is built from Debian, but extended with more features and polish and, most importantly, it has a commercial vendor<a id="_idIndexMarker102"/> backing it: <strong class="bold">Canonical</strong>. With Canonical you have options of getting primary vendor support for Ubuntu which means that many organizations requiring primary vendor support are able to choose Ubuntu where Debian was not an option for them. Ubuntu most certainly has many differences from Debian itself including some additions of non-open-source packages, but for many it is through of basically being a vendor supported, business ready version of Debian.</p>
			<p>Ubuntu leads, at this current time, across deployment types. They lead in desktops, traditional servers, cloud servers, and more. To a limited extent, you can even find Ubuntu on some phones, tablets, single board computers like the <em class="italic">Raspberry Pi</em>, and IoT devices! Ubuntu is everywhere. Ubuntu is pretty much on everyone's short list.</p>
			<p>In its early days, Ubuntu focused very hard on desktop features and on marketing themselves as being easier for people new to Linux. Whether or not this was true, this benefitted Ubuntu in getting a lot of developer and other non-IT adoption and in getting many IT professionals from the Windows world to be willing to test the Linux waters. It also gave <a id="_idIndexMarker103"/>Ubuntu a stigma that took some time to overcome. Today<a id="_idIndexMarker104"/> this is purely historical and discussions of easy to use or being desktop focused are long gone.</p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor039"/>IBM Red Hat Enterprise Linux (RHEL)</h2>
			<p>Another<a id="_idIndexMarker105"/> early <strong class="bold">Linux vendor</strong>, Red <a id="_idIndexMarker106"/>Hat also, like Debian, entered the market in 1993 and has remained one of the largest and most influential vendors for its entire history. In 2019 Red Hat was purchased by IBM. Since 2002, Red Hat's flagship Linux distribution has gone by the moniker <strong class="bold">Red Hat Enterprise Linux</strong>, but as this name is too long the industry refers to it as <strong class="bold">RHEL</strong>.</p>
			<p>RHEL is nearly unique in the Linux space as one of the rare distributions that is not free. Of course, being built from GPL-licensed Linux and other components requires that Red Hat make the source code of their operating system be open and free, but the GPL puts no such conditions on the compiled final product. This makes RHEL a much more limited use product on its own. It is one that always comes bundled with vendor support.</p>
			<p>Because of this, RHEL is seen as the big business solution for Linux and for a long time was one of only two big vendors making products with an enterprise focus, the other being <em class="italic">SUSE</em>. For most of its history, Red Hat was the market leader with SUSE trailing behind. But in recent years, Ubuntu has pulled ahead in market terms, even if it hasn't in profit terms. </p>
			<p>RHEL is seen as an extremely conservative distribution that is slightly heavier in standard installs compared to most of its competitors. RHEL often gets the most security focus and review<a id="_idIndexMarker107"/> and has the biggest <a id="_idIndexMarker108"/>support vendor behind it.</p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor040"/>RHEL alternatives</h2>
			<p>As this book<a id="_idIndexMarker109"/> goes to press a lot is changing in <a id="_idIndexMarker110"/>the Red Hat world. For many years, CentOS was a Linux distribution built to be a RHEL-clone as closely as possible, made by recompiling the RHEL source code, while removing any trademarked names, logos, and so forth, and making a binary compatible distribution for free that was RHEL in all but name. Red Hat eventually bought CentOS but operated it for some time exactly as it had always been. But just before this book was written, Red Hat discontinued CentOS leaving the market in disarray. Until that point, CentOS was the primary product in the Red Hat ecosystem and most companies using RHEL in some fashion were actually doing so using CentOS which was free and came without support. The sudden cancelation has left that portion of the market in disarray.</p>
			<p>A few other immediate options have presented themselves in the aftermath of this announcement. One is Rocky Linux which is essentially the CentOS project recreated by its original founder with the same mission. Another is Oracle Linux which was built the same was that CentOS was, by taking the RHEL source code and recompiling it, but by Oracle a major industry vendor (and the creator of the Solaris operating system) and offering it still for free, but also with optional Oracle vendor support and with a few extra features that RHEL itself did not have.</p>
			<p>In reaction to the market furor over the sudden death of CentOS and the obvious market move to take their business to other non-IBM vendors, Red Hat has announced programs to provide a limited number of RHEL licenses for free for small businesses or IT professionals needing access to learn the operating system.</p>
			<p>How this will play out in the next few years will be interesting and is difficult to predict. But needless to say the strong market position and longevity of RHEL, are not the near certainties that we would have thought that they were just a few months ago.</p>
			<p>This also highlights a general rule of business: products from large proprietary vendors are often the riskiest, contrary to most emotional responses from business owners, because their direction is set by boards, investors, and market opportunity making it surprisingly easy for large products to be suddenly abandoned or discontinued even if they are doing well in the market. Often smaller vendors that are more focused can actually be more stable in the ways that most affect their customers. They simply have far more riding on keeping their existing products viable and cannot afford to gamble on killing off major <a id="_idIndexMarker111"/>product lines or alienating their <a id="_idIndexMarker112"/>user base.</p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor041"/>Fedora</h2>
			<p><strong class="bold">Fedora</strong> is an interesting<a id="_idIndexMarker113"/> player in the business Linux <a id="_idIndexMarker114"/>space. Technically Fedora is part of Red Hat, which is in turn a part of IBM. Fedora operates much like an independent nonprofit but is not a legal entity on its own. So many people believe it to be its own company but it is not. Fedora was originally its own project before it was merged with an early Red Hat Linux product in 2002. </p>
			<p>Fedora, as a product serves two key purposes in which we are interested in the aim of this book. The first is that it produces one of the best completely free Linux distributions, simply called Fedora, which is designed to be able to be used well as both a desktop and a server distribution. The second is that Fedora is focused on innovation and their work is used as the foundation for what becomes both CentOS Stream and RHEL.</p>
			<p>Originally, Red Hat was the seeding distribution and Fedora worked from their code and extended it. But over the years, Fedora is now the base seed distribution from which RHEL is derived. In that regard, Fedora is a bit similar to Debian in Debian's relationship with Ubuntu, but with RHEL instead. Like Debian, Fedora does not offer vendor support. And also, like Debian, Fedora's downstream child product is far better known than the parent is â€“ that is that RHEL and CentOS are better known than Fedora on which they are based.</p>
			<p>In other ways, however, we find in practice Fedora and Ubuntu are more alike overall both with similar foci broadly on many different use cases, both being used as the base for many other products, both sharing similar design strategies. There are no exact analogues, unfortunately.</p>
			<p>Fedora's biggest challenges come from its lack of primary vendor support options. It also suffers from not being seen as a top tier distribution by many software makers. These vendors tend to then target Ubuntu and RHEL while Fedora often only gets support as an afterthought <a id="_idIndexMarker115"/>or <a id="_idIndexMarker116"/>because of its naturally high compatibility with RHEL.</p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor042"/>OpenSUSE and SLES</h2>
			<p>The last <a id="_idIndexMarker117"/>of the <a id="_idIndexMarker118"/>big <a id="_idIndexMarker119"/>three <em class="italic">old guard</em> Linux<a id="_idIndexMarker120"/> vendors, <strong class="bold">SUSE</strong> products its first product release in 1994, but was a support vendor for older distributions like SLS and Slackware, which didn't have a support vendor of their own, as far back as 1992. Linux itself dates only back to 1991 and SUSE is often believed to be the first commercial support vendor for Linux. SUSE originally used other distributions as the basis for <strong class="bold">Suse Linux</strong>, but<a id="_idIndexMarker121"/> its underlying projects all faded away during the 1990s and since about 2000 SUSE Linux has been its own root distribution seeding others from itself.</p>
			<p>SUSE has always made for confusing product and company names. SUSE makes its primary products under the <strong class="bold">OpenSuse</strong> name. These products are free and quite popular. Additionally, SUSE Linux <strong class="bold">Enterprise Server</strong> is a commercially supported copy of one version of OpenSUSE. There is no direct comparison to either the Red Hat/Fedora ecosystem nor the Debian/Ubuntu ecosystem. All three primary ecosystems operate rather differently.</p>
			<p>OpenSUSE's Linux distributions are very popular in Europe, especially in Germany where they are headquartered. In North American markets they are far less prevalent.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor043"/>Digging into distribution history</h2>
			<p>It is easy, and <a id="_idIndexMarker122"/>interesting, to get lost trying<a id="_idIndexMarker123"/> to track down the real history not only of Linux as a kernel, but also of all of the distributions that have been created from it over the years and how they relate to one another. So many distributions have come and gone. So many foundations and guiding organizations have attempted to control or oversee different aspects of Linux or Linux distributions, but most have faded into obscurity.</p>
			<p>For even more fun, go back and try to track UNIX history starting in the 1960s and try to understand where the products on the market today have come from! At this point, UNIX is well over fifty years old and Linux turns thirty years old this year, in 2021! These are old systems with a lot of history and both UNIX and Linux being rooted at least partially in open source has made for so many different <em class="italic">stories</em> all stemming from one beginning. Unlike a product like Windows, which is complex enough as it is, UNIX isn't the product of a single vendor and is not really a product on its own. So, the story of what we have today is complex.</p>
			<p>While this history is interesting, it is hard to say how much of it would have real value today. With the amount of history behind us and the rather extensive disassociation that we have between products today and vendors of the past, knowing the story of how that we got where we are is more of a party trick than useful IT knowledge. Knowing the basics of current vendors and distributions is very important, but knowing who came first, who is older, from whose work they built and so forth is banal. All of today's key vendors are nearing twenty years old or older and so all of the people involved in the early days are all gone. Even the vendors themselves would struggle to track down their<a id="_idIndexMarker124"/> products' own histories at <a id="_idIndexMarker125"/>this point.</p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor044"/>Other Linux distributions</h2>
			<p>There are<a id="_idIndexMarker126"/> so <a id="_idIndexMarker127"/>many potential <strong class="bold">Linux distributions</strong> that you could consider, and if you are working on desktops you might reasonably go with any number of niche or unproven systems because the ability to deal with instability or support issues on desktops is generally pretty flexible. In the desktop Linux world, many the most popular alternative <a id="_idIndexMarker128"/>desktops are <a id="_idIndexMarker129"/>built <a id="_idIndexMarker130"/>on top of one of the major distributions such as <strong class="bold">ElementaryOS</strong>, <strong class="bold">Zorin OS</strong>, and <strong class="bold">Linux Mint</strong> which are all additional layers on top of Ubuntu (which is already built on top of Debian.) A few such as Solus start from scratch and use no one else as a seed distribution.</p>
			<p>If we are looking at servers, we are going to struggle to justify using any distribution outside of the extreme mainstream. Mainstream distributions get more vendor support, more testing, broader third-party support for both software and hardware compatibility, and so on. But beyond the obvious, big distributions also have better community documentation, more how-tos and guides, and more professionals in the wild with specific experience on your exact operating system. Part of deciding what operating system should be installed required considering all of the possibilities and that includes finding additional system administration resources or replacement ones. If we had the ability to hire proactively with adequate time to train any good system administrator could get up to speed on even a completely obscure and unusual operating system easily as the basic concepts always remain constant. However, being able to find someone that is knowledgeable, comfortable, and available in a time of crisis means we must stick to distributions that are broadly known.</p>
			<p>Over time, new distributions will rise, and old ones will fall. Change happens. The best practice in this case is to evaluate the industry and determine based on current factors if the advice in this book is current and still relevant, or if perhaps a distro here has lost popularity or run into support issues or if a new distribution with great features and amazing industry support has arisen and requires consideration. Nothing is static, especially not in IT. I do my best here to give you a good starting point on choosing your distribution(s), but never make the mistake of thinking that this list is gospel or unchanging. IT always requires us to take all of the factors that we can, apply what we know, and make the best determination based on current factors as they are applicable to us. My guide here hopefully helps you see how I look at these distributions and why these are the<a id="_idIndexMarker131"/> ones that I single out for key<a id="_idIndexMarker132"/> consideration at the time of this writing.</p>
			<h1 id="_idParaDest-46"><a id="_idTextAnchor045"/>The myth of popularity</h1>
			<p>We must balance<a id="_idIndexMarker133"/> the idea of believing that just because something is popular that it will have a lot of support available in the market with the idea of practical support. Just because a product is popular or has many people offering support for it does not mean that support is better or easier to obtain in a practical sense.</p>
			<p>For years, this is something that we have discussed about Windows and Linux operating systems. There were, and remain, far more Windows system administrators marketing themselves on the market than there are Linux administrators. But experience tells us that when hiring an administrator in the Linux world it is relatively easy to find at least reasonably qualified candidates. Run a series of interviews and almost every candidate will be able to do the job, even if not well. But run a similar interview looking for the exact same position but for Windows instead of for Linux and you will likely get twice or thrice the candidates to wade through with only a very small number able to do the tasks at the same level as the Linux candidates.</p>
			<p>Why is this? Many reasons, we assume. For one, the majority of Windows shops allow or require work to be done from a GUI, rather than from a command line. This means that most people who have never done a task before can simply poke around, apply some basic common sense, read what is on the screen and appear to a casual observer to be able to do system administration duties, even if they have never seen a server before in their lives. But nearly all Linux shops allow no GUIs on servers and when they do have no administration tools in the GUI forcing all work to be done at the command line where it is far harder to simply look around and hope for the best. Familiarity with the commands and outcomes is very much needed. Basically, bluffing is much harder. This isn't because Linux is harder, at all. Not in the least. </p>
			<p>This is because of a culture in the Linux world of GUIs being unacceptable on servers and the opposite culture in the Windows world. In the early days, in the early 1990s, Linux had no GUI, and everything was done at the command line and at the same time Windows was GUI only and the full command line capability wasn't added until decades later. This started a trend that has remained to this day. If you talk to someone who works on Linux as an administrator, they will simply assume that everything is command line only and have the same conversation with a Windows admin and while they will be familiar with the command line, they will almost universally assume that it is a partial tool used in conjunction with the GUI. Of course, if you wanted to administer Windows completely from PowerShell today, you can and you can do so very well. And likewise, if you really wanted to, Linux can be administrated from a GUI. No one does because that's a bad idea, but it is possible.</p>
			<p>Another factor is that small Windows shops abound and tend to throw around the title of system <a id="_idIndexMarker134"/>administrator where little, if any, administration work has really happened. In the late 1990s and early 2000s we had a problem that Microsoft and other certification vendors were handing out certifications like candy on Halloween with many, possibly most, people obtaining certifications doing so through brain dumps or boot camps and having no experience and potentially even no knowledge of Windows or system administration. The use of these <em class="italic">paper administrators</em>, as they came to be known, threatened to break many IT shops that thought that they had an easy way to hire without doing any validation of their own and ended up with the industry developing a culture of IT often having no knowledge or training which, given the critical position that IT staff is in, putting companies at severe risk, but because IT is so complicated, companies often failed to identify the failings of the process, even after the fact as few companies do <em class="italic">post mortems</em> on things like hiring processes. Most companies would not even know how or where to begin to evaluate the efficacy of decision processes in that way, so they simple ignore it.</p>
			<p>For whatever reason, finding someone claiming to be a Windows administrator is easy, but finding one with any real level of knowledge is quite difficult. Linux, with a much smaller pool of claimed administrators, the ability to hire one that can provide you with good results is decently easy. This is just an example case and is not caused by anything intrinsic to Windows or Linux, it is just resulting artefacts of many historical factors coming together, so do not attempt to read into it anything that isn't there. The only point of this example is to show that popularity or abundance of a resource on the market is not <a id="_idIndexMarker135"/>the same as having useful support.</p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor046"/>Using multiple distributions</h2>
			<p>New system <a id="_idIndexMarker136"/>administrators often believe that they need to pick a single distribution for their entire organization and stick to it through thick and thin. This is called a <strong class="bold">homogeneous environment</strong> and<a id="_idIndexMarker137"/> has many obvious advantages. It is easier to learn, easier to automate, easier to test, easier to monitor and stay on top of the latest news and changes. Certainly, consider that a homogeneous environment might be right for your organization.</p>
			<p>There are many reasons why we might need to consider a heterogeneous environment, that is one in which there are multiple Linux distributions (and more broadly speaking, perhaps other operating systems entirely like Solaris, AIX, macOS, FreeBSD, or even Windows!) Not many companies of any size are truly able to be homogeneous regardless of if they prefer Windows, Linux, or <em class="italic">other</em>. This goes for both the server world and the end user device space. These days most IT shops are forced to content with a mixture of systems on servers, desktops, laptops, and even cellular phones. </p>
			<p>This variety is spreading rapidly not just in software but in hardware as well. In the last few years alternative CPU architectures have started to gain a foothold. This is how the industry was for its first several decades until a little less than fifteen years ago. In the mid-2000s the industry broadly consolidated around the AMD64 architecture (there were always niches of alternative architectures out there, but they were truly niche for many years) with all other major contenders failing completely or being relegated to very specialty roles. But around 2020 there was such a leap forward in non-AMD64 architecture popularity that we now have to consider heterogeneous hardware environments again, as well.</p>
			<p>Hardware architecture may seem like an aside, but it is not. Every operating system and each Linux distro are made for only a limited number of hardware architectures. This means that your choice of operating system will determine your hardware options, or that your choice of hardware will determine your operating system options. Ideally decisions around this will be made holistically considering all of the needs of both software and hardware and coming to a design decision that creates the best resultant package rather than looking at the two in isolation and hoping to come to a working compromise that doesn't account for the results.</p>
			<p>In general, my advice is to avoid unnecessary <em class="italic">operating system sprawl</em> in your organization. It is all too easy to end up with a dozen different operating systems, each doing a niche task, and each requiring a bit of special care and feeding different from all of the others. But don't take that as saying that you should be homogeneous unless you have no choice. There is a balance that will make sense for you. Attempting to be homogeneous will almost certainly be a fruitless effort that will result in unnecessary struggles. And allowing unchecked sprawl will almost certainly result in an unnecessarily complicated <a id="_idIndexMarker138"/>environment. Be thoughtful in your choice to deploy something new and different, but do not fear it.</p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor047"/>Making the choice</h2>
			<p>Knowing the likely <a id="_idIndexMarker139"/>range of Linux distributions, and understanding our design to avoid operating system sprawl within reason, how should we approach our final operating system selection decision?</p>
			<p>The simple answer is <em class="italic">take everything into account</em>. That is easier said than done. For me when I am looking to deploy a new workload my first question is about the workload itself. <em class="italic">On what distribution does its vendor support running it</em>? <em class="italic">On what distribution does its vendor recommend running it?</em> <em class="italic">What is the current support path and the future support paths by distribution?</em></p>
			<p>Working with, rather than against, the workload application vendor can be a big deal. Choosing the wrong distribution can result in poor performance or installation problems or even stability problems long term. It is common for vendors to officially support more operating systems than they regularly test against. For example, perhaps a vendor uses Debian in their development lab and tests every release against it, but only tests Fedora once a year or so, even though Fedora is on their support list. If you choose Fedora thinking that the vendor supports it, you might find deployment or stability problems with the application on Fedora long before the vendor does, and you might find them ill prepared to support something outside of their ken. This is the fault of the vendor for not making it clear enough that all of their support is not equal, but it is a very common scenario. Even a vendor who does an excellent job of supporting and testing many release targets still has one or two that they test more frequently or heavily. Generally, this is the operating system in use by their developers.</p>
			<p>Different operating systems will have different performance characteristics as well. Generally, between different Linux distributions this difference is nominal. There can be large differences, even for very simple applications, between Linux and Windows, for example. Between Linux distributions we are most likely to see performance differences less from core features like the kernel configuration or system libraries, but much more likely to see differences caused by things like different programming language versions which can often vary widely between distributions based on several factors behind the scenes that are determined by the distribution's governance.</p>
			<p>Once we know how our distribution will impact our workload we can work with other factors, like which distributions are already in our organization or part of our future planning, cost, current knowledge, support options, and so forth to determine what is the right distribution for us. In an ideal world, operating system and hardware considerations would also play a part in the selection of workloads in the first place, but in reality, it is shockingly rare for organizations to take a holistic view of their entire business and instead often make decisions, such as which applications to deploy, in isolation without considering how that will impact the business across the board. As system administrators <a id="_idIndexMarker140"/>we often have little say as to which workloads we will be supporting and so we must therefore react as best as we can to accommodate them.</p>
			<p>And there we have it, a survey of popular Linux vendors and products. I know, it is a lot to take in. Working with Linux tends to result in getting to know many vendors and distributions and often just taking different ones out for a test drive on a regular basis. From a career perspective having many of these in your knowledge arsenal is important. The more you know the more value you have to an employer and the more career doors will be open to you. </p>
			<p>In our next section we are going to look at support and release models commonly found for Linux and look at real world examples available for the vendors and distributions that we just learned<a id="_idIndexMarker141"/> about.</p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor048"/>Releases and support: LTS, current, and rolling</h1>
			<p>Picking your vendor <a id="_idIndexMarker142"/>might seem like it gets you everything that you need to get started on your Linux deployment, but it does not. We still have to consider release management as part of our distribution decision plan. </p>
			<p>A release model or release regime is an approach to how the distribution will update itself. There are three standard models followed by essentially all vendors. These are <strong class="bold">rolling releases</strong>, <strong class="bold">short term releases</strong>, and <strong class="bold">long-term releases</strong>.</p>
			<p>Not all vendors provide all the different models. And each vendor approaches support differently. We will do our best to make useful generalizations, but when you make your decision you will need to consider the current strategies available from your prospective vendors as well as considering the quality of the support that they provide.</p>
			<p>There is a second factor that is often confused with the release model, and that is the support period. The two are roughly related, but a vendor can make updates and support closely tied together, or potentially not at all. In the real world, almost all vendors seem to stick to just a few common models and vendors who traditionally did not follow these models, like Microsoft, have changed to match the models of the big Linux distributions.</p>
			<p>To make things more complicated, each vendor provides different models under totally different naming conventions so that once you learn how one vendor does it, you will have no better understanding of what the next vendor might be doing.</p>
			<p>We will start by exploring each release model before we try to decipher which vendors provide for each model. We should also talk about the differences between a patch and a release.</p>
			<p>A release is a new version of an operating system. We often talk about major and minor releases. But like anything else in this topic this is all by convention. If you are familiar with the Windows world, major releases would be analogous to Windows 2000, XP, Vista and so forth. Minor releases <a id="_idIndexMarker143"/>were called <strong class="bold">Service Packs</strong>. So, <em class="italic">Windows XP</em> was a major release coming between Windows 2000 and Windows Vista, while <em class="italic">Windows XP SP2</em> was a minor release coming between <em class="italic">Windows XP SP1</em> and <em class="italic">Windows XP SP3</em>. Red Hat follows a similar and easy to understand model with major releases looking like <strong class="bold">RHEL 7</strong> and <strong class="bold">RHEL 8</strong>. Minor releases would be in format of <strong class="bold">RHEL 7.2</strong> and <strong class="bold">RHEL 7.3</strong>.</p>
			<p>The idea behind a major release is that software in one major release may not be backward compatible with previous major releases. A major release is meant to provide a stable target for software vendors or projects to be able to write for and test against and feel confident that the software that they make will continue to work on a major release for its entire lifecycle. Therefore most software designates major releases against which it is known to work such as <em class="italic">Compatible with RHEL 8</em> or <em class="italic">Built for Windows 7</em>.</p>
			<p>Minor releases are intended to be significant changes that maintain backwards compatibility. In<a id="_idIndexMarker144"/> theory you should be able to update a system from its initial minor release all the way until its final minor release without any compatibility issues with software as long as your major release does not change. Of course, in practice there is always a risk anytime that there is a change, no matter how minor it is supposed to be, that some compatibility will change. The purpose of minor releases is to be able to provide new functionality and bigger updates that might affect training, end users, performance, and other factors, but not stop software from working properly and not to require extra testing.</p>
			<p>The major/minor release system is not adhered to be all vendors. In the Linux world's big commercial vendors, Red Hat and Suse, use the major/minor system, but Canonical (who makes Ubuntu) does not. Traditionally, Microsoft use a major/minor system, but this ended with the release of Windows 10. It should be noted that Red Hat uses the major/minor system with RHEL but does not do so with Fedora.</p>
			<p>Canonical pioneered a now standard date-based naming convention with Ubuntu that approaches versioning completely different. Ubuntu releases are numbers by the year and month in which they release and also with a somewhat whimsical name to make them easier to remember (or something like that, honestly the numbers are really easy to remember and the animal-based names are not at all.) Microsoft copied this when they moved to Windows 10. Fedora does something similar but with a simple incrementing number that is not based on a date (nor on an animal.)</p>
			<p>The extreme differences in underlying approach combined with the differences in naming conventions can make it tricky to understand the cycles from one vendor or product to another. We will cover some in this book, but of course they are subject to change and all three major vendors have changed these in the past (as has Microsoft) and are likely to change again in the future. The only large vendor that has remained steadfast with the same naming convention for decades is Apple with their macOS and iOS products and even those have had some marketing changes here and there to keep us on our toes.</p>
			<p>Best practice here is to take some time and learn the current release patterns, conventions, names, and versions of the vendor(s) that you are working with and keep yourself current with them. This is something everyone working with software needs to know and understand.</p>
			<p class="callout-heading">Patches can have schedules too</p>
			<p class="callout">It might seem crazy to talk about having patch schedules. If software is vulnerable and a patch is available, surely, we need access to that right away and there should be no intentional waiting or schedule for patch releases. For the most part, that is how vendors work. Patches come out continuously when they are available, and releases work on whatever scheduling regime is in place for the product.</p>
			<p class="callout">Famously Microsoft<a id="_idIndexMarker145"/> has not followed this strategy and their Patch Tuesday is well known. Except for the most critical patches Microsoft has long held to a scheduled patch release of just one time per month!</p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/>What does support mean?</h2>
			<p>If you say that your <a id="_idIndexMarker146"/>software has <strong class="bold">available support</strong> or is <em class="italic">supported</em>, we pretty much all immediately think of the same things. However, the term support means completely different things in different situations and never is simply saying that something is supported enough to actually mean anything.</p>
			<p>On its own the term support means literally nothing, but it conjures up assurances in the minds of those who hear it which makes it a powerful marketing term. Both the offer of included support puts our minds at ease while something lacking support causes us to panic. No company in their right mind would ever use software without support, right? Well, yes and no. What does that even mean? Everything has and does not have support depending on what you mean at the time.</p>
			<p>What often matters when discussing support, or what managers mean most, when it comes to operating systems is whether the primary vendor is continuing to supply security patches or stability patches when problems are discovered. Software is a living thing and regular patching is one of the most important things that we need our vendors to provide. This kind of support is where we absolutely must rely on our software vendor. There is no reasonable possibility that we can handle this through any other channel, and it is essentially the purpose of having an operating system distribution in the first place.</p>
			<p>After patching, we tend to assume that a vendor saying that a product is supported will mean that they provide updates and consulting support should anything with the operating system fail. This is not a given in any sense and some of the biggest vendors, like Microsoft, do not actually include this when they refer to a system as being supported. In the Linux world, most major vendors do provide some level of support for users who run into<a id="_idIndexMarker147"/> problems or need help, and this can be very valuable. But this is actually an area where Linux tends to have something above and beyond other arenas and it can represent a significant selling point, but of course is only available in situations where support is paid for and so many companies opt not to have this kind of support.</p>
			<p>We tend to refer to this top level of support where we have the right to submit a ticket for assistance to the operating system vendor and expect a quick response to help us with nearly anything from actual problems with the operating system itself to simple configuration or use issues or possibly even training as paid vendor support. Some companies completely depend on this type of support while some others have never used it, and some are even unaware that it exists.</p>
			<p>Support can also mean third-party support. This can come from big vendors such as Oracle (who offers third-party vendor support for RHEL) or from small consulting firms such as Managed Service Providers (MSPs). Nearly any product can get some level of support via third parties, which can lead to an unclear support situation as some products expect support to be via a third party and others expect it to be first party.</p>
			<p>And then there comes Community Support, a term used for any support from places like online forums and communities. This has a tendency to get a lot of focus in the Linux world and very little in other realms. All operating systems or IT products really have this kind of assistance. Linux gets more attention, most likely, because there tends to be more knowledge in the field and very little is secreted by the vendor, as is the nature of open source. Closed source software gets less benefit from community support because details must be either discovered through luck or released by the vendor. Community support often gets a lack of respect from management, but it is actually an important sign of what makes the Linux ecosystem strong: vendors that make everything public and communities of professionals looking to support one another. In many cases community support is so significant that it can completely change how we approach a product and can actually be better than vendor support.</p>
			<p>Basically, support means many different things, and everyone has their own definition. We need to think broadly about what support needs our organization has and how different approaches will impact us. Many large organizations require primary vendor support with a service level agreement for internal political reasons. Just keeping a system running in a healthy way often requires nothing more than basic security patches and moderate community support. Evaluate your own needs, remove emotions, and do not assume that the term support implies more than it does. </p>
			<p>We have now established what these terms mean and how releases and support and tied together<a id="_idIndexMarker148"/> and how they are provided. This gives us a framework for exploring real world models from actual products and vendors.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/>Release model: rapid release</h2>
			<p>The best known<a id="_idIndexMarker149"/> and <a id="_idIndexMarker150"/>arguably most important release model has no official or standard name. You will hear names like Rapid Release, Short Term Support, Current, and similar applied to it, but generally it is seen simply as the standard against which other models are measured against. Kind of the <em class="italic">happy medium</em> of models.</p>
			<p>The key products are:</p>
			<ul>
				<li>Fedora</li>
				<li>Ubuntu</li>
			</ul>
			<p>We start our discussion with <strong class="bold">Rapid Release</strong> models because this is what most people perceive as being the standard or baseline approach to releases. These are the most well-known and understood releases even if not the most commonly used in practice. They are quickly becoming more popular in recent years.</p>
			<p>Rapid release (which could also be called <em class="italic">Standard</em> or <em class="italic">Common Release</em>) models have a convention of releasing new versions roughly every six months, but of course every vendor is free to use whatever time frame that they want. We would generally consider something to fall into this category if the release was at least two months apart, but no more than a year apart.</p>
			<p>The best known and easiest to explain product in this category is Fedora, which is made by the Red Hat division of IBM. Fedora releases a new major version roughly every six months and has no minor versions. Fedora numbers each release sequentially to make tracking changes as easy as possible. There are no weird numbers to remember, no point releases, no skipping around. Just Fedora 1, 2, 3... 30, 31, 32, 33, and so forth. Support for each Fedora release is roughly thirteen months. So, at any given time at least the two latest, if not the three latest, releases are all under support. </p>
			<p>We have to mention that Fedora does not have any paid primary vendor support. Support in Fedora terms refers to Red Hat's support for updates and security patches. Third party support for Fedora is, of course, extensive.</p>
			<p>The mainline Ubuntu product is rapid release as well but with a much more confusing naming convention than Fedora uses. Like Red Hat's Fedora, Ubuntu is released every six months. Ubuntu's support is for nine months from initial release giving just three months of overlap<a id="_idIndexMarker151"/> from the subsequent version's<a id="_idIndexMarker152"/> release date until the end of Ubuntu's support commitment to the previous release.</p>
			<p>Unlike Fedora which has only software level support, Canonical offers full primary vendor paid support options for Ubuntu's rapid release option. </p>
			<p>These short support time frames may feel problematic and it is because of the emotional feeling of needing to find a new solution every nine to thirteen months to avoid the <em class="italic">end of support</em> that is always looming when choosing a rapid release product that so many companies jump to other models to avoid having to find a new solution on a regular basis. This is illogical because this is based on believing that updating the system in question is not an option. </p>
			<p>Rapid release support may be <em class="italic">short term</em> in most cases, but this is just one perspective. In both example cases here (and all cases of which I am aware) getting <em class="italic">eternal support</em> is as simple as keeping your systems up to date within a reasonable time frame. With Ubuntu this means updating to the current release at least every nine months and with Fedora at least every thirteen months. In both of these cases, and in most normal cases, these are in place updates done with just a command or two not situations that involve replacing one solution with another. So, while we may call these short term support approaches, in practice they are quite the opposite. This is the industry standard approach to having<a id="_idIndexMarker153"/> a continuously supported <a id="_idIndexMarker154"/>system that always stays reasonably up to date.</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor051"/>Release model: LTS</h2>
			<p>The key LTS products are: </p>
			<ul>
				<li>Red Hat Enterprise Linux (RHEL)</li>
				<li>OpenSuse Leap</li>
				<li>Ubuntu LTS</li>
				<li>Debian</li>
			</ul>
			<p><strong class="bold">LTS</strong> might <a id="_idIndexMarker155"/>be <a id="_idIndexMarker156"/>standard for long term support, but most people think of LTS in terms of the associated release schedule. While there is no hard and fast rule for what constitutes an LTS outside of a vendor designating it as such we typically assume that LTS releases will be at least two years apart. Ideally vendors would separate the naming conventions of releases and support models to make it clearer, but few major vendors do. </p>
			<p>Technically an LTS release means that that release will be supported for a <em class="italic">long time</em>, which what that exactly means being unique to each vendor. LTS is a marketing term, more than anything, but one that tends to inspire instant confidence in many customers and so is often used for that purpose.</p>
			<p>The underlying theoretical goal of an LTS release is to provide a <em class="italic">stable</em> product that remains <em class="italic">supported</em> for a <em class="italic">long time</em> (we must use a lot of quotes when doing this) to make it easier for software vendors to make products that will work on that product and not have to continuously maintain updates. This makes them popular with software vendors because they require less work to support. They tend to be popular with IT departments because the primary risks of LTS releases can be many years or even decades down the road and so most negative ramifications of choosing an LTS release tend to end up being someone else's problem.</p>
			<p>Speaking in generalities can only get us so far. Be cognizant that vendors can use any model that they want and may change at any time and can use the term LTS without any underlying change to their support. Do not let the emotional reaction to the term cause you to favor an LTS release if the overall support does not best meet your needs.</p>
			<p>Red Hat's LTS product is RHEL. All versions of RHEL are LTS. Major Versions of RHEL release on a somewhat unpredictable schedule that started roughly every two years and has slowly increased to be closer to five years between releases and, we would guess, will continue to slowly expand in time between releases in the future.</p>
			<p>Red Hat provides support for each release for approximately ten years. As you can easily see, the support cycle and the release cycle are both <em class="italic">long term</em> in terms of time but are not directly related to one another. The support timeline is two to five times the length of the release cycle, in this case. So, it is a long-term <a id="_idIndexMarker157"/>release (aka <strong class="bold">slow release</strong>) as well as a long-term support, model. </p>
			<p>RHEL itself is not<a id="_idIndexMarker158"/> free except under special circumstances. A number <a id="_idIndexMarker159"/>of RHEL clones exist, most of which are free and have no official vendor support but do receive patches making them <em class="italic">supported</em> in a similar way. Traditionally CentOS was the main, free LTS release mirroring RHEL. As CentOS was discontinued projects following in its footsteps like <em class="italic">RockyLinux</em>, <em class="italic">Oracle Linux</em> and <em class="italic">AlmaLinux</em> cover the same territory. We can completely legitimately call them LTS releases because they keep patch level and update support for a long time.</p>
			<p>Suse's LTS product is SUSE Linux Enterprise Server or <strong class="bold">SLES</strong>. This product uses a nearly identical major/minor and support model to Red Hat's and has always been considered the most direct competitor. SLES releases new major versions every three to five years on a rather irregular schedule as they feel that they are ready. Like Red Hat, official support for each major release is approximately ten years. So like RHEL, SLES is a slow release with a long term support model.</p>
			<p>Like RHEL, SLES is not free on its own... <em class="italic">well not exactly</em>. Under the SLES brand name, SLES is not free. But SUSE makes a free version of SLES <a id="_idIndexMarker160"/>called <strong class="bold">OpenSuse Leap</strong>. This can be a bit confusing because Leap is the free version of SLES, but it causes the linguistic and logical challenge of having to say that SLES is not free, but Leap is the free version of SLES. Basically, SLES is not free when using the SLES name, but it is free when using the Leap name. Confusing? You had better believe it. </p>
			<p>Both SLES and OpenSUSE Leap are slow releases and LTS. Both have support for the same length of time, but SLES has much more intensive support.</p>
			<p>Canonical takes a very different approach with Ubuntu. Unlike Red Hat and SUSE which each make multiple products, Canonical makes only one: Ubuntu. Ubuntu releases like clockwork every six months as we mentioned above. Instead of making a separate product for its LTS release, Canonical simply designates every fourth release of its rapid release product as its LTS release. So, every two years a <em class="italic">special</em> Ubuntu release happens that gets approximately eight years of support. So, Ubuntu has only one product, and only one release cycle (every six months) but two support cycles. While the most complex to explain, this results in the most flexible and straight forward product development, testing, and use.</p>
			<p>Debian takes yet another approach. Remember that Debian never offers paid vendor support options, but only security and software support. This influences their support model. Debian performs releases roughly every two years making it a slow-release product. However officially they only fully support the current release at any given time. Unofficially they often continue to support the previous version in many cases. This creates an odd situation where the release cycle is relatively slow, but the support mechanism is very <a id="_idIndexMarker161"/>aggressive expecting everyone using Debian <a id="_idIndexMarker162"/>to almost immediately update to the latest version which undermines the reasons that most companies want to work with a slow-release product in the first place. So, Debian is slow on release, but has anything but long-term support. </p>
			<h2 id="_idParaDest-53"><a id="_idTextAnchor052"/>Release and support schedule interplay: The overlap</h2>
			<p>Release and support <a id="_idIndexMarker163"/>schedules on their own provide a limited picture. It is in putting the two together that we really see how we must view a distribution. With Ubuntu LTS, for example, a release cycle of two years means that we have the option to update our platform at one pace, and their long-term support cycle of eight years means that we have the option of not updating if we do not want to for several cycles without losing vendor support. Most people expect this behavior when talking about LTS models, but such behavior is not implied.</p>
			<p>Debian's two-year release schedule is nearly identical to Ubuntu LTS' but with official support ending upon release of the latest version the guaranteed support is actually less than from even the Ubuntu interim release cycle which provides a three month overlap between the time that a new release comes out and when the support for the previous release ends. </p>
			<p>This overlap, a number that no one ever talks about, is easily the most important factor to be discussed - if we were to believe that we could single out any one factor on its own in a meaningful way. The overlap tells us our window of opportunity not only for we as system administrators to update our systems, but also how long our third-party software vendors will have to test and release their new products while maintaining support from the operating system vendor. This overlap number varies from a low of 0 to a high of over 10 years. No one number is better or worse. Too large of an overlap encourages big problems. Too small can make maintaining systems difficult.</p>
			<p>To make matters more confusing, there is a volunteer team of developers that work with Debian to provide unofficial long-term support for every Debian release. So, while officially the Debian team provides extremely limited support, in practice and unofficially the support for previous versions is extensive and may easily challenge any other support<a id="_idIndexMarker164"/> vendor. This has created the situation where Debian is seen as stable, conservative, well supports, and rock solid while also lacking any paid primary vendor support or official LTS options! </p>
			<h2 id="_idParaDest-54"><a id="_idTextAnchor053"/>Release model: Rolling</h2>
			<p>The key <a id="_idIndexMarker165"/>Rolling <a id="_idIndexMarker166"/>products are:</p>
			<ul>
				<li>Fedora Rawhide</li>
				<li>OpenSUSE Tumbleweed</li>
			</ul>
			<p>A <strong class="bold">rolling release</strong> means that system updates are made available immediately. We typically assume that this means that they will release <em class="italic">as available</em> which could mean that they release at any time, day or night, and potentially multiple times per day. Updates are not released on a pre-determined schedule. As soon as they are ready, they release. Of course, as the system administrator it is up to you to control when they are applied. Just because they release does not mean that they apply automatically.</p>
			<p>Rolling releases are the rarest and as you can imagine, can have a bit of difficulty coordinating with application vendors. The product is a constantly moving target and there is little, if any, ability to designate compatibility.</p>
			<p>Rolling releases have some interesting artefacts to consider. First, they are great because you get absolutely all the latest features as quickly as possible. No waiting for a release cycle to come around. If a new feature that you want from a component product in the operating system releases the day after your rapid release prepares to go to market, you will have to wait at least six months for any major product to get that through to you. And if you are dealing with a slow-release distribution you have to wait two to five years! That can be quite a long wait if it is an important feature for you.</p>
			<p>A famous example of waiting on features happened when <em class="italic">PHP 7</em> released and promised to completely revitalize the PHP landscape with far better performance and features. Companies stuck on slow-release products were waiting years to get the performance upgrade while rapid and rolling release distributions were running circles around them in benchmarks. In a world where features often include improved security capabilities waiting<a id="_idIndexMarker167"/> on new features can include <a id="_idIndexMarker168"/>security risks, as well.</p>
			<h2 id="_idParaDest-55"><a id="_idTextAnchor054"/>Why not just update the packages manually</h2>
			<p>Proponents of<a id="_idIndexMarker169"/> long-term support and slow-release distributions will often make the claim that to solve the obvious short comings of the LTS ecosystem that we can just acquire the packages that we need in some other way and keep them up to date individually. A great example is the PHP case that I mentioned.</p>
			<p>This is entirely possible, and people do this all of the time. But just because it can be done, does not mean that it makes logical sense. The point, literally the entire point, of getting a slow release, long term support operating system is that you want there to be a predictable, supported target on which to run applications. Outside of that, everything about an LTS release is a negative to the customer organization.</p>
			<p>If we approach an LTS release with the assumption or willingness to simply start pulling apart the operating system and modifying pieces of it to get newer features, we undermine its function. The operating system vendor will no longer provide support, or have insight, into the full stack that they did before, and the application vendor will have an unknown target product. At this point we effectively take on all of the complications, overhead, and risk of a slow-release distribution while also taking on the problems and risks of a fast or rolling release distribution while additionally adding some overhead and risk of doing it ourselves outside of the purview of the vendor. </p>
			<p>All totally doable and it will easily work. But that it can work should never cause us to perceive this as being a good idea. Instead, it should expose how fundamentally foolish the idea of clinging to LTS distributions is if we do not actually believe in their value!</p>
			<p>A better approach would be to select a faster release distribution that properly meets our needs while also providing whatever level of support we require and getting a more complete support and update experience, less work on our end to recreate work that the vendor has already done, and not leaving the world of tested application targets to build something ourselves for no reason. </p>
			<p>Best Practice: Use the tools as they are designed, do not try to work around the design to satisfy an emotional or political desire to use a long-term support distribution when it is not able to meet the needs. </p>
			<p>The underlying mistake we normally see here is losing sight of the goal. Presumably, the goal in a business is always to maximize profits. For practical reasons we often have to use intermediary goals to refine achieving our primary goal. In doing so we might distill part of our goal down to maximizing vendor support, which is already a dangerous intermediary goal. What is then happening in many organizations is taking that questionable<a id="_idIndexMarker170"/> intermediary goal and attempting to make a yet more intermediary goal of using LTS releases to meet the first intermediary goal and forgetting that just because a release is designated LTS does not mean that it provides better support necessarily or meets our needs and totally misses the point that if we do not use it as designed it is not really an LTS release any longer. At least not in practical terms.</p>
			<p>Rolling releases are less common than other types both in that fewer vendors make them and that fewer companies deploy them. The best-known rolling release is OpenSUSE Tumbleweed. Tumbleweed is given so much attention that OpenSUSE actually promotes it most of the time as their primary product. It is anything but a second-class citizen. Red Hat's rolling release is Fedora Rawhide. </p>
			<p>Support of rolling releases creates interesting conversation because with other releases we think of support and support time frames in relation to <em class="italic">time since the initial release</em>. But with a rolling release there are no release versions and so in some ways support is generally considered to only be for one day, or it is for forever, all depending on how you look at it.</p>
			<p>The reason that it is hard to understand or express how support works with rolling releases is not because rolling releases are complex, but rather because they are so simple that they do not hide the real problems that we are attempting to address with other release models: the desire to maintain vendor support while avoiding updating.</p>
			<p>With any release model if we keep our system continuously up to date, we are always covered by vendor support. What changes is not whether support is available, but what we are required to do to qualify for said support. With LTS releases we accept that we have to update (or just replace) our systems every five to ten years. With rapid release we accept that we have to update our systems every six to thirteen months. And with rolling releases we just have to accept that updating is a daily process. As long as we accept<a id="_idIndexMarker171"/> these things, all approaches have <em class="italic">eternal support</em> as long as the vendor supports the products in any capacity.</p>
			<h2 id="_idParaDest-56"><a id="_idTextAnchor055"/>Choosing the release model for our workloads</h2>
			<p>Now that we<a id="_idIndexMarker172"/> understand the release and support models, we need to think about applying them to our own decision making. Primarily our needs are going to be defined by our workload, as is always the case. But when we have options we need to be prepared to make well thought out and strategic decisions.</p>
			<p>In general, most people lean heavily towards LTS releases, often irrationally so unable to state any benefit to the approach. Much of this emotional baggage likely stems from earlier days of IT when operating systems only had long term releases and updates were problematic and fragile often causing breaks. This was so significant that we often think of updating an operating system as something we assume cannot be done. This was (and still is) heavily prevalent in the Windows world were updates between operating system major releases truly did cause breaks of great significance with nearly every update and rarely was able to safely update a system <em class="italic">in situ</em>. The assumption became, and remains, that to upgrade the operating system under a workload that a new system will need to be deployed and the workload migrated over to it.</p>
			<p>This was mostly true in the UNIX world in the 1990s and earlier as well, but never to the same degree due to the prevalence of interface standards and the lack of GUI-based applications. The types of workloads typical on UNIX systems were generally able to work across many disparate systems already so version differences of a single operating system were trivialized by comparison. This fear of older systems, and especially Windows systems, not handling updates gracefully has unfortunately infected many managers and Linux decisions are often made on misinformation because of it.</p>
			<p>The problem is exacerbated by two key things as well. One is that slow-release systems such as RHEL and Ubuntu LTS go years between updates during which time many individual changes accumulate in the underlying components. So LTS updates often do present some complications because of this. Add to this the general trend of IT departments that choose LTS releases to also avoid other forms of updates or to not update LTS versions promptly (sometimes resulting in updates of more than one version at once) and updates can often truly become quite scary.</p>
			<p>Of course, we can tackle some of this by treating LTS releases properly and updating them as quickly as is appropriate, but we can never eliminate the additional overhead that they create entirely. By comparison we should look at a rapid release product like Fedora or Ubuntu that releases something like four to six times during the time that its associated LTS release updates once. On the surface, if you fear <em class="italic">updating</em> as a singular terrifying <a id="_idIndexMarker173"/>experience then doing so several times instead of once sounds downright dreadful. This is a misapplication of the concept, however.</p>
			<p>For the most part, interim releases like Ubuntu happening in between LTS releases are essentially incremental releases. The LTS release will get all of the same changes, but it will get many all at once. This makes updates much scarier and more complicated. Splitting up those same changes into four smaller releases generally makes it far easier to deal with any breaking compatibility issues sooner and more gracefully.</p>
			<p>Rolling releases, logically, extend these benefits even further and reduce system changes to the smallest possible amount per update. They do create a new problem in doing so which is that we lose the ability to identify a specific target release for testing. We then run the risk that when a vendor is testing in software will never exist on our own systems and we lose a bit of predictability. In practice rolling releases tend to work quite well and are completely valid in production, but they do add some risk through a loss of predictability and focused testing of third-party products.</p>
			<p>If what we need is a system essentially only comprised of operating system components then a rolling release easily can pull into the lead in terms of the best support, security, and features. If we need to support third party applications on top of the operating system then we will mostly favor rapid releases, instead.</p>
			<p class="callout-heading">Nothing but the operating system</p>
			<p class="callout">It was not so long ago that we would laugh at the idea that we could deploy an operating system for a desktop or a server, and never deploy another application on top of it but run the system only for components that are included in the operating system itself. If you come from the Windows world this is likely extra strange to contemplate as the operating system itself is so devoid of extra components.</p>
			<p class="callout">In the Linux world operating systems tend to be rather full of additional components. On my desktop devices nearly every tool that I use comes included with my operating system. In fact, the Chromebook ecosystem is designed completely around this concept. In Linux servers we see this happen a lot as well with many components from web servers to databases all included in the operating system.</p>
			<p class="callout">The overall amount and general fragility of third-party applications being run today is very different than it was just<a id="_idTextAnchor056"/> ten, let alone twenty, years ago. Another factor lessening the benefits of slow-release distributions.</p>
			<p>Understanding support and release models is not a trivial task and surprisingly few system administrators ever take the time to really understand what it means. Now that you understand <a id="_idIndexMarker174"/>what each model means you will be able to apply future offerings from potentially new vendors and use that to make decisions for your organization. You already have a jump on many in the industry who tend to gloss over or ignore these types of decisions as if they are trivial when they can result in significant implications if chosen incorrectly.</p>
			<p>Now that we have gone into so many different types of details about Linux distributions we are going to take all of these different aspects and concerns and attempt to combine them into a holistic decision-making strategy to help us pick our distribution for deployment for any workload that we may be considering.</p>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor057"/>Choosing your distribution </h1>
			<p>Surprisingly, picking <a id="_idIndexMarker175"/>which <strong class="bold">distribution</strong>, or <strong class="bold">distro</strong> as it is commonly called in the Linux world, can be far more of a challenge than it seems like it should be. You might be <em class="italic">lucky</em> and work for a company that has a pre-determined Linux distro standard that you have to follow, and this question is already answered for you. This is becoming an increasingly rare scenario, though, as companies begin to realize the benefits of using the right distro for the right use case, and as it becomes better known that the idea that skills standardization just doesn't benefit from keeping systems identical as much as it was commonly assumed. But the practice still exists.</p>
			<p>At the end of the day, it is essentially nonsensical to lead with operating system over workload choices. There is relatively little value in forcing a specific operating system choice and making application choices based on that. Of course, in an ideal world, all factors are considered and weighed and licensing, support knowledge, standardization and other factors heavily impacting operating system choice will play a role, they tend to be pretty small in comparison to application choice factors. And that's assuming that we are considering Windows, macOS, and some <em class="italic">Linux variant</em>; if the decision is just about one Linux option or another then the differences between distributions drops considerably.</p>
			<p>Of course, if you are in an environment with thousands of <strong class="bold">RHEL servers</strong> and are tempted to install a single Ubuntu server for a specific workload, the value of figuring out how to get that workload working on RHEL or considering another workload might be reasonable given the scale of standardization that we are talking about. But it's very rare that an IT shop will ever be in a position to have hundreds or thousands of operating system<a id="_idIndexMarker176"/> images that are homogenous. Very much an edge case scenario.</p>
			<p>Using our workload to tell us what distributions realistic options are, and then applying any homogeneity factors, we then can factor in release and support models that best suit the needs of the application and the business. Risk aversion and affinity is, of course, a major factor.</p>
			<h2 id="_idParaDest-58"><a id="_idTextAnchor058"/>Do not fear risk</h2>
			<p>Every business, every<a id="_idIndexMarker177"/> decision has risks. In IT one of our most important jobs is evaluating risks and balancing those risks against opportunity and reward. Reducing risk factors to pure math can be difficult to do, often impossible, but even if we cannot simply create numbers to show us what risk and reward levels are in any given decision this should not change the fundamental fact that our goal is to apply math and logic to a situation to decide the best course of action.</p>
			<p>A real threat to businesses and one that causes businesses to fail with great frequency is risk aversion. This might sound counter intuitive, but it is not. If risk aversion, or truly conservative business practices, are based in reason and logic then this should increase a business' chances of survival. Rarely is this the case, however. Most risk aversion is emotional and illogical and emotional decisions, especially when made around risk, almost always result in more risk rather than less, regardless of what the intended outcome was to be. Much as how a panic response will rarely save you in a dangerous situation, an emotional panic-like response to business decisions will almost entirely remove your ability to make good decisions.</p>
			<p>As IT professionals, working with our businesses to understand risk assessments, factors, and affinity levels is a large part of our value to the organization. Choosing an operating system might be a tiny individual component taken on its own, but it is a common view into the workings of a business' decision-making machinery. If a business requires expensive vendor support or risk slow-release cycles out of fear rather than out of calculated risk assessment, this tells us a lot about how decision making is viewed as a process.</p>
			<p>Best Practice: A business should hold their staff responsible not for the outcome of decisions, but rather for the quality of the decision-making process.</p>
			<p>This best<a id="_idIndexMarker178"/> practice applies to absolutely every facet of an organization and is in no way specific to choosing a Linux distribution or workload. That is how best practices really are, very general and widely applicable.</p>
			<h1 id="_idParaDest-59"><a id="_idTextAnchor059"/>Summary</h1>
			<p>We covered a lot in this chapter and a lot of seemingly unimportant factors that, I believe, tend to actually be pretty important in our roles in system administration. We learned how Linux fits into modern organizations and where it comes from historically which might give us some view into where it is going, as well. We dove into open-source licensing and how software licensing plays a role in how we work with our operating systems. </p>
			<p>We took a look at who the big vendors are today and what key products they have on the market. Then we investigated release and support patterns both in general and specifically from the major vendors on the market today. And then we looked at putting all of those factors together to try to make a decision process for picking the best distribution for our workload.</p>
			<p>In our next chapter we are going to be leaving behind the ten-thousand-foot views and we will be digging into the very technical world of <em class="italic">System Storage Best Practices</em>. This is one of my favorite areas of system <strong class="bold">administration</strong>!</p>
		</div>
	</div></body></html>