<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building a Standard Operating Environment on Linux</h1>
                </header>
            
            <article>
                
<p class="mce-root">This chapter provides a detailed exploration of the <strong>Standard Operating Environment</strong> (henceforth, <strong>SOE</strong> for short) concept in Linux. Although we will go into much greater detail later, in short, an SOE is an environment where everything is created and modified in a standard way. For example, this would mean that all Linux servers are built in the same way, using the same software versions. This is an important concept because it makes managing the environment much easier and reduces the workload for those looking after it. Although this chapter is quite theoretical in nature, it sets the groundwork for the rest of this book.</p>
<p class="mce-root">We will start by looking at the fundamental definition of such an environment, and then proceed to explore why it is desirable to want to create one. From there, we will look at some of the pitfalls of an SOE to give you a good perspective on how to maintain the right balance in such an environment, before finally discussing how an SOE should be integrated into day-to-day maintenance processes. The effective application of this concept enables efficient and effective management of Linux environments at very large scales.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Understanding the challenges of Linux environment scaling</li>
<li>What is an SOE?</li>
<li>Exploring SOE benefits</li>
<li>Knowing when to deviate from standards</li>
<li>Ongoing maintenance of SOEs</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the challenges of Linux environment scaling</h1>
                </header>
            
            <article>
                
<p>Before we delve into the definition of an SOE, let's explore the challenges of scaling a Linux environment without standards. An exploration of this will help us to understand the definition itself, as well as how to define the right standards for a given scenario.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Challenges of non-standard environments</h1>
                </header>
            
            <article>
                
<p>It is important to consider that many challenges experienced by enterprises with technology estates (whether Linux or otherwise) do not start out as such. In the early stages of growth, in fact, many systems and processes are entirely sustainable, and in the next section, we will look at this early stage of environment growth as a precursor to understanding the challenges associated with large-scale growth.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Early growth of a non-standard environment</h1>
                </header>
            
            <article>
                
<p class="mce-root">In a surprisingly large number of companies, Linux environments begin life without any form of standardization. Often, they grow organically over time. Deployments start out small, perhaps just covering a handful of core functions, and as time passes and requirements grow, so does the environment. Skilled system administrators often make changes by hand on a per-server basis, deploying new services and growing the server estate as business demands dictate.</p>
<p>This organic growth is the path of least resistance for most companies—project deadlines are often tight and in addition both budget and resource are scarce. Hence, when a skilled Linux resource is available, that resource can assist in just about all of the tasks required, from simple maintenance tasks to commissioning complex application stacks. It saves a great deal of time and money spent on architecture and makes good use of the skillset of staff on hand as they can be used to address immediate issues and deployments, rather than spending time on architectural design. Hence, quite simply, it makes sense, and the author has experienced this at several companies, even high-profile multi-national ones.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Impacts of non-standard environments</h1>
                </header>
            
            <article>
                
<p>Let's take a deeper look at this from a technical standpoint. There are numerous flavors of Linux, numerous applications that perform (at a high level) the same function, and numerous ways to solve a given problem. For example, if you want to script a task, do you write it in a shell script, Perl, Python, or Ruby? For some tasks, all can achieve the desired end result. Different people have different preferred ways of approaching problems and different preferred technology solutions, and often it is found that a Linux environment has been built using a technology that was <em>the flavor of the month</em> when it was created or that was a favorite of the person responsible for it. There is nothing wrong with this in and of itself, and initially, it does not cause any problems.</p>
<p>If organic growth brings with it one fundamental problem, it is this: scale. Making changes by hand and always using the latest and greatest technology is great when the environment size is relatively small, and often provides an interesting challenge, hence keeping technical staff feeling motivated and valued. It is vital for those working in technology to keep their skills up to date, so it is often a motivating factor to be able to employ up-to-date technologies as part of the day job.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scaling up non-standard environments</h1>
                </header>
            
            <article>
                
<p>When the number of servers enters the hundreds, never mind thousands (or even greater!), this whole <em>organic</em> process breaks down. What was once an interesting challenge becomes laborious and tedious, even stressful. The learning curve for new team members is steep. A new hire may find themselves with a disparate environment with lots of different technologies to learn, and possibly a long period of training before they can become truly effective. Long-serving team members can end up being silos of knowledge, and should they depart the business, their loss can cause continuity issues. Problems and outages become more numerous as the non-standard environment grows in an uncontrolled manner, and troubleshooting becomes a lengthy endeavor—hardly ideal when trying to achieve a 99.99% service uptime agreement, where every second of downtime matters! Hence, in the next section, we will look at how to address these challenges with an SOE.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Addressing the challenges</h1>
                </header>
            
            <article>
                
<p>From this, we realize our requirement for standardization. Building a suitable SOE is all about the following:</p>
<ul>
<li>Realizing economies of scale</li>
<li>Being efficient in day-to-day operations</li>
<li>Making it easy for all involved to get up to speed quickly and easily</li>
<li>Being aligned with the growing needs of the business</li>
</ul>
<p>After all, if an environment is concise in its definition, then it is easier for everyone involved in it to understand and work with. This, in turn, means tasks are completed quicker and with greater ease. In short, standardization can bring cost savings and improved reliability.</p>
<p class="mce-root">It must be stressed that this is a concept and not an absolute. There is no right or wrong way to build such an environment, though there are best practices. Throughout this chapter, we will explore the concept further and help you to identify core best practices associated with SOEs so that you can make informed decisions when defining your own.</p>
<p>Let's proceed to explore this in more detail. Every enterprise has certain demands of their IT environments, whether they are based on Linux, Windows, FreeBSD, or any other technology. Sometimes, these are well understood and documented, and sometimes, they are simply implicit<span>—</span>that is to say, everyone assumes the environment meets these <em>standards</em>, but there is no official definition. These requirements often include the following:</p>
<ul>
<li>Security</li>
<li>Reliability</li>
<li>Scalability</li>
<li>Longevity</li>
<li>Supportability</li>
<li>Ease of use</li>
</ul>
<p>These, of course, are all high-level requirements, and very often, they intersect with each other. Let's explore these in more detail.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security</h1>
                </header>
            
            <article>
                
<p>Security in an environment is established by several factors. Let's look at some questions to understand the factors involved:</p>
<ul>
<li>Is the configuration secure?</li>
<li>Have we allowed the use of weak passwords?</li>
<li>Is the superuser, root, allowed to log in remotely?</li>
<li>Are we logging and auditing all connections?</li>
</ul>
<p>Now, in a non-standard environment, how can you truly say that these requirements are all enforced across all of your Linux servers? To do so requires a great deal of faith they have all been built the same way, that they had the same security parameters applied, and that no-one has ever revisited the environment to change anything. In short, it requires fairly frequent auditing to ensure compliance. </p>
<p>However, where the environment has been standardized, and all servers have been built from a common source or using a common automation tool (we shall demonstrate this later in this book), it is much easier to say with confidence that your Linux estate is secure.</p>
<div class="packt_tip">A standards-based environment isn't implicitly secure, of course<span>—</span>if there is an issue that results in a vulnerability in the build process for this environment, automation means this vulnerability will be replicated across the entire environment! It is important to be aware of the security requirements of your environment and to implement these with care, maintaining and auditing your environment continuously to ensure security levels are maintained.</div>
<p>Security is also enforced by patches, which ensure you are not running any software with vulnerabilities that could allow an attacker to compromise your servers. Some Linux distributions have longer lives than others. For example, Red Hat Enterprise Linux (and derivatives such as CentOS) and the Ubuntu LTS releases all have long, predictable life cycles and make good candidates for your Linux estate.</p>
<p>As such, they should be part of your standards. By contrast, if a <em>bleeding edge</em> Linux distribution such as Fedora has been used because, perhaps, it had the latest packages required at the time, you can be sure that the life cycle will be short, and that updates would cease in the not too distant future, hence leaving you open to potential unpatched vulnerabilities and the need to upgrade to a newer release of Fedora.</p>
<p class="mce-root"/>
<p>Even if the upgrade to a newer version of Fedora is performed, sometimes packages get <em>orphaned—</em>that is to say, they do not get included in the newer release. This might be because they have been superseded by a different package. Whatever the cause, upgrading one distribution to another could cause a false sense of security and should be avoided unless thoroughly researched. In this way, standardization helps to ensure good security practices.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reliability</h1>
                </header>
            
            <article>
                
<p>Many enterprises expect their IT operations to be up and running 99.99% of the time (or better). Part of the route to achieving this is robust software, application of relevant bug fixes, and well-defined troubleshooting procedures. This ensures that in the worst case scenario of an outage, the downtime is as minimal as possible.</p>
<p>Standardization again helps here<em>—</em>as we discussed in the preceding section on security, a good choice of underlying operating system ensures that you have ongoing access to bug fixes and updates, and if you know that your business needs a vendor backup to ensure business continuity, then the selection of a Linux operating system with a support contract (available with Red Hat or Canonical, for example) makes sense.</p>
<p>Equally, when servers are all built to a well-defined and understood standard, making changes to them should yield predictable results as everyone knows what they are working with. If all servers are built slightly differently, then a well-meaning change or update could have unintended consequences and result in costly downtime.</p>
<p>Again with standardization, even if the worst-case scenario occurs, everyone involved should know how to approach the problem because they will know that all servers have been built on a certain base image and have a certain configuration. This knowledge and confidence reduce troubleshooting times and ultimately downtime.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scalability</h1>
                </header>
            
            <article>
                
<p>All enterprises desire their business to grow and most times, this means that IT environments need to scale up to deal with increased demand. In an environment where the servers are built in a non-standard manner, scaling up an environment becomes more of a challenge. </p>
<p>For example, if scaling horizontally (adding more identical servers to an existing service), the new servers should all have the same configuration as the existing ones. Without standards, the first step is to work out how the initial set of servers was built and then to clone this and make the necessary changes to produce more unique servers.</p>
<p class="mce-root"/>
<p>This process is somewhat cumbersome whereas, with a standardized environment, the investigative step is completely unnecessary, and horizontal scaling becomes a predictable, repeatable, <em>business-as-usual</em> task. It also ensures greater reliability as there should be no unintended results from the new servers in the case that a non-standard configuration item was missed. Human beings are incredible, intelligent beings capable of sending a man to the moon, and yet they are equally capable of overlooking a single line in a configuration file. The idea of standardization is to mitigate this risk, and hence make it quick and efficient to scale an environment either up or out using a well-thought-out operating system template, the concept of which we will explore as we proceed through this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Longevity</h1>
                </header>
            
            <article>
                
<p>Sometimes when deploying a service, a particular software version is needed. Let's take the example of a web application that runs on PHP. Now, suppose that your particular enterprise has, for historical reasons, standardized on CentOS 6 (or RHEL 6). This operating system only ships with PHP 5.3, meaning that if you suddenly take on an application that only supports PHP 7.0 and above, you need to figure out how to host this.</p>
<p>One apparently obvious solution to this would be to roll out a Fedora virtual machine image. After all, it shares similar technologies to CentOS and RHEL and has much more up-to-date libraries included with it. The author has direct experience of this kind of solution in several roles! However, let's take a look at the bigger picture.</p>
<p>RHEL (and CentOS, which is based upon this) has a lifespan of around 10 years, depending on the point at which you purchased it. In an enterprise, this is a valuable proposition<em>—</em>it means that you can guarantee that any servers you build will have patches and support for up to 10 years (and possibly longer with extended life cycle support) from the point at which you built them. This ties in nicely with our previous points around security, reliability, and supportability (in the following section).</p>
<p>However, any servers that you build on Fedora will have a lifespan of somewhere in the region of 12-18 months (depending on the Fedora release cycle)<em>—</em>in an enterprise setting, having to redeploy a server after, say, 12-18 months is a headache that is not needed.</p>
<p>This is not to say there is never a case for deploying on Fedora or any other fast-moving Linux platform<em>—</em>it is simply to state that in an enterprise where security and reliability are vitally important, you are unlikely to want a Linux platform with a short life cycle as the short term gain (newer library support) would be replaced in 12-18 months with the pain of a lack of updates and the need to rebuild/upgrade the platform. </p>
<p class="mce-root"/>
<p>Of course, this does depend very much on your approach to your infrastructure<em>—</em>some enterprises take a very container-like approach to their servers and re-deploy them with every new software release or application deployment. When your infrastructure and build standards are defined by code (such as Ansible), then it is entirely possible to do this with a fairly minimal impact on your day-to-day operations, and it is unlikely that any single server would be around for long enough for the operating system to become outdated or unsupported.</p>
<p>At the end of the day, the choice is yours and you must establish which path you feel provides you with the most business benefit without putting your operations at risk. Part of standardization is to make sound, rational decisions on technology and to adopt them wherever feasible, and your standard could include frequent rebuilds such that you can use a fast-moving operating system such as Fedora. Equally, you might decide that your standard is that servers will have long lives and be upgraded in place, and in this case, you would be better choosing an operating system such as an Ubuntu LTS release or RHEL/CentOS. </p>
<p>In the following section, we will look in greater detail at how an SOE benefits the concept of supportability in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Supportability</h1>
                </header>
            
            <article>
                
<p>As we have already discussed, having a standardized environment brings with it two benefits. The first is that a well-chosen platform means a long vendor support life cycle. This, in turn, means long support from either the vendor (in the case of a product such as RHEL) or the community (in the case of CentOS). Some operating systems such as Ubuntu Server are available with either community support or a paid contract directly from Canonical.</p>
<p>Supportability doesn't just mean support from the vendor or the Linux community at large, however. Remember that, in an enterprise, your staff is your front line support before anyone external steps in. Now, imagine having a crack team of Linux staff, and presenting them with a server estate comprised of Debian, SuSe, CentOS, Fedora, Ubuntu, and Manjaro. There are similarities between them, but also a huge number of differences. Across them, there are four different package managers for installing and managing software packages, and that's just one example.</p>
<p>Whilst entirely supportable, it does present more of a challenge for your staff and means that, for anyone joining the company, you require both a broad and a deep set of Linux experience<em>—</em>either that or an extensive on-boarding process to get them up to speed. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>With a standardized environment, you might end up with more than one operating system, but nonetheless, if you can meet all of your requirements with, say, CentOS 7 and Ubuntu Server 18.04 LTS (and know that you are covered for the next few years because of your choices), then you immediately reduce the workload on your Linux team and enable them to spend more time creatively solving problems (for example, automating solutions with Ansible!) and less time figuring out the nuances between operating systems. As we have also discussed, in the event of an issue, they will be more familiar with each OS and hence need to spend less time debugging, reducing downtime.</p>
<p>This brings us nicely into the subject of ease of use at scale, and we will provide an overview of this in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ease of use</h1>
                </header>
            
            <article>
                
<p>This final category overlaps heavily with the last two—that is to say that, quite simply, the more standardized your environment, the easier it is for a given set of employees to get to grips with it. This automatically promotes all of the benefits we have discussed so far around reducing downtime, easier recruitment and on-boarding of staff, and so on.</p>
<p>Having set out the challenges that an SOE helps to address, we will proceed in the next section to look at the anatomy of such an environment to understand it from a technical standpoint.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is an SOE?</h1>
                </header>
            
            <article>
                
<p>Now that we've explored the reasons why an SOE is important to the enterprise and understood at a high level the solutions for these problems, let's look in detail at an SOE. We will begin by defining the SOE itself.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the SOE</h1>
                </header>
            
            <article>
                
<p>Let's take a quick look at this from a more practical standpoint. As we have already said, an SOE is a concept, not an absolute. It is, at its simplest level, a common server image or build standard that is deployed across a large number of servers throughout a company. Here, all required tasks are completed in a known, documented manner.</p>
<p class="mce-root"/>
<p>To start with, there is the base operating system—and, as we have discussed, there are hundreds of Linux distributions to choose from. Some are quite similar from a system administration perspective (for example, Debian and Ubuntu), whilst some are markedly different (for example, Fedora and Manjaro). By way of a simple example, let's say you wanted to install the Apache Web Server on Ubuntu 18.04 LTS<span>—</span>you would enter the following commands:</p>
<pre><strong># sudo apt-get update</strong><br/><strong># sudo apt-get install apache2</strong></pre>
<p>Now, if you wanted to do the same thing but on CentOS 7, you would enter the following:</p>
<pre><strong># sudo yum install httpd</strong></pre>
<p>As you can see, there is nothing in common between these commands<span>—</span>not even the name of the package, even though the end result in both cases is an installation of Apache. On a small scale, this is not an issue, but when servers are numerous and as server count goes up, so does the complexity of managing such an environment. </p>
<p>The base operating system is just the start. Our example above was installing Apache, yet we could also install nginx or even lighttpd. They are, after all, also web servers.</p>
<p>Then, there is configuration. Do you want users to be able to log in as<span> </span>root<span> </span>over SSH? Do you need a certain level of logging for audit or debug purposes? Do you need local or centralized authentication? The list is myriad, and as you can see, if left unchecked could grow into a massive headache.</p>
<p>This is where the SOE comes in. It is effectively a specification, and at a high level, it might say the following:</p>
<ul>
<li>Our standard base operating system is Ubuntu 18.04 LTS.</li>
<li>Our standard web server will be Apache 2.4.</li>
<li>SSH logins are enabled, but only for users with SSH keys and not root.</li>
<li>All user logins must be logged and archived for audit purposes.</li>
<li>Except for a few local <em>break glass</em> accounts, all accounts must be centrally managed (for example, by LDAP or Active Directory).</li>
<li>Our corporate monitoring solution must be integrated (for example, the Nagios NCPA agent must be installed and configured to communicate with our Nagios server).</li>
<li>All system logs must be sent to the corporate central log management system.</li>
<li>Security hardening must be applied to the system.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The preceding is simply an example, and it is by no means complete; however, it should begin to give you an idea of what an SOE looks like at a high level. As we proceed through this chapter, we will delve deeper into this subject and give more examples to build up a clear definition.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Knowing what to include</h1>
                </header>
            
            <article>
                
<p>Before we proceed, let's take a look in a little more detail at what to include in the environment. We have outlined in the previous section a very simplistic definition for an SOE. Part of any good SOE operating process is to have a pre-defined operating system build that can be deployed at a moment's notice. There are multiple ways this might be achieved and we will discuss these later in this book<span>—</span>however, for the time being, let's assume that a base image of Ubuntu 18.04 LTS as suggested previously has been built. What do we integrate into this <em>standard</em> build?</p>
<p>We know, for example, that our login policy is going to be applied throughout the organization—hence, when the build is created,<span> </span><kbd>/etc/ssh/sshd_config</kbd><span> </span>must be customized to include <kbd>PermitRootLogin no</kbd><span> </span>and <span><kbd>PasswordAuthentication no</kbd>. There is no point in performing this step in the post-deployment configuration, as this would have to be performed on each and every single deployment. Quite simply, this would be inefficient.</span></p>
<p>There are also important automation considerations for our operating system image. We know that Ansible itself communicates over SSH, and so we know that we are going to require some kind of credentials (it is quite likely this will be SSH key-based) for Ansible to run against all of the deployed servers. There is little point in having to manually roll out Ansible credentials to every single machine before you can actually perform any automation, and so it is important to consider the kind of authentication you want Ansible to use (for example, password- or SSH key-based), and to create the account and corresponding credentials when you build the image. The exact method for doing this will depend upon your corporate security standards, but I would advocate as a potential solution the following:</p>
<ul>
<li>Creating a local account on the standard image for Ansible to authenticate against</li>
<li>Giving this account appropriate sudo rights to ensure all desired automation tasks can be performed</li>
<li>Setting the local password for this account, or adding the SSH public key from an Ansible key-pair to the <kbd>authorized_keys</kbd> file for the local Ansible account you created</li>
</ul>
<div class="packt_tip">Doing this, of course, does present some security risks. It is most likely that Ansible will need full access to root on your servers for it to effectively perform all of the automation tasks you might ask of it, and so this Ansible account could become a backdoor if the credentials were ever compromised. It is recommended that as few people as possible have access to the credentials and that you make use of a tool such as AWX or Ansible Tower (which we shall explore in <a href="b0c37bde-4b12-4619-94f1-dd14ae0c96ff.xhtml" target="_blank">Chapter 3</a>, <em>Streamlining Infrastructure Management with AWX</em>) to manage your credentials, hence preventing people from getting hold of them inappropriately. You will also almost certainly want to enable auditing of all activities performed by the Ansible account and have these logged to a central server somewhere so that you can inspect them for any suspicious activity and audit them as required.</div>
<p>Moving on from user accounts and authentication, consider also <strong>Nagios Cross-Platform Agent</strong> (<strong>NCPA</strong>). We know in our example that all deployed servers are going to need to be monitored, and so it is a given that NCPA agent must be installed, and the token defined such that it can communicate with the Nagios server. Again, there is no point doing this on every single server after the standard image is deployed.</p>
<p>What about the web server though? It is sensible to have a standard, as it means all who are responsible for the environment can become comfortable with the technology. This makes administration easier and is especially beneficial for automation, as we shall see in the next section. However, unless you only ever deploy web servers running on Linux, this probably shouldn't be included as part of the standard build. </p>
<p>As a sound principle, the standard builds should be as simple and lightweight as possible. There is no point in having additional services running on them, taking up memory and CPU cycles, when they are redundant. Equally, having unconfigured services increases the attack surface for any potential attacker and so for security reasons, it is advisable to leave them out. </p>
<p>In short, the standard build should only include configuration and/or services that are going to be common to every server deployed. This approach is sometimes referred to as <strong>Just enough Operating System</strong> or <strong>JeOS</strong> for short, and it is the best starting point for your SOE.</p>
<p>Having understood the basic principles of an SOE, we will proceed in the next section to look in more detail at the benefits an SOE brings to your enterprise.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring SOE benefits</h1>
                </header>
            
            <article>
                
<p>By now, you should have some idea of what an SOE is, and<span> </span>how it brings economies of scale and greater efficiency to a Linux environment. Now, let's build on that and look in more detail at an example of the importance of standardization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Example benefits of an SOE in a Linux environment</h1>
                </header>
            
            <article>
                
<p>To say that there are commonalities in a Linux environment is to say that the servers that comprise it all share attributes and features. For example, they might all <span>be</span><span> </span><span>built upon Ubuntu Linux, or they might all have Apache as their web server. </span></p>
<p>We can explore this concept with an example. Suppose that you have 10 Linux web servers behind a load balancer and that they are all serving simple static content. Everything is working fine, but then a configuration change is mandated. Perhaps this is to change the document root of each web server to point to a new code release that has been deployed to them by another team.</p>
<p>As the person responsible, you know that because the overall solution is load balanced, all servers should be serving the same content. Therefore, the configuration change is going to be required on each and every one. That means 10 configurations changes to make if you do it by hand.</p>
<p>You could, of course, do this by hand, but this would be tedious and certainly isn't the best use of time for a skilled Linux admin. It is also error-prone—a typo could be made on one of the 10 servers and not spotted. Or the admin could be interrupted by an outage elsewhere and only a subset of the server configurations changed.</p>
<p>The better solution would be to write a script to make the change. This is the very basis of automation and it is almost certainly going to be a better use of time to run a single script once against 10 servers than to manually make the same change 10 times over. Not only is it more efficient, but if the same change became required in a month, the script could be reused with just minimal adjustment.</p>
<p class="mce-root"/>
<p>Now, let's throw a spanner into the works. What if, for reasons unknown, someone built five of the web servers using Apache on CentOS 7, and the other five using nginx on Ubuntu 18.04 LTS? The end result would, after all, be the same<span>—</span>at a basic level, they are both web servers. However, if you want to change the document root in Apache on CentOS 7, you would need to do the following:</p>
<ol>
<li>Locate the appropriate configuration file in<span> </span><kbd>/etc/httpd/conf.d</kbd>.</li>
<li>Make the required change to the <kbd>DocumentRoot</kbd><span> </span>parameter.</li>
<li>Reload the web server with<span> </span><kbd>systemctl reload httpd.service</kbd>.</li>
</ol>
<p>If you had to do the same thing for nginx on Ubuntu 18.04 LTS, you would do the following:</p>
<ol>
<li>Locate the correct configuration file in<span> </span><kbd>/etc/nginx/sites-available</kbd>.</li>
<li>Make the required change to the<span> </span><kbd>root</kbd><span> </span>parameter.</li>
<li>Ensure that the site configuration file is enabled using the <kbd>a2ensite</kbd> command<span>—</span>otherwise, Apache will not actually see the configuration file.</li>
<li>Reload the web server with<span> </span><kbd>systemctl reload apache2.service</kbd>.</li>
</ol>
<p>As you can see from this rather simplistic (albeit contrived) example, a lack of commonality is the enemy of automation. To cope with the case, you would need to do as follows:</p>
<ol>
<li>Detect the operating system on each server. This in itself is non-trivial—there is no one way to detect a Linux operating system, so your script would have to walk through a series of checks, including the following:
<ol>
<li>The contents of<span> </span><kbd>/etc/os-release</kbd><span>, </span>if it exists</li>
<li>The output of<span> </span><kbd>lsb_release</kbd><span>, </span>if it is installed</li>
<li>The contents of<span> </span><kbd>/etc/redhat-release</kbd><span>, </span>if it exists</li>
<li>The contents of<span> </span><kbd>/etc/debian_version</kbd><span>, </span>if it exists</li>
<li>Other OS-specific files as required, if none of the preceding produce meaningful results</li>
</ol>
</li>
<li>Run different modification commands in different directories to effect the change as discussed previously.</li>
<li>Run different commands to reload the web server, again as detailed previously.</li>
</ol>
<p>Hence, the script becomes complex, more difficult to write and maintain, and certainly more difficult to make reliable.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Although this particular example is unlikely to occur in real life, it does serve to make an important point—automation is much easier to implement when the environment is built to a given standard. If a decision is made that all web servers are to be based on CentOS 7, to run Apache 2, and have the site configuration named after the service name, then our automation becomes so much easier. In fact, you could even run a simple<span> </span><kbd>sed</kbd><span> </span>command to complete the change; for example, suppose the new web application was deployed to<span> </span><kbd>/var/www/newapp</kbd>:</p>
<pre># sed -i 's!DocumentRoot.*!DocumentRoot /var/www/newapp!g' /etc/httpd/conf.d/webservice.conf<br/># systemctl reload httpd.service</pre>
<p>No environment detection was necessary at all<span>—</span>just two simple shell commands. This could be the basis of a really simple automation script to be run either on each of the 10 servers in turn or remotely over SSH. Either way, our automation task is now very simple and shows how important commonality is. Importantly, an SOE by its very nature provides this commonality. Lack of commonality doesn't just make automation difficult though<span>—</span>it also hampers testing, often distorting test results as they may not be representative if environments are different.</p>
<p>In the next section of this chapter, we will build on this knowledge to demonstrate how an SOE benefits the process of software testing.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Benefits of SOE to software testing</h1>
                </header>
            
            <article>
                
<p>A common problem I have seen in many environments is that of a new software deployment having been successfully tested in an isolated pre-production environment and yet not working correctly when it is released into the production environment. More often than not, this problem is traced back to fundamental differences between the production and pre-production environments, and so it is clear that for testing to be valid, both environments must be as similar as possible.</p>
<p>Indeed, one of the problems containerization platforms such as Docker set out to solve was exactly this, and hence portability is a core feature of container environments. Code deployed on Docker is built on top of a container image that is, in simple terms, a stripped-down operating system image (remember JeOS?). This, in effect, is a really tiny SOE, just running in a container rather than on a bare metal server or virtual machine. However, it is worth considering that if portability through environment standardization is a key feature of container technology, then should we not try to achieve this across the board regardless of our infrastructure.</p>
<p class="mce-root"/>
<p>After all, if the configuration of the production servers is different from the pre-production ones, then how valid is the testing? If the pre-production environment was built on CentOS 7.6, but the production environment lags behind it on CentOS 7.4, then can you really ensure that a successful test result in one environment will guarantee it in the other? On paper, it should work, but with fundamental differences in software and library versions between the environments, this can never be guaranteed. This is before we even consider possible differences in configuration files and installed software.</p>
<p>Hence, SOEs can help here<span>—</span>if all environments are built to the same standards, then in theory, they should all be identical. Those of you who are eagle-eyed will notice the use of the word <em>should</em> in the previous sentence and it is there for a good reason. SOEs are a great step forward in defining the solution for testing failures, but they are not the whole story. </p>
<p>An environment is only standard as long as no-one modifies it, and if all users have administration-level privileges, then it is very easy for someone (well-meaning or otherwise) to log in and make changes that mean the environment deviates from the standard.</p>
<p>The answer to this issue is automation<span>—</span>not only do SOEs promote and enable automation, they also rely on it to maintain the level of standardization that they were required for in the first place. The two support each other directly and should ideally be inseparable partners<span>—</span>the SOE being the definition for the environment itself, and the automation providing the implementation, enforcement, and auditing of the standard. Indeed, this is the very premise of this book<span>—</span>that environments should be standardized as far as possible, and that as many changes as possible should be automated. </p>
<p>The focus of this book will be on the automation aspect of this equation, as other than adhering to the principles outlined in this chapter, the standards adopted will be unique for every environment and it is not the goal of this book to determine them at a low level. Working with our earlier example, both Apache and nginx have their benefits, and what fits one use case may not fit another.</p>
<p>The same is true with operating systems<span>—</span>some organizations may rely on the support package provided with Red Hat Enterprise Linux, whilst others don't need this but need the bleeding edge technologies provided by, say, Fedora. There is no right or wrong way to define a standard, as long as it meets the needs of the services it underpins. So far, we have focused very much on commonality and standards; however, there will always be edge cases where an alternative solution is required. In the next section, we will establish how to know when you should deviate from your standards.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Knowing when to deviate from standards</h1>
                </header>
            
            <article>
                
<p>It would be easy to oversell the benefits of standardization, and they are certainly a requirement for automation to be effective. However, like anything, it can be taken too far. There is no point, for example, building servers on top of Red Hat Enterprise Linux 5.7 in 2019 simply because this was once defined as a standard (it is now End of Life and no longer supported or updated). Similarly, from time to time, software vendors will have qualified their product on certain specific Linux distributions or application stacks and will not provide support unless their software is run within that ecosystem.</p>
<p>These are cases when deviations from the SOE are necessary, but they should be performed in a controlled manner. For example, if a business has built up its Linux server estate on Ubuntu 18.04 LTS, and then a new software stack is purchased that is only qualified on RHEL 7, it is clear that builds of RHEL 7 are going to be required. These should, however, be part of a new set of standards if possible and become a secondary SOE.</p>
<p>For example, if the CIS security hardening benchmark is applied to the Ubuntu SOE, then the equivalent one should be applied to the RHEL too. Similarly, if the business has standardized on nginx, then this should be used on the environment unless there is a compelling reason not to (hint: a compelling reason is not that it's new and sexy<span>—</span>it is that it solves a real problem or somehow improves something in a tangible way).</p>
<p>This results in the business going from one Linux SOE to two, which is still entirely manageable and certainly better than returning to organic growth methodologies that hamper effective automation.</p>
<p>In short, expect deviations, and don't fear them. Instead, handle them and use the requirements to expand your standards, but stick with them where you can. SOEs present a balancing act for everyone<span>—</span>on the one hand, they bring advantages of scale, make automation easier, and reduce the training time for new staff (as all servers are more or less the same in build and configuration), but if applied too rigidly, they could hamper innovation. They must not be used as an excuse to do things a certain way <em>because that's how it has always been done</em>.</p>
<p>There will always be a good reason to deviate from a standard; simply look for the business benefit it brings, whether it's vendor support, lower resource requirements (hence saving power and money), a longer support window, or otherwise. Try and avoid doing so just because a new technology is <em>shiny</em>. As long as you are mindful of this fact, you will make good decisions regarding deviation from your standards. In the next section of this chapter, we will explore the ongoing maintenance of SOEs.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ongoing maintenance of SOEs</h1>
                </header>
            
            <article>
                
<p>Although we will look at patching and maintenance in much greater detail later in this book, it deserves a mention here as it dovetails nicely into the discussion on commonality and deviations.</p>
<p>If nothing else, you are going to have to patch your Linux environment. For security reasons alone, this is a given and good practice, even in an air-gapped environment. Let's say that your environment is made up entirely of virtual machines and that you decided to standardize on CentOS 7.2 some time ago. You built a virtual machine, performed all of the required configuration steps to turn it into your SOE image, and then converted it into a template for your virtualization environment. This becomes your <em>gold build</em>. So far, so good.</p>
<p>However, CentOS 7.2 was released in December 2015, nearly 4 years ago at the time of writing, and if you were to deploy such an image today, the first thing you would have to do is patch it. This would, depending on the build definition (and the number of packages included in it), possibly involve downloading a gigabyte or more of packages to bring it up to the latest standard and ensure you were running with all discovered vulnerabilities patched, and all of the requisite bug fixes in place.</p>
<p>Obviously, if you are doing this at scale, this is inefficient—each new server is going to pull all that data down over the network (or worse, the internet, if you don't have an internal mirror), and then consume a great deal of I/O time and CPU time applying the patches, during which the server can't be used for anything meaningful. If you only deploy one server every few months, you can probably put up with this. If you deploy them on a more regular basis, then this is going to waste a lot of valuable time and resources.</p>
<p>Hence, as well as performing ongoing maintenance of your environment itself, it is important to perform ongoing maintenance of your standards. In 2019, it makes sense to update your CentOS build to 7.6. At the very least, your ongoing maintenance schedule should involve updating the <em>gold build</em> regularly. </p>
<p>We will go into much greater detail on how this might be performed later in this book. However, for those who are eager to know now, this might be as simple as booting the virtual machine image up, performing the updates, sanitizing it (for example, removing SSH host keys that would be duplicated when the template is cloned), and then creating a new template from it. Obviously, if any other changes to the SOE have been made since the last maintenance cycle, then these can be incorporated too.</p>
<p class="mce-root"/>
<p>You should expect your SOE to evolve over time—it would be easy perhaps to labor this point<span>—</span>but there is an important balance between creating and maintaining standards, and being overly rigid with them. You must accept that there are times when you will need to deviate from them as we discussed in the previous section and that, over time, they will evolve.</p>
<p>In short, SOEs should become a part of your regular IT processes; if employed correctly, they don't hinder innovation<span>—</span> instead, they actively support it by giving back time to those working with them and ensuring they spend less time performing mundane, repetitive tasks and hence have more time for evaluating new technologies and finding better ways of doing things. This, after all, is one of the key benefits of automation, which SOEs support directly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>SOEs are a valuable addition to technology processes in almost any environment. They require some time to be spent upfront on design work and defining standards, but this time is more than offset later on as it supports efficient and effective automation of the environments, and in this manner, actually gives time back to those responsible for the environment, giving them more time to work on evaluating new technologies, finding more efficient ways to do things, and being innovative in general.</p>
<p>In this chapter, you learned the fundamental definition of an SOE. You explored the benefits that they bring to just about any Linux environment where scale is important, how they support automation, and when and how to make deviations from the standards to ensure that they do not become overly rigid and hamper growth. Finally, you learned about the importance of ongoing maintenance, including maintenance of your standards as part your ongoing maintenance cycles.</p>
<p>In the next chapter, we will explore how to make use of Ansible as an effective automation framework for your Linux environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>What does the acronym SOE stand for?</li>
<li>Why would you choose an operating system with a long support cycle, such as CentOS, rather than one with a more rapid release cycle, such as Fedora?</li>
<li>Should you ever deviate from the standards you have defined for your environment?</li>
<li>List three challenges of scaling Linux environments up to enterprise scale.</li>
<li>Name three benefits that SOEs bring to Linux in the enterprise.</li>
<li>How does an SOE help to reduce the training requirements in an enterprise?</li>
<li>Why does an SOE benefit the security of your Linux environment?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li>To learn more about SOEs from a Red Hat perspective, refer to this article: <a href="https://servicesblog.redhat.com/2016/11/03/standard-operating-environment-part-i-concepts-and-structures/">https://servicesblog.redhat.com/2016/11/03/standard-operating-environment-part-i-concepts-and-structures/</a>.</li>
</ul>


            </article>

            
        </section>
    </body></html>