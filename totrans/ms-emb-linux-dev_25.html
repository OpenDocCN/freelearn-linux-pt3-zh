<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer175" class="Basic-Text-Frame">
    <h1 class="chapterNumber"><a id="_idTextAnchor667"/>20</h1>
    <h1 id="_idParaDest-575" class="chapterTitle"><a id="_idTextAnchor668"/>Profiling and Tracing</h1>
    <p class="normal">Interactive debugging using a source-level debugger, as described in the previous chapter, can give you an insight into the way a program works, but it constrains your view to a small body of code. In this chapter, we will look at the larger picture to see whether the system is performing as intended.</p>
    <p class="normal">Programmers and system designers are notoriously bad at guessing where bottlenecks are. So, if your system has performance issues, it is wise to start by looking at the full system and then work down, using more sophisticated tools as you go. In this chapter, I’ll begin with the well-known <code class="inlineCode">top</code> command as a means of getting an overview. Often, the problem can be localized to a single program, which you can analyze using the Linux profiler, <code class="inlineCode">perf</code>. If the problem is not so localized and you want to get a broader picture, <code class="inlineCode">perf</code> can do that as well. To diagnose problems associated with the kernel, I will describe some trace tools—Ftrace, LTTng, and eBPF—as a means of gathering detailed information.</p>
    <p class="normal">I will also cover Valgrind, which, because of its sandboxed execution environment, can monitor a program and report on code as it runs. I will complete the chapter with a description of a simple trace tool, <code class="inlineCode">strace</code>, which reveals the execution of a program by tracing the system calls it makes.</p>
    <p class="normal">In this chapter, we will cover the following topics:</p>
    <ul>
      <li class="bulletList">Observer effect</li>
      <li class="bulletList">Beginning to profile</li>
      <li class="bulletList">Profiling with <code class="inlineCode">top</code></li>
      <li class="bulletList">Profiling with GDB</li>
      <li class="bulletList">Introducing <code class="inlineCode">perf</code></li>
      <li class="bulletList">Tracing events</li>
      <li class="bulletList">Introducing Ftrace</li>
      <li class="bulletList">Using LTTng</li>
      <li class="bulletList">Using eBPF</li>
      <li class="bulletList">Using Valgrind</li>
      <li class="bulletList">Using <code class="inlineCode">strace</code></li>
    </ul>
    <h1 id="_idParaDest-576" class="heading-1"><a id="_idTextAnchor669"/>Technical requirements</h1>
    <p class="normal">To follow along with the examples, make sure you have the following:</p>
    <ul>
      <li class="bulletList">An Ubuntu 24.04 or later LTS host system with at least 90 GB of free disk space</li>
      <li class="bulletList">Buildroot 2024.02.6 LTS release</li>
      <li class="bulletList">A microSD card reader and card</li>
      <li class="bulletList">balenaEtcher for Linux</li>
      <li class="bulletList">An Ethernet cable and router with an available port for network connectivity</li>
      <li class="bulletList">Raspberry Pi 4</li>
      <li class="bulletList">A 5 V USB-C power supply capable of delivering 3 A</li>
    </ul>
    <p class="normal">You should have already installed the 2024.02.6 LTS release of Buildroot in <a href="Chapter_04.xhtml#_idTextAnchor110"><em class="italic">Chapter 6</em></a>. If you have not, then refer to the <em class="italic">System requirements </em>section of <em class="italic">The Buildroot user manual</em> (<a href="https://buildroot.org/downloads/manual/manual.html"><span class="url">https://buildroot.org/downloads/manual/manual.html</span></a>) before installing Buildroot on your Linux host according to the instructions from <a href="Chapter_04.xhtml#_idTextAnchor110"><em class="italic">Chapter 6</em></a>.</p>
    <p class="normal">The code used in this chapter can be found in the chapter folder in this book’s GitHub repository: <a href="https://github.com/PacktPublishing/Mastering-Embedded-Linux-Development/tree/main/Chapter20/buildroot"><span class="url">https://github.com/PacktPublishing/Mastering-Embedded-Linux-Development/tree/main/Chapter20/buildroot</span></a>.</p>
    <h1 id="_idParaDest-577" class="heading-1"><a id="_idTextAnchor670"/>Observer effect</h1>
    <p class="normal">Before diving into the tools, let’s talk about what the tools will show you. As is the case in many fields, measuring a certain property affects the observation itself. Measuring the electric current in a power supply line<a id="_idIndexMarker1477"/> requires measuring the voltage drop over a small resistor. However, the resistor itself affects the current. The same is true for profiling: every system observation has a cost in CPU cycles, and that resource is no longer spent on the application. Measurement tools also mess up caching behavior, eat memory space, and write to disk, which all make it worse. There is no measurement without overhead.</p>
    <p class="normal">I’ve often heard engineers say that the results of a profiling job were totally misleading. That is usually because they were performing the measurements on something not approaching a real situation. Always try to measure on the target, running release builds of the software, with a valid dataset preferably obtained from the field, using as few extra services as possible.</p>
    <p class="normal">A release build usually implies building fully optimized binaries without debug symbols. These production requirements severely limit the functionality of most profiling tools.</p>
    <p class="normal">Once our system is up and running, we will hit a problem right away. While it is important to observe the system in its natural state, the tools often need additional information to make sense of the events.</p>
    <p class="normal">Some tools require special kernel options. For the tools we are examining in this chapter, this applies to <code class="inlineCode">perf</code>, Ftrace, LTTng, and eBPF. Therefore, you will probably have to build and deploy a new kernel for these tests.</p>
    <p class="normal">Debug symbols are very helpful in translating raw program addresses into function names and line numbers in source code. Deploying executables with debug symbols does not change the execution of the code, but it does require that you have copies of the binaries, and a kernel compiled with debug information, at least for the components you want to profile. Some tools work best if you have these installed on the target system: <code class="inlineCode">perf</code>, for example. The techniques are the same as for general debugging, as I discussed in <a href="Chapter_19.xhtml#_idTextAnchor611"><em class="italic">Chapter 19</em></a>.</p>
    <p class="normal">If you want a tool to generate call graphs, you may have to compile with stack frames enabled. If you want the tool to attribute addresses with line numbers in source code accurately, you may need to compile with lower levels of optimization.</p>
    <p class="normal">Finally, some tools require<a id="_idIndexMarker1478"/> instrumentation to be inserted into the program to capture samples, so you will have to recompile those components. This applies to Ftrace and LTTng for the kernel.</p>
    <p class="normal">Be aware that the more you change the system you are observing, the harder it is to relate the measurements you make to the production system.</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">TIP</strong></p>
      <p class="normal">It is best to adopt a wait-and-see approach, making changes only when the need is clear, and being mindful that each time you do so, you will change what you are measuring.</p>
    </div>
    <p class="normal">Because the results of profiling can be so ambiguous, start with simple, easy-to-use tools that are readily available before reaching for more complex and invasive instruments.</p>
    <h1 id="_idParaDest-578" class="heading-1"><a id="_idTextAnchor671"/>Beginning to profile</h1>
    <p class="normal">When looking at the entire system, a good place to start is with a simple tool such as <code class="inlineCode">top</code>, which gives you an overview very quickly. It <a id="_idIndexMarker1479"/>shows you how much memory is being used, which processes are eating CPU cycles, and how this is spread across different cores and times.</p>
    <p class="normal">If <code class="inlineCode">top</code> shows that a single application is using up all the CPU cycles in user space, then you can profile that application using <code class="inlineCode">perf</code>.</p>
    <p class="normal">If two or more processes have a high CPU usage, there is probably something that is coupling them together, perhaps data communication. If a lot of cycles are spent on system calls or handling interrupts, then there may be an issue with the kernel configuration or with a device driver. In either case, you need to start by taking a profile of the whole system, again using <code class="inlineCode">perf</code>.</p>
    <p class="normal">If you want to find out more about the kernel and the sequencing of events there, use Ftrace, LTTng, or eBPF.</p>
    <p class="normal">There could be other problems that <code class="inlineCode">top</code> will not help you with. If you have multi-threaded code and there are problems with lockups, or if you have random data corruption, then <code class="inlineCode">pidstat</code> (part of <code class="inlineCode">sysstat</code>) or Valgrind plus the Helgrind plugin might be helpful. Memory leaks also fit into this category; I covered memory-related diagnosis in <a href="Chapter_18.xhtml#_idTextAnchor581"><em class="italic">Chapter 18</em></a>.</p>
    <p class="normal">Before we get into these more advanced profiling tools, let’s start with the most rudimentary one that is found on most systems, including those in production.</p>
    <h2 id="_idParaDest-579" class="heading-2"><a id="_idTextAnchor672"/>Profiling with top</h2>
    <p class="normal">The <strong class="keyWord">top</strong> program is a simple<a id="_idIndexMarker1480"/> tool that doesn’t require any special kernel options or symbol tables. There is a basic version in BusyBox and a more functional version in the <code class="inlineCode">procps</code> package, which is available in The Yocto Project and Buildroot. You may also want to consider using <code class="inlineCode">htop</code>, which has functionally similar to <code class="inlineCode">top</code> but a much nicer user interface.</p>
    <p class="normal">To begin with, focus on the summary line of <code class="inlineCode">top</code>, which is the second line if you are using BusyBox and the third line if you are using <code class="inlineCode">top</code> from <code class="inlineCode">procps</code>. Here is an example, using BusyBox’s <code class="inlineCode">top</code>:</p>
    <pre class="programlisting con"><code class="hljs-con">Mem: 57044K used, 446172K free, 40K shrd, 3352K buff, 34452K cached
CPU: 58% usr 4% sys 0% nic 0% idle 37% io 0% irq 0% sirq
Load average: 0.24 0.06 0.02 2/51 105
PID PPID USER STAT   VSZ %VSZ %CPU COMMAND
105  104 root    R 27912   6%  61% ffmpeg -i track2.wav
&lt;…&gt;
</code></pre>
    <p class="normal">The summary line shows the percentage of time spent running in various states, as shown in this table:</p>
    <table id="table001-6" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">procps</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">BusyBox</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Description</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">us</code></p>
          </td>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">usr</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">User-space programs with a default nice value</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">sy</code></p>
          </td>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">sys</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Kernel code</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">ni</code></p>
          </td>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">nic</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">User-space programs with a non-default nice value</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">id</code></p>
          </td>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">idle</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Idle</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">wa</code></p>
          </td>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">io</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">I/O wait</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">hi</code></p>
          </td>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">irq</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Hardware interrupts</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">si</code></p>
          </td>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">sirq</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Software interrupts</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">st</code></p>
          </td>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">-</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Steal time: only relevant in virtual environments</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Table 20.1 – procps top vs. BusyBox top</p>
    <p class="normal">In the preceding example, almost all of the time (58%) is spent in user mode, with a small amount (4%) in system mode, so this is a system that is CPU-bound in user space. The first line after the summary shows that just one application is responsible: <code class="inlineCode">ffmpeg</code>. Any efforts toward reducing CPU usage should be directed there.</p>
    <p class="normal">Here is another example:</p>
    <pre class="programlisting con"><code class="hljs-con">Mem: 13128K used, 490088K free, 40K shrd, 0K buff, 2788K cached
CPU: 0% usr 99% sys 0% nic 0% idle 0% io 0% irq 0% sirq
Load average: 0.41 0.11 0.04 2/46 97
PID PPID USER STAT   VSZ %VSZ %CPU COMMAND
<a id="_idTextAnchor673"/> 92   82 root    R  2152   0% 100% cat /dev/urandom
&lt;…&gt;
</code></pre>
    <p class="normal">This system is spending almost all of the time in kernel space (99% <code class="inlineCode">sys</code>), as a result of <code class="inlineCode">cat</code> reading from <code class="inlineCode">/dev/urandom</code>. In this artificial case, profiling <code class="inlineCode">cat</code> by itself would not help, but profiling the kernel<a id="_idIndexMarker1481"/> functions that <code class="inlineCode">cat</code> calls might.</p>
    <p class="normal">The default view of <code class="inlineCode">top</code> shows only processes, so the CPU usage is the total of all the threads in the process. Press <em class="italic">H</em> to see information for each thread. Likewise, it aggregates the time across all CPUs. If you are using the <code class="inlineCode">procps</code> version of <code class="inlineCode">top</code>, you can see a summary per CPU by pressing the <em class="italic">1</em> key.</p>
    <p class="normal">Once we have singled out the problem process using <code class="inlineCode">top</code>, we can attach GDB to it.</p>
    <h2 id="_idParaDest-580" class="heading-2"><a id="_idTextAnchor674"/>Profiling with GDB</h2>
    <p class="normal">You can profile an <a id="_idIndexMarker1482"/>application just by using <strong class="keyWord">GDB</strong> to stop it at arbitrary intervals to see what it is doing. This is the <strong class="keyWord">poor man’s profiler</strong>. It is easy to set up and is one way of gathering profile data.</p>
    <p class="normal">The procedure is simple:</p>
    <ol>
      <li class="numberedList" value="1">Attach to the process using <code class="inlineCode">gdbserver</code> (for a remote debug) or GDB (for a native debug). The process stops.</li>
      <li class="numberedList">Observe the function it stopped in. You can use the <code class="inlineCode">backtrace</code> GDB command to see the call stack.</li>
      <li class="numberedList">Type <code class="inlineCode">continue</code> so that the program resumes.</li>
      <li class="numberedList">After a while, press <em class="italic">Ctrl + C</em> to stop it again, and go back to <em class="italic">step 2</em>.</li>
    </ol>
    <p class="normal">If you repeat <em class="italic">steps 2</em> to <em class="italic">4</em> several times, you will quickly get an idea of whether it is looping or making progress, and if you repeat them often enough, you will get an idea of where the hotspots in the code are.</p>
    <p class="normal">There is a whole web page dedicated to this idea at <a href="https://poormansprofiler.org/"><span class="url">https://poormansprofiler.org/</span></a>, together with scripts that make it a little easier. I have used this technique many times over the years with various operating systems and debuggers.</p>
    <p class="normal">This is an example of <strong class="keyWord">statistical profiling</strong>, in which you sample the program state at intervals. After a number of samples, you begin to learn the statistical likelihood of the functions being executed. It is surprising how few you really need. Other statistical profilers are <code class="inlineCode">perf record</code>, OProfile, and <code class="inlineCode">gprof</code>.</p>
    <p class="normal">Sampling using a debugger is intrusive because the program is stopped for a significant period while you collect the sample. Other tools can sample with less overhead. One such tool is <code class="inlineCode">perf</code>.</p>
    <h1 id="_idParaDest-581" class="heading-1"><a id="_idTextAnchor675"/>Introducing perf</h1>
    <p class="normal"><strong class="keyWord">perf</strong> is an abbreviation of the Linux <strong class="keyWord">performance event counter subsystem</strong>, <code class="inlineCode">perf_events</code>, and also the name of the <a id="_idIndexMarker1483"/>command-line tool for interacting with <code class="inlineCode">perf_events</code>. Both have been part of the kernel since Linux 2.6.31. There is plenty of useful information in the Linux source tree in <code class="inlineCode">tools/perf/Documentation</code> as well as at <a href="https://perfwiki.github.io"><span class="url">https://perfwiki.github.io</span></a>.</p>
    <p class="normal">The initial impetus for developing <code class="inlineCode">perf</code> was to provide a unified way to access the registers of the <strong class="keyWord">performance measurement unit</strong> (<strong class="keyWord">PMU</strong>), which is part of most modern processor cores. Once the API was defined and integrated into Linux, it became logical to extend it to cover other types of performance counters.</p>
    <p class="normal">At its heart, <code class="inlineCode">perf</code> is a collection of event counters with rules about when they actively collect data. By setting the rules, you can capture data from the whole system, just the kernel, or just one process and its children, and do it across all CPUs or just one CPU. It is very flexible. With this one tool, you can start by looking at the whole system, then zero in on a device driver that seems to be causing problems, an application that is running slowly, or a library function that seems to be taking<a id="_idIndexMarker1484"/> longer to execute than you thought.</p>
    <p class="normal">The code for the <code class="inlineCode">perf</code> command-line tool is part of the kernel, in the <code class="inlineCode">tools/perf</code> directory. The tool and the kernel subsystem are developed hand in hand, meaning that they must be from the same version of the kernel. <code class="inlineCode">perf</code> can do a lot. In this chapter, I will examine it only as a profiler. For a description of its other capabilities, read the <code class="inlineCode">perf</code> man pages and refer to the documentation mentioned at the start of this section.</p>
    <p class="normal">In addition to debug symbols, there are two configuration options we need to set to fully enable <code class="inlineCode">perf</code> in the kernel.</p>
    <h2 id="_idParaDest-582" class="heading-2"><a id="_idTextAnchor676"/>Configuring the kernel for perf</h2>
    <p class="normal">You need a kernel that is configured for <code class="inlineCode">perf_events</code>, and you need the <code class="inlineCode">perf</code> command cross-compiled to run on <a id="_idIndexMarker1485"/>the target. The relevant kernel configuration is <code class="inlineCode">CONFIG_PERF_EVENTS</code>, present in the <strong class="screenText">General setup</strong> | <strong class="screenText">Kernel Performance Events and Counters</strong> menu.</p>
    <p class="normal">If you want to profile using tracepoints—more on this subject later—also enable the options described in the section about Ftrace. While you are there, it is worthwhile enabling <code class="inlineCode">CONFIG_DEBUG_INFO</code> as well.</p>
    <p class="normal">The <code class="inlineCode">perf</code> command has many dependencies, which makes cross-compiling it quite messy. However, both The Yocto Project and Buildroot have target packages for it.</p>
    <p class="normal">You will also need debug symbols on the target for the binaries that you are interested in profiling; otherwise, <code class="inlineCode">perf</code> will not be able to resolve addresses to meaningful symbols. Ideally, you want debug symbols for the whole system, including the kernel. For the latter, remember that the debug symbols for the kernel are in the <code class="inlineCode">vmlinux</code> file.</p>
    <h2 id="_idParaDest-583" class="heading-2"><a id="_idTextAnchor677"/>Building perf with The Yocto Project</h2>
    <p class="normal">If you are using the standard <code class="inlineCode">linux-yocto</code> kernel, <code class="inlineCode">perf_events</code> is enabled already, so there is nothing more to do.</p>
    <p class="normal">To build the <code class="inlineCode">perf</code> tool, you can<a id="_idIndexMarker1486"/> add it explicitly to the target image dependencies, or you can add the <code class="inlineCode">tools-profile</code> feature. You also want debug symbols on the target image as well as the kernel <code class="inlineCode">vmlinux</code> image. In total, this is what you will need in <code class="inlineCode">conf/local.conf</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">EXTRA_IMAGE_FEATURES:append = " tools-profile dbg-pkgs src-pkgs"
IMAGE_INSTALL:append = " kernel-vmlinux binutils"
</code></pre>
    <p class="normal">Adding <code class="inlineCode">perf</code> to a Buildroot image is more involved for several reasons.</p>
    <h2 id="_idParaDest-584" class="heading-2"><a id="_idTextAnchor678"/>Building perf with Buildroot</h2>
    <p class="normal">Many Buildroot kernel configurations do not include <code class="inlineCode">perf_events</code>, so you should begin by checking that your kernel includes the <a id="_idIndexMarker1487"/>options mentioned in the preceding section.</p>
    <p class="normal">To cross-compile <code class="inlineCode">perf</code>, run the Buildroot <code class="inlineCode">menuconfig</code> and select the following:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">BR2_PACKAGE_LINUX_TOOLS_PERF</code> in <strong class="screenText">Kernel</strong> | <strong class="screenText">Linux Kernel Tools</strong> | <strong class="screenText">perf</strong></li>
      <li class="bulletList"><code class="inlineCode">BR2_PACKAGE_LINUX_TOOLS_PERF_TUI</code> in <strong class="screenText">Kernel</strong> | <strong class="screenText">Linux Kernel Tools</strong> | <strong class="screenText">perf</strong> | <strong class="screenText">Enable perf TUI</strong></li>
    </ul>
    <p class="normal">To build binaries with debug information and install them onto the target without stripping, enable the first and disable the second of these two options:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">BR2_ENABLE_DEBUG</code> in <strong class="screenText">Build options</strong> | <strong class="screenText">Build packages with debugging symbols</strong></li>
      <li class="bulletList"><code class="inlineCode">BR2_STRIP_strip</code> in <strong class="screenText">Build options</strong> | <strong class="screenText">Strip target binaries</strong></li>
    </ul>
    <p class="normal">To copy the unstripped <code class="inlineCode">vmlinux</code> file to the target image, select the following:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">BR2_LINUX_KERNEL_VMLINUX</code> in <strong class="screenText">Kernel</strong> | <strong class="screenText">Kernel binary format</strong> | <strong class="screenText">vmlinux</strong></li>
      <li class="bulletList"><code class="inlineCode">BR2_LINUX_KERNEL_INSTALL_TARGET</code> in <strong class="screenText">Kernel</strong> | <strong class="screenText">Install kernel image to /boot in target</strong></li>
    </ul>
    <p class="normal">To increase the size of the root filesystem to accommodate the unstripped binaries and the <code class="inlineCode">vmlinux</code> file:</p>
    <ul>
      <li class="bulletList">Select <strong class="screenText">Filesystem images</strong> | <strong class="screenText">ext2/3/4 root filesystem</strong> | <strong class="screenText">Exact size</strong> and enter <code class="inlineCode">960M</code> in the text field.</li>
    </ul>
    <p class="normal">Then run <code class="inlineCode">make clean</code> followed by <code class="inlineCode">make</code>.</p>
    <p class="normal">Once you have built everything, you will have to copy <code class="inlineCode">vmlinux</code> to the target image manually.</p>
    <h2 id="_idParaDest-585" class="heading-2"><a id="_idTextAnchor679"/>Profiling with perf</h2>
    <p class="normal">You can use <code class="inlineCode">perf</code> to sample the state of a program using one of the event counters and accumulate samples over a <a id="_idIndexMarker1488"/>period of time to create a profile. This is another example of statistical profiling. The default event counter is called <code class="inlineCode">cycles</code>, which is a generic hardware counter that is mapped to a PMU register representing a count of cycles at the core clock frequency.</p>
    <p class="normal">Creating a profile using <code class="inlineCode">perf</code> is a two-stage process: the <code class="inlineCode">perf record</code> command captures samples and writes them to a file named <code class="inlineCode">perf.data</code>, then <code class="inlineCode">perf report</code> analyzes the results. Both commands are run on the target. The samples being collected are filtered for the process and any of its children. Here is an example of profiling a shell script that searches for the <code class="inlineCode">linux</code> string:</p>
    <pre class="programlisting con"><code class="hljs-con"># perf record -a sh -c "find /usr/share | xargs grep linux &gt; /dev/null"
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.176 MB perf.data (2677 samples) ]
# ls -l perf.data
-rw------- 1 root root 190024 Mar  9 14:28 perf.data
</code></pre>
    <p class="normal">Now you can display the results from <code class="inlineCode">perf.data</code> using the <code class="inlineCode">perf report</code> command.</p>
    <p class="normal">There are three user interfaces to choose from:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">--stdio</code>: This is a pure-text interface with no user interaction. You will have to launch <code class="inlineCode">perf report</code> and <code class="inlineCode">annotate</code> for each view of the trace.</li>
      <li class="bulletList"><code class="inlineCode">--tui</code>: This is a <a id="_idIndexMarker1489"/>simple text-based menu interface with traversal between screens.</li>
      <li class="bulletList"><code class="inlineCode">--gtk</code>: This is a graphical interface that otherwise acts in the same way as <code class="inlineCode">--tui</code>.</li>
    </ul>
    <p class="normal">The default is TUI, as shown in this example:</p>
    <figure class="mediaobject"><img src="../Images/B18466_20_1.png" alt="Figure 20.1 – perf report TUI" width="1092" height="752"/></figure>
    <p class="packt_figref">Figure 20.1 – perf report TUI</p>
    <p class="normal"><code class="inlineCode">perf</code> is able to record the kernel functions executed on behalf of the processes because it collects samples in kernel space.</p>
    <p class="normal">The list is ordered with<a id="_idIndexMarker1490"/> the most active functions first. In this example, all but one are captured while <code class="inlineCode">grep</code> is running. Some are in a library, <code class="inlineCode">libc-2.20</code>, some are in a program, <code class="inlineCode">busybox.nosuid</code>, and some are in the kernel. We have symbol names for program and library functions because all the binaries have been installed on the target with debug information, and kernel symbols are being read from <code class="inlineCode">/boot/vmlinux</code>. If you have <code class="inlineCode">vmlinux</code> in a different location, add <code class="inlineCode">-k &lt;path&gt;</code> to the <code class="inlineCode">perf report</code> command. Rather than storing <a id="_idIndexMarker1491"/>samples in <code class="inlineCode">perf.data</code>, you can save them to a different file using <code class="inlineCode">perf record -o &lt;file name&gt;</code> and analyze them using <code class="inlineCode">perf report</code> <code class="inlineCode">-i &lt;file name&gt;</code>.</p>
    <p class="normal">By default, <code class="inlineCode">perf record</code> samples at a frequency of 1,000 Hz using the <code class="inlineCode">cycles</code> counter.</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">TIP</strong></p>
      <p class="normal">A sampling frequency of 1,000 Hz may be higher than you really need and may be the cause of the observer effect. Try lower rates; 100 Hz is enough for most cases. You can set the sample frequency using the <code class="inlineCode">-F</code> option.</p>
    </div>
    <p class="normal">This is still not really making life easy; the functions at the top of the list are mostly low-level memory operations, and you can be fairly sure that they have already been optimized. Fortunately, <code class="inlineCode">perf record</code> also gives us the ability to crawl up the call stack and see where these functions are being invoked.</p>
    <h2 id="_idParaDest-586" class="heading-2"><a id="_idTextAnchor680"/>Call graphs</h2>
    <p class="normal">It would be nice to step back<a id="_idIndexMarker1492"/> and see the surrounding context of these costly functions. You can do that by passing the <code class="inlineCode">-g</code> option to <code class="inlineCode">perf record</code> to capture the backtrace from each sample.</p>
    <p class="normal">Now, <code class="inlineCode">perf report</code> shows a plus sign (<code class="inlineCode">+</code>) where the function is part of a call chain. You can expand the trace to see the functions lower down in the chain:</p>
    <figure class="mediaobject"><img src="../Images/B18466_20_2.png" alt="Figure 20.2 – perf report (call graphs)" width="1090" height="754"/></figure>
    <p class="packt_figref">Figure 20.2 – perf report (call graphs)</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">IMPORTANT NOTE</strong></p>
      <p class="normal">Generating call graphs<a id="_idIndexMarker1493"/> relies on the ability to extract call frames from the stack, just like backtraces in GDB. The debug information needed to unwind stacks is encoded in the executables. Call graphs cannot be produced for some combinations of architecture and toolchains because the binaries lack the necessary debug information.</p>
    </div>
    <p class="normal">Backtraces are <a id="_idIndexMarker1494"/>nice, but where is the assembler, or better yet, the source code, for these functions?</p>
    <h2 id="_idParaDest-587" class="heading-2"><a id="_idTextAnchor681"/>perf annotate</h2>
    <p class="normal">Now that you know which functions to <a id="_idIndexMarker1495"/>look at, it would be nice to step inside and see the code and to have hit counts for each instruction. That is what <code class="inlineCode">perf annotate</code> does, by calling down to a copy of <code class="inlineCode">objdump</code> installed on the target. You just need to use <code class="inlineCode">perf annotate</code> in place of <code class="inlineCode">perf report</code>.</p>
    <p class="normal"><code class="inlineCode">perf annotate</code> requires symbol tables for the executables and <code class="inlineCode">vmlinux</code>. Here is an example of an annotated function:</p>
    <figure class="mediaobject"><img src="../Images/B18466_20_3.png" alt="Figure 20.3 – perf annotate (assembler)" width="904" height="768"/></figure>
    <p class="packt_figref">Figure 20.3 – perf annotate (assembler)</p>
    <p class="normal">If you want to see the source code interleaved with the assembler, you can copy the relevant source files to the target device. If you are using The Yocto Project and build with the <code class="inlineCode">src-pkgs</code> extra image feature<a id="_idIndexMarker1496"/> or have installed the individual <code class="inlineCode">&lt;package&gt;-src</code> packages, then the source will have been installed for you in <code class="inlineCode">/usr/src/debug</code>. Otherwise, you can examine the debug information to see the location of the source code:</p>
    <pre class="programlisting con"><code class="hljs-con">$ cd ~/buildroot/output
$ host/aarch64-buildroot-linux-gnu/bin/objdump --dwarf target/lib/libc.so.6 | grep DW_AT_comp_dir | grep libgcc
&lt;41f4dd&gt; DW_AT_comp_dir : (indirect string, offset: 0x2d355): /home/frank/buildroot/output/build/host-gcc-initial-12.4.0/build/aarch64-buildroot-linux-gnu/libgcc
</code></pre>
    <p class="normal">The path on the target should be <em class="italic">exactly the same</em> as the path you can see in <code class="inlineCode">DW_AT_comp_dir</code>.</p>
    <p class="normal">Here is an example <a id="_idIndexMarker1497"/>of annotation with the source and assembler code:</p>
    <figure class="mediaobject"><img src="../Images/B18466_20_4.png" alt="Figure 20.4 – perf annotate (source code)" width="1292" height="772"/></figure>
    <p class="packt_figref">Figure 20.4 – perf annotate (source code)</p>
    <p class="normal">Now we can see the corresponding C source code above <code class="inlineCode">cmp r0</code> and below the <code class="inlineCode">str r3, [fp, #-40] </code>instruction.</p>
    <p class="normal">This concludes our coverage of <code class="inlineCode">perf</code>. While there are other statistical sampling profilers that predate <code class="inlineCode">perf</code>, like OProfile and <code class="inlineCode">gprof</code>, these tools have fallen out of favor in recent years, so I chose to omit them. Next, we will look at event tracers.</p>
    <h1 id="_idParaDest-588" class="heading-1"><a id="_idTextAnchor682"/>Tracing events</h1>
    <p class="normal">The tools we have seen so far all use statistical sampling. You often want to know more about the ordering of events so that you <a id="_idIndexMarker1498"/>can see them and relate them to each other. Function tracing involves instrumenting the code with tracepoints that capture information about the event, and may include some or all of the following:</p>
    <ul>
      <li class="bulletList">A timestamp</li>
      <li class="bulletList">Context, such as the current PID</li>
      <li class="bulletList">Function parameters and return values</li>
      <li class="bulletList">A call stack</li>
    </ul>
    <p class="normal">It is more intrusive than statistical profiling and it can generate a large amount of data. The latter problem can be mitigated by applying filters when the sample is captured and, later on, when viewing the trace.</p>
    <p class="normal">I will cover three trace tools here: the kernel function tracers Ftrace, LTTng, and eBPF.</p>
    <h1 id="_idParaDest-589" class="heading-1"><a id="_idTextAnchor683"/>Introducing Ftrace</h1>
    <p class="normal">The kernel function tracer <strong class="keyWord">Ftrace</strong> evolved from work done by Steven Rostedt and many others as they were tracking down the causes <a id="_idIndexMarker1499"/>of high scheduling latency in real-time applications. Ftrace appeared in Linux 2.6.27 and has been actively developed since then. There are a number of documents describing kernel tracing in the kernel source in <code class="inlineCode">Documentation/trace</code>.</p>
    <p class="normal">Ftrace consists of a number of tracers that can log various types of activity in the kernel. Here, I am going to talk about the <code class="inlineCode">function</code> and <code class="inlineCode">function_graph</code> tracers and the event tracepoints. In <a href="Chapter_19.xhtml#_idTextAnchor654"><em class="italic">Chapter 21</em></a>, I will revisit Ftrace when I talk about real-time latencies.</p>
    <p class="normal">The <code class="inlineCode">function</code> tracer instruments each kernel function so that calls can be recorded and timestamped. It compiles the kernel with the <code class="inlineCode">-pg</code> switch to inject the instrumentation. The <code class="inlineCode">function_graph</code> tracer goes further and records both the entry and exit of functions so that it can create a call graph. The event tracepoints feature records parameters associated with the call.</p>
    <p class="normal">Ftrace has a very embedded-friendly user interface that is entirely implemented through virtual files in the <code class="inlineCode">debugfs</code> filesystem, meaning that you do not have to install any tools on the target to make it work. Nevertheless, there are other user interfaces if you prefer: <code class="inlineCode">trace-cmd</code> is a command-line tool that records and views traces and is available in Buildroot (<code class="inlineCode">BR2_PACKAGE_TRACE_CMD</code>) and The Yocto Project (<code class="inlineCode">trace-cmd</code>). There is a graphical trace viewer named <strong class="keyWord">KernelShark</strong> that is available as a package for The Yocto Project.</p>
    <p class="normal">Like <code class="inlineCode">perf</code>, enabling Ftrace requires setting certain kernel configuration options.</p>
    <h2 id="_idParaDest-590" class="heading-2"><a id="_idTextAnchor684"/>Preparing to use Ftrace</h2>
    <p class="normal">Ftrace and its various <a id="_idIndexMarker1500"/>options are configured in the kernel configuration menu. You will need the following at a minimum:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">CONFIG_FUNCTION_TRACER</code> from the <strong class="screenText">Kernel hacking</strong> | <strong class="screenText">Tracers</strong> | <strong class="screenText">Kernel Function Tracer</strong> menu.</li>
    </ul>
    <p class="normal">You would be well advised to <a id="_idIndexMarker1501"/>turn on these options as well:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">CONFIG_FUNCTION_GRAPH_TRACER</code> in the <strong class="screenText">Kernel hacking</strong> | <strong class="screenText">Tracers</strong> | <strong class="screenText">Kernel Function Tracer</strong> |<strong class="screenText"> Kernel Function Graph Tracer</strong> menu</li>
      <li class="bulletList"><code class="inlineCode">CONFIG_DYNAMIC_FTRACE</code> in the <strong class="screenText">Kernel hacking</strong> | <strong class="screenText">Tracers</strong> | <strong class="screenText">Kernel Function Tracer</strong> | <strong class="screenText">Enable/disable function tracing dynamically</strong> menu</li>
      <li class="bulletList"><code class="inlineCode">CONFIG_FUNCTION_PROFILER</code> in the <strong class="screenText">Kernel hacking</strong> | <strong class="screenText">Tracers</strong> | <strong class="screenText">Kernel Function Tracer</strong> | <strong class="screenText">Kernel function profiler</strong> menu</li>
    </ul>
    <p class="normal">Since the whole thing is hosted in the kernel, there is no user-space configuration to be done.</p>
    <h2 id="_idParaDest-591" class="heading-2"><a id="_idTextAnchor685"/>Using Ftrace</h2>
    <p class="normal">Before you can use Ftrace, you <a id="_idIndexMarker1502"/>have to mount the <code class="inlineCode">debugfs</code> filesystem, which goes in the <code class="inlineCode">/sys/kernel/debug</code> directory:</p>
    <pre class="programlisting con"><code class="hljs-con"># mount -t debugfs none /sys/kernel/debug
</code></pre>
    <p class="normal">All the controls for Ftrace are in the <code class="inlineCode">/sys/kernel/debug/tracing</code> directory; there is even a mini <code class="inlineCode">HOWTO</code> in the <code class="inlineCode">README</code> file there.</p>
    <p class="normal">This is the list of tracers available in the kernel:</p>
    <pre class="programlisting con"><code class="hljs-con"># cat /sys/kernel/debug/tracing/available_tracers
blk function_graph function nop
</code></pre>
    <p class="normal">The active tracer is shown by <code class="inlineCode">current_tracer</code>. Initially, it will be the null tracer, <code class="inlineCode">nop</code>.</p>
    <p class="normal">To capture a trace, select the tracer by writing the name of one of the <code class="inlineCode">available_tracers</code> to <code class="inlineCode">current_tracer</code>. Then, enable tracing for a short while:</p>
    <pre class="programlisting con"><code class="hljs-con"># echo function &gt; /sys/kernel/debug/tracing/current_tracer
# echo 1 &gt; /sys/kernel/debug/tracing/tracing_on
# sleep 1
# echo 0 &gt; /sys/kernel/debug/tracing/tracing_on
</code></pre>
    <p class="normal">In that one second, the trace buffer will have been filled with the details of every function called by the kernel. The format of the trace buffer is plain text, as described in <code class="inlineCode">Documentation/trace/ftrace.txt</code>. You can read the trace buffer from the <code class="inlineCode">trace</code> file:</p>
    <pre class="programlisting con"><code class="hljs-con"># cat /sys/kernel/debug/tracing/trace
# tracer: function
#
# entries-in-buffer/entries-written: 40051/40051   #P:1
#
#                   _-----=&gt; irqs-off
#                  / _----=&gt; need-resched
#                 | / _---=&gt; hardirq/softirq
#                 || / _--=&gt; preempt-depth
#                 ||| /     delay
# TASK-PID  CPU#  |||| TIMESTAMP  FUNCTION
#    | |      |   ||||    |         |
    sh-361  [000] ...1 992.990646: mutex_unlock &lt;-rb_simple_write
    sh-361  [000] ...1 992.990658: __fsnotify_parent &lt;-vfs_write
    sh-361  [000] ...1 992.990661: fsnotify &lt;-vfs_write
    sh-361  [000] ...1 992.990663: __srcu_read_lock &lt;-fsnotify
    sh-361  [000] ...1 992.990666: preempt_count_add &lt;-__srcu_read_lock
    sh-361  [000] ...2 992.990668: preempt_count_sub &lt;-__srcu_read_lock
    sh-361  [000] ...1 992.990670: __srcu_read_unlock &lt;-fsnotify
    sh-361  [000] ...1 992.990672: __sb_end_write &lt;-vfs_write
    sh-361  [000] ...1 992.990674: preempt_count_add &lt;-__sb_end_write
&lt;…&gt;
</code></pre>
    <p class="normal">You can capture a large<a id="_idIndexMarker1503"/> number of data points in just one second—in this case, over 40,000.</p>
    <p class="normal">As with profilers, it is difficult to make sense of a flat function list like this. If you select the <code class="inlineCode">function_graph</code> tracer, Ftrace captures call graphs like this:</p>
    <pre class="programlisting con"><code class="hljs-con"># tracer: function_graph
#
# CPU   DURATION               FUNCTION CALLS
# |      |   |                  |   |   |   |
<a id="_idTextAnchor686"/> 0) + 63.167 us   |              } /* cpdma_ctlr_int_ctrl */
 0) + 73.417 us   |            } /* cpsw_intr_disable */
 0)               |            disable_irq_nosync() {
 0)               |              __disable_irq_nosync() {
 0)               |                __irq_get_desc_lock() {
 0)   0.541 us    |                  irq_to_desc();
 0)   0.500 us    |                  preempt_count_add();
 0) + 16.000 us   |                }
 0)               |                __disable_irq() {
 0)   0.500 us    |                  irq_disable();
 0)   8.208 us    |                }
 0)               |                __irq_put_desc_unlock() {
 0)   0.459 us    |                  preempt_count_sub();
 0)   8.000 us    |                }
 0) + 55.625 us   |              }
 0) + 63.375 us   |            }
</code></pre>
    <p class="normal">Now you can see the nesting of the function calls, delimited by braces, <code class="inlineCode">{</code> and <code class="inlineCode">}</code>. At the terminating brace, there is a measurement of the time taken in the function, annotated with a plus sign (<code class="inlineCode">+</code>) if it takes more than 10 µs and an exclamation mark (<code class="inlineCode">!</code>) if it takes more than 100 µs.</p>
    <p class="normal">You are often only interested in the kernel activity caused by a single process or thread, in which case you can restrict the trace to one thread by writing the thread ID to <code class="inlineCode">set_ftrace_pid</code>.</p>
    <h2 id="_idParaDest-592" class="heading-2"><a id="_idTextAnchor687"/>Dynamic Ftrace and trace filters</h2>
    <p class="normal">Enabling <code class="inlineCode">CONFIG_DYNAMIC_FTRACE</code> allows Ftrace to modify the function trace sites at runtime, which has a couple of benefits. Firstly, it triggers additional build-time processing of the trace function probes, which allows the <a id="_idIndexMarker1504"/>Ftrace subsystem to locate them at boot time and overwrite them <a id="_idIndexMarker1505"/>with <code class="inlineCode">nop</code> instructions, thus reducing the overhead of the function trace code to almost nothing. You can then enable Ftrace in production or near-production kernels with no impact on performance.</p>
    <p class="normal">The second advantage is that you can selectively enable function trace sites rather than tracing everything. The list of functions is put into <code class="inlineCode">available_filter_functions</code>. You can selectively enable function traces as needed by copying the name from <code class="inlineCode">available_filter_functions</code> to <code class="inlineCode">set_ftrace_filter. </code>To stop tracing that function, write its name to <code class="inlineCode">set_ftrace_notrace</code>. You can also use wildcards and append names to the list. For example, suppose you are interested in <code class="inlineCode">tcp</code> handling:</p>
    <pre class="programlisting con"><code class="hljs-con"># cd /sys/kernel/debug/tracing
# echo "tcp*" &gt; set_ftrace_filter
# echo function &gt; current_tracer
# echo 1 &gt; tracing_on
</code></pre>
    <p class="normal">Run some tests and then look at <code class="inlineCode">trace</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"># cat trace
# tracer: function
#
# entries-in-buffer/entries-written: 590/590   #P:1
#
#                     _-----=&gt; irqs-off
#                   / _----=&gt; need-resched
#                  | / _---=&gt; hardirq/softirq
#                  || / _--=&gt; preempt-depth
#                  ||| /     delay
#   TASK-PID CPU#  ||||   TIMESTAMP  FUNCTION
#      | |     |   ||||      |         |
dropbear-375 [000] ...1 48545.022235: tcp_poll &lt;-sock_poll
dropbear-375 [000] ...1 48545.022372: tcp_poll &lt;-sock_poll
dropbear-375 [000] ...1 48545.022393: tcp_sendmsg &lt;-inet_sendmsg
dropbear-375 [000] ...1 48545.022398: tcp_send_mss &lt;-tcp_sendmsg
dropbear-375 [000] ...1 48545.022400: tcp_current_mss &lt;-tcp_send_mss
&lt;…&gt;
</code></pre>
    <p class="normal">The <code class="inlineCode">set_ftrace_filter</code> function can also contain commands to start and stop tracing when certain functions are executed. There isn’t space to go into these details here, but if you want to find out more, read the <em class="italic">Filter commands</em> section in <code class="inlineCode">Documentation/trace/ftrace.txt</code>.</p>
    <h2 id="_idParaDest-593" class="heading-2"><a id="_idTextAnchor688"/>Trace events</h2>
    <p class="normal">The <code class="inlineCode">function</code> and <code class="inlineCode">function_graph</code> tracers only record the time at which the function was executed. The trace events feature also records parameters associated with the call, making the trace more readable and<a id="_idIndexMarker1506"/> informative. For example, instead of just recording that the <code class="inlineCode">kmalloc</code> function has been called, a trace event will record the number of bytes requested and the returned pointer. Trace events are used in <code class="inlineCode">perf</code> and LTTng as well as Ftrace, but the development of the trace events subsystem was prompted by the LTTng project.</p>
    <p class="normal">It takes effort from kernel developers to create trace events. They are defined in the source code using the <code class="inlineCode">TRACE_EVENT</code> macro; there are over a thousand of them now. You can see the list of events available at runtime in <code class="inlineCode">/sys/kernel/debug/tracing/available_events</code>. They are named &lt;<code class="inlineCode">subsystem&gt;:&lt;function&gt;</code> (e.g., <code class="inlineCode">kmem:kmalloc</code>). Each event is also represented by a subdirectory in <code class="inlineCode">tracing/events/&lt;subsystem&gt;/&lt;function&gt;</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"># ls events/kmem/kmalloc
enable filter format id trigger
</code></pre>
    <p class="normal">The files are:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">enable</code>: You write a <code class="inlineCode">1</code> to this file to enable the event.</li>
      <li class="bulletList"><code class="inlineCode">filter</code>: This is an expression that must evaluate to <code class="inlineCode">true</code> for the event to be traced.</li>
      <li class="bulletList"><code class="inlineCode">format</code>: This is the format of the event and parameters.</li>
      <li class="bulletList"><code class="inlineCode">id</code>: This is a numeric identifier.</li>
      <li class="bulletList"><code class="inlineCode">trigger</code>: This is a command that is executed when the event occurs using the syntax defined in the <em class="italic">Filter commands</em> section of <code class="inlineCode">Documentation/trace/ftrace.txt</code>.</li>
    </ul>
    <p class="normal">I will show you a simple example involving <code class="inlineCode">kmalloc</code> and <code class="inlineCode">kfree</code>. Event tracing does not depend on the function tracers, so begin by selecting the <code class="inlineCode">nop</code> tracer:</p>
    <pre class="programlisting con"><code class="hljs-con"># echo nop &gt; current_tracer
</code></pre>
    <p class="normal">Next, select the events to trace by enabling each one individually:</p>
    <pre class="programlisting con"><code class="hljs-con"># echo 1 &gt; events/kmem/kmalloc/enable
# echo 1 &gt; events/kmem/kfree/enable
</code></pre>
    <p class="normal">You can also write the event names to <code class="inlineCode">set_event</code>, as shown here:</p>
    <pre class="programlisting con"><code class="hljs-con"># echo "kmem:kmalloc kmem:kfree" &gt; set_event
</code></pre>
    <p class="normal">Now, when you read the trace, you can see the functions and their parameters:</p>
    <pre class="programlisting con"><code class="hljs-con"># tracer: nop
#
# entries-in-buffer/entries-written: 359/359   #P:1
#
#                      _-----=&gt; irqs-off
#                     / _----=&gt; need-resched
#                    | / _---=&gt; hardirq/softirq
#                    || / _--=&gt; preempt-depth
#                    ||| /     delay
#   TASK-PID   CPU#  ||||   TIMESTAMP  FUNCTION
#      | |       |   ||||      |         |
     cat-382   [000] ...1  2935.586706: kmalloc:call_site=c0554644 ptr=de515a00 bytes_req=384 bytes_alloc=512 gfp_flags=GFP_ATOMIC|GFP_NOWARN|GFP_NOMEMALLOC
     cat-382   [000] ...1  2935.586718: kfree: call_site=c059c2d8 ptr=(null)
</code></pre>
    <p class="normal">Exactly the same trace events are visible in <code class="inlineCode">perf</code> as tracepoint events.</p>
    <p class="normal">Since there is no<a id="_idIndexMarker1507"/> bloated user-space component to build, Ftrace is well suited for deploying to most embedded targets. Next, we will look at another popular event tracer whose origins predate those of Ftrace.</p>
    <h1 id="_idParaDest-594" class="heading-1"><a id="_idTextAnchor689"/>Using LTTng</h1>
    <p class="normal">The <strong class="keyWord">Linux Trace Toolkit</strong> (<strong class="keyWord">LTT</strong>) project was started by Karim Yaghmour as a means of tracing kernel activity and was one of the first trace<a id="_idIndexMarker1508"/> tools generally available for the <a id="_idIndexMarker1509"/>Linux kernel. Later, Mathieu Desnoyers took up the idea and re-implemented it as a next-generation trace tool, <strong class="keyWord">LTTng</strong>. It was then expanded to cover user-space traces as well as the<a id="_idIndexMarker1510"/> kernel. The project website is at <a href="https://lttng.org/"><span class="url">https://lttng.org/</span></a> and contains a comprehensive user manual.</p>
    <p class="normal">LTTng consists of three components:</p>
    <ul>
      <li class="bulletList">A core session manager</li>
      <li class="bulletList">A kernel tracer implemented as a group of kernel modules</li>
      <li class="bulletList">A user-space tracer implemented as a library</li>
    </ul>
    <p class="normal">In addition to those, you will need a trace viewer such as <strong class="keyWord">Babeltrace</strong> (<a href="https://babeltrace.org/"><span class="url">https://babeltrace.org/</span></a>) or the <strong class="keyWord">Eclipse Trace Compass</strong> plugin to display and filter the raw trace data on the host or target.</p>
    <p class="normal">LTTng requires a kernel configured with <code class="inlineCode">CONFIG_TRACEPOINTS</code>, which is enabled when you select <strong class="screenText">Kernel hacking</strong> | <strong class="screenText">Tracers</strong> | <strong class="screenText">Kernel Function Tracer</strong>.</p>
    <p class="normal">The description that follows refers to LTTng version 2.13. Other versions may be different.</p>
    <h2 id="_idParaDest-595" class="heading-2"><a id="_idTextAnchor690"/>LTTng and The Yocto Project</h2>
    <p class="normal">You need to add these <a id="_idIndexMarker1511"/>packages to the target dependencies in <code class="inlineCode">conf/local.conf</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">IMAGE_INSTALL:append = " lttng-tools lttng-modules lttng-ust"
</code></pre>
    <p class="normal">If you want to run Babeltrace on the target, also append the <code class="inlineCode">babeltrace2</code> package.</p>
    <h2 id="_idParaDest-596" class="heading-2"><a id="_idTextAnchor691"/>LTTng and Buildroot</h2>
    <p class="normal">You need to enable the<a id="_idIndexMarker1512"/> following:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">BR2_PACKAGE_LTTNG_MODULES</code> in the <strong class="screenText">Target packages</strong> | <strong class="screenText">Debugging, profiling and benchmark</strong> | <strong class="screenText">lttng-modules</strong> menu</li>
      <li class="bulletList"><code class="inlineCode">BR2_PACKAGE_LTTNG_TOOLS</code> in the <strong class="screenText">Target packages</strong> | <strong class="screenText">Debugging, profiling and benchmark</strong> | <strong class="screenText">lttng-tools</strong> menu</li>
    </ul>
    <p class="normal">For user-space trace tracing, enable these:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">BR2_PACKAGE_UTIL_LINUX_UUIDD</code> in the <strong class="screenText">Target packages</strong> | <strong class="screenText">System tools</strong> | <strong class="screenText">util-linux</strong> | <strong class="screenText">uuidd</strong> menu</li>
      <li class="bulletList"><code class="inlineCode">BR2_PACKAGE_LTTNG_LIBUST</code> in the <strong class="screenText">Target packages</strong> | <strong class="screenText">Libraries</strong> | <strong class="screenText">Other</strong> | <strong class="screenText">lttng-libust</strong> menu</li>
      <li class="bulletList"><code class="inlineCode">BR2_PACKAGE_HOST_BABELTRACE2</code> in the <strong class="screenText">Host utilities</strong> | <strong class="screenText">host babeltrace2</strong> menu</li>
    </ul>
    <p class="normal">There is a package called <code class="inlineCode">babletrace2</code> for the target. Buildroot installs <code class="inlineCode">babeltrace2</code> for the host in <code class="inlineCode">output/host/usr/bin/babeltrace2</code>.</p>
    <h2 id="_idParaDest-597" class="heading-2"><a id="_idTextAnchor692"/>Using LTTng for kernel tracing</h2>
    <p class="normal">LTTng can use the set of Ftrace <a id="_idIndexMarker1513"/>events described previously as potential tracepoints. Initially, they are disabled.</p>
    <p class="normal">The control interface for LTTng is the <code class="inlineCode">lttng</code> command. You can list the kernel probes using the following:</p>
    <pre class="programlisting con"><code class="hljs-con"># lttng list --kernel
Kernel events:
-------------
writeback_nothread (loglevel: TRACE_EMERG (0)) (type: tracepoint)
writeback_queue (loglevel: TRACE_EMERG (0)) (type: tracepoint)
writeback_exec (loglevel: TRACE_EMERG (0)) (type: tracepoint)
&lt;…&gt;
</code></pre>
    <p class="normal">Traces are captured in the context of a session, which, in this example, is called <code class="inlineCode">test</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"># lttng create test
Session test created.
Traces will be written in /home/root/lttng-traces/test20150824-140942
# lttng list
Available tracing sessions:
<a id="_idTextAnchor693"/>1) test (/home/root/lttng-traces/test-20150824-140942) [inactive]
</code></pre>
    <p class="normal">Now enable a few events in the current session. You can enable all kernel tracepoints using the <code class="inlineCode">--all</code> option, but remember the warning about generating too much trace data. Let’s start with a couple of scheduler-related trace events:</p>
    <pre class="programlisting con"><code class="hljs-con"># lttng enable-event --kernel sched_switch,sched_process_fork
</code></pre>
    <p class="normal">Check that everything is set up:</p>
    <pre class="programlisting con"><code class="hljs-con"># lttng list test
Tracing session test: [inactive]
    Trace path: /home/root/lttng-traces/test-20150824-140942
    Live timer interval (usec): 0
 === Domain: Kernel ===
 Channels:
-------------
- channel0: [enabled]
 Attributes:
      overwrite mode: 0
      subbufers size: 26214
      number of subbufers: 4
      switch timer interval: 0
      read timer interval: 200000
      trace file count: 0
      trace file size (bytes): 0
      output: splice()
 Events:
      sched_process_fork (loglevel: TRACE_EMERG (0)) (type: tracepoint) [enabled]
      sched_switch (loglevel: TRACE_EMERG (0)) (type: tracepoint) [enabled]
</code></pre>
    <p class="normal">Now start tracing:</p>
    <pre class="programlisting con"><code class="hljs-con"># lttng start
</code></pre>
    <p class="normal">Run the test load, and<a id="_idIndexMarker1514"/> then stop tracing:</p>
    <pre class="programlisting con"><code class="hljs-con"># lttng stop
</code></pre>
    <p class="normal">Traces for the session are written to the session directory, <code class="inlineCode">lttng-traces/&lt;session&gt;/kernel</code>.</p>
    <p class="normal">Use the Babeltrace viewer to dump the raw trace data in text format. In this case, I ran it on the host computer:</p>
    <pre class="programlisting con"><code class="hljs-con">$ babeltrace2 lttng-traces/test-20150824-140942/kernel
</code></pre>
    <p class="normal">The output is too verbose to fit on this page, so I will leave it as an exercise for you to capture and display a trace in this way. The text output from Babeltrace has the advantage that it is easy to search for strings using <code class="inlineCode">grep</code> and similar commands.</p>
    <p class="normal">A good choice for a graphical trace viewer is the <strong class="keyWord">Trace Compass</strong> plugin for Eclipse, which is now part of the Eclipse IDE for the C/C++ developer bundle. Importing the trace data into Eclipse is characteristically fiddly. Follow these steps:</p>
    <ol>
      <li class="numberedList" value="1">Open the <strong class="screenText">Tracing</strong> perspective.</li>
      <li class="numberedList">Create a new project by selecting <strong class="screenText">File</strong> | <strong class="screenText">New</strong> | <strong class="screenText">Tracing project</strong>.</li>
      <li class="numberedList">Enter a project name and click on <strong class="screenText">Finish</strong>.</li>
      <li class="numberedList">Right-click on the <strong class="screenText">New Project</strong> option in the <strong class="screenText">Project Explorer</strong> menu and select <strong class="screenText">Import</strong>.</li>
      <li class="numberedList">Expand <strong class="screenText">Tracing</strong>, and then select <strong class="screenText">Trace Import</strong>.</li>
      <li class="numberedList">Browse to the directory containing the traces (e.g., <code class="inlineCode">test-20150824-140942</code>), tick the box to indicate which subdirectories you want (might be <strong class="screenText">kernel</strong>), and click on <strong class="screenText">Finish</strong>.</li>
      <li class="numberedList">Expand the project, expand <strong class="screenText">Traces[1]</strong>, and then double-click on <strong class="screenText">kernel</strong>.</li>
    </ol>
    <p class="normal">Now, let’s switch <a id="_idIndexMarker1515"/>gears away from LTTng and jump headfirst into the latest and greatest event tracer for Linux.</p>
    <h1 id="_idParaDest-598" class="heading-1"><a id="_idTextAnchor694"/>Using eBPF</h1>
    <p class="normal"><strong class="keyWord">Berkeley Packet Filter</strong> (<strong class="keyWord">BPF</strong>) is a technology<a id="_idIndexMarker1516"/> that was first introduced in 1992 to capture, filter, and analyze network traffic. In 2013, Alexi Starovoitov undertook a rewrite of BPF <a id="_idIndexMarker1517"/>with help from Daniel Borkmann. Their work, then known as <strong class="keyWord">eBPF</strong> (<strong class="keyWord">extended BPF</strong>), was merged into the kernel in 2014, where it has been available since Linux 3.15. eBPF provides a sandboxed execution environment for running programs inside the Linux kernel. eBPF programs<a id="_idIndexMarker1518"/> are written in C and are <strong class="keyWord">just-in-time</strong> (<strong class="keyWord">JIT</strong>) compiled to native code. Before that happens, the intermediate eBPF bytecode must first pass through a series of safety checks so that a program cannot crash the kernel.</p>
    <p class="normal">Despite its networking origins, eBPF is now a general-purpose virtual machine running inside the Linux kernel. By making it easy to run small programs on specific kernel and application events, eBPF has quickly emerged as the most powerful tracer for Linux. Like what cgroups did for containerized deployments, eBPF has the potential to revolutionize observability by enabling users to fully instrument production systems. Netflix and Facebook make extensive use of eBPF across their microservices <a id="_idIndexMarker1519"/>and cloud infrastructure for performance analysis and thwarting <strong class="keyWord">distributed denial-of-service</strong> (<strong class="keyWord">DDoS</strong>) attacks.</p>
    <p class="normal">The tooling around eBPF is <a id="_idIndexMarker1520"/>evolving, with <strong class="keyWord">BPF Compiler Collection</strong> (<strong class="keyWord">BCC</strong>) and <strong class="keyWord">bpftrace</strong> establishing <a id="_idIndexMarker1521"/>themselves as the two most prominent frontends. Brendan Gregg was deeply involved in both projects and has written about eBPF extensively in his book <em class="italic">BPF Performance Tools: Linux System and Application Observability</em>. With so many possibilities covering such a vast scope, new technology such as eBPF can seem overwhelming. But much like cgroups, we don’t need to understand how eBPF works to start making use of it. BCC comes with several ready-made tools and examples that we can simply run from the command line.</p>
    <h2 id="_idParaDest-599" class="heading-2"><a id="_idTextAnchor695"/>Configuring the kernel for eBPF</h2>
    <p class="normal">A package named <strong class="keyWord">ply</strong> (<a href="https://github.com/iovisor/ply"><span class="url">https://github.com/iovisor/ply</span></a>) was merged into Buildroot on January 23, 2021, for<a id="_idIndexMarker1522"/> inclusion in the 2021.02 LTS release of Buildroot. <strong class="keyWord">ply</strong> is a lightweight, dynamic tracer for Linux that leverages eBPF so that probes can be attached to arbitrary points in the kernel. Unlike <code class="inlineCode">bpftrace</code>, which depends on BCC, <code class="inlineCode">ply</code> does not rely on LLVM and has no required external dependencies aside from <code class="inlineCode">libc</code>. This makes it much easier to port to embedded CPU architectures such as <code class="inlineCode">arm</code> and <code class="inlineCode">powerpc</code>.</p>
    <p class="normal">Let’s begin by configuring an eBPF-enabled kernel for Raspberry Pi 4:</p>
    <pre class="programlisting con"><code class="hljs-con">$ cd buildroot
$ make clean
$ make raspberrypi4_64_defconfig
$ make linux-configure
</code></pre>
    <p class="normal">The <code class="inlineCode">make linux-configure</code> command will download and build some host tools before fetching, extracting, and configuring the kernel source code. The <code class="inlineCode">raspberrypi4_64_defconfig</code> from the 2024.02.6 LTS release of Buildroot points to a custom 6.1 kernel source tarball <a id="_idIndexMarker1523"/>from the Raspberry Pi Foundation’s GitHub fork. Inspect the contents of your <code class="inlineCode">raspberrypi4_64_defconfig</code> to verify what version of the kernel you are on. Once <code class="inlineCode">make linux-configure</code> has configured the kernel, we can reconfigure it for eBPF:</p>
    <pre class="programlisting con"><code class="hljs-con">$ make linux-menuconfig
</code></pre>
    <p class="normal">To search for a specific kernel configuration option from the interactive menu, hit <em class="italic">/</em> and enter a search string. The search should return a numbered list of matches. Entering a given number takes you directly to that configuration option.</p>
    <p class="normal">At a minimum, we need to select the following to enable kernel support for eBPF:</p>
    <pre class="programlisting code"><code class="hljs-code">CONFIG_BPF=y
CONFIG_BPF_SYSCALL=y
</code></pre>
    <p class="normal">The following are intended for BCC but there is no harm in adding them:</p>
    <pre class="programlisting code"><code class="hljs-code">CONFIG_NET_CLS_BPF=m
CONFIG_NET_ACT_BPF=m
CONFIG_BPF_JIT=y
</code></pre>
    <p class="normal">Add these so that users can compile and attach eBPF programs to <code class="inlineCode">kprobe</code>, <code class="inlineCode">uprobe</code>, and <code class="inlineCode">tracepoint</code> events:</p>
    <pre class="programlisting code"><code class="hljs-code">CONFIG_HAVE_EBPF_JIT=y
CONFIG_BPF_EVENTS=y
</code></pre>
    <p class="normal">These need to be selected for <code class="inlineCode">ply</code> to work:</p>
    <pre class="programlisting code"><code class="hljs-code">CONFIG_KPROBES=y
CONFIG_TRACEPOINTS=y
CONFIG_FTRACE=y
CONFIG_DYNAMIC_FTRACE=y
CONFIG_KPROBE_EVENTS_ON_NOTRACE=y
</code></pre>
    <p class="normal">Make sure to save your changes when exiting <code class="inlineCode">make</code> <code class="inlineCode">linux-menuconfig</code> so that they get applied to <code class="inlineCode">output/build/linux-custom/.config</code> before building your eBPF-enabled kernel.</p>
    <h2 id="_idParaDest-600" class="heading-2"><a id="_idTextAnchor696"/>Building ply with Buildroot</h2>
    <p class="normal">Let’s build <code class="inlineCode">ply</code> and install the tool along <a id="_idIndexMarker1524"/>with some example scripts. The <code class="inlineCode">ply</code> scripts are bundled together inside an <code class="inlineCode">ebpf</code> package<a id="_idIndexMarker1525"/> under the <code class="inlineCode">MELD/Chapter20/</code> directory for easy installation. To copy them over to your 2024.02.06 LTS installation of Buildroot:</p>
    <pre class="programlisting con"><code class="hljs-con">$ cd ~
$ cp -a MELD/Chapter20/buildroot/* buildroot
</code></pre>
    <p class="normal">Now build the <code class="inlineCode">ply</code> image for Raspberry Pi 4:</p>
    <pre class="programlisting con"><code class="hljs-con">$ cd buildroot
$ make rpi4_64_ply_defconfig
$ make
</code></pre>
    <p class="normal">If your version of Buildroot is 2024.02.06 LTS and you copied the <code class="inlineCode">buildroot</code> overlay from <code class="inlineCode">MELD/Chapter20</code> correctly, then the <code class="inlineCode">ply</code> image should build successfully. The kernel built for this image is already configured for eBPF so there is no need to perform the previous <code class="inlineCode">linux-menuconfig</code> steps. The <code class="inlineCode">ply</code> image also automounts <code class="inlineCode">debugfs</code> at <code class="inlineCode">/sys/kernel/debug</code> so <code class="inlineCode">ply</code> is ready to run on boot up.</p>
    <p class="normal">Insert the finished microSD into your Raspberry Pi 4, plug it into your local network with an Ethernet cable, and power the device up. Use <code class="inlineCode">arp-scan</code> to locate your Raspberry Pi 4’s IP address and SSH into it as <code class="inlineCode">root</code> with the password you set in the previous section. I used <code class="inlineCode">temppwd</code> for the <code class="inlineCode">root</code> password in the <code class="inlineCode">configs/rpi4_64_ply_defconfig</code> that I included with my <code class="inlineCode">MELD/Chapter20/buildroot</code> overlay. Now, we are ready to gain some firsthand experience in experimenting with eBPF.</p>
    <h2 id="_idParaDest-601" class="heading-2"><a id="_idTextAnchor697"/>Using ply</h2>
    <p class="normal">Doing almost anything with <a id="_idIndexMarker1526"/>eBPF, including running the <code class="inlineCode">ply</code> tool and <a id="_idIndexMarker1527"/>examples, requires <code class="inlineCode">root</code> privileges, which is why we enabled <code class="inlineCode">root</code> login via SSH. Another prerequisite is mounting <code class="inlineCode">debugfs</code>. If there is no <code class="inlineCode">debugfs</code> entry in your <code class="inlineCode">/etc/fstab</code>, then mount <code class="inlineCode">debugfs</code> from the command line:</p>
    <pre class="programlisting con"><code class="hljs-con"># mount -t debugfs none /sys/kernel/debug
</code></pre>
    <p class="normal">Let’s start by counting <code class="inlineCode">syscalls</code> system-wide by function:</p>
    <pre class="programlisting con"><code class="hljs-con"># ply 'k:__arm64_sys_* { @syscalls[caller] = count(); }'
^C
@syscalls:
{ __arm64_sys_ppoll }: 1
{ __arm64_sys_rt_sigaction }: 2
{ __arm64_sys_rt_sigreturn }: 3
{ __arm64_sys_writev }: 12
{ __arm64_sys_brk }: 13
{ __arm64_sys_pselect6 }: 19
{ __arm64_sys_perf_event_open }: 174
{ __arm64_sys_epoll_pwait }: 176
{ __arm64_sys_newfstatat }: 188
{ __arm64_sys_close }: 205
{ __arm64_sys_ioctl }: 247
{ __arm64_sys_read }: 370
{ __arm64_sys_openat }: 383
</code></pre>
    <p class="normal">Notice that the <code class="inlineCode">ply</code> session terminates, and the trace results are displayed when the user enters <em class="italic">Ctrl + C</em>. You may need to enter <em class="italic">Ctrl + C</em> repeatedly until the <code class="inlineCode">ply</code> session finally terminates.</p>
    <p class="normal">The directory where <a id="_idIndexMarker1528"/>the <code class="inlineCode">ply</code> scripts are located is not in the <code class="inlineCode">PATH</code> environment variable, so navigate there for easier execution:</p>
    <pre class="programlisting con"><code class="hljs-con"># cd /root
</code></pre>
    <p class="normal">Let’s start with a system-wide <a id="_idIndexMarker1529"/>script that displays read sizes as a histogram:</p>
    <pre class="programlisting con"><code class="hljs-con"># ./read-dist.ply
^C
@:
{ retsize }:
        [   2,    3]           1 ┤▏                               │
        ...
        [   8,   15]           1 ┤▏                               │
        [  16,   31]           1 ┤▏                               │
        ...
        [ 256,  511]         181 ┤███████████████████████████████▌│
</code></pre>
    <p class="normal">The <code class="inlineCode">tcp-send-recv.ply</code> script counts TCP I/O by executable and direction:</p>
    <pre class="programlisting con"><code class="hljs-con"># ./tcp-send-recv.ply &amp;
# redis-cli --latency
min: 0, max: 1, avg: 0.29 (1033 samples)^C
# fg %1
./tcp-send-recv.ply
^C
@:
{ dropbear       , recv    }: 26
{ redis-cli      , recv    }: 1033
{ redis-cli      , send    }: 1033
{ redis-server   , send    }: 1033
{ redis-server   , recv    }: 1034
{ dropbear       , send    }: 1048
</code></pre>
    <p class="normal">In this instance, I am tracing all calls to <code class="inlineCode">tcp_sendmsg</code> and <code class="inlineCode">tcp_recvmsg</code> while I run a Redis client/server latency test. I performed the test from an SSH terminal so there is TCP I/O reported for <code class="inlineCode">dropbear</code> as well. The number of samples displayed increased from <code class="inlineCode">0</code> to <code class="inlineCode">1033</code> over the course of the latency test, which<a id="_idIndexMarker1530"/> explains the <code class="inlineCode">1048</code> sends made by <code class="inlineCode">dropbear</code>.</p>
    <p class="normal">The <code class="inlineCode">heap-allocs.ply</code> script <a id="_idIndexMarker1531"/>displays heap allocation counts. I ran an LRU cache simulation of 100,000 keys on Redis:</p>
    <pre class="programlisting con"><code class="hljs-con"># redis-cli flushall
OK
# ./heap-allocs.ply &amp;
# redis-cli --lru-test 100000
40500 Gets/sec | Hits: 18606 (45.94%) | Misses: 21894 (54.06%)
41000 Gets/sec | Hits: 32880 (80.20%) | Misses: 8120 (19.80%)
40250 Gets/sec | Hits: 35996 (89.43%) | Misses: 4254 (10.57%)
41000 Gets/sec | Hits: 38091 (92.90%) | Misses: 2909 (7.10%)
41000 Gets/sec | Hits: 38766 (94.55%) | Misses: 2234 (5.45%)
41000 Gets/sec | Hits: 39277 (95.80%) | Misses: 1723 (4.20%)
41000 Gets/sec | Hits: 39597 (96.58%) | Misses: 1403 (3.42%)
41000 Gets/sec | Hits: 39807 (97.09%) | Misses: 1193 (2.91%)
41000 Gets/sec | Hits: 39916 (97.36%) | Misses: 1084 (2.64%)
^C
# fg %1
./heap-allocs.ply
^C
@heap_allocs:
{ redis-cli      ,   215 }: 1027
</code></pre>
    <p class="normal">Notice that an instance of <code class="inlineCode">redis-cli</code> with PID <code class="inlineCode">215</code> performed <code class="inlineCode">1027</code> heap allocations. This concludes our coverage of Linux event tracing tools: Ftrace, LTTng, and eBPF. All of them require at least some kernel configuration to work. Valgrind offers more profiling tools that operate entirely from the comfort of user space.</p>
    <h1 id="_idParaDest-602" class="heading-1"><a id="_idTextAnchor698"/>Using Valgrind</h1>
    <p class="normal">I introduced <strong class="keyWord">Valgrind</strong> in <a href="Chapter_18.xhtml#_idTextAnchor581"><em class="italic">Chapter 18</em></a> as a tool for identifying memory problems using the <code class="inlineCode">memcheck</code> tool. Valgrind has other useful tools for application profiling. The two I am going to look at here are Callgrind and Helgrind. Since<a id="_idIndexMarker1532"/> Valgrind works by running the code in a sandbox, it can check the code as it runs and report certain behaviors, which native tracers and profilers cannot do.</p>
    <h2 id="_idParaDest-603" class="heading-2"><a id="_idTextAnchor699"/>Callgrind</h2>
    <p class="normal"><strong class="keyWord">Callgrind</strong> is a call graph-generating <a id="_idIndexMarker1533"/>profiler that also collects information about <a id="_idIndexMarker1534"/>processor cache hit rate and branch prediction. Callgrind is only useful if your bottleneck is CPU-bound. It’s not useful if heavy I/O or multiple processes are involved.</p>
    <p class="normal">Valgrind does not require kernel configuration, but it does need debug symbols. It is available as a target package in both The Yocto Project and Buildroot (<code class="inlineCode">BR2_PACKAGE_VALGRIND</code>).</p>
    <p class="normal">You run Callgrind in Valgrind on the target like so:</p>
    <pre class="programlisting con"><code class="hljs-con"># valgrind --tool=callgrind &lt;program&gt;
</code></pre>
    <p class="normal">This produces a file called <code class="inlineCode">callgrind.out.&lt;PID&gt;</code>, which you can copy to the host and analyze with <code class="inlineCode">callgrind_annotate</code>.</p>
    <p class="normal">The default is to capture data for all the threads together in a single file. If you add the <code class="inlineCode">--separate-threads=yes</code> option when <a id="_idIndexMarker1535"/>capturing, there will be profiles for each of the threads in files named <code class="inlineCode">callgrind.out.&lt;PID&gt;-&lt;thread id&gt;</code>.</p>
    <p class="normal">Callgrind can simulate the processor L1/L2 cache and report on cache misses. Capture the trace with the <code class="inlineCode">--simulate-cache=yes</code> option. L2 misses are much more expensive than L1 misses, so pay attention to code<a id="_idIndexMarker1536"/> with high <code class="inlineCode">D2mr</code> or <code class="inlineCode">D2mw</code> counts.</p>
    <p class="normal">The raw output from Callgrind can be overwhelming and difficult to untangle. A visualizer such as <strong class="keyWord">KCachegrind</strong> (<a href="https://kcachegrind.github.io/html/Home.html"><span class="url">https://kcachegrind.github.io/html/Home.html</span></a>) can help you navigate the mountains <a id="_idIndexMarker1537"/>of data Callgrind collects.</p>
    <h2 id="_idParaDest-604" class="heading-2"><a id="_idTextAnchor700"/>Helgrind</h2>
    <p class="normal"><strong class="keyWord">Helgrind</strong> is a thread-error detector for <a id="_idIndexMarker1538"/>detecting synchronization errors in C, C++, and Fortran programs that include POSIX threads.</p>
    <p class="normal">Helgrind can detect three classes<a id="_idIndexMarker1539"/> of errors. Firstly, it can detect the incorrect use of the API. Some examples are unlocking a mutex that is already unlocked, unlocking a mutex that was locked by a different thread, or not checking the return value of certain <code class="inlineCode">pthread</code> functions. Secondly, it monitors the order in which threads acquire locks to detect cycles that may result in deadlocks (also known as the deadly embrace). Finally, it detects data races, which can happen when two threads access a shared memory location without using suitable locks or other synchronization to ensure single-threaded access.</p>
    <p class="normal">Using Helgrind is simple; you just need this command:</p>
    <pre class="programlisting con"><code class="hljs-con"># valgrind --tool=helgrind &lt;program&gt;
</code></pre>
    <p class="normal">It prints problems and potential problems as it finds them. You can direct these messages to a file by adding <code class="inlineCode">--log-file=&lt;filename&gt;</code>.</p>
    <p class="normal">Callgrind and Helgrind rely on Valgrind’s virtualization for their profiling and deadlock detection. This heavyweight approach slows down the execution of your programs, increasing the likelihood of the observer effect.</p>
    <p class="normal">Sometimes the bugs in our programs are so reproducible and easy to isolate that a simpler, less invasive tool is enough to quickly debug them. That tool more often than not is <code class="inlineCode">strace</code>.</p>
    <h1 id="_idParaDest-605" class="heading-1"><a id="_idTextAnchor701"/>Using strace</h1>
    <p class="normal">I started the chapter with a<a id="_idIndexMarker1540"/> simple and ubiquitous tool, <code class="inlineCode">top</code>, and I will finish with another: <strong class="keyWord">strace</strong>. It is a very simple tracer that captures system calls made by a program and, optionally, its children. You can use it to do the following:</p>
    <ul>
      <li class="bulletList">Learn which system calls a program makes.</li>
      <li class="bulletList">Find those system calls that fail, together with the error code. I find this useful if a program fails to start but doesn’t print an error message or if the message is too general.</li>
      <li class="bulletList">Find which files a program opens.</li>
      <li class="bulletList">Find out which <code class="inlineCode">syscalls</code> a running program is making, for example, to see whether it is stuck in a loop.</li>
    </ul>
    <p class="normal">There are many more examples online. Just search for <code class="inlineCode">strace</code> tips and tricks. Everybody has a favorite <code class="inlineCode">strace</code> story, for example, <a href="https://alexbilson.dev/plants/technology/debug-a-program-with-strace/"><span class="url">https://alexbilson.dev/plants/technology/debug-a-program-with-strace/</span></a>.</p>
    <p class="normal"><code class="inlineCode">strace</code> uses the <code class="inlineCode">ptrace(2)</code> function to hook calls as they are made from user space to the kernel. If you want to know more <a id="_idIndexMarker1541"/>about how <code class="inlineCode">ptrace</code> works, the manual page is detailed and surprisingly readable.</p>
    <p class="normal">The simplest way to get a trace is to run the command as a parameter to <code class="inlineCode">strace</code> (the listing has been edited for clarity):</p>
    <pre class="programlisting con"><code class="hljs-con"># strace ./helloworld
execve("./helloworld", ["./helloworld"], [/* 14 vars */]) = 0
brk(0)                                  = 0x11000
uname({sys="Linux", node="beaglebone", ...}) = 0
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb6f40000
access("/etc/ld.so.preload", R_OK)      = -1 ENOENT (No such file or directory)
open("/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
fstat64(3, {st_mode=S_IFREG|0644, st_size=8100, ...}) = 0
mmap2(NULL, 8100, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb6f3e000
close(3)                                = 0
open("/lib/tls/v7l/neon/vfp/libc.so.6", O_RDONLY|O_CLOEXEC) = -1
ENOENT (No such file or directory)
&lt;…&gt;
open("/lib/libc.so.6", O_RDONLY|O_CLOEXEC) = 3
read(3, "\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0$`\1\0004\0\0\0"..., 512) = 512
fstat64(3, {st_mode=S_IFREG|0755, st_size=1291884, ...}) = 0
mmap2(NULL, 1328520, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6df9000
mprotect(0xb6f30000, 32768, PROT_NONE)  = 0
mmap2(0xb6f38000, 12288, PROT_READ|PROT_WRITE,
MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x137000) = 0xb6f38000
mmap2(0xb6f3b000, 9608, PROT_READ|PROT_WRITE,
MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xb6f3b000
close(3)
&lt;…&gt;
write(1, "Hello, world!\n", 14Hello, world!)         = 14
exit_group(0)                           = ?
+++ exited with 0 +++
</code></pre>
    <p class="normal">Most of the trace shows how the runtime environment is created. In particular, you can see how the library loader hunts for <code class="inlineCode">libc.so.6</code>, eventually finding it in <code class="inlineCode">/lib</code>. Finally, it gets to running the <code class="inlineCode">main()</code> function of the<a id="_idIndexMarker1542"/> program, which prints its message and exits.</p>
    <p class="normal">If you want <code class="inlineCode">strace</code> to follow any child processes or threads created by the original process, add the <code class="inlineCode">-f</code> option.</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">TIP</strong></p>
      <p class="normal">If you are using <code class="inlineCode">strace</code> to trace a program that creates threads, you almost certainly want to use the <code class="inlineCode">-f</code> option. Better still, use <code class="inlineCode">-ff</code> and -<code class="inlineCode">o &lt;file name&gt;</code> so that the output for each child process or thread is written to a separate file named <code class="inlineCode">&lt;filename&gt;.&lt;PID | TID&gt;</code>.</p>
    </div>
    <p class="normal">A common use of <code class="inlineCode">strace</code> is to discover which files a program tries to open at startup. You can restrict the system calls that are traced through the <code class="inlineCode">-e</code> option, and you can write the trace to a file instead of <code class="inlineCode">stdout</code> using the <code class="inlineCode">-o</code> option:</p>
    <pre class="programlisting con"><code class="hljs-con"># strace -e open -o ssh-strace.txt ssh localhost
</code></pre>
    <p class="normal">This shows the libraries and configuration files <code class="inlineCode">ssh</code> opens when it is setting up a connection.</p>
    <p class="normal">You can even use <code class="inlineCode">strace</code> as a basic profile tool. If you use the <code class="inlineCode">-c</code> option, it accumulates the time spent in system calls and prints out a summary like this:</p>
    <pre class="programlisting con"><code class="hljs-con"># strace -c grep linux /usr/lib/* &gt; /dev/null
% time     seconds  usecs/call     calls    errors syscall
------ ----------- ----------- --------- --------- ---------
<a id="_idTextAnchor702"/> 78.68    0.012825         1       11098      18    read
<a id="_idTextAnchor703"/> 11.03    0.001798         1        3551            write
<a id="_idTextAnchor704"/> 10.02    0.001634         8         216      15    open
  0.26    0.000043         0         202            fstat64
  0.00    0.000000         0         201            close
  0.00    0.000000         0          1             execve
  0.00    0.000000         0          1       1     access
  0.00    0.000000         0          3             brk
  0.00    0.000000         0         199            munmap
  0.00    0.000000         0          1             uname
  0.00    0.000000         0          5             mprotect
  0.00    0.000000         0         207            mmap2
  0.00    0.000000         0         15       15    stat64
  0.00    0.000000         0          1             getuid32
  0.00    0.000000         0          1             set_tls
------ ----------- ----------- --------- --------- ----------
100.00    0.016300                 15702      49 total
</code></pre>
    <p class="normal"><code class="inlineCode">strace</code> is extremely versatile. We have only scratched the surface of what the tool can do.</p>
    <p class="normal">I recommend <a id="_idIndexMarker1543"/>downloading <em class="italic">Spying on your programs with strace</em>, a free zine by Julia Evans available at <a href="https://wizardzines.com/zines/strace/"><span class="url">https://wizardzines.com/zines/strace/</span></a>.</p>
    <h1 id="_idParaDest-606" class="heading-1"><a id="_idTextAnchor705"/>Summary</h1>
    <p class="normal">Nobody can complain that Linux lacks options for profiling and tracing. This chapter has given you an overview of some of the most common ones.</p>
    <p class="normal">When faced with a system that is not performing as well as you would like, start with <code class="inlineCode">top</code> and try to identify the problem. If it proves to be a single application, then you can use <code class="inlineCode">perf record</code>/<code class="inlineCode">report</code> to profile it. Bear in mind that you will have to configure the kernel to enable <code class="inlineCode">perf</code> and you will need debug symbols for both the binaries and kernel. If the problem is not so well localized, use <code class="inlineCode">perf</code> or <code class="inlineCode">ply</code> to get a system-wide view.</p>
    <p class="normal">Ftrace comes into its own when you have specific questions about the behavior of the kernel. The <code class="inlineCode">function</code> and <code class="inlineCode">function_graph</code> tracers provide a detailed view of the relationship and sequence of function calls. The event tracers allow you to extract more information about functions, including the parameters and return values.</p>
    <p class="normal">LTTng performs a similar role, making use of the event trace mechanism, and adds high-speed ring buffers to extract large quantities of data from the kernel.</p>
    <p class="normal">Valgrind has the advantage of running code in a sandbox and can report on errors that are hard to track down in other ways. Using Callgrind, it can generate call graphs and report on processor cache usage, and with Helgrind, it can report on thread-related problems.</p>
    <p class="normal">Finally, don’t forget <code class="inlineCode">strace</code>. It is a good standby for finding out which system calls a program is making, from tracking file open calls to finding file pathnames and checking for system wake-ups and incoming signals.</p>
    <p class="normal">All the while, be aware of, and try to avoid, the observer effect by making sure that your measurements are valid for a production system. In the next chapter, we will delve into the latency tracers that help us quantify the real-time performance of a target system.</p>
    <h1 id="_idParaDest-607" class="heading-1"><a id="_idTextAnchor706"/>Further study</h1>
    <ul>
      <li class="bulletList"><em class="italic">Profiling and tracing with perf,</em> by Julia Evans</li>
      <li class="bulletList"><em class="italic">Systems Performance: Enterprise and the Cloud, Second Edition</em>, by Brendan Gregg</li>
      <li class="bulletList"><em class="italic">BPF Performance Tools: Linux System and Application Observability</em>, by Brendan Gregg</li>
      <li class="bulletList"><em class="italic">ply: lightweight eBPF tracing</em>, by Frank Vasquez: <a href="https://www.youtube.com/watch?v=GuEEJlU9Mr8"><span class="url">https://www.youtube.com/watch?v=GuEEJlU9Mr8</span></a></li>
      <li class="bulletList"><em class="italic">Spying on your programs with strace,</em> by Julia Evans</li>
    </ul>
  </div>
</div></div></body></html>