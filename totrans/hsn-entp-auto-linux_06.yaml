- en: Deployment Methodologies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, we have set the groundwork for a stable foundation for
    your Enterprise Linux environment. We have discussed in detail how to ensure your
    Linux environment lends itself well to automation through standardization and
    how to leverage Ansible and AWX to support you on your automation journey. Before
    we get started on the really detailed technical work in this chapter, we must
    take a look at one final piece of detail—your deployment methodology.
  prefs: []
  type: TYPE_NORMAL
- en: We have already established a need for a small number of consistent Linux builds
    for your environment. There is now a decision-making process for you to go through—how
    to deploy these builds across your enterprise. Most enterprises have several choices
    available to them, ranging from the easiest—downloading publicly available template
    images—through building their own templates, to perhaps the most complex—building
    from scratch using a pre-boot environment. Alternatively, the best approach might
    be some hybrid of these approaches. In this chapter, we will explore these options
    and understand how to ensure you are selecting the best one for your enterprise
    that supports you in your automation journey and is efficient and easy to implement.
    In subsequent chapters, we will then go into greater technical depth on each approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Knowing your environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping builds efficient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring consistency across Linux images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter assumes that you have access to a virtualization capable environment
    running Ubuntu 18.04 LTS. Some examples are also performed on CentOS 7\. In either
    of these cases, the examples can be run on either a physical machine (or laptop)
    running one of the aforementioned operating systems, with a process that has virtualization
    extensions enabled, or a virtual machine with nested virtualization enabled.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible 2.8 is also used later in this chapter and it is assumed you have this
    installed on the Linux host you are using.
  prefs: []
  type: TYPE_NORMAL
- en: All example code discussed in this book is available from GitHub at: [https://github.com/PacktPublishing/Hands-On-Enterprise-Automation-on-Linux](https://github.com/PacktPublishing/Hands-On-Enterprise-Automation-on-Linux).
  prefs: []
  type: TYPE_NORMAL
- en: Knowing your environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No two enterprise environments are the same. Some businesses still rely heavily
    on bare-metal servers, whilst others now rely on one of a myriad of virtualization
    or cloud providers (either private or public). Knowing which environments are
    available to you is a key part of the decision-making process.
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore the various environments and the relevant build strategies for
    each.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to bare-metal environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bare-metal environments are without a doubt the grandfather of all enterprise
    environments. Before the revolution in virtualization and then cloud technologies
    throughout the 21^(st) century, the only way to build an environment was on bare
    metal.
  prefs: []
  type: TYPE_NORMAL
- en: These days it is unusual to find an entire environment which is run on bare
    metal, though it is common to find ones where certain key components are run on
    physical hardware, especially databases or computational tasks that require certain
    physical hardware assistance (for example, GPU acceleration or hardware random
    number generation).
  prefs: []
  type: TYPE_NORMAL
- en: When building servers from bare metal, two fundamental approaches are suitable
    in most environments. The first is to build the servers manually using either
    optical media or, more commonly now, a USB drive. This is a slow, interactive
    process that is not repeatable at scale, and hence it is not recommended for any
    environments other than those containing just a handful of physical servers, where
    the requirement to build new machines is minimal and infrequent.
  prefs: []
  type: TYPE_NORMAL
- en: The other most viable option for building at scale in the repeatable, consistent
    manner that we have advocated throughout this book so far is to boot physical
    servers over the network, using a **Pre-eXecution Environment** (**PXE**). This
    involves loading a tiny boot environment from a network server, and then using
    this to load the Linux kernel and associated data. In this manner, it is possible
    to bring up an installation environment without the need for any form of physical
    media. Once the environment is up, we would use an unattended installation method
    to allow the installation to complete without any intervention from the user.
  prefs: []
  type: TYPE_NORMAL
- en: We will cover these methods in detail later in this book, as well as repeatable
    techniques for configuring the servers once they are built. In the meantime, however,
    it will suffice to simply state that, for building out physical Linux servers
    in an enterprise, PXE booting coupled with an unattended installation is the route
    that is easiest to automate and will produce the most repeatable results.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to traditional virtualization environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditional virtualization environments are those that predate what we know
    today as cloud environments—that is to say, they are straightforward hypervisors
    on which operating systems are run. Commercial examples such as VMware are common,
    as well as their open source counterparts such as Xen and KVM (and frameworks
    built off of these, such as oVirt).
  prefs: []
  type: TYPE_NORMAL
- en: As these technologies were originally built to supplement traditional physical
    environments, they present several possible options for building out your Enterprise
    Linux estate. For example, most of these platforms support the same network-booting
    capabilities as their bare-metal counterparts, and hence we could actually just
    pretend they are bare metal and continue with a network booting methodology.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, virtualized environments introduced something that was difficult to
    achieve in physical environments because of the differences in hardware between
    the bare-metal devices on which they all ran—templates. A templated virtual machine
    is quite simply a deployable snapshot of a preconfigured virtual machine. Hence,
    you might build out the perfect CentOS 7 image for your enterprise, integrate
    your monitoring platform, perform all of the security hardening required, and
    then, using tools built into the virtualization platform itself, turn it into
    a template. The following is a screenshot of the CentOS 7 templates in the author''s
    lab environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/18a0df96-60ff-4339-b5c5-04bc9318fdf6.png)'
  prefs: []
  type: TYPE_IMG
- en: Each of these templates is a fully configured CentOS 7 base image ready to be
    deployed, with all pre-deployment work such as removal of SSH host keys completed.
    As a result, all an administrator has to do is to select the appropriate template
    and click on the New VM button—the process will be similar in platforms other
    than RHV, as most mainstream virtualization solutions provide this functionality
    in some guise.
  prefs: []
  type: TYPE_NORMAL
- en: Note that, to keep the examples accessible, I have used the GUI as the primary
    process for creating a new VM. Nearly all virtualization and cloud platforms have
    APIs, command-line interfaces, and even Ansible modules that can be used to deploy
    virtual machines, and in an enterprise setting, these would scale far better than
    the GUI itself. Given the wide variety of environments available, this is left
    as an exercise for you to explore.
  prefs: []
  type: TYPE_NORMAL
- en: This is in itself a fairly straightforward process, but it requires a little
    care and attention. For example, nearly all Linux servers these days have SSH
    turned on, and the SSH daemon on each server has a unique host identification
    key that is used to prevent (amongst other things) man-in-the-middle attacks.
    If you template a preconfigured operating system, you will also template these
    keys, which means a distinct possibility of duplicates across your environment.
    This reduces security quite considerably. It is hence very important to perform
    several steps to prepare your virtual machine before turning it into a template,
    and one such common step is to delete the SSH host keys.
  prefs: []
  type: TYPE_NORMAL
- en: Servers created using the PXE method do not suffer from this problem, as they
    are all installed from scratch and hence there are no historic log entries to
    clean up and no duplicate SSH keys.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](3802fb48-9f14-4a52-98c5-280d381260a4.xhtml), *Using Ansible to
    Build Virtual Machine Templates for Deployment*, we will go into detail on creating
    virtual machine templates suitable for templating using Ansible. Although both
    the PXE boot and template deployment methodologies are equally valid for virtualized
    environments, most people find the templated route to be more efficient and easier
    to manage, and for this reason, I also advocate it (for example, most PXE boot
    environments need to know the MAC address of the network interface used on the
    physical or virtual server being deployed—this is not a necessary step in template
    deployment).
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to cloud environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most recent incumbent to Enterprise Linux architectures (barring of course
    containers, which is another discussion entirely) is the cloud provisioning environment.
    This might be through a *public cloud* solution such as **Amazon Web Services**
    (**AWS**), Microsoft Azure, **Google Cloud Platform** (**GCP**), or one of the
    myriad of smaller providers that have sprung up in recent years. It might equally
    be through an on-premise solution such as one of the variants of the OpenStack
    project or a proprietary platform.
  prefs: []
  type: TYPE_NORMAL
- en: These cloud environments have radically changed the life cycle of Linux machines
    in the enterprise. Whereas on bare-metal or traditional virtualized architectures,
    Linux machines were cared for, nurtured, and repaired if ever they failed, cloud
    architectures are built on the premise that each machine is more or less expendable,
    and that if it fails, a new one is simply deployed in its place.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, PXE deployment methodologies are not even possible in such environments,
    and instead they rely on pre-built operating system images. These are in essence
    just a template either created by a third-party vendor or prepared by the enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: Whether you go with a commercial provider or build an on-premise OpenStack architecture,
    you will find a catalog of available operating system images for you to choose
    from. Generally, those provided by the cloud provider themselves are trustworthy,
    though depending on your security requirements, you may find those provided by
    external parties suitable as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, here is a screenshot of the recommended operating system images
    available for OpenStack:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/27b9c9ea-b59a-4827-a9af-4813deb256ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from the table of contents, most of the major Linux distributions
    are represented here, which immediately saves you the task of building the basic
    operating system itself. The same is true of AWS:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d9bef8ae-be67-4214-a11d-793c794ae165.png)'
  prefs: []
  type: TYPE_IMG
- en: In short, if you are using a cloud environment, you will be spoiled for choice
    for base operating system images from which to get started. Even so, it is unlikely
    this choice will be sufficient for all enterprises. For example, using a pre-built,
    cloud-ready image does not negate requirements for things such as enterprise security
    standards, monitoring, or log forwarding agent integration, and a myriad of other
    things that are so important for the enterprise. Before we proceed, it is worth
    noting that you can, of course, create your own images for your chosen cloud platforms.
    In the interests of efficiency though, why re-invent the wheel? If someone has
    already completed this step for you, this is something that you can effectively
    delegate elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: Although most ready-made operating system images are trustworthy, you should
    always exercise caution when selecting a new one, especially if it has been created
    by an author you are unfamiliar with. There is no way to know for sure what the
    image comprises and you should always carry out due diligence when selecting an
    image to work with.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming that you do choose to proceed with a pre-made cloud-ready image, the
    post-installation configuration work can all be handled neatly by Ansible. In
    fact, the steps required are almost identical to those required to build templates
    for traditional virtualization platforms, and we shall again cover this process
    in detail a little later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Docker deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker deployments are a special case in our discussion on Linux environments.
    In practical terms, they share a lot in common with cloud environments—Docker
    images are built based upon pre-existing minimal OS images and are often built
    using the native Docker toolchains, though automation with Ansible is entirely
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: As Docker is a special case, we will not be focusing on it in this book, though
    it is important to note that Docker, being a recent incumbent into the presence
    of Linux in the enterprise, is actually designed around many of the principles
    we have already considered in this book. Let's briefly consider the Dockerfile
    used to create the official nginx container.
  prefs: []
  type: TYPE_NORMAL
- en: For those not familiar with Docker, a Dockerfile is a flat text file that contains
    all the directives and commands that are required to build up a container image
    for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing, this file contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Although not based on Ansible, we can see the following in the preceding code
    block:'
  prefs: []
  type: TYPE_NORMAL
- en: The `FROM` line near the top defines a minimal Ubuntu base image on which to
    perform the rest of the configuration—this can be thought of as your SOE Linux
    image that we have discussed for other platforms.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `RUN` command then performs the steps necessary to install the `nginx` package
    and perform some housekeeping to keep the image tidy and minimal (reducing space
    requirements and clutter).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The code then continues as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Continuing our analysis of this file, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The `VOLUME` line defines which directories from the host filesystem can be
    mounted within the container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `WORKDIR` directive tells Docker which directory to run the `CMD` that follows
    it in—think of it as a boot-time configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `CMD` line defines the command to run when the container starts—a microcosm
    of the process of defining which services will start at boot time in a full Linux
    system image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the `EXPOSE` lines define which ports the container should expose to
    the network—perhaps a little like a firewall might allow certain ports through.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In short, the native process to build a Docker container is very much aligned
    with our defined build process for an Enterprise Linux environment—hence, we can
    proceed in confidence with this process. With this in mind, we will now explore
    the process of ensuring our builds are as tidy and efficient as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping builds efficient
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Knowing the fundamentals of your Linux environment, as we discussed in the last
    section, is vital to working out your deployment methodology. Although there exist
    some similarities between the build processes themselves (especially between traditional
    hypervisors and cloud environments), knowing these differences enables you to
    make informed decisions about how to deploy Linux throughout your enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have chosen the methodologies most appropriate to your environment,
    it's important to consider a few principles to ensure your process is streamlined
    and efficient (again, bywords of Enterprise Linux deployments). We will cover
    these here to proceed into the real in-depth, hands-on work in the remainder of
    this book. Let's get started by looking at the need for simplicity in our builds.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping your builds simple
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start to put some practical application of our earlier discussion on the
    importance of SOEs to our Linux build processes. Whatever route you choose and
    whatever your environment looks like, one key facet you should consider is to
    keep your build standard as simple and concise as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'No two enterprise environments are the same, and hence the build requirements
    for each enterprise will certainly be different. Nonetheless, a common set of
    example requirements is given here to demonstrate the kinds of things that will
    be needed in the build process:'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring agents
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log forwarding configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security hardening
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Core enterprise software requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NTP configuration for time synchronization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This list is just a start, and every enterprise will be different, but it gives
    you an idea of the kinds of things that will go into a build. However, let's start
    to look at some of the edge cases to your build process. It is fair to say that
    each Linux server will be built with a purpose in mind and, as such, will run
    some form of application stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, the application stack is certain to vary between enterprises, but examples
    of the kinds of applications that might commonly be required are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A web server such as Apache or nginx
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The OpenJDK environment for Java workloads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A MariaDB database server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A PostgreSQL database server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NFS file-sharing tools and kernel extensions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, in your standardization process, when you originally defined your SOE,
    you may even have gone to the lengths of already specifying the use of (just as
    an example) OpenJDK 8 and MariaDB 10.1\. Does this mean you should actually include
    these in your build process?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is almost always, *no*. Quite simply, adding these applications adds
    to the complexity of the build and to post-install configuration and debugging.
    It also reduces security—but more on that shortly.
  prefs: []
  type: TYPE_NORMAL
- en: Let's suppose we standardize on MariaDB 10.1 and include that in our base operating
    system image (and hence every single Linux machine deployed contains it), knowing
    that only a subset of the machines in operation will actually ever use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several reasons for not including MariaDB in the base image:'
  prefs: []
  type: TYPE_NORMAL
- en: An install of just the server components of MariaDB 10.1 takes around 120 MB,
    depending on your operating system and packaging—there will also be dependency
    packages but let's just start with this. Although storage is cheap and plentiful
    these days, if you deploy 100 servers across your environment (actually a small
    number for most enterprises), that's approximately 11.7 GB of space dedicated
    to a package you don't need. The actual figure will be far higher as there will
    be dependency packages to install and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This may also have a knock-on effect on backups and the storage required for
    these, and indeed any virtual machine snapshots if you use that in the enterprise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If an application arrives that requires MariaDB 10.3 (or indeed, the business
    decides to update its standard to 10.3), then the images need to be upgraded or
    possibly version 10.1 uninstalled before 10.3 is installed. This is an unnecessary
    level of complexity when a minimal Linux image could just have received an updated
    MariaDB workload.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to ensure that MariaDB is turned off and firewalled off when not required
    to as to prevent any misuse—this is an additional auditing and enforcement requirement
    that again is unnecessary on many servers where MariaDB isn't used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are other security considerations too, but the key message here is that
    it is wasteful on resources and time. This doesn't, of course, only apply to MariaDB
    10.1—that is simply an example, but it serves to show that, as a rule, application
    workloads should not be included in the base operating system definition. Let's
    take a more detailed look at the security requirements for our builds now.
  prefs: []
  type: TYPE_NORMAL
- en: Making your builds secure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already touched on security and not installing or running unnecessary
    packages. Any running service provides a potential attack vector for an intruder,
    and whilst hopefully, you will never have one inside your enterprise network,
    it is still good practice to build the environment in a manner that is as secure
    as possible. This is especially true of services that come configured with default
    passwords (and in some cases, with no password configured at all—though this is
    thankfully becoming rare now).
  prefs: []
  type: TYPE_NORMAL
- en: These principles apply when defining the build itself too. Don't create a build
    with weak static passwords, for example. Ideally, every build should be configured
    to obtain even initial credentials from an external source, and although there
    are a myriad of ways to achieve this, you are encouraged to look up `cloud-init`
    if this is a new concept to you. There are cases, especially in legacy environments,
    where you may need some initial credentials to allow access to the newly built
    server, but reusing weak passwords is dangerous and opens up the possibility of
    the newly built server being intercepted before it is configured and some kind
    of malware planted on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, the following list provides some sound guidance on ensuring secure
    builds:'
  prefs: []
  type: TYPE_NORMAL
- en: Don't install applications or services that are not required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do ensure services that are common to all builds but require post-deployment
    configuration are disabled by default.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't re-use passwords even for initial access and configuration if at all possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do apply your enterprise security policy as early as possible in the process—in
    the build process of the image or server if possible, but if not, as soon as possible
    after installation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These principles are simple yet fundamental, and it is important to adhere to
    them. Hopefully, a situation will never arise where it matters that they have
    been applied, but if it does, they might just stop or sufficiently impede an intrusion
    or attack on your infrastructure. This, of course, is a topic that deserves its
    own book, but it is hoped these pointers, along with the examples in [Chapter
    13](3d4a9c0a-452f-4fbb-85c8-372149303613.xhtml), *Using CIS Benchmarks*, will
    point you in the right direction. Let's take a brief look now at ensuring our
    build processes are efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Creating efficient processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Efficient processes are supported heavily by automation, as this ensures minimal
    human involvement and consistent, repeatable end results. Standardization also
    supports this, as it means that much of the decision-making process has already
    been completed, and so all people involved know exactly what they are doing and
    how it should be done.
  prefs: []
  type: TYPE_NORMAL
- en: In short, stick to these principles outlined in this book and your build processes
    will, by their very nature, be efficient. Some degree of manual intervention is
    inevitable, even if it involves choosing a unique hostname (though this can be
    automated) or perhaps the process of a user requesting a Linux server in the first
    place. However, from here, you want to automate and standardize wherever possible.
    We will follow this mantra throughout this book. For now, though, we will take
    a look at the importance of consistency in our build processes.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring consistency across Linux images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 1](c7596fb8-4971-44d7-943a-7660c5eecb17.xhtml), *Building a Standard
    Operating Environment on Linux*, we discussed the importance of commonality in
    SOE environments. Now that we are actually looking at the build process itself,
    this comes back to the fore as we are, for the first time, looking at how to actually
    implement commonality. Assuming Ansible is your tool of choice, consider the following
    task. We are writing playbooks for our image build process and have decided that
    our standard image is to synchronize its time with our local time server. Suppose
    that our base operating system of choice is Ubuntu 16.04 LTS for historic reasons.
  prefs: []
  type: TYPE_NORMAL
- en: Let's create a simple role to ensure NTP is installed and to copy across our
    corporate standard `ntp.conf`, which includes the addresses of our in-house time
    servers. Finally, we need to restart NTP to pick up the changes.
  prefs: []
  type: TYPE_NORMAL
- en: The examples in this chapter are purely hypothetical and given to demonstrate
    what Ansible code for a given purpose might look like. We will expand on the tasks
    performed (such as deploying configuration files) in detail in later chapters
    and provide hands-on examples for you to try out.
  prefs: []
  type: TYPE_NORMAL
- en: 'This role could look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This role is simple, concise, and to the point. It always ensures the `ntp` package
    is installed, and also ensures we are copying across the same version of our configuration
    file, making sure it is the same on every server. We could improve this further
    by checking this file out of a version control system, but that is left as an
    exercise for you.
  prefs: []
  type: TYPE_NORMAL
- en: Instantly, you can see the power of writing an Ansible role for this one simple
    step—there is great consistency to be achieved from including this role in a playbook, and
    if you scale this approach up to your entire enterprise, then all configured services
    will be consistently installed and configured.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it gets better. Let''s say that the business decides to rebase the
    standard operating system to Ubuntu 18.04 LTS to make use of newer technologies
    and increase the supported lifespan of the environment. The `ntp` package is still
    available on Ubuntu 18.04, though by default, the `chrony` package is now installed.
    To proceed with NTP, the role would need only minor tweaks to simply ensure that `chrony` is
    removed first (or you could disable it if you prefer)—after this, it is identical,
    for example, consider the following role code that ensures the correct packages
    are absent and present:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We would then continue this code by adding two further tasks that copy across
    the configuration and restart the service to ensure it picks up the new configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we could decide to embrace this change and make use of `chrony` on
    the new base image. Hence, we would simply need to create a new `chrony.conf` to
    ensure it talks to our enterprise NTP servers, and then proceed exactly as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Notice how similar these roles all are? Only minor changes are required even
    when supporting a change in the base operating system or even underlying service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although these three roles differ in places, they are all performing the same
    basic tasks, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that the correct NTP service is installed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy across the standard configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure the service is enabled at boot time and has started.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hence, we can be sure that, using this approach, we have consistency.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even when changing the platform entirely, the high-level approach can still
    be applied. Let''s say that the enterprise has now taken on an application that
    is only supported on CentOS 7\. This means an accepted deviation to our SOE, however,
    even our new CentOS 7 build will need to have the correct time, and as NTP is
    a standard, it will still use the same time servers. Hence, we can write a role
    to support CentOS 7:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Again, the changes are incredibly subtle. This is a significant part of the
    reason for embracing Ansible as our automation tool of choice for enterprise automation—we
    can build and adhere to our standards with great ease, and our operating system
    builds are consistent if we change the version or even the entire distribution
    of Linux we are using.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this stage, we have defined our requirement for standardization, established
    which tools to use in our journey toward automation, and now taken a practical
    look at the fundamental types of environments into which enterprises can expect
    to deploy an operating system. This has set the groundwork for our automation
    journey and has provided us with the context for the rest of this book—a hands-on
    journey through the process of building and maintaining a Linux environment in
    the enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we learned about the different types of environments into which
    Linux might be deployed and the different build strategies available to each.
    We then looked at some practical examples of ensuring that our builds are of a
    high standard and can be completed efficiently and repeatably. Finally, we started
    to look at the benefits of automation and how it can ensure consistency across
    builds, even when we change the entire underlying Linux distribution.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will begin our hands-on journey into Enterprise Linux
    automation and deployments, looking at how Ansible can be employed to build out
    virtual machine templates, whether from cloud environment images or from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the similarities between building a Docker container and an SOE?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why would you not include MariaDB in your base build if it is only required
    on a handful of servers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How would you ensure your base operating system image is as small as possible?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why should you be careful about embedding passwords in your base operating system
    image?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How would you ensure all Linux images send their logs to your centralized logging
    server?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When would you not use a base image provided by a cloud provider and build your
    own instead?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How would you secure your SSH daemon configuration using Ansible?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For an in-depth understanding of Ansible, please refer to *Mastering Ansible,
    Third Edition* by *James Freeman* and *Jesse Keating* ([https://www.packtpub.com/gb/virtualization-and-cloud/mastering-ansible-third-edition](https://www.packtpub.com/gb/virtualization-and-cloud/mastering-ansible-third-edition)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To gain an understanding of the Docker code and discussion in this chapter,
    please refer to *Mastering Docker, Third Edition* by *Russ McKendrick* and *Scott
    Gallagher* ([https://www.packtpub.com/gb/virtualization-and-cloud/mastering-docker-third-edition](https://www.packtpub.com/gb/virtualization-and-cloud/mastering-docker-third-edition)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
