- en: '22'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Troubleshooting Ubuntu Servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we’ve covered many topics surrounding Ubuntu Server and worked on some
    really fun projects. We’ve set up web servers, built automation, and even created
    infrastructure in the cloud. As the applications and services you’ve implemented
    age, your organization may depend on them more and more. But what happens if something
    your organization relies on suddenly becomes unavailable? What do you do when
    things don’t quite go according to plan?
  prefs: []
  type: TYPE_NORMAL
- en: While it’s impossible for us to account for every possible problem that may
    come up, there are some common places to look for clues when you run into a problem.
    In this chapter, we’ll take a look at some common starting points and techniques
    that you can utilize when it comes to troubleshooting issues with your servers.
    Building solid troubleshooting skills is an important focus, and with the concepts
    explored here, you’ll be well on your way.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the scope
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conducting a root cause analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewing system logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracing network issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting resource issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagnosing defective RAM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first step with regards to troubleshooting is to analyze the problem and
    determine how critical a problem it may be. In the next section, we’ll explore
    how to do just that.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the scope
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a problem occurs within your servers or network, your systems will exhibit
    one or more symptoms. Perhaps an application is much slower than normal, maybe
    users are unable to access the network, or a server suffers from total failure.
    There are many problems that can come up at any time, and it can be challenging
    to keep up.
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve identified the symptoms of the problem, the next goal is to identify
    the overall scope. Essentially, this means determining (as best you can) where
    the problem is most likely to reside, and how many systems and services are affected.
    Sometimes the root cause is obvious. For example, if none of your computers are
    receiving an IP address from your DHCP server, then you’ll know straight away
    to start investigating the logs on that particular server concerning its ability
    (or inability) to do the job designated for it. In other cases, the cause may
    not be so obvious. Perhaps you have an application that exhibits problems every
    now and then but isn’t something you can reliably reproduce. In that case, it
    may take some digging before you know just how large the scope of the problem
    might be. Sometimes, the culprit is the last thing you expect.
  prefs: []
  type: TYPE_NORMAL
- en: Each component on your network works together with other components, or at least
    that’s how it should be. A network of Linux servers, just as with any other network,
    is a collection of services (daemons) that complement and often depend upon one
    another. For example, DHCP assigns IP addresses to all of your hosts, but it also
    assigns their default DNS servers as well. If your DNS server has encountered
    an issue, then your DHCP server would essentially be assigning a non-working DNS
    server to your clients. Identifying the problem space means that after you identify
    the symptoms, you’ll also work toward reaching an understanding of how each component
    within your network contributes to (or is affected by) the problem.
  prefs: []
  type: TYPE_NORMAL
- en: With regards to the scope, we identify how far the problem reaches, as well
    as how many users or systems are affected by the issue. Perhaps just one user
    is affected, or an entire subnet. This will help you determine the priority of
    the issue and decide whether this is something essential that you need to fix
    now, or something that can wait until later. Often, prioritizing is half the battle;
    sometimes a user will even be under the impression that their issues are more
    important than others. Use your best judgment.
  prefs: []
  type: TYPE_NORMAL
- en: 'When identifying the scope, you’ll want to answer the following questions as
    best as you can:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the symptoms of the issue?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When did this problem first occur?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Were there any changes made within the network around that time?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Has this problem happened before? If so, what was done to fix it last time?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which servers or nodes are impacted by this issue?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many users are impacted?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the problem is limited to a single machine, then a few really good places
    to start poking around is to check who is logged in to the server and which commands
    have recently been entered. Quite often, I’ve found the culprit just by checking
    the Bash history for logged-on users (or users that have recently logged in).
    With each user account, there should be a .bash_history file in their home directory.
    Within this file is a list of commands that were recently entered. Check this
    file and see if anyone modified anything recently. I can’t tell you how many times
    this alone has led directly to the answer. And what’s even better, sometimes the
    Bash history leads to the solution. If a problem has occurred before and someone
    has already fixed it at some point in the past, chances are their efforts were
    recorded in the Bash history, so you can see what the previous person did to solve
    the problem just by looking at it.
  prefs: []
  type: TYPE_NORMAL
- en: To view the Bash history, you can either view the contents of the .bash_history
    file in a user’s home directory, or you can simply execute the history command
    as that user.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, if you check who is currently logged into the server, you may
    be able to pinpoint if someone is working on an issue already, or perhaps something
    they’re doing caused the issue in the first place. If you enter the `w` command,
    you can see who is logged in to the server currently. In addition, you’ll also
    see the IP address of the user that’s logged in when you run this command. Therefore,
    if you don’t know who corresponds to a user account listed when you run the `w`
    command, you can check the IP address in your DHCP server to find out who the
    IP address belongs to, so you can ask that person directly. In a perfect world,
    other administrators will send out a departmental email when they work on something
    to make sure everyone is aware. Unfortunately, many don’t do this. By checking
    the logged-in users as well as their Bash history, you’re well on your way to
    determining where the problem originated.
  prefs: []
  type: TYPE_NORMAL
- en: After identifying the problem space and the scope, you can begin narrowing down
    the issue to help find a cause. Sometimes, the culprit will be obvious. If a website
    stopped working and you noticed that the Apache configuration on your web server
    was changed recently, you can attack the problem by investigating the change and
    who made it.
  prefs: []
  type: TYPE_NORMAL
- en: If the problem is a network issue, such as users not being able to visit websites,
    the potential problem space is much larger. Your internet gateway may be malfunctioning,
    your DNS or DHCP server may be down, your internet provider could be having issues,
    or perhaps your accounting department simply forgot to pay the internet bill.
    As long as you are able to determine a potential list of targets to focus your
    troubleshooting on, you’re well on your way to finding the issue. As we go through
    this chapter, I’ll talk about some common issues that can come up and how to deal
    with them.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the scope of the problem helps us understand just how severe it
    may be and the number of systems and users impacted, and sometimes, investigating
    the scope can lead you to the root cause of the problem. If you don’t already
    know the underlying cause, you can conduct a root cause analysis to attempt to
    find the source of the problem. That’s what we’ll explore next.
  prefs: []
  type: TYPE_NORMAL
- en: Conducting a root cause analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you resolve a problem on your server or network, you’ll immediately revel
    in the awesomeness of your troubleshooting skills. It’s a wonderful feeling to
    have fixed an issue, becoming the hero within your technology department. But
    you’re not done yet. The next step is looking toward preventing this problem from
    happening again. It’s important to look at how the problem started as well as
    steps you can take in order to help stop the problem from occurring again. This
    is known as a **root cause analysis**. A root cause analysis may be a report you
    file with your manager or within your knowledge-base system, or it could just
    be a memo you document for yourself. Either way, it’s an important learning opportunity.
  prefs: []
  type: TYPE_NORMAL
- en: A good root cause analysis has several sides to the equation. First, it will
    demonstrate the events that led to the problem occurring in the first place. Then,
    it will contain a list of steps that you’ve completed to correct the problem.
    If the problem is something that could potentially recur, you would want to include
    information about how to prevent it from happening again in the future.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with a root cause analysis is that it’s rare that you can be 100
    percent accurate. Sometimes, the root cause may be obvious. For example, suppose
    a user named `Bob` deleted an entire directory that contained files important
    to your company. If you log into the server and check the logs, you can see that
    `Bob` not only logged into the server near the time of the incident, but his Bash
    history literally shows him running the `rm -rf /work/important-files` command.
    At this point, the case is closed. You figured out how the problem happened and
    who did it, and you can restore the files from your most recent backup. But a
    root cause is usually not that cut and dry.
  prefs: []
  type: TYPE_NORMAL
- en: One example I’ve personally encountered was a pair of **Virtual Machine** (**VM**)
    servers that were “fencing.” At a company I once worked for, our Citrix-based
    VM servers (which were part of a cluster) both went down at the same time, taking
    every Linux VM down with them. When I attached a monitor to them, I could see
    them both rebooting over and over. After I got the servers to settle down, I started
    to investigate deeper. I read in the documentation for Citrix XenServer that you
    should never install a cluster of anything less than three machines because it
    can create a situation exactly like the one I experienced. We only had two servers
    in that cluster, so I concluded that the servers were set up improperly and the
    company would need a third server if they wanted to cluster them.
  prefs: []
  type: TYPE_NORMAL
- en: The problem though is that this root cause analysis wasn’t 100 percent perfect.
    Were the servers having issues because they needed a third server? The documentation
    did mention that three servers were a minimum, but there’s no way to know for
    sure that was the reason the problem started. However, not only was I not watching
    the servers when it happened, but I also wasn’t the individual who set them up;
    that person had already left the company. There was no way I could reach an absolute
    conclusion, but my root cause analysis was sound in the sense that it was the
    most likely explanation (that we weren’t using best practices). Someone could
    counter my root cause analysis with “but the servers were running fine that way
    for several years.” True, but nothing is absolute when dealing with technology.
    Sometimes, you never really know. The only thing you can do is make sure everything
    is set up properly according to the guidelines set forth by the manufacturer.
  prefs: []
  type: TYPE_NORMAL
- en: A good root cause analysis is as sound in logic as it can be, though not necessarily
    bulletproof. Correlating system events to symptoms is often a good first step
    but is not necessarily perfect. After investigating the symptoms, solving the
    issue, and documenting what you’ve done to rectify it, sometimes the root cause
    analysis writes itself. Other times, you’ll need to read the documentation and
    ensure that the configuration of the server or daemon that failed was implemented
    along with best practices. In a worst-case scenario, you won’t really know how
    the problem happened or how to prevent it, but it should still be documented in
    case other details come to light later. And without documentation, you’ll never
    gain anything from the situation.
  prefs: []
  type: TYPE_NORMAL
- en: 'A root cause analysis should include details such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A description of the issue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which application or piece of hardware encountered a fault
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The date and time the issue was first noticed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What you found while investigating the issue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What you’ve done to resolve the issue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What events, configurations, or faults caused the issue to happen
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A root cause analysis should be used as a learning experience. Depending on
    what the issue was, it may serve as an example of what not to do, or what to do
    better. In the case of my VM server fiasco, the moral of the story was to follow
    best practices from Citrix and use three servers for the cluster instead of two.
    Other times, the end result may be another technician not following proper directives
    or making a mistake, which is unfortunate. In the future, if the issue were to
    happen again, you’ll be able to look back and remember exactly what happened last
    time and what you did to fix it. This is valuable, if only because we’re all human
    and prone to forgetting important details after a time. In an organization, a
    root cause analysis is valuable to show stakeholders that you’re able to not only
    address a problem but are reasonably able to prevent it from happening again.
  prefs: []
  type: TYPE_NORMAL
- en: Often, log files are a great place to find clues, as quite a bit of information
    surrounding system and application events are stored there. In the next section,
    we’ll explore log files in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing system logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you’re having trouble finding the root cause, or you just want more information
    regarding a problem that occurred, consider looking through log files. Linux has
    great logging capabilities, and many of the applications you may be running are
    writing log files as events happen. If there’s an issue, you may be able to find
    information about it within an application’s logs.
  prefs: []
  type: TYPE_NORMAL
- en: There are two primary methods of viewing logs. Historically, for most of Ubuntu’s
    life, you could simply inspect the log files that are stored within the `/var/log`
    directory. The files contained within that directory are standard files and directories,
    so you can use commands you’ve used in the past to view the contents of text files
    to view the contents of the log files within the `/var/log` directory as well.
    This method of viewing log files is slowly being aged out; however, the majority
    of applications still store their log files within that directory, even today.
  prefs: []
  type: TYPE_NORMAL
- en: 'The newer method of viewing logging information for an application is to use
    the `journalctl` command. This command is part of `systemd`, and it’s dedicated
    to the purpose of viewing logs. To use the `journalctl` command to check the status
    of a running service, you provide it the `-u` option, along with the name of a
    service you’d like to check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'With that example, we’re attempting to view logging information for the `ssh`
    service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_22_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22.1: Viewing logging information via the `journalctl` command'
  prefs: []
  type: TYPE_NORMAL
- en: The `-u` option is required and tells the `journalctl` command that you’d like
    to check on a service. So in the previous example, we provided `ssh` as an argument
    for what we wanted to find logging information on. The name of the unit (or service)
    will be the same as it is when you’re starting, stopping, or restarting a service
    with the `systemctl` command. I recommend making the `journalctl` command your
    first consideration when checking logging information on a Linux system.
  prefs: []
  type: TYPE_NORMAL
- en: If you also add the `-f` option in addition to the `-u` option, the output will
    continue to scroll as new information is added to the logs for the particular
    service you’re checking. This is very useful if you want to follow along with
    what’s going on with a service as new events occur.
  prefs: []
  type: TYPE_NORMAL
- en: However, not all services log information via `journalctl`, so understanding
    the legacy approach to viewing log files is also important. Inside the `/var/log`
    directory, you’ll see a handful of logs you can view, which differs from server
    to server depending on which applications are installed. In quite a few cases,
    an installed application will create its own log file somewhere within `/var/log`,
    either in a log file or a log file within a subdirectory of `/var/log`. For example,
    once you install Apache, it will create log files in the `/var/log/apache2` directory,
    and looking through those logs may give you a hint as to what may be going on
    if the problem is related to your web server. These are known as **Application
    Logs**, which are basically log files created by an application and not the distribution.
    There are also **System Logs**, which are the log files created by the distribution
    and allow you to view system events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Viewing a log file stored within the `/var/log` directory can be done in several
    ways. One way is to use the `cat` command along with the path and filename of
    a log file. For example, the Apache access log can be viewed with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Some log files are restricted and need `root` privileges in order to access
    them. If you get a permission denied error when attempting to view a log, use
    `sudo` in front of any of the commands in this section to view the file.
  prefs: []
  type: TYPE_NORMAL
- en: One problem with the `cat` command is that it will print out the entire file,
    no matter how big it is. It will scroll by your terminal and if the file is large,
    you won’t be able to see all of it. In addition, if your server is already taxed
    when it comes to performance, using `cat` can actually tie up the server for a
    bit in a case where the log file is massive. This will cause you to lose control
    of your shell until the file stops printing. You can press *Ctrl + c* to stop
    printing the log file, but the server may end up being too busy to respond to
    *Ctrl + c* and show the entire file anyway.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another method is to use the `tail` command. By default, the `tail` command
    shows you the last ten lines of a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If you wish to see more than the last ten lines, you can use the `-n` option
    to specify a different amount. To view the last `100` lines, we would use the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Perhaps one of the most useful features of the `tail` command is the `-f` option,
    which allows you to follow a log file. Basically, this means that as entries are
    written to the log file, it will scroll by in front of you. It’s close to watching
    the log file in real time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Once you start using the `follow` option, you’ll wonder how you ever lived without
    it. If you’re having a specific problem that you are able to reproduce, you can
    watch the log file for that application and see the log entries as they appear
    while you’re reproducing the issue. In the case of a DHCP server not providing
    IP addresses to clients, you can view the output of the `/var/log/syslog` file
    (the `isc-dhcp-server` daemon doesn’t have its own log file), and you can see
    any errors that come up as your clients try to re-establish their DHCP lease,
    allowing you to see the problem as it is happening.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful command for viewing logs is `less`. The `less` command allows
    you to scroll through a log file with the page up and page down keys on your keyboard,
    which makes it more useful for viewing log files than the `cat` command. You can
    press *q* to exit the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: So now that you know a few ways in which you can view these files, which files
    should you inspect? Unfortunately, there’s no one rule, as each application handles
    its logging differently. Some daemons have their own log file stored somewhere
    in `/var/log`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, a good place to check is in that directory, to see if there is a
    log file with the name of the daemon. Some daemons don’t even have their own log
    file and will use `/var/log/syslog` instead. You may try viewing the contents
    of the file while using `grep` to find messages related to the daemon you’re troubleshooting.
    In regard to the `isc-dhcp-server` daemon, the following would narrow down the
    `syslog` to messages from that specific daemon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: While troubleshooting security issues, the log file you’ll definitely want to
    look at is the **Authorization Log**, located at `/var/log/auth.log`. You’ll need
    to use the `root` account or `sudo` to view this file. The authorization log includes
    information regarding authentication attempts to the server, including logins
    from the server itself, as well as logins over OpenSSH. This is useful for several
    reasons, among them the fact that if something really bad happens on your server,
    you can find out who logged in to the server around that time. In addition, if
    you or one of your users is having trouble accessing the server via OpenSSH, you
    may want to look at the authorization log for clues, as additional information
    for OpenSSH failures will be logged there. Often, the `ssh` command may complain
    about permissions of key files not being correct, which would give you an answer
    as to why public key authentication stopped working, as OpenSSH expects specific
    permissions for its files. For example, the private key file (typically `/home/<user>/.ssh/id_rsa`)
    should not be readable or writable by anyone other than its owning user. You’d
    see errors within `/var/log/auth.log` mentioning such a thing if that were the
    case.
  prefs: []
  type: TYPE_NORMAL
- en: Another use case for checking `/var/log/auth.log` is for security, as a high
    number of login attempts may indicate an intrusion attempt. (Hopefully, you have
    Fail2ban installed, which we went over in the last chapter.) An unusually high
    number of failed password attempts may indicate someone trying to log in to the
    server by brute force. That would definitely be a cause for concern, and you’d
    want to block their IP address immediately.
  prefs: []
  type: TYPE_NORMAL
- en: The **System Log**, located in `/var/log/syslog`, contains logging information
    for quite a few different things. It’s essentially the Swiss Army knife of Ubuntu’s
    logs. If a daemon doesn’t have its own log file, chances are its logs are being
    written to this file. In addition, information regarding cron jobs will be written
    here, which makes it a candidate to check when a cron job isn’t being executed
    properly. The `dhclient` daemon, which is responsible for grabbing an IP address
    from a DHCP server, is also important.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll be able to see from `dhclient` events within the system log when an IP
    address is renewed, and you can also see messages relating to failures if it’s
    not able to obtain an IP address. Also, the `systemd init` daemon itself logs
    here, which allows you to see messages related to server startup as well as applications
    it’s trying to run.
  prefs: []
  type: TYPE_NORMAL
- en: Another useful log is the `/var/log/dpkg.log` file, which records log entries
    relating to installing and upgrading packages. If a server starts misbehaving
    after you roll out updates across your network, you can view this log to see which
    packages were recently updated. This log will not only give you a list of updated
    or installed packages, but also a timestamp from when the installation occurred.
    If a user installed an unauthorized application, you can correlate this log to
    the authentication log to determine who logged in around that time, and then you
    can check that user’s Bash history to confirm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Often, log files will get rotated after some time by a utility known as `logrotate`.
    Inside the `/var/log` directory, you’ll see several log files with a `.gz` extension,
    which means that the original log file was compressed and renamed, and a new log
    file was created in its place. For example, you’ll see the `syslog` file for the
    system log in the `/var/log` directory, but you’ll also see files named with a
    number and a `.gz` extension as well, such as `syslog.2.gz`. These are compressed
    logs. Normally, you’d view these logs by uncompressing them and then opening them
    via any of the methods mentioned in this section. An easier way to do so is with
    the `zcat` command, which allows you to view compressed files immediately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: There’s also `zless`, which serves a similar purpose as the `less` command.
  prefs: []
  type: TYPE_NORMAL
- en: Another useful command for checking logging information is `dmesg`. Unlike other
    log files, `dmesg` is literally its own command, and you can execute it from anywhere
    in the filesystem. The `dmesg` command allows you to view log entries from the
    Linux kernel’s ring buffer, which can be very useful when troubleshooting hardware
    issues (such as seeing which disks were recognized by the kernel). When troubleshooting
    hardware, the system log is also helpful, but using the `dmesg` command may be
    a good place to check as well.
  prefs: []
  type: TYPE_NORMAL
- en: As I mentioned earlier, on an Ubuntu system, there are two types of log files,
    system logs and application logs. System logs, such as `auth.log` and `dpkg.log`,
    detail important system events and aren’t specific to any one particular application.
    Application logs become installed when you install their parent packages, such
    as Apache or MariaDB. Application logs create log entries into their own log file.
  prefs: []
  type: TYPE_NORMAL
- en: Some daemons you install will not create their own application log, such as
    `isc-dhcp-server`. Since there’s no general rule when it comes to which applications
    log is where, the first step in finding a log file is to see if the application
    you want log entries from creates its own log file. If not, it’s likely using
    a system log.
  prefs: []
  type: TYPE_NORMAL
- en: When faced with a problem, it’s important to practice viewing log files at the
    same time as you try and reproduce the problem. Using `follow` mode with `tail`
    (`tail -f`) works very well for this, as you can watch the log file generate new
    entries as you try and reproduce the issue. This technique works very well in
    almost any situation where you’re dealing with a misbehaving daemon. This technique
    can also help narrow down hardware issues. For example, I once dealt with an Ubuntu
    system where when I plugged in a flash drive, nothing happened. When I followed
    the log as I inserted and removed the flash drive, I saw the system log update
    and recognize each insertion and removal. So clearly, the Linux kernel itself
    saw the hardware and was prepared to use it. This helped me narrow down the problem
    to being that the desktop environment I was using wasn’t updating to show the
    inserted flash drive, but my hardware and USB ports were operating perfectly fine.
    With one command, I was able to determine that the issue was a software problem
    and not related to hardware.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, Ubuntu contains very helpful log files that will aid you in
    troubleshooting your servers. Often, when you’re faced with a problem, viewing
    relevant log entries and then conducting a Google search regarding them will result
    in a useful answer, or at least bring you to a bug report to let you know the
    problem isn’t just limited to you or your configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, your search results will lead you right to the answer, or at least
    to a workaround. From there, you can continue to work through the problem until
    it is solved.
  prefs: []
  type: TYPE_NORMAL
- en: What about network issues? Tracking down the root cause of an issue on the network
    can be especially challenging, but it’s not as difficult as it may seem. In the
    next section, we’ll take a look at a few ways you can trace network issues.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing network issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s amazing how important TCP/IP networking is to the world today. Of all the
    protocols in use in modern computing, it’s by far the most widespread. But it’s
    also one of the most annoying situations to figure out when it’s not working well.
    Thankfully, Ubuntu features really handy utilities you can use in order to pinpoint
    what’s going on.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s look at connectivity. After all, if you can’t connect to a network,
    your server is essentially useless. In most cases, Ubuntu recognizes just about
    all network cards without fail, and it will automatically connect your server
    or workstation to your network if it is within reach of a DHCP server.
  prefs: []
  type: TYPE_NORMAL
- en: While troubleshooting, get the obvious stuff out of the way first. The following
    may seem like a no-brainer, but you’d be surprised how often one can miss something
    obvious. I’m going to assume you’ve already checked to make sure network cables
    are plugged in tight on both ends. Another aspect regarding cabling is that sometimes
    network cables themselves develop faults and need to be replaced. You should be
    able to use a cable tester and get a clean signal through the cable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Routing issues can sometimes be tricky to troubleshoot, but by testing each
    destination point one by one, you can generally see where the problem lies. Typical
    symptoms of a routing issue may include being unable to access a device within
    another subnet, or perhaps not being able to get out to the internet, despite
    being able to reach internal devices. To investigate a potential routing issue,
    first, check your routing table. You can do so with the `ip route` command. This
    command will print your current routing table information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_22_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22.2: Viewing the routing table on an Ubuntu server'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, you can see that the default gateway for all traffic is `10.10.10.1`.
    This is the first entry on the table, which tells us that all traffic to the destination
    `0.0.0.0` (which is everything) leaves via `10.10.10.1`. As long as ICMP traffic
    isn’t disabled, you should be able to ping this default gateway, and you should
    be able to ping other nodes within your subnet as well.
  prefs: []
  type: TYPE_NORMAL
- en: To start troubleshooting a routing issue, you would use the information shown
    after printing your routing table to conduct several ping tests. First, try to
    ping your default gateway. If you cannot, then you’ve found the issue. If you
    can, try running the `traceroute` command.
  prefs: []
  type: TYPE_NORMAL
- en: This command isn’t available by default, but all you’ll have to do is install
    the `traceroute` package, so hopefully, you have it installed on the server. If
    you do, you can run `traceroute` against a host, such as an external URL, to find
    out where the connection drops. The `traceroute` command should show every hop
    between you and your target. Each “hop” is basically another default gateway.
    You traverse through one gateway after another until you ultimately reach your
    destination. With the `traceroute` command, you can see where the chain stops.
    In all likelihood, you’ll find that perhaps the problem isn’t even on your network,
    but perhaps your internet service provider is where the connection drops.
  prefs: []
  type: TYPE_NORMAL
- en: DNS issues don’t happen very often, but by using a few tricks, you should be
    able to resolve them. Symptoms of DNS failures will usually result in a host being
    unable to access internal or external resources by name.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing whether the problem is with internal or external hosts (or both) should
    help you determine whether it’s your DNS server that’s the problem, or perhaps
    the DNS server at your ISP.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step in pinpointing the source of DNS woes is to ping a known IP
    address on your network, preferably the default gateway. If you can ping it, but
    you can’t ping the gateway by name, then you probably have a DNS issue. You can
    confirm a potential DNS issue by using the `nslookup` command against the domain,
    such as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In addition, make sure you try and ping external resources as well, such as
    a website. This will help you narrow down the scope of the issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will also want to know which DNS server your host is sending queries to.
    In the past, finding out which DNS server was assigned to your host was as simple
    as inspecting the contents of `/etc/resolv.conf`. However, nowadays, this file
    will often refer to a local resolver instead and won’t reveal the actual server
    requests are being sent to. To find out the real DNS server that’s assigned to
    your host, the following command will do the trick:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Are they what you expect? If not, you can temporarily fix this problem by removing
    the incorrect name server entries from this file and replacing them with the correct
    IP addresses. The reason I suggest this as a temporary fix and not a permanent
    one is because the next thing you’ll need to do is investigate how the invalid
    IP addresses got there in the first place. Normally, these are assigned by your
    DHCP server. As long as your DHCP server is sending out the appropriate name server
    list, you shouldn’t run into this problem. If you’re using a static IP address,
    then perhaps there’s an error in your Netplan config file.
  prefs: []
  type: TYPE_NORMAL
- en: A useful method of pinpointing DNS issues in regard to being unable to resolve
    external sites is to temporarily switch your DNS provider on your local machine.
    Normally, your machine is going to use your external DNS provider, such as the
    one that comes from your ISP. Your external DNS server is something we went through
    setting up in *Chapter 11*, *Setting Up Network Services*, specifically the forwarders
    section of the configuration for the `bind9` daemon. The forwarders used by the
    `bind9` daemon are where it sends traffic if it isn’t able to resolve your request
    based on its internal list of hosts.
  prefs: []
  type: TYPE_NORMAL
- en: You could consider bypassing this by changing your local workstation’s DNS name
    servers to Google’s, which are `8.8.8.8` and `8.8.4.4`. If you’re able to reach
    the external resource after switching your name servers, you can be reasonably
    confident that your forwarders are the culprit.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve actually seen situations in which a website has changed its IP address
    but the ISP’s DNS servers didn’t get updated quickly enough, causing some clients
    to be unable to reach a site they need to perform their job. Switching everyone
    to alternate name servers (by adjusting the `forwarders` option, as we did in
    *Chapter 11*, *Setting Up Network Services*) was the easiest way they could work
    around the issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some additional tools to consider while checking your server’s ability to resolve
    DNS entries are `dig` and `nslookup`. You should be able to use both commands
    to test your server’s DNS settings. Both commands are used with a hostname or
    domain name as an option. The `dig` command will present you with information
    regarding the address (`A`) record of the DNS zone file responsible for the IP
    address or domain. The `host` command should return the IP address of the host
    you’re trying to reach. Here’s some example output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_22_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22.3: Output of the dig and host commands'
  prefs: []
  type: TYPE_NORMAL
- en: Hardware support is also critical when it comes to networking. If the Linux
    kernel doesn’t support your network hardware, then you’ll likely run into a situation
    where the distribution doesn’t recognize or do anything when you insert a network
    cable, or in the case of wireless networking, doesn’t show any nearby networks
    despite there being one or more. Unlike the Windows platform, hardware support
    is generally baked right into the kernel when it comes to Linux. While there are
    exceptions to this, the Linux kernel shipped with a distribution typically supports
    hardware the same age as itself or older.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of Ubuntu 22.04 LTS (which was released in April 2022), it’s able
    to support hardware released as of the beginning of 2022 and older. Future releases
    of Ubuntu Server will publish hardware enablement updates, which will allow Ubuntu
    Server 22.04 to support newer hardware and chip sets once they come out. Typically,
    Ubuntu will release several point releases during the life of a supported distribution,
    such as 22.04.1, 22.04.2, and so on. As long as you’re using the latest one, you’ll
    have access to the latest hardware support that Ubuntu has made available at the
    time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other cases, hardware support may depend on external kernel modules. In
    the case of a missing hardware driver, the first thing you should try when faced
    with network hardware that’s not recognized is to look up the hardware using a
    search engine. Typically the search term `<hardware name> Ubuntu` will do the
    trick. But what do you search for? To find out the hardware string for your network
    device, try the `lspci` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `lspci` command lists hardware connected to your server’s PCI bus. Here,
    we’re using the command with a case insensitive `grep` search for the word `net`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This should return a list of networking components available on your server.
    On my machine, for example, I get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, I have a wired and wireless network card on this machine. If
    one of them wasn’t working, I could search online for information by searching
    for the hardware string and the keyword `Ubuntu`, which should give me results
    pertaining to my exact hardware. If a package is required to be installed, the
    search results will likely give me some clues as to what package I need to install.
  prefs: []
  type: TYPE_NORMAL
- en: Without having network access though, the worst-case scenario is that I may
    have to download the package from another computer and transfer it to the server
    via a flash drive. That’s certainly not a fun thing to need to do, but it does
    work if the latest Ubuntu installation media doesn’t yet offer full support for
    your hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Another potential problem point is DHCP. When it works well, DHCP is a wonderfully
    magical thing. When it stops working, it can be frustrating. But generally, DHCP
    issues often end up being a lack of available IP addresses, the DHCP daemon (`isc-dhcp-server`)
    not running, an invalid configuration, or hosts that have clocks that are out
    of sync (all servers should have the `ntp` package installed).
  prefs: []
  type: TYPE_NORMAL
- en: If you have a server that is unable to obtain an IP address via DHCP and your
    network utilizes a Linux-based DHCP server, check the system log (`/var/log/syslog`)
    for events related to `dhcpd`. Unfortunately, there’s no command you can run that
    I’ve ever been able to find that will print how many IP address leases your DHCP
    server has remaining, but if you run out, chances are you’ll see log entries related
    to an exhausted pool in the system log. In addition, the system log will also
    show you attempts from your nodes to obtain an IP address as they attempt to do
    so. Feel free to use `tail -f` against the system log to watch for any events
    related to DHCP leases.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, a lack of DHCP leases being available can come down to having
    a very generous lease time enabled. Some administrators will give their clients
    up to a week for the lease time, which is generally unnecessary. A lease time
    of one day is fine for most networks, but ultimately, the lease time you decide
    on is up to you. In *Chapter 11*, *Setting Up Network Services*, we looked at
    configuring our DHCP server, so feel free to refer to that chapter if you need
    a refresher on how to configure the `isc-dhcp-server` daemon.
  prefs: []
  type: TYPE_NORMAL
- en: Although it’s probably not the first thing you’ll think of while facing DHCP
    issues, hosts having out-of-sync clocks can actually contribute to the problem.
    DHCP requests are `timestamped` on both the client and the server, so if the clock
    is off by a large degree on one, the timestamps will be off as well, causing the
    DHCP server to become confused. Surprisingly, I’ve seen this come up fairly often.
    I recommend standardizing NTP across your network as early on as you can. DHCP
    isn’t the only service that suffers when clocks are out of sync; file synchronization
    utilities also require accurate time. If you ensure NTP is installed on all of
    your clients and it’s up to date and working, you should be in good shape. Using
    configuration management utilities such as Ansible to ensure NTP is not only configured
    but is running properly on all the machines in your network will only benefit
    you.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there are many things that can go wrong when it comes to networking,
    but the information here should cover the majority of issues. In summary, troubleshooting
    network issues generally revolves around ping tests. Trying to ping your default
    gateway, tracing failed endpoints with `traceroute`, and troubleshooting DNS and
    DHCP will take care of a majority of issues. Then again, faulty hardware such
    as failed network cards and bad cabling will no doubt present themselves as well.
  prefs: []
  type: TYPE_NORMAL
- en: Our servers utilize storage, CPU, memory, and other resources to provide us
    with value and serve our clients. In the next section, we’ll take a closer look
    at how to check those resources.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting resource issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I don’t know about others, but it seems that a majority of my time troubleshooting
    servers is usually spent pinpointing resource issues. By resources, I’m referring
    to CPU, memory, disk, input/output, and so on. Generally, issues come down to
    a user storing too many large files, a process going haywire that consumes a large
    amount of CPU, or a server running out of memory. In this section, we’ll go through
    some of the common things you’re likely to run into while administering Ubuntu
    servers.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s revisit topics related to storage. In *Chapter 9*, *Managing Storage
    Volumes*, we went over concepts related to this already, and many of those concepts
    also apply to troubleshooting as well. Therefore, I won’t spend too much time
    on those concepts here, but it’s worth a refresher in regard to troubleshooting
    storage issues. First, whenever you have users that are complaining about being
    unable to write new files to the server, the following two commands are the first
    you should run. You are probably already well aware of these, but they’re worth
    repeating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The first `df` command variation gives you information regarding how much space
    is used on a drive, in a human-readable format (the `-h` option), which will print
    the information in terms of megabytes and gigabytes.
  prefs: []
  type: TYPE_NORMAL
- en: The `-i` option in the second command gives you information regarding in-use
    and available inodes. The reason you should also run this is that on a Linux system,
    it can report storage as full even if there’s plenty of free space. But if there
    are no remaining inodes, it’s the same as being full, but the first command wouldn’t
    show the usage as 100 percent when no inodes are free. Usually, the number of
    inodes a storage medium has available is extremely generous, and the limit is
    hard to hit. However, if a service is creating new log files over and over every
    second, or a mail daemon grows out of control and generates a huge backlog of
    undelivered mail, you’d be surprised how quickly inodes can empty out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, once you figure out that you have an issue with full storage, the
    next logical question becomes, what is eating up all my free space? The `df` commands
    will give you a list of storage volumes and their sizes, which will tell you at
    least which disk or partition to focus your attention on. My favorite command
    for pinpointing storage hogs, as I mentioned in *Chapter 9*, *Managing Storage
    Volumes*, is the `ncdu` command. While not installed by default, `ncdu` is a wonderful
    utility for checking to see where your storage is being consumed the most. If
    run by itself, `ncdu` will scan your server’s entire filesystem. Instead, I recommend
    running it with the `-x` option, which will limit it to a specific folder as a
    starting point. For example, if the `/home` partition is full on your server,
    you might want to run the following to find out which directory is using the most
    space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `-x` option will cause `ncdu` to not cross filesystems. This means if you
    have another disk mounted within the folder you’re scanning, it won’t touch it.
    With `-x`, `ncdu` is only concerned with the target you give it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you aren’t able to utilize `ncdu`, there’s also the `du` command, which
    takes some extra work. The `du -h` command, for example, will give you the current
    usage of your current working directory, with human-readable numbers. It doesn’t
    traverse directory trees by default like `ncdu` does, so you’d need to run it
    on each subdirectory until you manually find the directory that’s holding the
    most files. A very useful variation of the `du` command, nicknamed `ducks`, is
    the following. It will show you the top 15 largest directories in your current
    working directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Another issue with storage volumes that can arise is to do with filesystem
    integrity. Most of the time, these issues only seem to come up when there’s an
    issue with power, such as a server powering off unexpectedly. Depending on the
    server and the formatting you’ve used when setting up your storage volumes (and
    several other factors), power issues are handled differently from one installation
    to another. In most cases, a filesystem check (`fsck`) will happen automatically
    during the next boot. If it doesn’t, and you’re having odd issues with storage
    that can’t be explained, a manual filesystem check is recommended. Scheduling
    a filesystem check is actually very easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The previous command will create an empty file, `forcefsck`, at the root of
    the filesystem. When the server reboots and it sees this file, it will trigger
    a filesystem check on that volume and then remove the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’d like to check a filesystem other than the root volume, you can create
    the `forcefsck` file elsewhere. For example, if your server has a separate `/home`
    partition, you could create the file there instead to check that volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The filesystem check will usually complete fairly quickly unless there’s an
    issue it needs to fix. Depending on the nature of the problem, the issue could
    be repaired quickly, or perhaps it will take a while. I’ve seen some really bad
    integrity issues that have taken over four hours to fix, but I’ve seen others
    fixed in a matter of seconds. Sometimes it will finish so quickly that it will
    scroll by so fast during boot that you may miss seeing it. In case of a large
    volume, you may want to schedule the `fsck` check to happen after-hours in case
    the scan takes a long time.
  prefs: []
  type: TYPE_NORMAL
- en: 'With regards to issues with memory, the `free -m` command will give you an
    overview of how much memory and swap are available on your server. It won’t tell
    you what exactly is using up all your memory, but you’ll use it to see if you’re
    in jeopardy of running out. The **free** column from the output of the `free`
    command will show you how much memory is remaining, and allow you to make a decision
    on when to take action:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_22_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22.4: Checking the available memory on an Ubuntu server'
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 8*, *Monitoring System Resources*, we took a look at the `htop`
    command, which helps us answer the question of “what” is using up our resources.
    Using `htop` (once installed), you can sort the list of processes by CPU or memory
    usage by pressing *F6* and then selecting a new sort field, such as `PERCENT_CPU`
    or `PERCENT_MEM`. This will give you an idea of what is consuming resources on
    your server, allowing you to make a decision on what to do about it. The action
    you take will differ from one process to another, and your solution may range
    from adding more memory to the server to tuning the application to have a lower
    memory ceiling. But what do you do when the results from `htop` don’t correlate
    to the usage you’re seeing? For example, what if your load average is high, but
    no process seems to be consuming a large portion of CPU?
  prefs: []
  type: TYPE_NORMAL
- en: 'One command I haven’t discussed so far in this book is `iotop`. While not installed
    by default, the `iotop` utility is definitely a must-have, so I recommend you
    install the `iotop` package. The `iotop` utility itself needs to be run as `root`
    or with `sudo`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `iotop` command will allow you to see how much data is being written to
    or read from your disks. **Input/Output** (**IO**) definitely contributes to a
    system’s load, and not all resource monitoring utilities will show this usage.
    If you see a high load average but nothing in your resource monitor shows anything
    to account for it, check the IO.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `iotop` utility is a great way to do that as if data is bottle-necked while
    being written to disk, which can account for a serious overhead in IO that will
    slow other processes down. If nothing else, it will give you an idea of which
    process is misbehaving, in case you need to kill it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_22_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22.5: The iotop utility running on an Ubuntu server'
  prefs: []
  type: TYPE_NORMAL
- en: The `iotop` window will refresh on its own, sorting processes by the column
    that is highlighted. To change the highlight, you’ll only need to press the *left*
    and *right* arrows on your keyboard. You can sort processes by columns such as
    `IO`, `SWAPIN`, `DISK WRITE`, `DISK READ`, and others. When you’re finished with
    the application, press *q* to quit.
  prefs: []
  type: TYPE_NORMAL
- en: The utilities we looked at in this section are very useful when identifying
    issues with bottle-necked resources. What you do to correct the situation after
    you find the culprit will depend on the daemon. Perhaps there’s an invalid configuration,
    or the daemon has encountered a fault and needs to be restarted. Often, checking
    the logs may lead you to an answer as to why a daemon misbehaves. In the case
    of full storage, almost nothing beats `ncdu`, which will almost always lead you
    directly to the problem. Tools such as `htop` and `iotop` allow you to view additional
    information regarding resource usage as well, and `htop` even allows you to kill
    a misbehaving process right from within the application, by pressing *F9*.
  prefs: []
  type: TYPE_NORMAL
- en: What do you do when system memory (RAM) becomes physically defective? It happens
    more often than you’d think. In the next section, we’ll look at a way we can test
    our RAM to see if it’s defective or not.
  prefs: []
  type: TYPE_NORMAL
- en: Diagnosing defective RAM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All server and computing components can and will fail eventually, but there
    are a few pieces of hardware that seem to fail more often than others. Fans, power
    supplies, and hard disks definitely make the list of common things administrators
    will end up replacing, but defective memory is also a situation I’m sure you’ll
    run into eventually.
  prefs: []
  type: TYPE_NORMAL
- en: Although memory sticks becoming defective is something that could happen, I
    made it the last section in this chapter because unfortunately, I can’t give you
    a definitive list of symptoms to look out for that indicate that memory is the
    source of an issue. RAM issues are very mysterious in nature, and each time I’ve
    run into one, I’ve always stumbled across memory being bad only after troubleshooting
    everything else. It’s for this reason that nowadays I’ll often test the memory
    on a server or workstation first since it’s very easy to do. Even if memory has
    nothing to do with an issue, it’s worth checking anyway since it could become
    a problem later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most distributions of Linux (Ubuntu included) feature **Memtest86+** right
    on the installation media. Whether you create a bootable CD or flash drive, there’s
    a memory test option available from the Ubuntu Server media. When you first boot
    from the Ubuntu Server media, you’ll see an icon toward the bottom indicating
    that you can press a key to bring up a menu (if you don’t press a key, the installer
    will automatically start). Next, you’ll be asked to choose your language, and
    then you’ll be shown an installation menu. Among the choices there will be a **Test
    memory** option:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18425_22_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22.6: The main menu of the Ubuntu installer, showing a Test memory option'
  prefs: []
  type: TYPE_NORMAL
- en: Other editions of Ubuntu, such as the Ubuntu desktop distribution or any of
    its derivatives, also feature an option to test memory. Even if you don’t have
    installation media handy for the server edition, you can use whichever version
    you have.
  prefs: []
  type: TYPE_NORMAL
- en: When you choose the **Test memory** option from your installation media, the
    **Memtest86+** program will immediately get to work and start testing your memory
    (press *Esc* to exit the test). The test may take a long time, depending on how
    much memory your workstation or server has installed. It can take minutes or even
    hours to complete. Generally speaking, when your machine has defective RAM, you’ll
    see a bunch of errors show up relatively quickly, usually within the first 5-10
    minutes.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t see errors within 15 minutes, you’re most likely in good shape.
    In my experience, every time I’ve run into defective memory, I’ve seen errors
    in 15 minutes or less (usually within 5). Theoretically, though, you could very
    well have a small issue with your memory modules that may not show up until after
    15 minutes, so you should let the test finish if you can spare the time for it.
  prefs: []
  type: TYPE_NORMAL
- en: The main question becomes when to run **Memtest86+** on a machine. In my experience,
    symptoms of bad memory are almost never the same from one machine to another.
    Usually, you’ll run into a situation where a server doesn’t boot properly, applications
    close unexpectedly, applications don’t start at all, or perhaps an application
    is behaving irregularly. In my view, testing memory should be done whenever you
    experience a problem that doesn’t necessarily seem straightforward. In addition,
    you may want to consider testing the memory on your server before you roll it
    out into production. That way, you can ensure that it starts out as free of hardware
    issues as possible. If you install new memory modules, make sure to test the RAM
    right away.
  prefs: []
  type: TYPE_NORMAL
- en: If the test does report errors, you’ll next want to find out which memory module
    is faulty. This can be difficult, as some servers can have more than a dozen memory
    modules installed. To narrow it down, you’d want to test each memory module independently
    if you can, until you find out which one is defective. You should also continue
    to test the other modules, even after you discover the culprit. The reason for
    this is that having multiple memory modules going bad isn’t outside the realm
    of possibility, considering whatever situation led to the first module becoming
    defective may have affected others.
  prefs: []
  type: TYPE_NORMAL
- en: Another tip I’d like to pass along regarding memory is that when you do discover
    a bad stick of memory, it’s best to erase the hard disk and start over if you
    can. I understand that this isn’t always feasible, and you could have many hours
    logged into setting up a server. Some servers can take weeks to rebuild, depending
    on their workload. But at least keep in mind that any data that passes through
    defective RAM can become corrupted.
  prefs: []
  type: TYPE_NORMAL
- en: This means that data at rest (data stored on your hard disk) may be corrupt
    if it was sitting in a defective area of RAM before it was written to disk. When
    a server or workstation encounters defective RAM, you really can’t trust it anymore.
    I’ll leave the decision on how to handle this situation up to you (hopefully you’ll
    never encounter it at all), but just keep this in mind as you plan your course
    of action. Personally, I don’t trust an installation of any operating system after
    its hardware has encountered such issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'I also recommend that you check the capacitors on your server’s motherboard
    whenever you’re having odd issues. Although this isn’t necessarily related to
    memory, I mention it here because the symptoms are basically the same as bad memory
    when you have bad capacitors. I’m not asking you to get a voltage meter or do
    any kind of electrician work, but sometimes it may make sense to open the case
    of your server, shine a flashlight on the capacitors, and see if any of them appear
    to be leaking fluid or expanding. The reason I bring this up is that I’ve personally
    spent hours troubleshooting a machine (more than once) where I would test the
    memory and hard disk and look through system logs, without finding any obvious
    causes, only to later look at the hardware and discover that capacitors on the
    motherboard were leaking. It would have saved me a lot of time if I had simply
    looked at the capacitors. And that’s really all you have to do: just take a quick
    glance around the motherboard and look for anything that doesn’t seem right.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While Ubuntu is generally a very stable and secure platform, it’s important
    to be prepared for problems occurring and to know how to deal with them. In this
    chapter, we discussed common troubleshooting we can perform when our servers stop
    behaving themselves. We started off by evaluating the scope, which gives us an
    understanding of how many users or servers are affected by the issue. Then, we
    looked into Ubuntu’s log files, which are a treasure trove of information that
    we can use to pinpoint issues and narrow down the problem. We also covered several
    networking issues that can come up, such as issues with DHCP, DNS, and routing.
    We certainly can’t predict problems before they occur, nor can we be prepared
    in advance for every type of problem that can possibly happen. However, applying
    sound logic and common sense to problems will go a long way in helping us figure
    out the root cause.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a look at preventing disasters in the first
    place and recovering from them if they happen anyway. See you there!
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Reporting Bugs in Ubuntu Server: [https://learnlinux.link/report-bugs](https://learnlinux.link/report-bugs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/LWaZ0](https://packt.link/LWaZ0)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code50046724-1955875156.png)'
  prefs: []
  type: TYPE_IMG
