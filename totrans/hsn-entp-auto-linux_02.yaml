- en: Building a Standard Operating Environment on Linux
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Linux上构建标准操作环境
- en: This chapter provides a detailed exploration of the **Standard Operating Environment**
    (henceforth, **SOE** for short) concept in Linux. Although we will go into much
    greater detail later, in short, an SOE is an environment where everything is created
    and modified in a standard way. For example, this would mean that all Linux servers
    are built in the same way, using the same software versions. This is an important
    concept because it makes managing the environment much easier and reduces the
    workload for those looking after it. Although this chapter is quite theoretical
    in nature, it sets the groundwork for the rest of this book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细探讨了Linux中的**标准操作环境**（以下简称**SOE**）概念。虽然我们稍后会详细讨论，但简而言之，SOE是指所有事物都以标准化的方式进行创建和修改的环境。例如，这意味着所有Linux服务器都以相同的方式构建，使用相同的软件版本。这个概念很重要，因为它使得管理环境变得更容易，并减少了管理人员的工作量。尽管本章的内容较为理论，但它为本书的其余部分奠定了基础。
- en: We will start by looking at the fundamental definition of such an environment,
    and then proceed to explore why it is desirable to want to create one. From there,
    we will look at some of the pitfalls of an SOE to give you a good perspective
    on how to maintain the right balance in such an environment, before finally discussing
    how an SOE should be integrated into day-to-day maintenance processes. The effective
    application of this concept enables efficient and effective management of Linux
    environments at very large scales.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从探讨这种环境的基本定义开始，然后继续研究为什么希望创建这种环境是有利的。从这里出发，我们将探讨一些SOE的陷阱，为你提供如何在这种环境中保持正确平衡的视角，最后讨论如何将SOE融入到日常维护流程中。有效应用这一概念，可以在非常大的规模下高效且有效地管理Linux环境。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding the challenges of Linux environment scaling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Linux环境扩展的挑战
- en: What is an SOE?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是SOE？
- en: Exploring SOE benefits
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索SOE的好处
- en: Knowing when to deviate from standards
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知道何时偏离标准
- en: Ongoing maintenance of SOEs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SOE的持续维护
- en: Understanding the challenges of Linux environment scaling
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Linux环境扩展的挑战
- en: Before we delve into the definition of an SOE, let's explore the challenges
    of scaling a Linux environment without standards. An exploration of this will
    help us to understand the definition itself, as well as how to define the right
    standards for a given scenario.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨SOE的定义之前，让我们先来探索没有标准的Linux环境扩展所面临的挑战。对这一问题的探讨将帮助我们理解SOE的定义，同时也帮助我们为特定场景定义适当的标准。
- en: Challenges of non-standard environments
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非标准环境的挑战
- en: It is important to consider that many challenges experienced by enterprises
    with technology estates (whether Linux or otherwise) do not start out as such.
    In the early stages of growth, in fact, many systems and processes are entirely
    sustainable, and in the next section, we will look at this early stage of environment
    growth as a precursor to understanding the challenges associated with large-scale
    growth.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑的是，许多企业在拥有技术资源（无论是Linux还是其他）的过程中所遇到的挑战，并非一开始就显现出来。事实上，在增长的早期阶段，许多系统和流程完全是可持续的，在下一部分中，我们将探讨环境增长的这一早期阶段，以便为理解大规模增长相关的挑战做铺垫。
- en: Early growth of a non-standard environment
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非标准环境的早期增长
- en: In a surprisingly large number of companies, Linux environments begin life without
    any form of standardization. Often, they grow organically over time. Deployments
    start out small, perhaps just covering a handful of core functions, and as time
    passes and requirements grow, so does the environment. Skilled system administrators
    often make changes by hand on a per-server basis, deploying new services and growing
    the server estate as business demands dictate.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多公司中，Linux环境的初始阶段往往没有任何标准化形式。通常，它们随着时间的推移而自然增长。最初的部署可能很小，可能仅覆盖一些核心功能，随着时间的推移和需求的增长，环境也随之扩展。熟练的系统管理员通常根据每台服务器手动进行更改，部署新服务，并根据业务需求扩展服务器规模。
- en: This organic growth is the path of least resistance for most companies—project
    deadlines are often tight and in addition both budget and resource are scarce.
    Hence, when a skilled Linux resource is available, that resource can assist in
    just about all of the tasks required, from simple maintenance tasks to commissioning
    complex application stacks. It saves a great deal of time and money spent on architecture
    and makes good use of the skillset of staff on hand as they can be used to address
    immediate issues and deployments, rather than spending time on architectural design.
    Hence, quite simply, it makes sense, and the author has experienced this at several
    companies, even high-profile multi-national ones.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这种有机增长是大多数公司选择的最小阻力路径——项目的截止日期通常很紧，而且预算和资源也很紧张。因此，当有一位熟练的 Linux 人员时，这位人员几乎可以协助完成所有需要的任务，从简单的维护任务到复杂应用栈的调试与部署。这节省了大量在架构设计上花费的时间和金钱，并且能够充分利用现有员工的技能，因为他们可以用来处理紧急问题和部署，而不是在架构设计上浪费时间。因此，简而言之，这是有道理的，作者在几家公司，甚至一些知名的跨国公司中都经历过这种情况。
- en: Impacts of non-standard environments
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非标准环境的影响
- en: Let's take a deeper look at this from a technical standpoint. There are numerous
    flavors of Linux, numerous applications that perform (at a high level) the same
    function, and numerous ways to solve a given problem. For example, if you want
    to script a task, do you write it in a shell script, Perl, Python, or Ruby? For
    some tasks, all can achieve the desired end result. Different people have different
    preferred ways of approaching problems and different preferred technology solutions,
    and often it is found that a Linux environment has been built using a technology
    that was *the flavor of the month* when it was created or that was a favorite
    of the person responsible for it. There is nothing wrong with this in and of itself,
    and initially, it does not cause any problems.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度更深入地看这个问题。Linux 有多种版本，也有多种应用程序执行（在高层次上）相同的功能，并且有多种方式解决给定的问题。例如，如果你想写一个任务脚本，你是写一个
    shell 脚本、Perl、Python 还是 Ruby？对于某些任务，所有这些方式都能实现预期的最终结果。不同的人在解决问题时有不同的偏好方式和技术解决方案，通常会发现一个
    Linux 环境是使用一种当时“月度风味”的技术或负责此环境的人最喜欢的技术构建的。就其本身而言，这没有什么问题，最初也不会引发任何问题。
- en: 'If organic growth brings with it one fundamental problem, it is this: scale.
    Making changes by hand and always using the latest and greatest technology is
    great when the environment size is relatively small, and often provides an interesting
    challenge, hence keeping technical staff feeling motivated and valued. It is vital
    for those working in technology to keep their skills up to date, so it is often
    a motivating factor to be able to employ up-to-date technologies as part of the
    day job.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有机增长带来一个根本性的问题，那就是：规模。当环境的规模相对较小时，手动进行更改并始终使用最新、最先进的技术是非常不错的，通常也会带来有趣的挑战，因此能够保持技术人员的积极性和价值感。对从事技术工作的人来说，保持技能的更新至关重要，因此，能够在日常工作中运用最新技术，常常是一个激励因素。
- en: Scaling up non-standard environments
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展非标准环境
- en: When the number of servers enters the hundreds, never mind thousands (or even
    greater!), this whole *organic* process breaks down. What was once an interesting
    challenge becomes laborious and tedious, even stressful. The learning curve for
    new team members is steep. A new hire may find themselves with a disparate environment
    with lots of different technologies to learn, and possibly a long period of training
    before they can become truly effective. Long-serving team members can end up being
    silos of knowledge, and should they depart the business, their loss can cause
    continuity issues. Problems and outages become more numerous as the non-standard
    environment grows in an uncontrolled manner, and troubleshooting becomes a lengthy
    endeavor—hardly ideal when trying to achieve a 99.99% service uptime agreement,
    where every second of downtime matters! Hence, in the next section, we will look
    at how to address these challenges with an SOE.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Addressing the challenges
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From this, we realize our requirement for standardization. Building a suitable
    SOE is all about the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Realizing economies of scale
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being efficient in day-to-day operations
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making it easy for all involved to get up to speed quickly and easily
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being aligned with the growing needs of the business
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After all, if an environment is concise in its definition, then it is easier
    for everyone involved in it to understand and work with. This, in turn, means
    tasks are completed quicker and with greater ease. In short, standardization can
    bring cost savings and improved reliability.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: It must be stressed that this is a concept and not an absolute. There is no
    right or wrong way to build such an environment, though there are best practices.
    Throughout this chapter, we will explore the concept further and help you to identify
    core best practices associated with SOEs so that you can make informed decisions
    when defining your own.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s proceed to explore this in more detail. Every enterprise has certain
    demands of their IT environments, whether they are based on Linux, Windows, FreeBSD,
    or any other technology. Sometimes, these are well understood and documented,
    and sometimes, they are simply implicit—that is to say, everyone assumes the environment
    meets these *standards*, but there is no official definition. These requirements
    often include the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Security
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reliability
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Longevity
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supportability
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ease of use
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These, of course, are all high-level requirements, and very often, they intersect
    with each other. Let's explore these in more detail.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Security
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Security in an environment is established by several factors. Let''s look at
    some questions to understand the factors involved:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Is the configuration secure?
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have we allowed the use of weak passwords?
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the superuser, root, allowed to log in remotely?
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are we logging and auditing all connections?
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, in a non-standard environment, how can you truly say that these requirements
    are all enforced across all of your Linux servers? To do so requires a great deal
    of faith they have all been built the same way, that they had the same security
    parameters applied, and that no-one has ever revisited the environment to change
    anything. In short, it requires fairly frequent auditing to ensure compliance.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: However, where the environment has been standardized, and all servers have been
    built from a common source or using a common automation tool (we shall demonstrate
    this later in this book), it is much easier to say with confidence that your Linux
    estate is secure.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: A standards-based environment isn't implicitly secure, of course—if there is
    an issue that results in a vulnerability in the build process for this environment,
    automation means this vulnerability will be replicated across the entire environment!
    It is important to be aware of the security requirements of your environment and
    to implement these with care, maintaining and auditing your environment continuously
    to ensure security levels are maintained.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Security is also enforced by patches, which ensure you are not running any software
    with vulnerabilities that could allow an attacker to compromise your servers.
    Some Linux distributions have longer lives than others. For example, Red Hat Enterprise
    Linux (and derivatives such as CentOS) and the Ubuntu LTS releases all have long,
    predictable life cycles and make good candidates for your Linux estate.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: As such, they should be part of your standards. By contrast, if a *bleeding
    edge* Linux distribution such as Fedora has been used because, perhaps, it had
    the latest packages required at the time, you can be sure that the life cycle
    will be short, and that updates would cease in the not too distant future, hence
    leaving you open to potential unpatched vulnerabilities and the need to upgrade
    to a newer release of Fedora.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Even if the upgrade to a newer version of Fedora is performed, sometimes packages
    get *orphaned—*that is to say, they do not get included in the newer release.
    This might be because they have been superseded by a different package. Whatever
    the cause, upgrading one distribution to another could cause a false sense of
    security and should be avoided unless thoroughly researched. In this way, standardization
    helps to ensure good security practices.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Reliability
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many enterprises expect their IT operations to be up and running 99.99% of the
    time (or better). Part of the route to achieving this is robust software, application
    of relevant bug fixes, and well-defined troubleshooting procedures. This ensures
    that in the worst case scenario of an outage, the downtime is as minimal as possible.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Standardization again helps here*—*as we discussed in the preceding section
    on security, a good choice of underlying operating system ensures that you have
    ongoing access to bug fixes and updates, and if you know that your business needs
    a vendor backup to ensure business continuity, then the selection of a Linux operating
    system with a support contract (available with Red Hat or Canonical, for example)
    makes sense.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Equally, when servers are all built to a well-defined and understood standard,
    making changes to them should yield predictable results as everyone knows what
    they are working with. If all servers are built slightly differently, then a well-meaning
    change or update could have unintended consequences and result in costly downtime.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Again with standardization, even if the worst-case scenario occurs, everyone
    involved should know how to approach the problem because they will know that all
    servers have been built on a certain base image and have a certain configuration.
    This knowledge and confidence reduce troubleshooting times and ultimately downtime.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All enterprises desire their business to grow and most times, this means that
    IT environments need to scale up to deal with increased demand. In an environment
    where the servers are built in a non-standard manner, scaling up an environment
    becomes more of a challenge.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: For example, if scaling horizontally (adding more identical servers to an existing
    service), the new servers should all have the same configuration as the existing
    ones. Without standards, the first step is to work out how the initial set of
    servers was built and then to clone this and make the necessary changes to produce
    more unique servers.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: This process is somewhat cumbersome whereas, with a standardized environment,
    the investigative step is completely unnecessary, and horizontal scaling becomes
    a predictable, repeatable, *business-as-usual* task. It also ensures greater reliability
    as there should be no unintended results from the new servers in the case that
    a non-standard configuration item was missed. Human beings are incredible, intelligent
    beings capable of sending a man to the moon, and yet they are equally capable
    of overlooking a single line in a configuration file. The idea of standardization
    is to mitigate this risk, and hence make it quick and efficient to scale an environment
    either up or out using a well-thought-out operating system template, the concept
    of which we will explore as we proceed through this chapter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Longevity
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes when deploying a service, a particular software version is needed.
    Let's take the example of a web application that runs on PHP. Now, suppose that
    your particular enterprise has, for historical reasons, standardized on CentOS
    6 (or RHEL 6). This operating system only ships with PHP 5.3, meaning that if
    you suddenly take on an application that only supports PHP 7.0 and above, you
    need to figure out how to host this.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: One apparently obvious solution to this would be to roll out a Fedora virtual
    machine image. After all, it shares similar technologies to CentOS and RHEL and
    has much more up-to-date libraries included with it. The author has direct experience
    of this kind of solution in several roles! However, let's take a look at the bigger
    picture.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: RHEL (and CentOS, which is based upon this) has a lifespan of around 10 years,
    depending on the point at which you purchased it. In an enterprise, this is a
    valuable proposition*—*it means that you can guarantee that any servers you build
    will have patches and support for up to 10 years (and possibly longer with extended
    life cycle support) from the point at which you built them. This ties in nicely
    with our previous points around security, reliability, and supportability (in
    the following section).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: However, any servers that you build on Fedora will have a lifespan of somewhere
    in the region of 12-18 months (depending on the Fedora release cycle)*—*in an
    enterprise setting, having to redeploy a server after, say, 12-18 months is a
    headache that is not needed.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: This is not to say there is never a case for deploying on Fedora or any other
    fast-moving Linux platform*—*it is simply to state that in an enterprise where
    security and reliability are vitally important, you are unlikely to want a Linux
    platform with a short life cycle as the short term gain (newer library support)
    would be replaced in 12-18 months with the pain of a lack of updates and the need
    to rebuild/upgrade the platform.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this does depend very much on your approach to your infrastructure*—*some
    enterprises take a very container-like approach to their servers and re-deploy
    them with every new software release or application deployment. When your infrastructure
    and build standards are defined by code (such as Ansible), then it is entirely
    possible to do this with a fairly minimal impact on your day-to-day operations,
    and it is unlikely that any single server would be around for long enough for
    the operating system to become outdated or unsupported.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the day, the choice is yours and you must establish which path
    you feel provides you with the most business benefit without putting your operations
    at risk. Part of standardization is to make sound, rational decisions on technology
    and to adopt them wherever feasible, and your standard could include frequent
    rebuilds such that you can use a fast-moving operating system such as Fedora.
    Equally, you might decide that your standard is that servers will have long lives
    and be upgraded in place, and in this case, you would be better choosing an operating
    system such as an Ubuntu LTS release or RHEL/CentOS.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will look in greater detail at how an SOE benefits the
    concept of supportability in the next section.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Supportability
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have already discussed, having a standardized environment brings with
    it two benefits. The first is that a well-chosen platform means a long vendor
    support life cycle. This, in turn, means long support from either the vendor (in
    the case of a product such as RHEL) or the community (in the case of CentOS).
    Some operating systems such as Ubuntu Server are available with either community
    support or a paid contract directly from Canonical.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经讨论过的，拥有标准化的环境带来了两个好处。第一个好处是，精心选择的平台意味着较长的供应商支持生命周期。反过来，这意味着无论是来自供应商（例如RHEL产品）的长期支持，还是来自社区（例如CentOS）的长期支持。某些操作系统，如Ubuntu
    Server，可以选择通过社区支持或直接从Canonical获得付费合同支持。
- en: Supportability doesn't just mean support from the vendor or the Linux community
    at large, however. Remember that, in an enterprise, your staff is your front line
    support before anyone external steps in. Now, imagine having a crack team of Linux
    staff, and presenting them with a server estate comprised of Debian, SuSe, CentOS,
    Fedora, Ubuntu, and Manjaro. There are similarities between them, but also a huge
    number of differences. Across them, there are four different package managers
    for installing and managing software packages, and that's just one example.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，可支持性不仅仅意味着来自供应商或Linux社区的支持。请记住，在企业中，你的员工是前线支持，外部人员介入之前，员工就已经在处理问题了。现在，想象一下你有一支优秀的Linux团队，并且他们面对的是由Debian、SuSe、CentOS、Fedora、Ubuntu和Manjaro组成的服务器环境。它们之间有相似之处，但也有大量的差异。它们之间有四种不同的软件包管理器来安装和管理软件包，这只是其中的一个例子。
- en: Whilst entirely supportable, it does present more of a challenge for your staff
    and means that, for anyone joining the company, you require both a broad and a
    deep set of Linux experience*—*either that or an extensive on-boarding process
    to get them up to speed.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然完全可以支持，但这对你的员工提出了更大的挑战，这意味着对于任何加入公司的人，你需要一套广泛且深入的Linux经验——或者需要一个广泛的入职过程来帮助他们快速上手。
- en: With a standardized environment, you might end up with more than one operating
    system, but nonetheless, if you can meet all of your requirements with, say, CentOS
    7 and Ubuntu Server 18.04 LTS (and know that you are covered for the next few
    years because of your choices), then you immediately reduce the workload on your
    Linux team and enable them to spend more time creatively solving problems (for
    example, automating solutions with Ansible!) and less time figuring out the nuances
    between operating systems. As we have also discussed, in the event of an issue,
    they will be more familiar with each OS and hence need to spend less time debugging,
    reducing downtime.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个标准化的环境中，你可能会使用多个操作系统，但如果你能够通过选择例如CentOS 7和Ubuntu Server 18.04 LTS来满足所有的需求，并且知道你在未来几年内选择是有保障的，那么你立刻就能减少Linux团队的工作负担，让他们有更多时间去创造性地解决问题（例如，通过Ansible自动化解决方案！），而不是花时间去琢磨操作系统之间的细微差别。正如我们所讨论的，在出现问题时，他们会更熟悉每个操作系统，因此需要花费更少的时间来调试，从而减少停机时间。
- en: This brings us nicely into the subject of ease of use at scale, and we will
    provide an overview of this in the next section.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了一个关于大规模易用性的话题，我们将在下一节中对此进行概述。
- en: Ease of use
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 易用性
- en: This final category overlaps heavily with the last two—that is to say that,
    quite simply, the more standardized your environment, the easier it is for a given
    set of employees to get to grips with it. This automatically promotes all of the
    benefits we have discussed so far around reducing downtime, easier recruitment
    and on-boarding of staff, and so on.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这一最终类别与前两个类别有很大重叠——也就是说，更标准化的环境使得给定的员工更容易掌握。这样就自动促进了我们之前讨论的所有好处，包括减少停机时间、简化员工招聘和入职等。
- en: Having set out the challenges that an SOE helps to address, we will proceed
    in the next section to look at the anatomy of such an environment to understand
    it from a technical standpoint.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在列出了SOE帮助解决的挑战之后，我们将在下一节中继续探讨这种环境的结构，从技术角度理解它。
- en: What is an SOE?
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是SOE？
- en: Now that we've explored the reasons why an SOE is important to the enterprise
    and understood at a high level the solutions for these problems, let's look in
    detail at an SOE. We will begin by defining the SOE itself.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了SOE对企业重要性的原因，并且在高层次上了解了这些问题的解决方案，让我们详细了解SOE。我们将从定义SOE本身开始。
- en: Defining the SOE
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义SOE
- en: Let's take a quick look at this from a more practical standpoint. As we have
    already said, an SOE is a concept, not an absolute. It is, at its simplest level,
    a common server image or build standard that is deployed across a large number
    of servers throughout a company. Here, all required tasks are completed in a known,
    documented manner.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, there is the base operating system—and, as we have discussed,
    there are hundreds of Linux distributions to choose from. Some are quite similar
    from a system administration perspective (for example, Debian and Ubuntu), whilst
    some are markedly different (for example, Fedora and Manjaro). By way of a simple
    example, let''s say you wanted to install the Apache Web Server on Ubuntu 18.04
    LTS—you would enter the following commands:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, if you wanted to do the same thing but on CentOS 7, you would enter the
    following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As you can see, there is nothing in common between these commands—not even the
    name of the package, even though the end result in both cases is an installation
    of Apache. On a small scale, this is not an issue, but when servers are numerous
    and as server count goes up, so does the complexity of managing such an environment.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The base operating system is just the start. Our example above was installing
    Apache, yet we could also install nginx or even lighttpd. They are, after all,
    also web servers.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Then, there is configuration. Do you want users to be able to log in as root over
    SSH? Do you need a certain level of logging for audit or debug purposes? Do you
    need local or centralized authentication? The list is myriad, and as you can see,
    if left unchecked could grow into a massive headache.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where the SOE comes in. It is effectively a specification, and at a
    high level, it might say the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Our standard base operating system is Ubuntu 18.04 LTS.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our standard web server will be Apache 2.4.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SSH logins are enabled, but only for users with SSH keys and not root.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All user logins must be logged and archived for audit purposes.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Except for a few local *break glass* accounts, all accounts must be centrally
    managed (for example, by LDAP or Active Directory).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our corporate monitoring solution must be integrated (for example, the Nagios
    NCPA agent must be installed and configured to communicate with our Nagios server).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All system logs must be sent to the corporate central log management system.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security hardening must be applied to the system.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding is simply an example, and it is by no means complete; however,
    it should begin to give you an idea of what an SOE looks like at a high level.
    As we proceed through this chapter, we will delve deeper into this subject and
    give more examples to build up a clear definition.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Knowing what to include
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we proceed, let's take a look in a little more detail at what to include
    in the environment. We have outlined in the previous section a very simplistic
    definition for an SOE. Part of any good SOE operating process is to have a pre-defined
    operating system build that can be deployed at a moment's notice. There are multiple
    ways this might be achieved and we will discuss these later in this book—however,
    for the time being, let's assume that a base image of Ubuntu 18.04 LTS as suggested
    previously has been built. What do we integrate into this *standard* build?
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: We know, for example, that our login policy is going to be applied throughout
    the organization—hence, when the build is created, `/etc/ssh/sshd_config` must
    be customized to include `PermitRootLogin no` and `PasswordAuthentication no`.
    There is no point in performing this step in the post-deployment configuration,
    as this would have to be performed on each and every single deployment. Quite
    simply, this would be inefficient.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also important automation considerations for our operating system
    image. We know that Ansible itself communicates over SSH, and so we know that
    we are going to require some kind of credentials (it is quite likely this will
    be SSH key-based) for Ansible to run against all of the deployed servers. There
    is little point in having to manually roll out Ansible credentials to every single
    machine before you can actually perform any automation, and so it is important
    to consider the kind of authentication you want Ansible to use (for example, password-
    or SSH key-based), and to create the account and corresponding credentials when
    you build the image. The exact method for doing this will depend upon your corporate
    security standards, but I would advocate as a potential solution the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Creating a local account on the standard image for Ansible to authenticate against
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Giving this account appropriate sudo rights to ensure all desired automation
    tasks can be performed
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting the local password for this account, or adding the SSH public key from
    an Ansible key-pair to the `authorized_keys` file for the local Ansible account
    you created
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing this, of course, does present some security risks. It is most likely that
    Ansible will need full access to root on your servers for it to effectively perform
    all of the automation tasks you might ask of it, and so this Ansible account could
    become a backdoor if the credentials were ever compromised. It is recommended
    that as few people as possible have access to the credentials and that you make
    use of a tool such as AWX or Ansible Tower (which we shall explore in [Chapter 3](b0c37bde-4b12-4619-94f1-dd14ae0c96ff.xhtml),
    *Streamlining Infrastructure Management with AWX*) to manage your credentials,
    hence preventing people from getting hold of them inappropriately. You will also
    almost certainly want to enable auditing of all activities performed by the Ansible
    account and have these logged to a central server somewhere so that you can inspect
    them for any suspicious activity and audit them as required.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Moving on from user accounts and authentication, consider also **Nagios Cross-Platform
    Agent** (**NCPA**). We know in our example that all deployed servers are going
    to need to be monitored, and so it is a given that NCPA agent must be installed,
    and the token defined such that it can communicate with the Nagios server. Again,
    there is no point doing this on every single server after the standard image is
    deployed.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: What about the web server though? It is sensible to have a standard, as it means
    all who are responsible for the environment can become comfortable with the technology.
    This makes administration easier and is especially beneficial for automation,
    as we shall see in the next section. However, unless you only ever deploy web
    servers running on Linux, this probably shouldn't be included as part of the standard
    build.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: As a sound principle, the standard builds should be as simple and lightweight
    as possible. There is no point in having additional services running on them,
    taking up memory and CPU cycles, when they are redundant. Equally, having unconfigured
    services increases the attack surface for any potential attacker and so for security
    reasons, it is advisable to leave them out.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: In short, the standard build should only include configuration and/or services
    that are going to be common to every server deployed. This approach is sometimes
    referred to as **Just enough Operating System** or **JeOS** for short, and it
    is the best starting point for your SOE.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Having understood the basic principles of an SOE, we will proceed in the next
    section to look in more detail at the benefits an SOE brings to your enterprise.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Exploring SOE benefits
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, you should have some idea of what an SOE is, and how it brings economies
    of scale and greater efficiency to a Linux environment. Now, let's build on that
    and look in more detail at an example of the importance of standardization.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Example benefits of an SOE in a Linux environment
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To say that there are commonalities in a Linux environment is to say that the
    servers that comprise it all share attributes and features. For example, they
    might all be built upon Ubuntu Linux, or they might all have Apache as their web
    server.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: We can explore this concept with an example. Suppose that you have 10 Linux
    web servers behind a load balancer and that they are all serving simple static
    content. Everything is working fine, but then a configuration change is mandated.
    Perhaps this is to change the document root of each web server to point to a new
    code release that has been deployed to them by another team.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: As the person responsible, you know that because the overall solution is load
    balanced, all servers should be serving the same content. Therefore, the configuration
    change is going to be required on each and every one. That means 10 configurations
    changes to make if you do it by hand.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: You could, of course, do this by hand, but this would be tedious and certainly
    isn't the best use of time for a skilled Linux admin. It is also error-prone—a
    typo could be made on one of the 10 servers and not spotted. Or the admin could
    be interrupted by an outage elsewhere and only a subset of the server configurations
    changed.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: The better solution would be to write a script to make the change. This is the
    very basis of automation and it is almost certainly going to be a better use of
    time to run a single script once against 10 servers than to manually make the
    same change 10 times over. Not only is it more efficient, but if the same change
    became required in a month, the script could be reused with just minimal adjustment.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s throw a spanner into the works. What if, for reasons unknown, someone
    built five of the web servers using Apache on CentOS 7, and the other five using
    nginx on Ubuntu 18.04 LTS? The end result would, after all, be the same—at a basic
    level, they are both web servers. However, if you want to change the document
    root in Apache on CentOS 7, you would need to do the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Locate the appropriate configuration file in `/etc/httpd/conf.d`.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make the required change to the `DocumentRoot` parameter.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reload the web server with `systemctl reload httpd.service`.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you had to do the same thing for nginx on Ubuntu 18.04 LTS, you would do
    the following:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Locate the correct configuration file in `/etc/nginx/sites-available`.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make the required change to the `root` parameter.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the site configuration file is enabled using the `a2ensite` command—otherwise,
    Apache will not actually see the configuration file.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reload the web server with `systemctl reload apache2.service`.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As you can see from this rather simplistic (albeit contrived) example, a lack
    of commonality is the enemy of automation. To cope with the case, you would need
    to do as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'Detect the operating system on each server. This in itself is non-trivial—there
    is no one way to detect a Linux operating system, so your script would have to
    walk through a series of checks, including the following:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The contents of `/etc/os-release`, if it exists
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The output of `lsb_release`, if it is installed
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The contents of `/etc/redhat-release`, if it exists
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The contents of `/etc/debian_version`, if it exists
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Other OS-specific files as required, if none of the preceding produce meaningful
    results
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run different modification commands in different directories to effect the change
    as discussed previously.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run different commands to reload the web server, again as detailed previously.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hence, the script becomes complex, more difficult to write and maintain, and
    certainly more difficult to make reliable.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'Although this particular example is unlikely to occur in real life, it does
    serve to make an important point—automation is much easier to implement when the
    environment is built to a given standard. If a decision is made that all web servers
    are to be based on CentOS 7, to run Apache 2, and have the site configuration
    named after the service name, then our automation becomes so much easier. In fact,
    you could even run a simple `sed` command to complete the change; for example,
    suppose the new web application was deployed to `/var/www/newapp`:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: No environment detection was necessary at all—just two simple shell commands.
    This could be the basis of a really simple automation script to be run either
    on each of the 10 servers in turn or remotely over SSH. Either way, our automation
    task is now very simple and shows how important commonality is. Importantly, an
    SOE by its very nature provides this commonality. Lack of commonality doesn't
    just make automation difficult though—it also hampers testing, often distorting
    test results as they may not be representative if environments are different.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: In the next section of this chapter, we will build on this knowledge to demonstrate
    how an SOE benefits the process of software testing.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of SOE to software testing
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common problem I have seen in many environments is that of a new software
    deployment having been successfully tested in an isolated pre-production environment
    and yet not working correctly when it is released into the production environment.
    More often than not, this problem is traced back to fundamental differences between
    the production and pre-production environments, and so it is clear that for testing
    to be valid, both environments must be as similar as possible.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, one of the problems containerization platforms such as Docker set out
    to solve was exactly this, and hence portability is a core feature of container
    environments. Code deployed on Docker is built on top of a container image that
    is, in simple terms, a stripped-down operating system image (remember JeOS?).
    This, in effect, is a really tiny SOE, just running in a container rather than
    on a bare metal server or virtual machine. However, it is worth considering that
    if portability through environment standardization is a key feature of container
    technology, then should we not try to achieve this across the board regardless
    of our infrastructure.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: After all, if the configuration of the production servers is different from
    the pre-production ones, then how valid is the testing? If the pre-production
    environment was built on CentOS 7.6, but the production environment lags behind
    it on CentOS 7.4, then can you really ensure that a successful test result in
    one environment will guarantee it in the other? On paper, it should work, but
    with fundamental differences in software and library versions between the environments,
    this can never be guaranteed. This is before we even consider possible differences
    in configuration files and installed software.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Hence, SOEs can help here—if all environments are built to the same standards,
    then in theory, they should all be identical. Those of you who are eagle-eyed
    will notice the use of the word *should* in the previous sentence and it is there
    for a good reason. SOEs are a great step forward in defining the solution for
    testing failures, but they are not the whole story.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: An environment is only standard as long as no-one modifies it, and if all users
    have administration-level privileges, then it is very easy for someone (well-meaning
    or otherwise) to log in and make changes that mean the environment deviates from
    the standard.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: The answer to this issue is automation—not only do SOEs promote and enable automation,
    they also rely on it to maintain the level of standardization that they were required
    for in the first place. The two support each other directly and should ideally
    be inseparable partners—the SOE being the definition for the environment itself,
    and the automation providing the implementation, enforcement, and auditing of
    the standard. Indeed, this is the very premise of this book—that environments
    should be standardized as far as possible, and that as many changes as possible
    should be automated.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: The focus of this book will be on the automation aspect of this equation, as
    other than adhering to the principles outlined in this chapter, the standards
    adopted will be unique for every environment and it is not the goal of this book
    to determine them at a low level. Working with our earlier example, both Apache
    and nginx have their benefits, and what fits one use case may not fit another.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: The same is true with operating systems—some organizations may rely on the support
    package provided with Red Hat Enterprise Linux, whilst others don't need this
    but need the bleeding edge technologies provided by, say, Fedora. There is no
    right or wrong way to define a standard, as long as it meets the needs of the
    services it underpins. So far, we have focused very much on commonality and standards;
    however, there will always be edge cases where an alternative solution is required.
    In the next section, we will establish how to know when you should deviate from
    your standards.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Knowing when to deviate from standards
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It would be easy to oversell the benefits of standardization, and they are certainly
    a requirement for automation to be effective. However, like anything, it can be
    taken too far. There is no point, for example, building servers on top of Red
    Hat Enterprise Linux 5.7 in 2019 simply because this was once defined as a standard
    (it is now End of Life and no longer supported or updated). Similarly, from time
    to time, software vendors will have qualified their product on certain specific
    Linux distributions or application stacks and will not provide support unless
    their software is run within that ecosystem.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: These are cases when deviations from the SOE are necessary, but they should
    be performed in a controlled manner. For example, if a business has built up its
    Linux server estate on Ubuntu 18.04 LTS, and then a new software stack is purchased
    that is only qualified on RHEL 7, it is clear that builds of RHEL 7 are going
    to be required. These should, however, be part of a new set of standards if possible
    and become a secondary SOE.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if the CIS security hardening benchmark is applied to the Ubuntu
    SOE, then the equivalent one should be applied to the RHEL too. Similarly, if
    the business has standardized on nginx, then this should be used on the environment
    unless there is a compelling reason not to (hint: a compelling reason is not that
    it''s new and sexy—it is that it solves a real problem or somehow improves something
    in a tangible way).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: This results in the business going from one Linux SOE to two, which is still
    entirely manageable and certainly better than returning to organic growth methodologies
    that hamper effective automation.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: In short, expect deviations, and don't fear them. Instead, handle them and use
    the requirements to expand your standards, but stick with them where you can.
    SOEs present a balancing act for everyone—on the one hand, they bring advantages
    of scale, make automation easier, and reduce the training time for new staff (as
    all servers are more or less the same in build and configuration), but if applied
    too rigidly, they could hamper innovation. They must not be used as an excuse
    to do things a certain way *because that's how it has always been done*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: There will always be a good reason to deviate from a standard; simply look for
    the business benefit it brings, whether it's vendor support, lower resource requirements
    (hence saving power and money), a longer support window, or otherwise. Try and
    avoid doing so just because a new technology is *shiny*. As long as you are mindful
    of this fact, you will make good decisions regarding deviation from your standards.
    In the next section of this chapter, we will explore the ongoing maintenance of
    SOEs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Ongoing maintenance of SOEs
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although we will look at patching and maintenance in much greater detail later
    in this book, it deserves a mention here as it dovetails nicely into the discussion
    on commonality and deviations.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: If nothing else, you are going to have to patch your Linux environment. For
    security reasons alone, this is a given and good practice, even in an air-gapped
    environment. Let's say that your environment is made up entirely of virtual machines
    and that you decided to standardize on CentOS 7.2 some time ago. You built a virtual
    machine, performed all of the required configuration steps to turn it into your
    SOE image, and then converted it into a template for your virtualization environment.
    This becomes your *gold build*. So far, so good.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: However, CentOS 7.2 was released in December 2015, nearly 4 years ago at the
    time of writing, and if you were to deploy such an image today, the first thing
    you would have to do is patch it. This would, depending on the build definition
    (and the number of packages included in it), possibly involve downloading a gigabyte
    or more of packages to bring it up to the latest standard and ensure you were
    running with all discovered vulnerabilities patched, and all of the requisite
    bug fixes in place.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, if you are doing this at scale, this is inefficient—each new server
    is going to pull all that data down over the network (or worse, the internet,
    if you don't have an internal mirror), and then consume a great deal of I/O time
    and CPU time applying the patches, during which the server can't be used for anything
    meaningful. If you only deploy one server every few months, you can probably put
    up with this. If you deploy them on a more regular basis, then this is going to
    waste a lot of valuable time and resources.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Hence, as well as performing ongoing maintenance of your environment itself,
    it is important to perform ongoing maintenance of your standards. In 2019, it
    makes sense to update your CentOS build to 7.6\. At the very least, your ongoing
    maintenance schedule should involve updating the *gold build* regularly.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: We will go into much greater detail on how this might be performed later in
    this book. However, for those who are eager to know now, this might be as simple
    as booting the virtual machine image up, performing the updates, sanitizing it
    (for example, removing SSH host keys that would be duplicated when the template
    is cloned), and then creating a new template from it. Obviously, if any other
    changes to the SOE have been made since the last maintenance cycle, then these
    can be incorporated too.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: You should expect your SOE to evolve over time—it would be easy perhaps to labor
    this point—but there is an important balance between creating and maintaining
    standards, and being overly rigid with them. You must accept that there are times
    when you will need to deviate from them as we discussed in the previous section
    and that, over time, they will evolve.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: In short, SOEs should become a part of your regular IT processes; if employed
    correctly, they don't hinder innovation— instead, they actively support it by
    giving back time to those working with them and ensuring they spend less time
    performing mundane, repetitive tasks and hence have more time for evaluating new
    technologies and finding better ways of doing things. This, after all, is one
    of the key benefits of automation, which SOEs support directly.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SOEs are a valuable addition to technology processes in almost any environment.
    They require some time to be spent upfront on design work and defining standards,
    but this time is more than offset later on as it supports efficient and effective
    automation of the environments, and in this manner, actually gives time back to
    those responsible for the environment, giving them more time to work on evaluating
    new technologies, finding more efficient ways to do things, and being innovative in
    general.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned the fundamental definition of an SOE. You explored
    the benefits that they bring to just about any Linux environment where scale is
    important, how they support automation, and when and how to make deviations from
    the standards to ensure that they do not become overly rigid and hamper growth.
    Finally, you learned about the importance of ongoing maintenance, including maintenance
    of your standards as part your ongoing maintenance cycles.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore how to make use of Ansible as an effective
    automation framework for your Linux environment.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What does the acronym SOE stand for?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why would you choose an operating system with a long support cycle, such as
    CentOS, rather than one with a more rapid release cycle, such as Fedora?
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should you ever deviate from the standards you have defined for your environment?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List three challenges of scaling Linux environments up to enterprise scale.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name three benefits that SOEs bring to Linux in the enterprise.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does an SOE help to reduce the training requirements in an enterprise?
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why does an SOE benefit the security of your Linux environment?
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To learn more about SOEs from a Red Hat perspective, refer to this article: [https://servicesblog.redhat.com/2016/11/03/standard-operating-environment-part-i-concepts-and-structures/](https://servicesblog.redhat.com/2016/11/03/standard-operating-environment-part-i-concepts-and-structures/).
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
