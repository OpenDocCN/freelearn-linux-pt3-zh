- en: '*Chapter 13*: Understanding cgroup Version 2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第13章*：理解cgroup Version 2'
- en: In this chapter, we'll look at **cgroup** **Version 2**. We'll see how it's
    different from **cgroups** **Version 1**, and how it improves upon Version 1\.
    After that, we'll take a brief look at how to work with it. We'll wrap up by converting
    the **AlmaLinux** machine to use cgroup Version 2\. Learning how to use cgroup
    Version 2 will be very helpful to developers of new software, as well as to **Linux**
    administrators who want to be prepared for the future.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论**cgroup** **Version 2**。我们将看到它与**cgroups** **Version 1**有何不同，以及它如何在Version
    1的基础上进行改进。之后，我们将简要了解如何使用它。最后，我们将把**AlmaLinux**机器转换为使用cgroup Version 2。学习如何使用cgroup
    Version 2将对新软件开发者以及希望为未来做好准备的**Linux**管理员非常有帮助。
- en: By the way, that's not a typo that you see in the chapter title. One of the
    Version 2 changes is in the official name of the technology. So, we have *cgroups*
    Version 1, and *cgroup* Version 2\. Strange, but true. (I didn't explain this
    before, because I didn't want to create more confusion).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，章节标题中的这个并不是打字错误。Version 2的一个变化是官方名称的变化。所以，我们有*cgroups* Version 1和*cgroup*
    Version 2。听起来很奇怪，但是真的。（我之前没有解释过这个，因为我不想引起更多混淆。）
- en: 'Specific topics in this chapter include:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的具体主题包括：
- en: Understanding the need for Version 2
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Version 2的需求
- en: Understanding the improvements in Version 2
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Version 2的改进
- en: Setting resource limits on rootless containers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置无根容器的资源限制
- en: Understanding **cpuset**
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解**cpuset**
- en: Converting RHEL 8-type distros to cgroup version 2
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将RHEL 8类发行版转换为cgroup Version 2
- en: With the introduction out of the way, let's get started.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍完毕，让我们开始吧。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This time, we'll use a **Fedora** **virtual machine** that's set to use as many
    CPU cores and as much memory as you can spare. (I'll still have mine set to use
    four CPU cores and eight GB of memory.) So, download your favorite spin of Fedora,
    and create a virtual machine from it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们将使用一台**Fedora** **虚拟机**，该虚拟机配置为尽可能使用更多的CPU核心和内存。（我的虚拟机仍然设置为使用四个CPU核心和8GB内存。）因此，下载你喜欢的Fedora版本，并从中创建虚拟机。
- en: For the *Understanding cpuset* section, it would be helpful to have a host computer
    with at least two physical CPUs. I realize that not many people will have access
    to a machine like that, and that's okay. I do have such a machine, so I can show
    you what you need to see.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*理解cpuset*部分，最好使用至少有两个物理CPU的主机。我知道不是每个人都有机会使用这样的机器，但没关系。我有这样一台机器，所以我可以向你展示你需要看到的内容。
- en: We'll also use the AlmaLinux machine for a couple of brief demos.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用AlmaLinux机器进行几次简短的演示。
- en: All right, let's get with it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们开始吧。
- en: 'Check out the following link to see the Code in Action video: [https://bit.ly/3xJNcDx](https://bit.ly/3xJNcDx)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接以观看《代码实战》视频：[https://bit.ly/3xJNcDx](https://bit.ly/3xJNcDx)
- en: Understanding the need for Version 2
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Version 2的需求
- en: As good as cgroups Version 1 is, it does have a few rather serious flaws. Let's
    take a quick look.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管cgroups Version 1已经相当不错，但它确实存在一些相当严重的缺陷。我们来快速看一下。
- en: Version 1 complexity
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Version 1的复杂性
- en: To begin with, Version 1 has too many resource controllers and too many attributes
    per controller. Very few people use more than just the *Big Three* controllers
    that we covered in [*Chapter 12*](B17491_12_Final_NM_ePub.xhtml#_idTextAnchor164),
    Controlling Resource Usage with cgroups Version 1\. Some unnecessary controllers
    have been removed from Version 2.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，Version 1拥有过多的资源控制器和每个控制器上过多的属性。很少有人会使用我们在[*第12章*](B17491_12_Final_NM_ePub.xhtml#_idTextAnchor164)中介绍的那三个主要的控制器，资源使用控制通过cgroups
    Version 1来实现。Version 2去除了一些不必要的控制器。
- en: 'There''s also too much complexity with the Version 1 hierarchy, which makes
    it a bit confusing to use and can hurt performance. To see what I mean, think
    back about what we saw in the Version 1 `cgroup` filesystem. You saw that each
    resource controller has its own subdirectory, as we see here:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Version 1层次结构的复杂性也过高，这使得它的使用有些混乱，并且可能影响性能。要理解我的意思，回想一下我们在Version 1的`cgroup`文件系统中看到的内容。你会发现，每个资源控制器都有自己的子目录，就像我们在这里看到的那样：
- en: '![](img/Figure_13.1_B17491.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Figure_13.1_B17491.jpg)'
- en: Figure 13.1 – The resource controllers for version 1 on Ubuntu
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 – Ubuntu上Version 1的资源控制器
- en: 'In [*Chapter 12*](B17491_12_Final_NM_ePub.xhtml#_idTextAnchor164), *Controlling
    Resource Usage with cgroups Version 1*, we also saw that when we set a `CPUQuota`
    for Vicky, it appeared in her `user-1001.slice` subdirectory that''s under the
    `cpu/user.slice` subdirectory, like this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第12章*](B17491_12_Final_NM_ePub.xhtml#_idTextAnchor164)，《使用cgroups Version
    1控制资源使用》中，我们也看到，当我们为Vicky设置`CPUQuota`时，它出现在她的`user-1001.slice`子目录下，这个目录位于`cpu/user.slice`子目录下，像这样：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, when we set a `MemoryMax` restriction, it showed up under the `memory`
    subdirectory, like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，当我们设置`MemoryMax`限制时，它出现在`memory`子目录下，像这样：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Okay, you''ll never guess what happened when we set Vicky''s `BlockIOReadBandwidth`
    parameter. That''s right, it shows up under the `blkio` subdirectory, like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，你绝对猜不到，当我们设置Vicky的`BlockIOReadBandwidth`参数时发生了什么。没错，它出现在`blkio`子目录下，像这样：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: So you see, Vicky's settings are in three different places, which means that
    the operating system has to look in all three places to get them all.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你看，Vicky的设置在三个不同的地方，这意味着操作系统必须查看所有三个地方才能获取完整的设置。
- en: Note
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: I accidentally used Vicky's login window instead of my own for these screenshots,
    but that's okay. It shows you that Vicky can see the settings in her own cgroup
    files. Of course, she can't change the settings, because she doesn't have the
    correct root privileges.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我不小心用了Vicky的登录窗口，而不是我自己的截图工具，不过没关系。这说明Vicky可以查看她自己cgroup文件中的设置。当然，她无法更改设置，因为她没有正确的root权限。
- en: Version 1 attribute filenames
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Version 1属性文件名
- en: 'Another problem with Version 1 is that there''s no consistent naming convention
    for the attribute files of the different resource controllers. For example, setting
    `MemoryMax` on Version 1 places a value in the `memory.max_usage_in_bytes` file,
    as we see here for Vicky:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Version 1的另一个问题是，不同资源控制器的属性文件没有统一的命名规范。例如，在Version 1中，设置`MemoryMax`会将值放入`memory.max_usage_in_bytes`文件中，就像我们在这里为Vicky看到的那样：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'However,Vicky''s `CPUQuota` setting shows up in the `cpu.cfs_quota_us` file,
    as we see here:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Vicky的`CPUQuota`设置出现在`cpu.cfs_quota_us`文件中，正如我们在这里看到的：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As we'll see in a few moments, naming conventions are a lot more consistent
    with Version 2.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们稍后会看到的，命名约定在第2版中要一致得多。
- en: Okay, let's get to the real root of the problem by talking about *rootless containers*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们从真正的根本问题入手，讨论一下*无root容器*。
- en: No support for rootless containers
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不支持无root权限的容器
- en: 'As you saw in [*Chapter 5*](B17491_05_Final_NM_ePub.xhtml#_idTextAnchor063),
    *Creating and Editing Services*, we can use `podman` to create and run **Docker**
    containers without either root privileges or membership in the docker group. However,
    with cgroups Version 1, it''s not possible for a non-privileged user to set runtime
    resource limits when creating a container. For example, let''s go to the AlmaLinux
    machine and create a new user account for my buddy, Pogo, by doing:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[*第5章*](B17491_05_Final_NM_ePub.xhtml#_idTextAnchor063)《创建和编辑服务》中看到的，我们可以使用`podman`创建并运行**Docker**容器，而不需要root权限或docker组的成员资格。然而，在cgroups
    Version 1中，非特权用户无法在创建容器时设置运行时资源限制。例如，让我们去AlmaLinux机器，并为我的朋友Pogo创建一个新用户账户，操作如下：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Look at what happens to the poor guy when he tries to create a container with
    a 50% `CPUQuota`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 看看这个可怜的家伙试图创建一个50%的`CPUQuota`容器时发生了什么：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Alas, poor Pogo doesn't have root privileges. So, he can create and run `podman`
    containers, but he can't set any resource limits for them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 唉，可怜的Pogo没有root权限。所以，他可以创建和运行`podman`容器，但无法为它们设置任何资源限制。
- en: Note
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Actually, with cgroups Version 1, it *is* possible for a non-privileged user
    to set runtime resource limits on rootless `podman` containers. But, it requires
    that you delegate this ability to non-root users. With cgroups Version 1, that
    constitutes a security hazard because it could allow someone to create a container
    that could freeze your system. So, we're not going to do it (We'll talk more about
    delegation in just a bit).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，在cgroups Version 1中，非特权用户确实可以为无root权限的`podman`容器设置运行时资源限制。但这需要你将此权限委派给非root用户。在cgroups
    Version 1中，这构成了安全隐患，因为它可能允许某人创建一个容器，进而冻结你的系统。所以，我们不打算这么做（稍后我们会详细讨论委派问题）。
- en: Now, let's contrast that with what we see on the Fedora machine, which is running
    a pure cgroup Version 2 environment.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来对比一下在运行纯cgroup Version 2环境的Fedora机器上看到的情况。
- en: Understanding the improvements in cgroup Version 2
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解cgroup Version 2中的改进
- en: Version 2 is a bit more streamlined and simpler to understand. At the time of
    writing, Fedora, **Arch**, and **Debian 11** are the only three Linux distros
    of which I know that run cgroup Version 2 by default (that will likely change
    by the time you read this).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 版本 2 更加简化，易于理解。在写这篇文章时，我知道只有 **Arch**、**Debian 11** 和 Fedora 这三个 Linux 发行版默认运行
    cgroup 版本 2（到你读这篇文章时，这个情况可能会有所变化）。
- en: Note
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: It is possible to convert RHEL 8-type distros, such as **Alma** and **Rocky**,
    over to a pure Version 2 setup. Unfortunately, the RHEL-type distros use an older
    implementation of Version 2 that still doesn't have all of the resource controllers
    that we need enabled. So, to see everything that we need to see, we'll use Fedora.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将 RHEL 8 类型的发行版，例如 **Alma** 和 **Rocky**，转换为纯版本 2 设置。不幸的是，RHEL 类型的发行版使用的是版本
    2 的较旧实现，其中一些我们需要的资源控制器仍未启用。因此，为了查看我们需要看到的所有内容，我们将使用 Fedora。
- en: 'To begin, let''s log in to the Fedora machine and create a user account for
    my buddy Pogo (Pogo is the awesome opossum who comes in through my cat door at
    night to chow down on the cat food – Yes,seriously.) Then,Then, have Pogo log
    in from a remote terminal (Note that on Fedora, you might have to start and enable
    the `sshd` service first.) On your own local terminal, look at the cgroup filesystem,
    which looks like this:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们登录到 Fedora 机器，并为我的朋友 Pogo 创建一个用户账户（Pogo 是那只从我家的猫门进来、晚上来吃猫粮的超棒负鼠——是的，是真的。）。然后，让
    Pogo 从远程终端登录（请注意，在 Fedora 上，你可能需要先启动并启用 `sshd` 服务）。在你本地的终端中，查看 cgroup 文件系统，内容如下所示：
- en: '![](img/Figure_13.2_B17491.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Figure_13.2_B17491.jpg)'
- en: Figure 13.2 – The cgroup filesystem on Fedora
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 – Fedora 上的 cgroup 文件系统
- en: The attribute files that we see here are for the global settings, which we don't
    really care about for now. What I really want you to see is under the `system.slice`
    and `user.slice` subdirectories. Let's look at the `user.slice` subdirectory first.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里看到的属性文件是用于全局设置的，目前我们暂时不关心这些。真正需要你注意的是 `system.slice` 和 `user.slice` 子目录下的内容。我们先看一下
    `user.slice` 子目录。
- en: 'Under the `user.slice` subdirectory, you''ll see lots of files for things that
    can be set at the user slice level. At the bottom, we see the subdirectories for
    both Pogo and me, as we see here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `user.slice` 子目录下，你会看到许多可以在用户切片级别设置的文件。底部，我们看到了 Pogo 和我自己的子目录，正如这里所示：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Each of these user slice subdirectories contains attribute files for all of
    the resource controllers, as we see here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户切片子目录都包含所有资源控制器的属性文件，如我们在这里看到的：
- en: '![](img/Figure_13.3_B17491.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Figure_13.3_B17491.jpg)'
- en: Figure 13.3 – Resource controllers for user-1001.slice
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3 – 用户-1001.slice 的资源控制器
- en: So now, all of the applicable settings for a particular user would be contained
    in the `user slice` directory for that user. The operating system now only has
    to look in one place to get all of the settings for a user.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在，特定用户的所有适用设置都将包含在该用户的 `user slice` 目录中。操作系统现在只需要在一个地方查找该用户的所有设置。
- en: 'Next, have Pogo log in from a remote terminal. Then, in your own terminal window,
    set `CPUQuota` for Pogo. The good news is that the command to do that is exactly
    the same as it was in Version 1\. If you don''t remember, the command is:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让 Pogo 从远程终端登录。然后，在你自己的终端窗口中，为 Pogo 设置 `CPUQuota`。好消息是，执行此操作的命令和版本 1 完全相同。如果你不记得了，命令是：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, do a `daemon-reload`. Once that''s done, look at the `cpu.max` file in
    Pogo''s user slice directory, which should look like this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行 `daemon-reload`。完成后，查看 Pogo 用户切片目录中的 `cpu.max` 文件，其内容应该如下所示：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `40000` figure represents the 40% `CPUShare`, and `100000` represents the
    time interval over which `CPUShare` is measured. The default time setting, which
    you see here, is 100 milliseconds (you can change that time interval, but you'll
    likely never need to).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`40000` 表示 40% 的 `CPUShare`，而 `100000` 表示测量 `CPUShare` 的时间间隔。默认的时间设置是 100 毫秒（你可以更改这个时间间隔，但你很可能永远不需要这样做）。'
- en: 'You would also set Pogo''s memory limit the same you did with Version 1, as
    we see here:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以像设置版本 1 一样设置 Pogo 的内存限制，如我们在这里所示：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This time, the setting shows up in Pogo''s `memory.max` file, as we see here:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，设置出现在 Pogo 的 `memory.max` 文件中，如我们在这里看到的：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now, understand that this `MemoryMax` setting is a hard limit. In other words,
    Pogo absolutely cannot use more memory than what `MemoryMax` allocates. If you
    look in the `systemd.resource-control` man page, you'll see other options that
    are available for Version 2 and that aren't available for Version 1\. (Note that
    this man page always refers to cgroup Version 2 as the *unified control group
    hierarchy*.) One such parameter is `MemoryHigh`, which is more of a soft limit.
    `MemoryHigh` would allow Pogo to exceed his memory allocation if it's unavoidable,
    but his processes would be throttled until his memory usage goes back down to
    within his allocation. This makes it easier for a system to deal with temporary
    spikes in memory usage for any given process or user.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，理解这个 `MemoryMax` 设置是一个硬限制。换句话说，Pogo 绝对不能使用超过 `MemoryMax` 分配的内存。如果你查看 `systemd.resource-control`
    的 man 页面，你会看到版本 2 中可用的一些其他选项，而版本 1 中没有。（请注意，该 man 页面总是将 cgroup 版本 2 称为 *统一控制组层次结构*。）其中一个参数是
    `MemoryHigh`，它更像是一个软限制。如果不可避免，`MemoryHigh` 允许 Pogo 超过其内存分配，但他的进程会被限制，直到他的内存使用降回到分配的范围内。这使得系统更容易处理任何给定进程或用户的内存使用临时峰值。
- en: Version 2 also has the `MemoryLow` and `MemoryMin` parameters, which cause a
    process to reclaim memory from unprotected processes if the amount of free memory
    for the protected process drops to the specified threshold. If you want to control
    swap memory usage, Version 2 lets you do that with the `MemorySwapMax` parameter.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 版本 2 还具有 `MemoryLow` 和 `MemoryMin` 参数，当受保护进程的空闲内存降至指定阈值时，这些参数会导致进程从未受保护进程中回收内存。如果你想控制交换内存的使用，版本
    2 允许你通过 `MemorySwapMax` 参数来实现。
- en: 'Setting limits on `block I/O` usage is a bit different, because the parameter
    names have changed. To limit Pogo''s read bandwidth, we''ll first use `df` to
    see what drive devices we have, as we see here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 `block I/O` 使用限制有些不同，因为参数名称已经发生了变化。为了限制 Pogo 的读取带宽，我们首先使用 `df` 查看我们有哪些驱动器设备，如下所示：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The desktop versions of Fedora now use the `btrfs` filesystem by default, which
    is why we just see regular drive partitions instead of logical volumes. (There's
    no need to use logical volumes with `btrfs` because it has its own built-in drive
    pooling mechanism.) If you're using `ext4` and logical volumes. Anyway, we see
    that the `/home/` directory is mounted on the `/dev/sda` drive, which of course
    is where Pogo's home directory is. (As we saw with version 1, you can set a rate
    limit on an entire drive, but not on a specific partition of that drive.)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Fedora 的桌面版本现在默认使用 `btrfs` 文件系统，这就是为什么我们看到的是常规的驱动器分区而不是逻辑卷。（使用 `btrfs` 时无需使用逻辑卷，因为它具有内置的驱动器池机制。）如果你使用的是
    `ext4` 和逻辑卷，情况就不一样了。不管怎样，我们看到 `/home/` 目录挂载在 `/dev/sda` 驱动器上，当然这就是 Pogo 的主目录所在。（正如我们在版本
    1 中看到的，你可以对整个驱动器设置速率限制，但不能对该驱动器的特定分区设置限制。）
- en: 'We''ll now use the `IOReadBandwidthMax` parameter to limit the rate at which
    Pogo can transfer files, like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用 `IOReadBandwidthMax` 参数来限制 Pogo 文件传输的速率，像这样：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that because there's a blank space in the `/dev/sda 1M` parameter, you
    have to surround it with a pair of double-quotes (`""`) when you set this from
    the command line.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于 `/dev/sda 1M` 参数中有空格，因此在从命令行设置时，必须将其用一对双引号（`""`）括起来。
- en: 'Next, look at the `io.max` file in Pogo''s user slice directory, which should
    look like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，查看 Pogo 用户切片目录中的 `io.max` 文件，应该是这样的：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here, we see another benefit of using Version 2\. Instead of having four separate
    attribute files for the four available parameter settings, as we had with Version
    1, Version 2 places the `IOReadBandwidthMax`, `IOWriteBandwidthMax`, `IOReadIOPSMax`,
    and `IOWriteIOPSMax` settings all in one file.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到了使用版本 2 的另一个好处。与版本 1 中有四个单独的属性文件来存放四个可用的参数设置不同，版本 2 将 `IOReadBandwidthMax`、`IOWriteBandwidthMax`、`IOReadIOPSMax`
    和 `IOWriteIOPSMax` 设置放在了一个文件中。
- en: 'Also, note that the `8:0` we see at the beginning of the line in this `io.max`
    file represents the major and minor numbers of the entire `sda` drive, as we see
    here:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，注意我们在 `io.max` 文件中看到的行首的 `8:0`，它表示整个 `sda` 驱动器的主设备号和次设备号，如下所示：
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Okay, if you really want to, you can play around with `stress-ng` for Pogo as
    you did for Vicky in [*Chapter 12*](B17491_12_Final_NM_ePub.xhtml#_idTextAnchor164),
    *Controlling Resource Usage with cgroups Version 1*, but I'm not going to repeat
    the directions for that here.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，如果你真的想要，你可以像在 [*第 12 章*](B17491_12_Final_NM_ePub.xhtml#_idTextAnchor164)
    中为 Vicky 所做的那样，尝试使用 `stress-ng` 来测试 Pogo，*使用 cgroups 版本 1 控制资源使用*，但我不会在这里重复相关的操作步骤。
- en: 'The main thing to know about setting limits on services is that each system
    service has its own subdirectory under the `/sys/fs/cgroup/system.slice/` directory,
    as we see here:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 设置服务限制时需要知道的主要事项是，每个系统服务在 `/sys/fs/cgroup/system.slice/` 目录下都有自己的子目录，正如我们在这里看到的：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Within each of these subdirectories, you'll see the same attribute files that
    you saw for Pogo. Also, the procedure for setting limits on services is the same
    as it was for Version 1, so I also won't repeat any of that.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些子目录中，你会看到与 Pogo 相同的属性文件。此外，设置服务限制的过程与 Version 1 相同，所以我也不会重复这些内容。
- en: Note
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Be aware that certain parameters that you may be used to using under cgroups
    Version 1 have been renamed for cgroup Version 2\. Specifically, the `CPUShares`,
    `StartupCPUShares`, and `MemoryLimit` parameters in Version 1 have been replaced
    by `CPUWeight`, `StartupCPUWeight`, and `MemoryMax`, respectively. Also, all Version
    1 parameter names that have the `BlockIO` prefix have been replaced with parameter
    names that have the `IO` prefix.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一些你习惯在 cgroups Version 1 下使用的参数，在 cgroups Version 2 中已经被重命名。具体来说，Version
    1 中的 `CPUShares`、`StartupCPUShares` 和 `MemoryLimit` 参数已经分别被 `CPUWeight`、`StartupCPUWeight`
    和 `MemoryMax` 替代。此外，所有以 `BlockIO` 前缀命名的 Version 1 参数，已被以 `IO` 前缀命名的参数替代。
- en: All righty, now that we know about the cgroup Version 2 filesystem, let's see
    if we can let Pogo set some resource limits on a rootless container.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们了解了 cgroup Version 2 文件系统，让我们看看能否让 Pogo 在无根容器上设置一些资源限制。
- en: Setting resource limits on rootless containers
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在无根容器上设置资源限制
- en: A few moments ago, I told you about the concept of *delegation*. Normally, you
    need root privileges in order to set any resource limits. However, you can delegate
    this chore to non-privileged users. The best news is that unlike delegation under
    cgroups Version 1, delegation under cgroup Version 2 is perfectly safe.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 刚才，我向你介绍了 *委派* 的概念。通常，你需要根权限才能设置任何资源限制。然而，你可以将这项工作委派给非特权用户。最好的消息是，与 cgroups
    Version 1 中的委派不同，cgroups Version 2 中的委派是完全安全的。
- en: 'To see the default setting, open the `/lib/systemd/system/user@.service` file,
    and look for the `Delegate=` line in the `[Service]` section. The applicable lines
    should look like this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看默认设置，请打开 `/lib/systemd/system/user@.service` 文件，并在 `[Service]` 部分中查找 `Delegate=`
    行。相关行应该像这样：
- en: '[PRE17]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'By default, Fedora only allows non-privileged users to set resource limits
    for memory and for the maximum number of running processes. We need to edit that
    to include the `cpu`, `cpuset`, and `io` resource controllers, like this:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Fedora 只允许非特权用户设置内存和最大运行进程数的资源限制。我们需要编辑这个配置，以包括 `cpu`、`cpuset` 和 `io`
    资源控制器，像这样：
- en: '[PRE18]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Edit the `Delegate=` line so that it will look like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑 `Delegate=` 行，使其看起来像这样：
- en: '[PRE19]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Save the file and do a `daemon-reload`. Note that if any users are logged in,
    they might have to log out and log back in again for this to take effect.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 保存文件并执行 `daemon-reload`。请注意，如果有用户已登录，他们可能需要注销并重新登录才能使其生效。
- en: 'Keep Pogo''s original login window open, and then open a second one for him.
    He''ll create a container in one window, and look at the container information
    in the second window. Have Pogo create an **Ubuntu** container, like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 保持 Pogo 原来的登录窗口打开，然后为他再打开一个新的窗口。他将在一个窗口中创建一个容器，在第二个窗口中查看该容器信息。让 Pogo 创建一个 **Ubuntu**
    容器，像这样：
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Pogo is setting a `CPUQuota` of `50%` over a 100-millisecond time interval.
    In Pogo''s other login window, have him view the information about his container.
    He''ll first do a `podman ps`, like this:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Pogo 正在设置一个 `CPUQuota` 为 `50%` 的限制，时间间隔为 100 毫秒。在 Pogo 的另一个登录窗口中，让他查看他的容器信息。他会首先执行
    `podman ps`，像这样：
- en: '[PRE21]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Pogo didn''t assign a name to this container, so `podman` randomly assigned
    the name `funny_zhukovsky`. (Remember that Pogo is a opossum, so don''t be too
    hard on him for forgetting to assign a name.) Now, have Pogo inspect the inner
    workings of this container, using whatever container name that came up for you:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Pogo 没有为这个容器指定名称，因此 `podman` 随机分配了名称 `funny_zhukovsky`。（记住，Pogo 是一只负鼠，所以不要因为他忘记指定名称而太苛责他。）现在，让
    Pogo 使用生成的容器名称来检查这个容器的内部工作：
- en: '[PRE22]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'There''s a lot of output here, but you only need to look at two lines. Keep
    scrolling down, and you should find them. They should look like this:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这里输出很多内容，但你只需要关注两行。继续向下滚动，你应该能找到它们。它们应该像这样：
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'So far, so good. But, here''s where things get a bit tricky. It''s just that
    the attribute file for this container is buried deep within the cgroup filesystem
    where it''s hard to find. Fortunately, Pogo is a more clever opossum than I thought
    he was, so he found a way to cheat. He knew that the `50000` text string would
    only show up in one of the attribute files under his user slice directory, so
    he used `grep` to find it, like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切都还好。但问题是，这个容器的属性文件深藏在cgroup文件系统中，难以找到。幸运的是，Pogo比我想象的更聪明，所以他找到了一个作弊的方法。他知道`50000`这个文本字符串只会出现在他用户切片目录下的一个属性文件中，因此他使用`grep`命令来找到它，像这样：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'At last, Pogo found the attribute file:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Pogo找到了属性文件：
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: That wraps it up for rootless containers. So now, let's get set to talk about
    `cpuset`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是关于无根容器的全部内容。接下来，我们来讨论`cpuset`。
- en: Understanding cpuset
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解cpuset
- en: 'When you''re dealing with a server that''s running lots of containers and processes,
    it''s sometimes beneficial to assign a container or a process to a certain CPU
    core or set of CPU cores. On a machine with more than one physical CPU, it might
    also be beneficial to assign a memory node, as well. To see what I''m talking
    about, install `numactl` on your Fedora machine, like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处理一个运行大量容器和进程的服务器时，有时将某个容器或进程分配给特定的CPU核心或一组CPU核心会更有益。对于具有多个物理CPU的机器，分配内存节点也可能会有所帮助。为了理解我说的内容，可以在你的Fedora机器上安装`numactl`，像这样：
- en: '[PRE26]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Use the `-H` option to look at the hardware list, like this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`-H`选项查看硬件列表，像这样：
- en: '[PRE27]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: There's one `NUMA` node, which is `node 0`, and which is associated with four
    CPUs. Well, in reality, there's only *one CPU* that has *four CPU cores*. We also
    see the amount of memory that is assigned to this node.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个`NUMA`节点，即`节点 0`，并且它与四个CPU相关联。实际上，只有*一个CPU*，它有*四个CPU核心*。我们还可以看到分配给这个节点的内存量。
- en: 'So, now you''re saying, *But Donnie, what is this NUMA business, and why should
    I care?.* Okay, **NUMA** stands for **non-uniform memory access**. It has to do
    with how the operating system deals with memory on machines with more than one
    physical CPU. On systems with only a single CPU, such as your Fedora virtual machine,
    NUMA doesn''t do anything for us, because there''s only one memory node. On machines
    with more than one CPU, each CPU has its own associated memory node. For example,
    check out this photo of one of my junk motherboards:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在你可能会说，*但是Donnie，什么是NUMA？我为什么要关心它？* 好吧，**NUMA** 代表 **非一致性内存访问**。它与操作系统如何处理具有多个物理CPU的机器上的内存有关。在只有一个CPU的系统上，比如你的Fedora虚拟机，NUMA对我们没有任何作用，因为只有一个内存节点。在具有多个CPU的机器上，每个CPU都有自己关联的内存节点。例如，看看这是我一块废旧主板的照片：
- en: '![](img/Figure_13.4_B17491.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Figure_13.4_B17491.jpg)'
- en: Figure 13.4 – A dual-CPU motherboard
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 – 一块双CPU主板
- en: 'There are two CPU sockets, each with its own bank of memory sockets. Each bank
    of memory constitutes a NUMA node. Now, let''s look at one of my running multi-CPU
    systems, which is an old **Hewlett-Packard** workstation that''s running with
    two quad-core **AMD** **Opterons** and **Fedora 34**:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个CPU插槽，每个插槽都有自己的一组内存插槽。每组内存构成一个NUMA节点。现在，我们来看一下我正在运行的多CPU系统，这是一个旧的**惠普**工作站，配备了两颗四核**AMD**
    **Opteron**处理器，并运行**Fedora 34**：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: So, we see two NUMA nodes this time. The even-number CPU cores are assigned
    to `node 0`, and the odd-number CPU cores are assigned to `node 1`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们看到了两个NUMA节点。偶数号的CPU核心被分配给`节点 0`，而奇数号的CPU核心被分配给`节点 1`。
- en: By default, most processes run under a randomly chosen CPU core or set of CPU
    cores upon startup. Sometimes, the operating system might move a running process
    from one core or set of cores to another. On a normal workstation like I'm running
    here, that doesn't matter. But, it might matter on a server that's running lots
    of processes. You could possibly improve efficiency and performance by assigning
    certain processes to their own dedicated CPU cores and NUMA nodes. If you're dealing
    with cgroups Version 1, you'll need to jump through hoops and perform unnatural
    acts to make this work, because the Version 1 `cpuset` controller doesn't directly
    work with `systemd`. With cgroup Version 2, it's a breeze. It's just a matter
    of either using `systemctl set-property` to set the `AllowedCPUs=` and `AllowedMemoryNodes=`
    parameters, or setting them in the `[Service]` section of the service file.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，大多数进程在启动时会随机选择一个 CPU 核心或一组 CPU 核心运行。有时，操作系统可能会将正在运行的进程从一个核心或一组核心移到另一个核心。像我这里的普通工作站，这并不重要。但如果是在运行大量进程的服务器上，这可能很重要。你可能通过将某些进程分配到专用的
    CPU 核心和 NUMA 节点来提高效率和性能。如果你使用的是 cgroups 版本 1，那么你需要做很多繁琐的工作来使其生效，因为版本 1 的 `cpuset`
    控制器无法直接与 `systemd` 配合使用。而使用 cgroup 版本 2，这就轻松多了。你只需要使用 `systemctl set-property`
    来设置 `AllowedCPUs=` 和 `AllowedMemoryNodes=` 参数，或者在服务文件的 `[Service]` 部分中进行设置。
- en: 'Now, even though you only have one CPU for your Fedora virtual machine, you
    can still try this to see what it looks like. First, install the **Apache** web
    server by doing:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，即使你只有一个 CPU 的 Fedora 虚拟机，你仍然可以尝试这样做，看看效果如何。首先，通过以下命令安装 **Apache** 网络服务器：
- en: '[PRE29]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, assign the Apache service to CPU cores `0` and `2`, like this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将 Apache 服务分配给 CPU 核心 `0` 和 `2`，像这样：
- en: '[PRE30]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Reminder
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒
- en: As before, remember to surround any set of parameters that contains a blank
    space with a pair of double-quotes.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 像之前一样，记得将任何包含空格的参数集用一对双引号括起来。
- en: 'Now, pretend that this virtual machine has more than one NUMA node, and assign
    the Apache service to NUMA node `0`, like this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设这台虚拟机有多个 NUMA 节点，将 Apache 服务分配给 NUMA 节点 `0`，像这样：
- en: '[PRE31]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'These two commands will affect the `cpuset.cpus` and `cpuset.mems` attribute
    files, as you see here:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个命令将影响 `cpuset.cpus` 和 `cpuset.mems` 属性文件，如你所见：
- en: '[PRE32]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'On my trusty dual-CPU Hewlett-Packard, I instead modified the `httpd.service`
    file to add these two parameters. The two new lines look like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我可靠的双 CPU 惠普电脑上，我改动了 `httpd.service` 文件，添加了这两个参数。新增的两行如下：
- en: '[PRE33]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: So, in both examples, I'm allowing Apache to use CPU cores 0 and 2, which are
    both associated with NUMA `node 0`.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在这两个例子中，我允许 Apache 使用 CPU 核心 0 和 2，它们都与 NUMA `node 0` 相关联。
- en: Pro Tip
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: You can separate the core numbers in your list with either a comma or a blank
    space, or use a dash (-) to list a range of CPU cores. Also, note that you do
    not surround the 0 2 in double-quotes when you add this AllowedCPUs= parameter
    to the unit file.)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用逗号或空格分隔列表中的核心编号，或者使用连字符（-）列出 CPU 核心的范围。另外，注意，当你在单元文件中添加 `AllowedCPUs=` 参数时，不需要将
    0 2 括在双引号中。
- en: 'After a `daemon-reload` and restart of the Apache service, we should see the
    appropriate attribute files show up in the `/sys/fs/cgroup/system.slice/httpd.service/`
    directory. Again, here''s what the `cpuset.cpus` file looks like:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行 `daemon-reload` 并重新启动 Apache 服务后，我们应该能看到相应的属性文件出现在 `/sys/fs/cgroup/system.slice/httpd.service/`
    目录下。再看一下 `cpuset.cpus` 文件的样子：
- en: '[PRE34]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Cool. Apache is running on CPU cores `0` and `2`, just like we want. Now, let''s
    look in the `cpuset.mems` file:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 很好。Apache 正在 `0` 和 `2` CPU 核心上运行，正如我们所希望的那样。现在，让我们查看 `cpuset.mems` 文件：
- en: '[PRE35]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Again, it's just what we want to see. Apache can now only use NUMA `node 0`.
    So, thanks to cgroup Version 2, we have achieved coolness with the bare minimum
    of effort.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 再次确认，这正是我们想要看到的。Apache 现在只能使用 NUMA `node 0`。因此，得益于 cgroup 版本 2，我们通过最小的努力就实现了酷炫的效果。
- en: Note
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: NUMA doesn't mean that a process that's running on one CPU can't access memory
    that's in the NUMA node for another CPU. By default, any process can access all
    system memory on all NUMA nodes. You would use the `AllowedMemoryNodes` parameter
    to change that.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: NUMA 并不意味着在一个 CPU 上运行的进程无法访问另一个 CPU 所在 NUMA 节点的内存。默认情况下，任何进程都可以访问所有 NUMA 节点上的所有系统内存。你可以使用
    `AllowedMemoryNodes` 参数来更改这一点。
- en: So, now you're wondering, "*Can I use cgroup Version 2 on my RHEL 8-type machine?*".
    Well, let's take a look.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在你可能在想，"*我能在我的 RHEL 8 类型机器上使用 cgroup 版本 2 吗？*"。好吧，我们来看看。
- en: Converting RHEL 8-type distros to cgroup version 2
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 RHEL 8 类型的发行版转换为 cgroup 版本 2
- en: 'It''s an easy matter to convert a Red Hat Enterprise Linux 8-type distro to
    cgroup Version 2\. Step 1 is to edit the `/etc/default/grub` file on your AlmaLinux
    machine. Find the line that starts with `GRUB_CMDLINE_LINUX=`. At the end of that
    line, add `systemd.unified_cgroup_hierarchy=1`. The whole line should now look
    like this:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Red Hat Enterprise Linux 8 类型的发行版转换为 cgroup Version 2 是一件简单的事情。第一步是编辑你 AlmaLinux
    机器上的 `/etc/default/grub` 文件。找到以 `GRUB_CMDLINE_LINUX=` 开头的行，并在该行的末尾添加 `systemd.unified_cgroup_hierarchy=1`。整个行现在应该看起来像这样：
- en: '[PRE36]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, rebuild the `GRUB` configuration, like this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，像这样重建 `GRUB` 配置：
- en: '[PRE37]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Reboot the machine, and then look in the `/sys/fs/cgroup/` directory. You should
    now see the same filesystem that you see on the Fedora machine. However, don't
    be too disappointed if you can't get all of the previous labs to work. It's just
    that the RHEL 8-type distros all use an older version of the Linux kernel, which
    doesn't yet have all of the cgroup resource controllers enabled. Will they ever
    be enabled in the RHEL 8 distros? Well, maybe. Red Hat's policy is to stick with
    one certain kernel version for the whole ten-year lifespan of each major release
    of RHEL. So, all of the RHEL 8-type distros will be stuck on the old kernel version
    *4.18* until they reach end-of-life in 2029\. Sometimes, Red Hat will backport
    features from newer kernels into their older RHEL kernel, but there's no guarantee
    that they'll do this with any newer cgroup Version 2 code. At any rate, once you've
    seen what you need to see on your AlmaLinux machine, feel free to delete the edit
    that you made to the `grub` file, and rebuild the GRUB configuration. This will
    convert the machine back to using cgroups Version 1.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 重启机器后，查看 `/sys/fs/cgroup/` 目录。你现在应该会看到与 Fedora 机器上相同的文件系统。不过，如果你不能让之前的实验都成功运行，不要太失望。这是因为
    RHEL 8 类型的发行版都使用较旧版本的 Linux 内核，尚未启用所有 cgroup 资源控制器。它们会在 RHEL 8 发行版中启用吗？也许吧。Red
    Hat 的政策是为每个主要的 RHEL 版本在整个十年的生命周期内坚持使用一个固定的内核版本。因此，所有 RHEL 8 类型的发行版将一直停留在旧的内核版本
    *4.18*，直到它们在 2029 年达到生命周期终结。Red Hat 有时会将新内核的特性回溯到它们的旧版 RHEL 内核中，但不能保证会对任何更新的 cgroup
    Version 2 代码做同样的事。无论如何，一旦你在 AlmaLinux 机器上看到所需的内容后，可以删除你在 `grub` 文件中所做的修改，并重建 GRUB
    配置。这将把机器转换回使用 cgroup Version 1。
- en: So, have you seen enough about cgroups? Hopefully not, because it's something
    that's worthwhile learning in depth. But, there's lots more that we need to cover,
    so let's go do that.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你已经了解足够的 cgroup 了吗？希望还没有，因为这是一个值得深入学习的内容。不过，还有很多内容需要我们继续讲解，接下来就让我们继续吧。
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we've learned a lot about cgroup Version 2\. We started with
    a discussion about the deficiencies in cgroups Version 1, and how cgroup Version
    2 is better. Then, we looked at how to allow non-privileged users to set resource
    limits on their containers, and how to use the `cpuset` resource controller. Finally,
    we took a brief look at how to convert a RHEL 8-type machine to use cgroup Version
    2.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了关于 cgroup Version 2 的许多内容。我们从讨论 cgroups Version 1 的不足开始，并介绍了 cgroup
    Version 2 是如何改进的。接着，我们探讨了如何允许非特权用户在其容器上设置资源限制，以及如何使用 `cpuset` 资源控制器。最后，我们简要了解了如何将
    RHEL 8 类型的机器转换为使用 cgroup Version 2。
- en: Once again, I'm reading your mind, and you're wondering why cgroup Version 2
    hasn't yet been universally adopted if it's so good. Well, it's just that certain
    critical programs and services, especially containerization services, are still
    hardcoded to use Version 1\. Fortunately, the situation is improving, and it's
    a safe bet that Version 2 will become the standard within our lifetimes.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，你一定在想，如果 cgroup Version 2 如此优秀，为什么它还没有被广泛采用呢？其实是因为某些关键程序和服务，尤其是容器化服务，仍然是硬编码为使用
    Version 1。幸运的是，情况正在改善，可以大胆预测，Version 2 会在我们有生之年成为标准。
- en: All right, this concludes Part 2 of this tome. Let's start Part 3 with a discussion
    of `journald`. I'll see you there.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这就结束了本书的第二部分。让我们从第三部分开始，讨论 `journald`。下次见！
- en: Questions
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Which of the following statements is true?
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪一项说法是正确的？
- en: A. You can safely use `podman` under cgroups Version 1 to set resource limits
    on rootless containers.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 你可以在 cgroup Version 1 下安全地使用 `podman` 设置无根容器的资源限制。
- en: B. You can safely use `podman` under cgroup Version 2 to set resource limits
    on rootless containers.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 你可以在 cgroup Version 2 下安全地使用 `podman` 设置无根容器的资源限制。
- en: C. You can't set resource limits on `podman` containers.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 你不能为 `podman` 容器设置资源限制。
- en: D. No special privileges are required to set resource limits on rootless `podman`
    containers.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: D. 设置无根`podman`容器的资源限制无需特殊权限。
- en: What is the difference between `MemoryMax` and `MemoryHigh`?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`MemoryMax`和`MemoryHigh`有什么区别？'
- en: A. `MemoryMax` is a hard limit, and `MemoryHigh` is a soft limit.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. `MemoryMax`是硬性限制，`MemoryHigh`是软性限制。
- en: B. `MemoryHigh` is a hard limit, and `MemoryMax` is a soft limit.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. `MemoryHigh`是硬性限制，`MemoryMax`是软性限制。
- en: C. They both do the same thing.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 它们都执行相同的操作。
- en: D. Neither one does anything.
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: D. 它们都没有任何作用。
- en: Which of the following statements is true about delegation?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪项关于委托的说法是正确的？
- en: A. It's perfectly safe for both cgroups Version 1 and cgroup Version 2.
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 对于cgroup版本1和cgroup版本2都是完全安全的。
- en: B. It's only safe for cgroups Version 1.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 仅对cgroup版本1是安全的。
- en: C. It's never safe to use delegation.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 使用委托永远不安全。
- en: D. It's only safe for cgroup Version 2.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: D. 仅对cgroup版本2是安全的。
- en: What is the first step for converting a RHEL 8-type system to cgroup Version
    2?
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将RHEL 8类型系统转换为cgroup版本2的第一步是什么？
- en: A. Edit the `/etc/grub.cfg` file.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 编辑`/etc/grub.cfg`文件。
- en: B. Edit the `/etc/default/grub` file.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 编辑`/etc/default/grub`文件。
- en: C. Edit the `/boot/grub2/grub.cfg` file.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 编辑`/boot/grub2/grub.cfg`文件。
- en: D. Edit the `/boot/grub` file.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编辑`/boot/grub`文件。
- en: Answers
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 答案
- en: B
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: B
- en: A
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A
- en: D
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: D
- en: B
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: B
- en: Further reading
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'A Red Hat blog post about cgroup Version 2:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇关于cgroup版本2的Red Hat博客文章：
- en: '[https://www.redhat.com/en/blog/world-domination-cgroups-rhel-8-welcome-cgroups-v2](https://www.redhat.com/en/blog/world-domination-cgroups-rhel-8-welcome-cgroups-v2)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.redhat.com/en/blog/world-domination-cgroups-rhel-8-welcome-cgroups-v2](https://www.redhat.com/en/blog/world-domination-cgroups-rhel-8-welcome-cgroups-v2)'
- en: 'An **Oracle** blog post about why Version 2 is better than Version 1:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇**Oracle**博客文章，讲述为什么版本2比版本1更好：
- en: '[https://blogs.oracle.com/linux/post/cgroup-v2-checkpoint](https://blogs.oracle.com/linux/post/cgroup-v2-checkpoint)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://blogs.oracle.com/linux/post/cgroup-v2-checkpoint](https://blogs.oracle.com/linux/post/cgroup-v2-checkpoint)'
- en: 'Comparing Version 1 and Version 2:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 比较版本1和版本2：
- en: '[https://chrisdown.name/talks/cgroupv2/cgroupv2-fosdem.pdf](https://chrisdown.name/talks/cgroupv2/cgroupv2-fosdem.pdf)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://chrisdown.name/talks/cgroupv2/cgroupv2-fosdem.pdf](https://chrisdown.name/talks/cgroupv2/cgroupv2-fosdem.pdf)'
- en: 'Using cgroup Version 2 for rootless Docker containers:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 使用cgroup版本2进行无根Docker容器管理：
- en: '[https://rootlesscontaine.rs/getting-started/common/cgroup2/](https://rootlesscontaine.rs/getting-started/common/cgroup2/)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://rootlesscontaine.rs/getting-started/common/cgroup2/](https://rootlesscontaine.rs/getting-started/common/cgroup2/)'
- en: 'The current adoption status of cgroup v2 in containers:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: cgroup v2在容器中的当前采用状态：
- en: '[https://medium.com/nttlabs/cgroup-v2-596d035be4d7](https://medium.com/nttlabs/cgroup-v2-596d035be4d7)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://medium.com/nttlabs/cgroup-v2-596d035be4d7](https://medium.com/nttlabs/cgroup-v2-596d035be4d7)'
