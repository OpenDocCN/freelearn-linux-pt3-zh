- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Packaging Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Python** is the most popular programming language for **machine learning**
    (**ML**). Combine that with the proliferation of ML in our day-to-day lives and
    it is no surprise that the desire to run Python on edge devices is intensifying.
    Even in this era of transpilers and WebAssembly, packaging Python applications
    for deployment remains an unsolved problem. In this chapter, you will learn what
    choices are out there for bundling Python modules together and when to use one
    method over another.'
  prefs: []
  type: TYPE_NORMAL
- en: We start with a look back at the origins of today’s Python packaging solutions,
    from the built-in standard `distutils` to its successor, `setuptools`. Next, we
    examine the `pip` package manager, before moving on to `venv` for Python virtual
    environments, followed by `conda`, the reigning general-purpose cross-platform
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: Since Python is an interpreted language, you cannot compile a program into a
    standalone executable like you can with a language such as Go. This makes deploying
    Python applications complicated. Running a Python application requires installing
    a Python interpreter and several runtime dependencies. These requirements need
    to be code-compatible for the application to work. That requires the precise versioning
    of software components. Solving these deployment problems is what Python packaging
    is all about.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Retracing the origins of Python packaging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Python packages with `pip`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing Python virtual environments with `venv`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing precompiled binaries with `conda`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To follow along with the examples, make sure you have the following software
    installed on your Linux host system:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Python: Python 3 interpreter and standard library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pip`: Package installer for Python 3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`venv`: Python module for creating and managing lightweight virtual environments'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miniconda: Minimal installer for the `conda` package and virtual environment
    manager'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I recommend using Ubuntu 24.04 LTS or later for this chapter. Even though Ubuntu
    24.04 LTS runs on the Raspberry Pi 4, I still prefer to develop on an x86-64 desktop
    PC or laptop. Ubuntu also comes with Python 3 and `pip` already installed since
    Python is used extensively throughout the system. Do not uninstall `python3` or
    you will render Ubuntu unusable. To install `venv` on Ubuntu, enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**IMPORTANT NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: Do not install Miniconda until you get to the section on `conda` because it
    interferes with the earlier `pip` exercises that rely on the system Python installation.
  prefs: []
  type: TYPE_NORMAL
- en: Retracing the origins of Python packaging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Python packaging landscape is a vast graveyard of failed attempts and abandoned
    tools. Best practices around dependency management change often within the Python
    community, and the recommended solution one year may be a broken nonstarter the
    next. As you research this topic, remember to look at when the information was
    published and do not trust any advice that may be out of date.
  prefs: []
  type: TYPE_NORMAL
- en: Most Python libraries are distributed using `setuptools`, including all the
    packages found on the **Python Package Index** (**PyPI**). This distribution method
    relies on a `setup.py` project specification file that the **package installer
    for Python** (**pip**) uses to install a package. `pip` can also generate or *freeze*
    a precise list of dependencies after a project is installed. This optional `requirements.txt`
    file is used by `pip` in conjunction with `setup.py` to ensure that project installations
    are repeatable.
  prefs: []
  type: TYPE_NORMAL
- en: distutils
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**distutils** is the original packaging system for Python. It was included
    in the Python standard library from Python 2.0 until its removal in Python 3.12\.
    `distutils` provided a Python package of the same name that could be imported
    by your `setup.py` script. Now that `distutils` is deprecated, direct usage of
    the package is no longer supported. `setuptools` has become its preferred replacement.'
  prefs: []
  type: TYPE_NORMAL
- en: While `distutils` may continue to work for simple projects, the community has
    moved on. Today, `distutils` survives only for legacy reasons. Many Python libraries
    were first published back when `distutils` was the only game in town. Porting
    them to `setuptools` now would take considerable effort and could break existing
    users.
  prefs: []
  type: TYPE_NORMAL
- en: setuptools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**setuptools** extends `distutils` by adding support for complex constructs
    that make larger applications based on web frameworks like Flask and FastAPI easier
    to distribute. It has become the de facto packaging system within the Python community.
    Like `distutils`, `setuptools` offers a Python package of the same name that you
    can import into your `setup.py` script. `distribute` was an ambitious fork of
    `setuptools` that eventually merged back into `setuptools 0.7`, cementing the
    status of `setuptools` as the definitive choice for Python packaging.'
  prefs: []
  type: TYPE_NORMAL
- en: '`setuptools` introduced a command-line utility known as `easy_install` (now
    deprecated) and a Python package called `pkg_resources` for runtime package discovery
    and access to resource files. `setuptools` can also produce packages that act
    as plugins for other extensible packages (for example, frameworks and applications).
    You do this by registering entry points in your `setup.py` script for the other
    overarching package to import.'
  prefs: []
  type: TYPE_NORMAL
- en: The term *distribution* means something different in the context of Python.
    A distribution is a versioned archive of packages, modules, and other resource
    files used to distribute a release. A *release* is a versioned snapshot of a Python
    project taken at a given point in time. To make matters worse, the terms *package*
    and *distribution* are overloaded and often used interchangeably by Pythonistas.
    For our purposes, let’s say that a distribution is what you download, and a package
    is the module that gets installed and imported.
  prefs: []
  type: TYPE_NORMAL
- en: Cutting a release can result in multiple distributions, such as a source distribution
    and one or more built distributions. There can be different built distributions
    for different platforms, such as one that includes a Windows installer. The term
    *built distribution* means that no build step is required before installation.
    It does not necessarily mean precompiled. Some built distribution formats such
    as **Wheel** (`.whl`) exclude compiled Python files, for example. A built distribution
    containing compiled extensions is known as a *binary distribution*.
  prefs: []
  type: TYPE_NORMAL
- en: An **extension module** is a Python module that is written in C or C++. Every
    extension module compiles down to a single dynamically loaded library, such as
    a shared object (`.so`) on Linux and a dynamic link library (`.pyd`) on Windows.
    Contrast this with pure modules, which must be written entirely in Python. The
    Egg (`.egg`) built distribution format introduced by `setuptools` supports both
    pure and extension modules. Since a Python source code (`.py`) file compiles down
    to a bytecode (`.pyc`) file when the Python interpreter imports a module at runtime,
    you can see how a built distribution format such as Wheel might exclude precompiled
    Python files.
  prefs: []
  type: TYPE_NORMAL
- en: setup.py
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Say you are developing a small program in Python, maybe something that queries
    a remote REST API and saves response data to a local SQL database. How do you
    package your program together with its dependencies for deployment? You start
    by defining a `setup.py` script that `setuptools` can use to install your program.
    Deploying with `setuptools` is the first step toward more elaborate automated
    deployment schemes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even if your program is small enough to fit comfortably inside a single module,
    chances are it won’t stay that way for long. Let’s say that your program consists
    of a single file named `follower.py`, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You could then convert this module into a package by splitting `follower.py`
    up into three separate modules and placing them inside a nested directory, also
    named `follower`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__main__.py` module is where your program starts, so it contains mostly
    top-level, user-facing functionality. The `fetch.py` module contains functions
    for sending HTTP requests to the remote REST API and the `store.py` module contains
    functions for saving response data to the local SQL database. To run this package
    as a script, you need to pass the `-m` option to the Python interpreter as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `PYTHONPATH` environment variable points to the directory where a target
    project’s package directories are located. The `follower` argument after the `-m`
    option tells Python to run the `__main__.py` module belonging to the `follower`
    package. Nesting package directories inside a project directory like this paves
    the way for your program to grow into a larger application made up of multiple
    packages each with its own namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the pieces of your project all in their right place, we are now ready
    to create a minimal `setup.py` script that `setuptools` can use to package and
    deploy it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `install_requires` argument is a list of external dependencies that need
    to be installed automatically for a project to work at runtime. Notice that I
    did not specify what versions of these dependencies are needed or where to fetch
    them from in my example. I only asked for libraries that look and act like `requests`
    and `sqlalchemy`. Separating policy from implementation like this allows you to
    easily swap out the official PyPI version of a dependency with your own in case
    you need to fix a bug or add a feature.
  prefs: []
  type: TYPE_NORMAL
- en: '**Information note**'
  prefs: []
  type: TYPE_NORMAL
- en: Adding optional version specifiers to your dependency declarations is fine,
    but hardcoding distribution URLs within `setup.py` as `dependency_links` is wrong
    in principle.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `packages` argument tells `setuptools` what in-tree packages to distribute
    with a project release. Since every package is defined inside its own subdirectory
    of the parent project directory, the only package being shipped in this case is
    `follower`. I am including data files along with my Python code in this distribution.
    To do that, you need to set the `include_package_data` argument to `True` so that
    `setuptools` looks for a `MANIFEST.in` file and installs all the files listed
    there. Here are the contents of the `MANIFEST.in` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If the data directory contained nested directories of data we wanted to include,
    we could glob all of them along with their contents using `recursive-include`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the final directory layout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`setuptools` excels at building and distributing Python packages that depend
    on other packages. It can do this thanks to features such as entry points and
    dependency declarations, which are simply absent from `distutils`. `setuptools`
    works well with `pip` and new releases of `setuptools` arrive on a regular basis.
    The Wheel build distribution format was created to replace the Egg format that
    `setuptools` introduced. That effort has largely succeeded with the addition of
    a popular `setuptools` extension for building wheels and `pip`''s great support
    for installing wheels.'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python packages with pip
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You now know how to define your project’s dependencies in a `setup.py` script.
    But how do you install those dependencies? How do you upgrade a dependency or
    replace it when you find a better one? How do you decide when it is safe to delete
    a dependency you no longer need?
  prefs: []
  type: TYPE_NORMAL
- en: Managing project dependencies is a tricky business. Luckily, Python comes with
    a tool called **pip** that can help, especially in the early stages of your project.
    The name stands for **pip installs Python**, which is a recursive acronym. `pip`
    is the official package manager for Python.
  prefs: []
  type: TYPE_NORMAL
- en: The initial 1.0 release of `pip` arrived on April 4, 2011, around the same time
    that Node.js and `npm` were taking off. Before it became `pip`, the tool was named
    `pyinstall`. `pyinstall` was created in 2008 as an alternative to `easy_install`,
    which came bundled with `setuptools` at the time. `easy_install` is now deprecated
    and `setuptools` recommends using `pip` instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since `pip` is included with the Python installer and you can have multiple
    versions of Python installed on your system (for example, 2.7 and 3.13), it helps
    to know which version of `pip` you are running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If no `pip` executable is found on your system, that probably means you are
    on Ubuntu 20.04 LTS or later and do not have Python 2.7 installed. That is fine.
    We will merely substitute `pip3` for `pip` and `python3` for `python` throughout
    the rest of this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If there is `python3` but no `pip3` executable, then install it as shown on
    Debian-based distributions such as Ubuntu:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`pip` installs packages to a directory called `site-packages`. To find the
    location of your `site-packages` directory, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**IMPORTANT NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: Now that Python 2 has been deprecated, `pip3` and `python3` commands are available
    on popular Linux distributions like Ubuntu. If your Linux distribution does not
    have the `pip3` and `python3` commands, then use the `pip` and `python` commands
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a list of packages already installed on your system, use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The list shows that `pip` is just another Python package, so you could use `pip`
    to upgrade itself, but I would advise you not to do that, at least not in the
    long term. I’ll explain why in the next section when I introduce virtual environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a list of packages installed in your `site-packages` directory, use
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This list should be empty or much shorter than the list of system packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go back to the example project from the last section. `cd` into the parent
    `follower` directory where `setup.py` is located. Then run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`pip` will use `setup.py` to fetch and install the packages declared by `install_requires`
    to your `site-packages` directory. The `--user` option instructs `pip` to install
    packages to your `site-packages` directory rather than globally. The `--ignore-installed`
    option forces `pip` to re-install any required packages already present on the
    system to `site-packages` so that no dependencies go missing. The `--break-system-packages`
    option is required on Debian-based Linux distributions like Ubuntu, which discourages
    users from installing non-Debian-packaged packages system-wide.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now list all the packages in your `site-packages` directory again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This time, you should see that both `requests` and `SQLAlchemy` are in the package
    list.
  prefs: []
  type: TYPE_NORMAL
- en: 'To view details on the `SQLAlchemy` package you just installed, issue the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The details shown contain the `Requires` and `Required-by` fields. Both are
    lists of related packages. You could use the values in these fields and successive
    calls to `pip show` to trace the dependency tree of your project. But it’s probably
    easier to `pip install` a command-line tool called `pipdeptree` and use that instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a `Required-by` field becomes empty, that is a good indicator that it
    is now safe to uninstall a package from your system. If no other packages depend
    on the packages in the deleted package’s `Requires` field, then it’s safe to uninstall
    those as well. This is how you uninstall `sqlalchemy` using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The trailing `-y` suppresses the confirmation prompt. To uninstall more than
    one package at a time, simply add more package names before the `-y`. The `--user`
    option is omitted here because `pip` is smart enough to uninstall from `site-packages`
    first when a package is also installed globally.
  prefs: []
  type: TYPE_NORMAL
- en: '**TIP**'
  prefs: []
  type: TYPE_NORMAL
- en: Uninstall the `follower` package and all its dependencies from your `site-packages`
    directory so that you do not pollute your Python installation or Linux distribution
    with non-Debian-packaged packages.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes you need a package that serves some purpose or utilizes a particular
    technology, but you don’t know the name of it. You can use `pip` to perform a
    keyword search against PyPI from the command line, but that approach often yields
    too many results. It is much easier to search for packages on the PyPI website
    ([https://pypi.org/search/](https://pypi.org/search/)), which allows you to filter
    results by various classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: requirements.txt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`pip` `install` will install the latest published version of a package, but
    often you want to install a specific version of a package that you know works
    with your project’s code. Eventually, you will want to upgrade your project’s
    dependencies. But before I show you how to do that, I first need to show you how
    to use `pip freeze` to fix your dependencies.'
  prefs: []
  type: TYPE_NORMAL
- en: Requirements files allow you to specify exactly which packages and versions
    `pip` should install for your project. By convention, project **requirements files**
    are always named `requirements.txt`. The contents of a requirements file are just
    a list of `pip install` arguments enumerating your project’s dependencies. These
    dependencies are precisely versioned so that there are no surprises when someone
    attempts to rebuild and deploy your project. It is good practice to add a `requirements.txt`
    file to your project’s repo to ensure reproducible builds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Returning to our `follower` project, now that we have installed all our dependencies
    and verified that the code works as expected, we are now ready to freeze the latest
    versions of the packages that `pip` installed for us. `pip` has a `freeze` command
    that outputs the installed packages along with their versions. You redirect the
    output from this command to a `requirements.txt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that you have a `requirements.txt` file, people who clone your project
    can install all its dependencies using the `-r` option and the name of the requirements
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The autogenerated requirements file format defaults to exact version matching
    (`==`). For example, a line such as `requests==2.32.3` tells `pip` that the version
    of `requests` to install must be exactly `2.32.3`. There are other version specifiers
    you can utilize in a requirements file, such as minimum version (`>=`), version
    exclusion (`!=`), and maximum version (`<=`). Minimum version (`>=`) matches any
    version greater than or equal to the right-hand side. Version exclusion (`!=`)
    matches any version except the right-hand side. Maximum version (`<=`) matches
    any version less than or equal to the right-hand side.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can combine multiple version specifiers in a single line using commas to
    separate them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The default behavior when `pip` installs the packages specified in a requirements
    file is to fetch them all from PyPI. You can override PyPI’s URL ([https://pypi.org/simple/)](https://pypi.org/simple/))
    with that of an alternate Python package index by adding a line such as the following
    to the top of your `requirements.txt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The effort required to stand up and maintain your own private PyPI mirror is
    not insubstantial. When all you need to do is fix a bug or add a feature to a
    project dependency, it makes more sense to override the package source instead
    of the entire package index.
  prefs: []
  type: TYPE_NORMAL
- en: 'I mentioned earlier how hardcoding distribution URLs inside `setup.py` is wrong.
    You can use the `-e` argument form in a requirements file to override individual
    package sources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, I am instructing `pip` to fetch the `flask` package sources
    from my team’s GitHub fork of `pallets/flask.git`. The `-e` argument form also
    takes a Git branch name, commit hash, or tag name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `pip` to upgrade a project’s dependencies to the latest versions published
    on PyPI is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'After you have verified that installing the latest versions of your dependencies
    does not break your project, you can then write them back out to the requirements
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Make sure that freezing did not overwrite any of the overrides or special version
    handling in your requirements file. Undo any mistakes and commit the updated `requirements.txt`
    file to version control.
  prefs: []
  type: TYPE_NORMAL
- en: At some point, upgrading your project dependencies will result in your code
    breaking. A new package release may introduce a regression or incompatibility
    with your project. The requirements file format provides syntax to deal with these
    situations. Let’s say you have been using version 2.32.3 of `requests` in your
    project and version 3.0 is released. According to the practice of semantic versioning,
    incrementing the major version number indicates that version 3.0 of `requests`
    includes breaking changes to that library’s API.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can express the new version requirements like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The compatible release specifier (`~=`) relies on semantic versioning. Compatible
    means greater than or equal to the right-hand side and less than the next version’s
    major number (for example, `>= 1.1` and `== 1.*`). You have already seen me express
    these same version requirements for `requests` less ambiguously as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: These `pip` dependency management techniques work fine if you only develop a
    single Python project at a time. But chances are you use the same machine to work
    on several Python projects at once, each potentially requiring a different version
    of the Python interpreter. The biggest problem with using only `pip` for multiple
    projects is that it installs all packages to the same user `site-packages` directory
    for a particular version of Python. This makes it very hard to isolate dependencies
    from one project to the next.
  prefs: []
  type: TYPE_NORMAL
- en: As we’ll see in the next chapter, `pip` combines well with Docker for deploying
    Python applications. You can add `pip` to a Buildroot or Yocto-based Linux image
    but that only enables quick on-device experimentation. A Python runtime package
    installer such as `pip` is ill-suited for Buildroot and Yocto environments where
    you want to define the entire contents of your embedded Linux image at build time.
    `pip` works great inside containerized environments such as Docker where the line
    between build time and runtime is often blurry.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 7*](Chapter_05.xhtml#_idTextAnchor151), you learned about the Python
    modules available to you in the `meta-python` layer and how to define a custom
    layer for your own application. You can use the `requirements.txt` files generated
    by `pip freeze` to inform the selection of dependencies from `meta-python` for
    your own layer recipes. Buildroot and Yocto both install Python packages in a
    system-wide manner, so the virtual environment techniques we are going to discuss
    next do not apply to embedded Linux builds per se. They do, however, help you
    assemble a complete list of dependencies for your embedded Python applications.
  prefs: []
  type: TYPE_NORMAL
- en: Managing Python virtual environments with venv
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **virtual environment** is a self-contained directory tree containing a Python
    interpreter for a particular version of Python, a `pip` executable for managing
    project dependencies, and a local `site-packages` directory. Switching between
    virtual environments tricks the shell into thinking that the only Python and `pip`
    executables available are the ones present in the active virtual environment.
    Best practice dictates that you create a different virtual environment for each
    of your projects. This form of isolation solves the problem of two projects depending
    on different versions of the same package.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual environments are not new to Python. The system-wide nature of Python
    installations necessitates them. Besides enabling you to install different versions
    of the same package, virtual environments also provide an easy way for you to
    run multiple versions of the Python interpreter. Several options exist for managing
    Python virtual environments. A tool that was immensely popular circa 2019 (`pipenv`)
    has since languished. The popular `conda` package manager has supported Python
    virtual environments since late 2014\. Meanwhile, Python 3’s built-in support
    for virtual environments (`venv`) introduced back in 2012 has slowly matured and
    is now widely adopted.
  prefs: []
  type: TYPE_NORMAL
- en: '**venv** has been shipping with Python since version 3.3\. Because it only
    comes bundled with Python 3 installations, `venv` is incompatible with projects
    that require Python 2.7\. As support for Python 2.7 officially ended on January
    1, 2020, this Python 3 limitation is less of a concern. `venv` is based on the
    popular `virtualenv` tool, which is still maintained and available on PyPI. If
    you have one or more projects that still require Python 2.7, then you can use
    `virtualenv` instead of `venv` to work on those.'
  prefs: []
  type: TYPE_NORMAL
- en: By default, `venv` installs the most recent version of Python found on your
    system. If you have multiple versions of Python on your system, you can select
    a specific Python version by running `python3` or whichever version you want when
    creating each virtual environment (*The Python Tutorial*, [https://docs.python.org/3/tutorial/venv.html](https://docs.python.org/3/tutorial/venv.html)).
    Developing with the most recent version of Python is usually fine for greenfield
    projects but unacceptable for most legacy and enterprise software. We will use
    the version of Python 3 that came with your Ubuntu system to create and work with
    a virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a virtual environment, first, decide where you want to put it, and
    then run the `venv` module as a script with the target directory path:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensure `venv` is installed on your Ubuntu system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new directory for your project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Switch to that new directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the virtual environment inside a subdirectory named `venv`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that you have created a virtual environment, here is how you activate and
    verify it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Switch to your project directory if you haven’t already:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check where your system’s `pip3` executable is installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activate the project’s virtual environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check where your project’s `pip3` executable is installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'List the packages that came installed with the virtual environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you enter the `which pip` command from within your virtual environment, you
    will see that `pip` now points to an executable. You can now omit the `3` when
    running either `pip` or `python` from within your virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s install a property-based testing library named `hypothesis` into
    our existing virtual environment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Switch to your project directory if you haven’t already:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reactivate the project’s virtual environment if it is not already active:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the `hypothesis` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'List the packages now installed inside the virtual environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that two new packages (`attrs` and `sortedcontainers`) were added to
    the list besides `hypothesis`. `hypothesis` depends on these two packages. Let’s
    say you had another Python project that depended on version 1.5.10 instead of
    version 2.4.0 of `sortedcontainers`. Those two versions would be incompatible
    and thus conflict with each other. Virtual environments allow you to install both
    versions of the same package, a different version for each of the two projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have noticed that switching out of a project directory does not deactivate
    its virtual environment. Don’t worry. Deactivating a virtual environment is as
    easy as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: This puts you back in the global system environment where you have to enter
    `python3` and `pip3` again. You have now seen everything you need to know to get
    started with Python virtual environments. Creating and switching between virtual
    environments is common practice now when developing in Python. Isolated environments
    make it easier to keep track of and manage your dependencies across multiple projects.
  prefs: []
  type: TYPE_NORMAL
- en: Installing precompiled binaries with conda
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**conda** is a package and virtual environment management system used by the
    **Anaconda** distribution of software for the PyData community. The Anaconda distribution
    includes Python as well as binaries for several hard-to-build open source projects
    such as PyTorch and TensorFlow. `conda` can be installed without the full Anaconda
    distribution, which is very large, or the minimal **Miniconda** distribution,
    which is still over 256 MB.'
  prefs: []
  type: TYPE_NORMAL
- en: Even though it was created for Python shortly after `pip`, `conda` has evolved
    into a general-purpose package manager like APT or Homebrew. Now, it can be used
    to package and distribute software for any language. Because `conda` downloads
    precompiled binaries, installing Python extension modules is a breeze. Another
    one of `conda`'s big selling points is that it is cross-platform, with full support
    for Linux, macOS, and Windows.
  prefs: []
  type: TYPE_NORMAL
- en: Besides package management, `conda` is also a full-blown virtual environment
    manager. `conda` virtual environments have all the benefits we have come to expect
    from Python `venv` environments and more. Like `venv`, `conda` lets you use `pip`
    to install packages from PyPI into a project’s local `site-packages` directory.
    If you prefer, you can use `conda`'s own package management capabilities to install
    packages from different channels. Channels are package feeds provided by Anaconda
    and other software distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Environment management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike `venv`, `conda`'s virtual environment manager can easily juggle multiple
    versions of Python, including Python 2.7\. You will need to have Miniconda installed
    on your Ubuntu system to do the following exercises. You want to use Miniconda
    instead of Anaconda for your virtual environments because Anaconda environments
    come with lots of preinstalled packages, many of which you will never need. Miniconda
    environments are stripped down and allow you to easily install any of Anaconda’s
    packages should you have to.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install and update Miniconda on Ubuntu 24.04 LTS:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download Miniconda:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install Miniconda:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Update all the installed packages in the root environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your fresh Miniconda installation comes with `conda` and a root environment
    with a Python interpreter and some basic packages installed. By default, the `python`
    and `pip` executables of `conda`''s root environment are installed in your home
    directory. The `conda` root environment is known as `base`. You can view its location,
    along with the locations of any other available `conda` environments, by issuing
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify this root environment before creating your own `conda` environment:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new shell after installing Miniconda.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check where the root environment’s `python` executable is installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the version of Python:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check where the root environment’s `pip` executable is installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the version of `pip`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'List the packages installed in the root environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create and work with your own `conda` environment named `py311`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new virtual environment named `py311`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activate your new virtual environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check where your environment’s `python` executable is installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check that the version of Python is 3.11.9:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'List the packages installed in your environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Deactivate your environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `conda` to create a virtual environment with Python 2.7 installed is
    as simple as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'View your `conda` environments again to see whether `py311` and `py27` now
    appear in the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, let’s delete the `py27` environment since we won’t be using it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Now that you know how to use `conda` to manage virtual environments, let’s use
    it to manage packages within those environments.
  prefs: []
  type: TYPE_NORMAL
- en: Package management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since `conda` supports virtual environments, we can use `pip` to manage Python
    dependencies from one project to another in an isolated manner, just like we did
    with `venv`. As a general-purpose package manager, `conda` has its own facilities
    for managing dependencies. We know that `conda list` lists all the packages that
    `conda` has installed in the active virtual environment. I also mentioned `conda`''s
    use of package feeds, which are called channels:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get the list of channel URLs `conda` is configured to fetch from by
    entering this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before proceeding any further, let’s reactivate the `py311` virtual environment
    you created during the last exercise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Most Python development nowadays happens inside a Jupyter notebook, so let’s
    install those packages first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Enter *y* when prompted. This will install the `jupyter` and `notebook` packages
    along with all their dependencies. When you enter `conda list`, you’ll see that
    the list of installed packages is much longer than before. Now, let’s install
    some more Python packages that we would need for a computer vision project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Again, enter *y* when prompted. This time, the number of dependencies installed
    is smaller. Both `opencv` and `matplotlib` depend on `numpy`, so `conda` installs
    that package automatically without you having to specify it. If you want to specify
    an older version of `opencv`, you can install the desired version of the package
    this way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`conda` will then attempt to *solve* the active environment for this dependency.
    Since no other packages installed in this active virtual environment depend on
    `opencv`, the target version is easy to solve for. If they did, then you might
    encounter a package conflict and the reinstallation would fail. After solving,
    `conda` will prompt you before downgrading `opencv` and its dependencies. Enter
    *y* to downgrade `opencv` to version 4.6.0.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now let’s say you change your mind or a newer version of `opencv` is released
    that addresses your previous concern. This is how you would upgrade `opencv` to
    the latest version provided by the Anaconda distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This time, `conda` will prompt you to ask whether you want to update `opencv`
    and its dependencies for the latest version. This time, enter *n* to cancel the
    package update. Instead of updating packages individually, it’s often easier to
    update all the packages installed in an active virtual environment at once:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Removing installed packages is also straightforward:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When `conda` removes `jupyter` and `notebook`, it removes all of their dangling
    dependencies as well. A dangling dependency is an installed package that no other
    installed packages depend on. Like most general-purpose package managers, `conda`
    will not remove any dependencies that other installed packages still depend on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes you may not know the exact name of a package you want to install.
    Amazon offers an AWS SDK for Python called Boto. Like many Python libraries, there
    is a version of Boto for Python 2 and a newer version (Boto3) for Python 3\. To
    search Anaconda for packages with the word `boto` in their names, enter the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see `boto3` and `botocore` in the search results. At the time of
    writing, the most recent version of `boto3` available on Anaconda is 1.36.3\.
    To view details on that specific version of `boto3`, enter the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The package details reveal that `boto3` version 1.36.3 depends on `botocore`
    (`botocore >=1.36.3,<1.37.0`), so installing `boto3` gets you both.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s say you’ve installed all the packages you need to develop an OpenCV
    project inside a Jupyter notebook. How do you share these project requirements
    with someone else so that they can recreate your work environment? The answer
    may surprise you:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You export your active virtual environment to a YAML file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Much like the list of requirements that `pip freeze` generates, the YAML that
    `conda` exports is a list of all the packages installed in your virtual environment
    together with their pinned versions. Creating a `conda` virtual environment from
    an environment file requires the `-f` option and the filename:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The environment name is included in the exported YAML, so no `--name` option
    is necessary to create the environment. Whoever creates a virtual environment
    from `my-environment.yaml` will now see `py311` in their list of environments
    when they issue `conda env list`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`conda` is a very powerful tool in a developer’s arsenal. By combining general-purpose
    package installation with virtual environments, it offers a compelling deployment
    story. `conda` achieves many of the same goals Docker (up next) does, but without
    the use of containers. It has an edge over Docker with respect to Python due to
    its focus on the data science community. Because the leading ML frameworks (such
    as PyTorch and TensorFlow) are largely CUDA-based, finding GPU-accelerated binaries
    is often difficult. `conda` solves this problem by providing multiple precompiled
    binary versions of packages.'
  prefs: []
  type: TYPE_NORMAL
- en: Exporting `conda` virtual environments to YAML files for installation on other
    machines offers another deployment option. This solution is popular among the
    data science community, but it does not work in production for embedded Linux.
    `conda` is not one of the three package managers that Yocto supports. Even if
    `conda` was an option, the storage needed to accommodate Miniconda on a Linux
    image is not a good fit for most embedded systems due to resource constraints.
  prefs: []
  type: TYPE_NORMAL
- en: If your dev board has an NVIDIA GPU such as the NVIDIA Jetson series, then you
    really want to use `conda` for on-device development. Luckily, there is a `conda`
    installer named **Miniforge** ([https://github.com/conda-forge/miniforge)](https://github.com/conda-forge/miniforge))
    that is known to work on 64-bit ARM machines like the Jetsons. With `conda` on
    the device, you can then install `jupyter`, `numpy`, `pandas`, `scikit-learn`,
    and most of the other popular Python data science libraries out there.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, you’re probably asking yourself, “What does any of this Python packaging
    stuff have to do with embedded Linux?” The answer is “not much” but bear in mind
    that the word *development* also happens to be in the title of this book, and
    this chapter has everything to do with modern-day software development. To succeed
    as a developer, you need to be able to deploy your code to production fast, frequently,
    and in a repeatable manner. That means managing your dependencies carefully and
    automating as much of the process as possible. You now know how to do that with
    Python.
  prefs: []
  type: TYPE_NORMAL
- en: Further study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Python Packaging User Guide*, PyPA – [https://packaging.python.org](https://packaging.python.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*setup.py vs requirements.txt*, by Donald Stufft – [https://caremad.io/posts/2013/07/setup-vs-requirement](https://caremad.io/posts/2013/07/setup-vs-requirement)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*pip User Guide*, PyPA – [https://pip.pypa.io/en/latest/user_guide/](https://pip.pypa.io/en/latest/user_guide/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Conda User Guide*, Anaconda, Inc. – [https://docs.conda.io/projects/conda/en/latest/user-guide](https://docs.conda.io/projects/conda/en/latest/user-guide)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
