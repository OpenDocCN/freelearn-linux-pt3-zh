<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer066">
<h1 class="chapter-number" id="_idParaDest-145"><a id="_idTextAnchor175"/>10</h1>
<h1 id="_idParaDest-146"><a id="_idTextAnchor176"/>Storage Management</h1>
<p>It feels like there’s never going to be enough space on our servers for everything that needs to be stored there. Despite the fact that the storage capacity of hard disks continues to increase and high-capacity disks are now more affordable than ever, our servers quickly fill up any available space. Our best efforts as server administrators have always been to order machines with as much storage as possible, but the reality is that even the most well-planned enterprises eventually run out of space. Additional storage space will certainly need to be added at some point in the course of administering your servers. Storage management, however, entails more than simply replacing full disks with empty ones. <strong class="bold">Logical Volume Manager</strong> (<strong class="bold">LVM</strong>) and other similar technologies can greatly simplify<a id="_idIndexMarker482"/> your work if you start using them as soon as possible, thus it’s crucial to <span class="No-Break">plan ahead.</span></p>
<p>The concepts discussed in this chapter, including LVM itself, will allow you greater freedom in the management of servers. I will also explain some other ideas that will prove useful when you work with volumes and storage on your server. In particular, the following topics will <span class="No-Break">be covered:</span></p>
<ul>
<li>Creating new volumes in <span class="No-Break">a filesystem</span></li>
<li>How to format and partition <span class="No-Break">storage devices</span></li>
<li>How to mount and <span class="No-Break">unmount volumes</span></li>
<li>Learning how to use a <strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">etc/fstab</strong></span><span class="No-Break"> file</span></li>
<li>Working with <strong class="bold">Logical Volume </strong><span class="No-Break"><strong class="bold">Manager</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">LVM</strong></span><span class="No-Break">)</span></li>
</ul>
<h1 id="_idParaDest-147"><a id="_idTextAnchor177"/>Adding additional storage volumes</h1>
<p>Additional server<a id="_idIndexMarker483"/> storage space will likely be required at some time. The capacity of a server can be expanded by installing more hard drives, either on a standalone machine or by using cloud computing. Whatever its name may be, we’ll need to find out how to format and mount the device before we can use the <span class="No-Break">additional space.</span></p>
<p>Using LVM (which we will cover later in this chapter), we can easily add space to an existing volume without restarting the server. However, there is an overarching procedure that must be followed when introducing a new device. The following are a few things to consider while upgrading your system’s <span class="No-Break">storage capacity:</span></p>
<ul>
<li><strong class="bold">Can you tell me how much space you’ll need?</strong> If there <a id="_idIndexMarker484"/>is enough free space in your hypervisor’s storage pool, you can create a virtual disk of any size <span class="No-Break">you like.</span></li>
<li><strong class="bold">How do you want to call it?</strong> Disks are typically labeled with increasing last numbers of their respective names (for example, <strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">dev/sdb1</strong></span><span class="No-Break">, </span><span class="No-Break"><strong class="source-inline">/dev/sdb2</strong></span><span class="No-Break">).</span></li>
<li><strong class="bold">What format do you want for your device?</strong> At present, ext4 is the most widely used filesystem. However, there are additional choices you might make for various tasks (such as XFS). Use ext4 if you’re unsure, but research the alternatives to see if any better suit your needs. ZFS is an additional possibility; however, it is more recent than many of the other filesystems out there. You may know this already, but new Linux users may be confused by the fact that the term <em class="italic">filesystem</em> has many meanings, depending on the situation. When <a id="_idIndexMarker485"/>discussing the file and directory structure of a normal Linux system, we Linux administrators will most often use the term <em class="italic">filesystem</em>. On the other hand, the phrase can also refer to the format of a disk that is compatible with the distribution (for example, the <span class="No-Break">ext4 filesystem).</span></li>
<li><strong class="bold">Where do you want it mounted?</strong> Since the new disk must be reachable by the system and possibly users, you must mount (attach) it to a directory on your filesystem from which users or applications can access it. In this chapter, we also cover LVM, and in most cases, you’ll want to add it to an existing storage group. The new volume can be used with any directory you like, but I’ll go over some typical ones in the <em class="italic">Formatting and partitioning storage devices</em> section. In the <em class="italic">Mounting and unmounting volumes</em> section, we will discuss the mounting and unmounting processes <span class="No-Break">in detail.</span></li>
</ul>
<p>Let’s think about the responses to the first two queries. To determine how much more room you should implement, you should analyze your program’s or company’s requirements. When it comes to actual disks, your options are limited to which disk to buy. With virtual drives, you can be more thrifty by adding a smaller disk to serve your needs (you can always add more later). The primary advantage of using LVM with virtual drives is the ability to increase a filesystem without restarting the server. If you have a 50 GB volume and want to make it larger, you can create two more 10 GB virtual disks and enlarge it <span class="No-Break">that way.</span></p>
<p>While LVM is not limited to virtual servers, it can be used on physical servers as well; however, doing so would likely necessitate a reboot due to the need to open the casing and physically attach a hard drive. The ability to add or remove physical hard disks from some servers is called <strong class="bold">hot-plugging</strong>, and it’s <a id="_idIndexMarker486"/>a huge time-saver that doesn’t need turning the server off. Finally, you may get the device’s name by typing <strong class="source-inline">fdisk -l</strong> into a terminal. We can find out what our new disk is called by using the <strong class="source-inline">fdisk</strong> command, which is more commonly used to create and erase partitions. If you<a id="_idIndexMarker487"/> run the <strong class="source-inline">fdisk -l</strong> command as <strong class="source-inline">root</strong> or with <strong class="source-inline">sudo</strong>, you’ll get the <span class="No-Break">following details:</span></p>
<pre class="source-code">
sudo fdisk -l</pre>
<div>
<div class="IMG---Figure" id="_idContainer053">
<img alt="Figure 10.1 – Listing all disks" height="785" src="image/B18575_10_01.jpg" width="976"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – Listing all disks</p>
<p>Now that we have learned how to list all the disks, we will next learn how to format and partition <span class="No-Break">storage devices.</span></p>
<h1 id="_idParaDest-148"><a id="_idTextAnchor178"/>Formatting and partitioning storage devices</h1>
<p>A disk must be formatted <a id="_idIndexMarker488"/>before it can be used. Finding the device’s given name is necessary to format the right disk. If you read the last section, you know that drives in Linux distributions follow a predetermined naming convention. Consequently, you should be familiar with the new disk’s device name. You can view information about the storage devices connected to your server using the <strong class="source-inline">sudo fdisk -l</strong> command, as <span class="No-Break">previously mentioned:</span></p>
<pre class="source-code">
sudo fdisk -l</pre>
<div>
<div class="IMG---Figure" id="_idContainer054">
<img alt="Figure 10.2 – Listing all disks" height="961" src="image/B18575_10_02.jpg" width="1009"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2 – Listing all disks</p>
<p>The <strong class="source-inline">/dev/sdb</strong> device is new to my server, as I just installed it (see <span class="No-Break"><em class="italic">Figure 10</em></span><em class="italic">.2</em>). I’m using it for the exercises in this chapter. Currently, it is not partitioned. At this point, it’s quite clear that the storage device referenced by <strong class="source-inline">/dev/sdb</strong> in the previous example is brand new. To avoid losing data, we must be careful never to format or repartition the wrong device. Since there are no partitions on <strong class="source-inline">/dev/sdb</strong> (as this volume wasn’t there before I added it), it’s evident that this is the disk we should work with. One or more partitions can be made on it at this point, bringing us one step closer to <a id="_idIndexMarker489"/>actually <span class="No-Break">using it.</span></p>
<p>Using the <strong class="source-inline">fdisk</strong> command with <strong class="source-inline">sudo</strong> and the device’s name as an option, we can partition the drive. The following is the command I would use to access <span class="No-Break">disk </span><span class="No-Break"><strong class="source-inline">/dev/sdb</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
sudo fdisk /dev/sdb</pre>
<p>You’ll see that I didn’t specify a partition number because <strong class="source-inline">fdisk</strong> deals with the disk directly (and we also have yet to create any partitions). In this section, I will assume that you have access to a drive that hasn’t been partitioned yet or is completely erasable. Upon successful execution, <strong class="source-inline">fdisk</strong> will display an introductory message <span class="No-Break">and prompt.</span></p>
<p>To see a list of available commands, use the <strong class="source-inline">m</strong> key on your keyboard, as shown in the <span class="No-Break">following screenshot:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer055">
<img alt="Figure 10.3 – Help menu for fdisk" height="1123" src="image/B18575_10_03.jpg" width="738"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3 – Help menu for fdisk</p>
<p>Here, I will demonstrate<a id="_idIndexMarker490"/> the sequence of steps necessary to create a new disk. Understand that <strong class="source-inline">fdisk</strong> can do serious damage to your system. Using <strong class="source-inline">fdisk</strong> on the wrong drive can cause permanent data loss. It’s normal for administrators to internalize the use of tools such as<strong class="source-inline">fdisk</strong> to the point where it’s second nature; however, before executing any such instructions, double-check that you’re indeed accessing the correct disk. There are two types of <a id="_idIndexMarker491"/>partition tables – the <strong class="bold">Master Boot Record</strong> (<strong class="bold">MBR</strong>) and <a id="_idIndexMarker492"/>the <strong class="bold">GUID Partition Table</strong> (<strong class="bold">GPT</strong>) – that need to be discussed before we can move further with creating a new partition. You can choose between the MBR and GPT partition tables when setting up a new disk’s partition table. If you’ve worked with servers for a while, you’ve undoubtedly used MBR, while GPT is the current standard. On older computers, the MBR partition structure can be referred to as the DOS partition structure. You may be aware that <strong class="bold">DOS</strong> refers to the <strong class="bold">Disk Operating System</strong>; nevertheless, in this chapter, we will refer to the <a id="_idIndexMarker493"/>partitioning scheme developed by IBM many years ago. For instance, the MBR partition structure is referred to as <em class="italic">DOS</em> while using <strong class="source-inline">fdisk</strong>. There are restrictions to think about when using MBR partition tables. To begin with, there is a limit of four primary partitions in MBR. It also restricts your disk use to about 2 TB. As long as your disk is under 2 TB in size, you should be fine, but disks greater than 2 TB are becoming increasingly prevalent. However, GPT doesn’t limit partition sizes, so if you have a disk that’s many TB in size, the choice between MBR and GPT is already made for you. In addition, <strong class="source-inline">fdisk</strong> with a GPT partition table allows you to construct up to 128 primary partitions. The following command gives options<a id="_idIndexMarker494"/> on what to do with the specific <span class="No-Break">HDD, </span><span class="No-Break"><strong class="source-inline">/dev/sdb</strong></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer056">
<img alt="Figure 10.4 – Creating a new partition" height="618" src="image/B18575_10_04.jpg" width="1134"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.4 – Creating a new partition</p>
<p>I used GPT, so I had to <span class="No-Break">enter </span><span class="No-Break"><strong class="source-inline">g</strong></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<img alt="Figure 10.5 – Creating a new GPT partition table" height="612" src="image/B18575_10_05.jpg" width="1030"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.5 – Creating a new GPT partition table</p>
<p>Don’t forget to<a id="_idIndexMarker495"/> enter <strong class="source-inline">w</strong> to <span class="No-Break">save changes.</span></p>
<p>If you made any mistakes, you can run <strong class="source-inline">fdisk</strong> again. After entering the <strong class="source-inline">fdisk</strong> prompt again, you can construct a new GPT layout by hitting <strong class="source-inline">g</strong>, or a new MBR layout by typing <strong class="source-inline">o</strong> if you made a mistake or simply wish to start over. Partitioning your drive is a two-step process, so you’ll need to repeat the previous stages. You can try this out for yourself a few times until you get the hang <span class="No-Break">of it.</span></p>
<p>Now, using <strong class="source-inline">fdisk -l /dev/sdb</strong>, we can see there is a new partition, <strong class="source-inline">/dev/sdb2</strong>, as shown in the <span class="No-Break">following screenshot:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<img alt="Figure 10.6 – Listing the partitions for /dev/sdb HDD" height="309" src="image/B18575_10_06.jpg" width="820"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.6 – Listing the partitions for /dev/sdb HDD</p>
<p>Now that we <a id="_idIndexMarker496"/>have learned how to create a new partition, we will see how to <span class="No-Break">format it.</span></p>
<h1 id="_idParaDest-149"><a id="_idTextAnchor179"/>Formatting a newly created partition</h1>
<p>Your new <a id="_idIndexMarker497"/>partition can be formatted once you’ve finished designing the disk’s partition arrangement and are satisfied with it. The results of <strong class="source-inline">sudo fdisk -l</strong> will be different now that I have partitioned the <span class="No-Break">new drive.</span></p>
<p>A new partition, <strong class="source-inline">/dev/sdb2</strong>, has been created and is reflected in the output. We can proceed with the formatting at this time. The <strong class="source-inline">mkfs</strong> command is used to create the filesystem. In order to execute this operation, you must use the correct syntax, which consists of entering <strong class="source-inline">mkfs</strong>, followed by a period (<strong class="source-inline">.</strong>), and then the name of the filesystem you wish to create. Using this code as an example, we can format <strong class="source-inline">/dev/sdb2</strong> as <strong class="source-inline">ext4</strong> by running the <strong class="source-inline">sudo mkfs.ext4 /</strong><span class="No-Break"><strong class="source-inline">dev/sdb2</strong></span><span class="No-Break"> command:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<img alt="Figure 10.7 – Formatting a partition" height="312" src="image/B18575_10_07.jpg" width="892"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.7 – Formatting a partition</p>
<p>It is important to<a id="_idIndexMarker498"/> remember to format the partition; otherwise, it won’t <span class="No-Break">be usable.</span></p>
<h1 id="_idParaDest-150"><a id="_idTextAnchor180"/>Mounting and unmounting volumes</h1>
<p>The next step after adding<a id="_idIndexMarker499"/> and formatting a new storage volume on your server is mounting the device. The <strong class="source-inline">mount</strong> command accomplishes this task. With this command, you can link a removable drive (or a network share) to a directory on the server’s hard drive. Mounting requires a clean directory. In order to mount a device, you must specify a directory to mount it to by using the <strong class="source-inline">mount</strong> command, which we will practice with an example shortly. Mounting additional storage is as simple as issuing the <strong class="source-inline">mount</strong> command and selecting a location that isn’t currently mounted or full of data. <strong class="source-inline">mount</strong> is a command that normally requires root privileges to execute. However, in most cases, only the root should mount volumes (although there is a workaround that involves allowing regular users to mount volumes; we won’t discuss that right now). Since you need a directory in which to mount these volumes, I’ll show you how to make one called <strong class="source-inline">/usbpartition</strong> using the <span class="No-Break">following command:</span></p>
<pre class="source-code">
sudo mkdir /usbpartition
sudo mount /dev/sdb2 /usbpartition</pre>
<p>With the preceding command, I mount the <strong class="source-inline">/dev/sdb2</strong> device to the <strong class="source-inline">/usbpartition</strong> directory as an example. Obviously, you’ll need to change the <strong class="source-inline">/dev/sdb2</strong> and <strong class="source-inline">/usbpartition</strong> references to reflect your own device and directory choices. A mount normally requires the <strong class="source-inline">-t</strong> option to specify the device type, but <strong class="source-inline">fdisk -l</strong> can be used as a handy reminder if you’ve forgotten what devices are installed on your server. The <strong class="source-inline">mount</strong> command that I should have used with the <strong class="source-inline">-t</strong> option, given that my disk is ext4-formatted, is <span class="No-Break">as follows:</span></p>
<pre class="source-code">
sudo mount /dev/sdb2 -t ext4 /usbpartition</pre>
<p>To check whether this has been mounted properly, use <span class="No-Break">this command:</span></p>
<pre class="source-code">
mount –v | grep usbpartition</pre>
<p>If you’re done working with a volume, you can unmount it with the <strong class="source-inline">umount</strong> command (the <em class="italic">n</em> in <em class="italic">unmount</em> is left out <span class="No-Break">on purpose):</span></p>
<pre class="source-code">
umount /usbpartition</pre>
<p>It is possible to remove a storage device from your filesystem using the <strong class="source-inline">umount</strong> command, which also requires you to be logged in as root or with <strong class="source-inline">sudo</strong>. The volume must be turned off for this command to take effect. A device or resource busy error message may appear if this is the case. After unmounting, you can verify that the filesystem is no longer mounted by running <strong class="source-inline">df -h</strong> and noting that it does not return any results. When devices are manually mounted, they will unmount when the server <a id="_idIndexMarker500"/>reboots. I will show you how to update the <strong class="source-inline">/etc/fstab</strong> file so that the mount is available at server startup in the <span class="No-Break">following section.</span></p>
<h2 id="_idParaDest-151"><a id="_idTextAnchor181"/>Updating the /etc/fstab file</h2>
<p>An essential Linux<a id="_idIndexMarker501"/> system file is the <strong class="source-inline">/etc/fstab</strong> file. You <a id="_idIndexMarker502"/>can manually mount additional volumes at boot time by editing this file. However, this file’s primary function is to mount your primary filesystem, thus any mistakes you make while modifying it will prevent your server from starting up (at all). Take <span class="No-Break">extreme caution.</span></p>
<p>The location of the root filesystem is determined by reading the <strong class="source-inline">/etc/fstab</strong> file, which is read during system boot. This file is also used to determine the swap partition’s location, and it is mounted at boot time. Each mount point in this file will be read and mounted sequentially by your system. This file can be used to automatically mount almost any type of storage device. You can even install Windows server network shares. In other words, it has no morals and won’t pass judgment (unless you make <span class="No-Break">a typo).</span></p>
<p>This is what an <strong class="source-inline">/etc/fstab</strong> file <span class="No-Break">looks like:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer060">
<img alt="Figure 10.8 – A sample of an /etc/fstab file" height="447" src="image/B18575_10_08.jpg" width="1315"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.8 – A sample of an /etc/fstab file</p>
<p>It is important to be<a id="_idIndexMarker503"/> careful when editing this file, as incorrect <a id="_idIndexMarker504"/>settings can cause the system to fail to boot or cause data loss. It is recommended to make a backup of the file before making <span class="No-Break">any changes.</span></p>
<h2 id="_idParaDest-152"><a id="_idTextAnchor182"/>Editing /etc/fstab file</h2>
<p>As we mentioned<a id="_idIndexMarker505"/> earlier, any device mounted manually<a id="_idIndexMarker506"/> won’t be mounted automatically <span class="No-Break">on reboot.</span></p>
<p>In order to do it automatically, the device has to be added to the <strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">etc/fstab</strong></span><span class="No-Break"> file.</span></p>
<p>I added an entry in <strong class="source-inline">/etc/fstab</strong> to mount <strong class="source-inline">/dev/sdb2</strong> automatically in <strong class="source-inline">/usbpartition/</strong> on boot, as shown in the last line of the <span class="No-Break">following screenshot:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer061">
<img alt="Figure 10.9 – A sample of the /etc/fstab file" height="471" src="image/B18575_10_09.jpg" width="1314"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.9 – A sample of the /etc/fstab file</p>
<p>On my machine, both the fifth and sixth columns read <strong class="source-inline">0</strong>, indicating a successful dump and a passing grade. Nearly invariably set to <strong class="source-inline">0</strong>, the dump partition can be checked by a backup program to see whether the filesystem needs to be backed up (<strong class="source-inline">0</strong> for no, and <strong class="source-inline">1</strong> for yes). Since almost nothing uses this anymore, you can usually just leave it at <strong class="source-inline">0</strong>. Filesystems will be checked in the order specified in the pass field. In the event of a system crash or as part of a routine maintenance procedure, the <strong class="source-inline">fsck</strong> utility checks drives for filesystem problems. Values can be either a <strong class="source-inline">0</strong> or a <strong class="source-inline">1</strong>. When set to <strong class="source-inline">0</strong>, <strong class="source-inline">fsck</strong> will never run to check on the partition. If this value is <strong class="source-inline">1</strong>, the partition is examined before <span class="No-Break">anything else.</span></p>
<p>By default, only the root user<a id="_idIndexMarker507"/> can modify the <strong class="source-inline">/etc/fstab</strong> file, so it’s<a id="_idIndexMarker508"/> important to be careful when editing it. Incorrectly modifying this file can cause serious problems with the system’s boot process and <span class="No-Break">data integrity.</span></p>
<h1 id="_idParaDest-153"><a id="_idTextAnchor183"/>Utilizing LVM</h1>
<p>Your organization’s <a id="_idIndexMarker509"/>requirements will evolve over time. As server administrators, we constantly strive to set up resources with future expansion in mind. Unfortunately, budgets and policy shifts frequently get in the way. You’ll find that LVM is invaluable in the long run. Linux’s superiority in scalability and cloud deployments is due in large part to technologies such as LVM. By using LVM, you can expand or contract your filesystems without having to restart the server. Consider the following scenario. Say you have a mission-critical app operating on a virtualized production server. It’s possible that when you initially set up the server, you allocated 300 GB of space for the application’s data directory, thinking it would never grow to fill that much space. The expansion of your company has not only increased your space requirements but also created a crisis. So, tell me, what do you do? If the server was initially configured to use LVM, then adding a new storage volume, including it in the LVM pool, and expanding the partition would not require a reboot. However, without LVM, you’d have to schedule downtime for your server while you added more storage the old-fashioned way, which could take hours. Even if your server isn’t virtual, you can still profit from expanding your filesystem online by installing more hard drives and leaving them on standby without using them. In addition, you can add more volumes without having to shut down the server if your server supports hot-plugging. Because of this, I can’t stress enough how important it is to use LVM whenever possible on storage volumes in virtual servers. Again, LVM is essential to set up storage volumes on a virtual server. If you don’t, you’ll have to spend your weekends laboring to add disks, since you will have ran out of space during <span class="No-Break">the week.</span></p>
<h1 id="_idParaDest-154"><a id="_idTextAnchor184"/>Getting started with LVM</h1>
<p>Linux’s server installer <a id="_idIndexMarker510"/>allows you to select LVM as a volume manager for a fresh server setup. However, LVM should be utilized extensively for storage volumes, especially those that will house user and application data. If you want the root filesystem on your Ubuntu server to take advantage of LVM’s functionality, LVM is a good option. We’ll need to have a firm grasp on volume groups, physical volumes, and logical volumes before we can begin using LVM. The logical and physical volumes you intend to use with an LVM solution are organized into volume groups. In a nutshell, a volume group is the umbrella term for your whole LVM infrastructure. You can think of it as a container that can hold disks. A <strong class="source-inline">vg-accounting</strong> volume group is an illustration of this type of group. The accounting department would use this volume group to store their records. It will include both the actual disk space and the virtual disk space that these users will access. It’s worth noting that you’re not restricted to a single volume group but can instead create multiple, each with its own set of disks and volumes. A physical volume is a disk, either real or virtual, that belongs to a volume group. A <strong class="source-inline">vg-accounting</strong> volume group might theoretically have three 500 GB hard drives, each of which would be treated as a physical volume. Keep in mind that, although these disks are virtual, in the context of LVM they are still referred to as physical volumes. A physical volume is a storage device that belongs to a volume group. Finally, the concept of logical volumes is comparable to that of partitions. In contrast to traditional partitions, logical volumes can span over numerous physical drives. A logical volume, for instance, may be set up with three 500 GB disks, giving you access to a total of 1,500 GB. When it’s mounted, it acts like a single partition on a regular hard drive, allowing users to save and access files with the same ease as they would with any other disk. When the space on the volume runs out, you can expand it by adding a new disk and then expanding the partition. Although it may actually be comprised of several hard drives, to your users it will appear as a single, unified space. Physical volumes can be subdivided in any way that makes sense to you. Users will interact with logical volumes, which are created from the underlying <span class="No-Break">physical volumes.</span></p>
<p>Installing LVM on a server that isn’t already utilizing it requires having at least one unused volume and the necessary packages, either of which may or may not already be present on the server. The following commands will tell you whether the necessary <strong class="source-inline">lvm2</strong> package is present on <span class="No-Break">your server:</span></p>
<p>For Debian, use <span class="No-Break">this command:</span></p>
<pre class="source-code">
sudo apt search lvm2 | grep installed</pre>
<p>For Redhat, use <span class="No-Break">this command:</span></p>
<pre class="source-code">
sudo yum list installed|grep lvm2</pre>
<p>The next step is to count all of the disks in our possession. Many times now, we have used the <strong class="source-inline">fdisk -l</strong> command to display a list of these drives. As an example, I have <strong class="source-inline">/dev/sdc</strong> on my server now. Disk names will vary by hardware or virtualization platform, so you’ll need to tweak the following commands to work with your setup. First, we must prepare each disk for usage with LVM by creating a physical volume. It is important to remember that setting up LVM does not include formatting a storage device or using <strong class="source-inline">fdisk</strong> to configure it. In this case, formatting occurs later. To begin setting up our drives for usage with LVM, we will use the <strong class="source-inline">pvcreate</strong> command. As a result, we must execute the <strong class="source-inline">pvcreate</strong> command on each of the drives we intend to employ. To set up LVM with my USB disks, I will execute <span class="No-Break">the following:</span></p>
<pre class="source-code">
sudo pvcreate /dev/sdc</pre>
<p>If you want to check that everything is set up properly, you can see a list of your server’s physical volumes by running the <strong class="source-inline">pvdisplay</strong> command as root or <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">sudo</strong></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer062">
<img alt="Figure 10.10 – The pvdisplay command output" height="309" src="image/B18575_10_10.jpg" width="848"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.10 – The pvdisplay command output</p>
<p>Only one volume <a id="_idIndexMarker511"/>could be displayed on this page, so only that one is shown in the screenshot. If you scroll up, more output from the <strong class="source-inline">pvdisplay</strong> command will be displayed. We have access to a number of physical volumes, but none of them have been placed in a volume group. Actually, we haven’t done something as simple as making a volume group yet. Using the <strong class="source-inline">vgcreate</strong> command, we can create a volume group, give it a name, and add our first disk <span class="No-Break">to it:</span></p>
<pre class="source-code">
sudo vgcreate vg-packt /dev/sdc</pre>
<p>At this point, I creating a volume group called <strong class="source-inline">vg-packt</strong> and allocate one of the created physical volumes (<strong class="source-inline">/dev/sdc</strong>) to it. With the <strong class="source-inline">sudo vgdisplay</strong> command, we can see the volume group’s configuration, including the number of disks it uses (which should be 1 at <span class="No-Break">this point):</span></p>
<p>Right now, all that has to be done is for us to make a logical volume and format it. The disk space we allocate to our volume group may be used in its entirety, or in part. Here’s the command I’ll use to partition the newly added virtual disk within the volume group into a 5 GB <span class="No-Break">logical volume:</span></p>
<pre class="source-code">
sudo lvcreate -n packtvol1 -L 5g vg-packt</pre>
<p>Although the command looks difficult, it is actually quite simple. For clarity, I use the <strong class="source-inline">-n</strong> option to give my logical volume the name <strong class="source-inline">packtvol1</strong> in this example. I use the <strong class="source-inline">-L</strong> option followed by <strong class="source-inline">5g</strong> to specify that I only want to allocate 5 GB of space. The volume group that this logical volume will be part of is listed as the final item. To view details about this volume, use the <strong class="source-inline">sudo </strong><span class="No-Break"><strong class="source-inline">lvdisplay</strong></span><span class="No-Break"> command:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<img alt="Figure 10.11 – The lvdisplay command output" height="481" src="image/B18575_10_11.jpg" width="897"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.11 – The lvdisplay command output</p>
<p>At this point, we<a id="_idIndexMarker512"/> have everything we need to set up LVM. Like with non-LVM disks, we must format a volume before <span class="No-Break">using it.</span></p>
<h2 id="_idParaDest-155"><a id="_idTextAnchor185"/>Creating a format for logical disks</h2>
<p>The next step <a id="_idIndexMarker513"/>is to utilize the correct <a id="_idIndexMarker514"/>format for our logical volume. However, for the formatting process to go smoothly, we must always know the device’s name. Since LVM exists, this is a breeze. You can see this in the output (it’s the third line down in <span class="No-Break"><em class="italic">Figure 10</em></span><em class="italic">.11</em>, under <strong class="bold">LV Path</strong>) that the <strong class="source-inline">lvdisplay</strong> command provided. Let’s use the <strong class="source-inline">ext4</strong> filesystem to set up <span class="No-Break">the drive:</span></p>
<pre class="source-code">
sudo mkfs.ext4 /dev/vg-packt/packtvol1</pre>
<p>Finally, this storage device can be used like any other hard drive. Mine will be mounted at <strong class="source-inline">/mnt/lvm/packtvol1</strong>, but you can use whatever <span class="No-Break">you like:</span></p>
<pre class="source-code">
sudo mount /dev/vg-packt/packtvol1 /mnt/lvm/packtvol1</pre>
<p>We can run <strong class="source-inline">df -h</strong> to verify that the volume is mounted and displays the right size. The single disk in our current LVM arrangement makes this useless. The 5 GB I’ve allotted probably won’t last very long, but we have some unused space that we can put to <span class="No-Break">good use:</span></p>
<pre class="source-code">
~$ df –h | grep packtvol1
/dev/mapper/vg--packt-packtvol1   4.9GB   20M.  4.6GB  1%   /mnt/lvm/packtvol1</pre>
<p>The following <strong class="source-inline">lvextend</strong> command allows me to expand my logical volume to fill the remaining space on the <span class="No-Break">physical disk:</span></p>
<pre class="source-code">
sudo lvextend -n /dev/vg-packt/packtvol1 -l +100%FREE</pre>
<div>
<div class="IMG---Figure" id="_idContainer064">
<img alt="Figure 10.12 – The lvextend command" height="111" src="image/B18575_10_12.jpg" width="1518"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.12 – The lvextend command</p>
<p>To be more <a id="_idIndexMarker515"/>specific, the preceding <strong class="source-inline">+100%FREE</strong> option<a id="_idIndexMarker516"/> specifies that we wish to allocate the full remaining space to the logical volume. In my case, this is only 2.5 GB, as I used a USB stick for <span class="No-Break">demo purposes.</span></p>
<p>All of the space on the physical drive I designated for my logical volume is being used up. However, tread carefully, because if I had more than one physical volume allocated, the command would have taken up all of that space as well, making the logical volume the size of all the space on all the disks. Even if you don’t want to do this all the time, it’s fine by me because I just have one physical volume. Feel free to use the <strong class="source-inline">df -h</strong> tool once again to verify your available <span class="No-Break">storage space:</span></p>
<pre class="source-code">
~$ df –h | grep packtvol1
/dev/mapper/vg--packt-packtvol1   4.9GB   20M.  4.6GB  1%   /mnt/lvm/packtvol1</pre>
<p>Unfortunately, the additional volume space we’ve added isn’t reflected. <strong class="source-inline">df</strong> still returns the old volume size in its output. The reason for this is that we did not resize the <strong class="source-inline">ext4</strong> filesystem that is located on this logical disk, despite the fact that we have a larger logical volume and it has all the space given to it. The <strong class="source-inline">resize2fs</strong> command is what we’ll utilize to <span class="No-Break">do this:</span></p>
<pre class="source-code">
sudo resize2fs /dev/mapper/vg--packt-packtvol1</pre>
<div>
<div class="IMG---Figure" id="_idContainer065">
<img alt="Figure 10.13 – The resize2fs command" height="176" src="image/B18575_10_13.jpg" width="1477"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.13 – The resize2fs command</p>
<p>Now, using<a id="_idIndexMarker517"/> the <strong class="source-inline">df -h</strong> command again, we can<a id="_idIndexMarker518"/> see we have all the <span class="No-Break">space allocated:</span></p>
<pre class="source-code">
~$ df –h | grep packtvol1
/dev/mapper/vg--packt-packtvol1   7.3GB   23M.  6.9GB  1%   /mnt/lvm/packtvol1</pre>
<p>In this section, we’ve learned how to use logical volumes and how to extend <span class="No-Break">a filesystem.</span></p>
<h2 id="_idParaDest-156"><a id="_idTextAnchor186"/>Deleting volumes with LVM</h2>
<p>Last but not <a id="_idIndexMarker519"/>least, you probably want to know what<a id="_idIndexMarker520"/> happens when you delete a logical volume or volume group. The <strong class="source-inline">lvremove</strong> and <strong class="source-inline">vgremove</strong> commands are used for this reason. Destructive as they may be, these commands can be very helpful if you ever need to get rid of a logical volume or volume group. The following syntax will get rid of any <span class="No-Break">logical volumes:</span></p>
<pre class="source-code">
sudo lvremove vg-packt/packtvol1</pre>
<p>Giving the <strong class="source-inline">lvremove</strong> command the name of the volume group you want to remove the logical volume from, followed by a forward slash, is all that’s required. To remove the entire volume group, the following command should do <span class="No-Break">the trick:</span></p>
<pre class="source-code">
sudo vgremove vg-packt</pre>
<p>Even though you probably won’t be removing logical volumes very often, there are commands available to help you do so if you ever find yourself in need of decommissioning an LVM component. Hopefully, you can see why LVM is so <span class="No-Break">great now.</span></p>
<p>The <strong class="source-inline">pvremove</strong> command in Linux is used to<a id="_idIndexMarker521"/> remove a <strong class="bold">physical volume</strong> (<strong class="bold">PV</strong>) from the LVM. Before using this command, make sure that the PV you want to remove is not part of any volume group and does not contain any active logical volumes. Otherwise, data loss <span class="No-Break">may occur.</span></p>
<p>This technology gives you unprecedented control over the data stored on your server. Linux’s versatility in the cloud is due in part to LVM’s adaptability. If you’re not familiar with LVM, these ideas may seem foreign at first. However, with virtualization, experimenting with LVM is straightforward. Until you feel comfortable making, editing, and erasing volume groups and logical volumes, I advise <a id="_idIndexMarker522"/>you to put in some practice<a id="_idIndexMarker523"/> time. Concepts that aren’t immediately evident will become so with <span class="No-Break">repeated exposure.</span></p>
<h1 id="_idParaDest-157"><a id="_idTextAnchor187"/>Summary</h1>
<p>Maintaining a smooth operation requires careful storage management, as a full filesystem will cause your server to cease. Fortunately, Linux servers come with a plethora of storage management capabilities, some of which are the envy of competing systems. It would not be possible to perform our jobs as Linux server administrators without innovations such as LVM. In this chapter, we dove into these resources and learned some storage management tricks. We went through a wide range of topics, including how to create and manage partitions, mount and unmount volumes, work with the <strong class="source-inline">fstab</strong> file, use LVM, and check <span class="No-Break">disk use.</span></p>
<p>In the next chapter, we will discuss logging configuration and <span class="No-Break">remote logging.</span></p>
</div>
</div>

<div id="sbo-rt-content"><div class="Content" id="_idContainer067">
<h1 id="_idParaDest-158" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor188"/>Part 3: Linux as a Part of a Larger System</h1>
<p>All modern IT infrastructures consist of multiple machines with different roles, so all systems administrators need to know how to make their Linux-based systems work together. In this part of the book, you will learn how to collect log messages from all these systems on a central server, simplify user account and permission management by using centralized authentication mechanisms, create robust services with automatic failover and load balancing, and manage multiple systems at once with automation tools. You will also learn how to keep your <span class="No-Break">systems secure.</span></p>
<p>This part has the <span class="No-Break">following chapters:</span></p>
<ul>
<li><a href="B18575_11.xhtml#_idTextAnchor189"><em class="italic">Chapter 11</em></a>, <em class="italic">Logging Configuration and Remote Logging</em></li>
<li><a href="B18575_12.xhtml#_idTextAnchor201"><em class="italic">Chapter 12</em></a>, <em class="italic">Centralized Authentication</em></li>
<li><a href="B18575_13.xhtml#_idTextAnchor216"><em class="italic">Chapter 13</em></a>, <em class="italic">High Availability</em></li>
<li><a href="B18575_14.xhtml#_idTextAnchor235"><em class="italic">Chapter 14</em></a>, <em class="italic">Automation with Chef</em></li>
<li><a href="B18575_15.xhtml#_idTextAnchor267"><em class="italic">Chapter 15</em></a>, <em class="italic">Security Guidelines and Best Practices </em></li>
</ul>
</div>
<div>
<div id="_idContainer068">
</div>
</div>
</div></body></html>