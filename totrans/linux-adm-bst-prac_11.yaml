- en: '*Chapter 7*: Documentation, Monitoring, and Logging Techniques'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we are getting into the real *meat* of system administration work, although
    I think that most people would feel like this is the *potatoes*. In this chapter
    we are going to be dealing with all of the parts of system administration that
    no one can see on our servers. These are those nearly invisible components of
    our jobs that are so critical and can do so much to separate the juniors from
    the seniors; the extra steps that make all of the difference when things start
    to go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we are going to learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modern Documentation: Wiki, Live Docs, Repos'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tooling and Impact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capacity Planning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log Management and Security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerts and Troubleshooting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Modern documentation: Wiki, live docs, repos'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The thing about documentation is that everyone admits that it is important,
    everyone talks about it, and almost no one does it or if they do, they don't keep
    it up to date. Documentation is boring, often harder than it seems to do well,
    and because almost no management will ever follow up and verify it, extremely
    easy to ignore. No one ever gets promoted because of excellent documentation,
    no one throws documentation parties, and no one talks about it on their curriculum
    vitae. Documentation just is not cool enough for people to want to spend time
    talking about.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation is, however uncool it might feel, amazingly important for so many
    reasons. It can go far for moving someone from being an acceptable system administrator
    to being a great one.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation does some interesting things. Of course, it allows us to recall
    how systems work and what tasks need to be done to them. It allows us to hand
    off tasks to others. It protects the business should we go on vacation, get sick,
    or move on to greener pastures or even retire. But beyond these obvious points,
    documentation allows us, forces us in fact, to think differently about our systems
    that we maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the software engineering world, a new technique of writing tests before
    writing the functions that they test has become popular and has shown that it
    can force people to think differently about how they approach problem solving
    and can lead to greater efficiency. We have very similar benefits in system administration.
    Approaching documentation more aggressively can lead to faster processes, better
    planning, less wasted time, and fewer mistakes. Taking a documentation-first approach,
    that is writing documentation before systems are built or configured, can help
    us think differently about our system designs and to document thoroughly: An intentional
    process of documenting what should be, rather than attempting to document what
    we did. This provides a wholly different way of thinking, and a way to double
    verify veracity, and an actual process to encourage completeness of documentation.'
  prefs: []
  type: TYPE_NORMAL
- en: If we force ourselves to document everything before we enter it into a system,
    we can improve our chances of having accurate and complete data. Avoiding the
    need to go back and attempt to remember everything that was needed or done on
    a system is important. Using a document first process we have an opportunity to
    catch missed documentation at the time that we go to use it, which may only be
    a few minutes later. If we work first and then document it, it is very easy to
    forget small details and there is no triggering event to remind us to verify that
    something is written. Alternatively, if we document first, we have the moment
    when we need to put data into a system or a configuration to make. We have a triggering
    event, the actual moment of entering configuration data to remind us that we should
    have pulled that out of a document. It is not foolproof, only more reliable than
    typical processes.
  prefs: []
  type: TYPE_NORMAL
- en: No one really disputes, at least not in polite company, that documentation is
    needed or that it is one of the most important things that we can do working as
    system administrators, or really working in information technology at all. It
    is practically a mantra that we repeat, yet few of us really internalize this
    decision. Instead, we pay lip service to the ideology of documenting everything
    and still push off documentation as a secondary concern that we might do tomorrow
    if, and only if, we get bored during some mythical free time. This is where things
    break down. We cannot simply claim to believe that documentation is all important,
    we have to truly believe it and act accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: We can talk all day about the importance of documentation, but all that really
    matters is taking that knowledge and putting it into action, however that works
    for you and your organization. To make that more likely to be successful we need
    to use good documentation tools. Having a high barrier to documentation encourages
    us to avoid it or to see it as too time consuming to do at the correct time. If
    we make documentation fast and easy, we are much more likely to find ourselves
    just doing it, perhaps even enjoying it to some degree. I know that I am personally
    very satisfied finding my documentation to be complete and up to date - having
    that satisfaction of knowing that I could show it to someone, at any time, and
    feel good about what is there.
  prefs: []
  type: TYPE_NORMAL
- en: 'In choosing a platform for documentation we have many considerations. How will
    the documentation be stored, backed up, protected, secured, and accessed? What
    kind of data will be stored: text, audio, images, video, or code? How many people
    will use it? Do you need to make it accessible inside an office? In multiple offices?
    Globally? Will third parties need to access it?'
  prefs: []
  type: TYPE_NORMAL
- en: Wikis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Over the last two decades, the wiki has arisen to be the de facto tool for documentation
    of all sorts. Wikis are designed around being fast and easy to edit and at this
    they excel. Wikis also traditionally use simple markup languages, like the MarkDown
    language, that make it easy to store exact text and technical data without it
    being manipulated by a formatting system. This creates a minor learning curve
    but rewards a small amount of very standard learning with the ability to make
    very accurate, well formatted documents quickly.
  prefs: []
  type: TYPE_NORMAL
- en: The wiki format is all about simplicity - the simplest possible system that
    still allows for enough formatting to be able to be used for nearly any documentation
    task. This simple format makes it easy to have a variety of wiki products on the
    market that satisfy nearly any specific need. From small, light, and free open-source
    products that you can run yourself to large, hosted commercial offerings that
    you simply sign up for and use. It covers nearly all bases. Organizations of any
    size can use it effectively and there is nearly always a wiki option that integrates
    with other systems that you have.
  prefs: []
  type: TYPE_NORMAL
- en: 'A wiki will generally suffer from a need for some degree of organization which
    is not native to the platform. The strength of a wiki, that it is fast and flexible,
    is also a great weakness: it is just far too easy to start to throw data someplace
    that it does not belong and to leave no trail as to how to find the information
    again. Some wikis will go above and beyond the basics and include meta data tagging
    options or structured data organization options. These are the exception, not
    the norm.'
  prefs: []
  type: TYPE_NORMAL
- en: Wikis have, for a number of years, been used as a component of or even the basis
    for larger products. A great example of this is Microsoft's SharePoint which uses
    a wiki engine as its core rendering engine and all of its interface details are
    simply advanced components being rendered on top of a wiki.
  prefs: []
  type: TYPE_NORMAL
- en: An issue typical to wikis is that they are rarely able to have the same data
    modified by multiple people at the same time. Their simplistic design often assumes
    that they will be treated quite simply - a single author, as the only reader,
    during the time of edits. This makes a wiki more useful in single user environments,
    or environments where users rarely use the documentation platform at the same
    time, or in organizations where different users tend to be segmented off from
    one another so that they will use different documentation pages at different times.
    If your team needs to have multiple people making active edits, or viewing updating
    information, in real time of the same data then other documentation options are
    likely going to be better.
  prefs: []
  type: TYPE_NORMAL
- en: Live docs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The newest way to approach documentation feels much like a step backward: word
    processor documents. Yes, you read that correctly. Hear me out.'
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, that is in the late 1990s and early 2000s, the idea that you
    would use a word processor document as documentation seemed ridiculous unless
    you were such a tiny company that you only had one person who would ever need
    to use and access these documents and then it was reasonable as it made storing
    everything as a file relatively easy. This has changed heavily in the last several
    years as new technologies have turned nearly all mainstream word processors into
    online, web-based, multi-user tools that only resemble early word processors in
    their superficial capacity, but not in usability or technology.
  prefs: []
  type: TYPE_NORMAL
- en: These next generation document systems provide a surprisingly powerful and robust
    mechanism to use for documentation purposes. While there is no single universal
    standard for how these systems should behave, a set of conventions have arisen
    that are sensible and are followed by all major systems and are available both
    commercially and in free, open-source packages as well as in hosted or self-hosting
    modes. Of the greatest importance to us are the ideas that these live documents
    are able to be edited by multiple users at the same time, show changes as they
    are made in real time, have secure access controls, track changes, and use web
    interfaces that are easily published online or anywhere that they are needed,
    as well as, being able to output documentation to an easily portable or transferable
    set of formats.
  prefs: []
  type: TYPE_NORMAL
- en: Modern document handling systems like these will often times use a database
    behind the scenes, rather than resorting to sets of individual documents, and
    only expose individual documents as views into a single, large data set rather
    than truly individual sets of data. These systems are becoming increasingly powerful
    and can fit easily into other document management or replacement workflows. Nearly
    all organizations today are already tackling the need for modern document systems
    in other parts of the business, and these will easily be systems into which system
    documentation can be added without incurring any additional cost or effort. Doing
    more with the systems you have to maintain already is a great way to get high
    value at low cost.
  prefs: []
  type: TYPE_NORMAL
- en: Because these modern document systems allow for multiple users on the same document
    at the same time, they are especially useful for times when you have a multi-person
    team working on a single customer or system at the same time and the documentation
    needs to be shared. That way one person making a change keeps the data on everyone's
    screens constantly updated. The documentation system itself becomes a mechanism
    for team collaboration instead of being a risk of using outdated data because
    someone did not know to refresh their view.
  prefs: []
  type: TYPE_NORMAL
- en: Alternative interfaces to similar data
  prefs: []
  type: TYPE_NORMAL
- en: As these kinds of tools have become more and more popular, alternative interfaces
    to similar database drive document data have started to arise. Popular alternative
    formats like notepad applications are beginning to become more popular. These
    formats are less well known than traditional word processing and spreadsheet tools
    but can be very good for system documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the multi-media and often changing ad hoc nature of documentation,
    journal-style applications can be ideal. Over time I expect to see more and more
    applications designed around flexible documentation to become more mainstream.
  prefs: []
  type: TYPE_NORMAL
- en: Personally, I have become a large fan of these systems. They utilize standard
    tools that nearly all staff know already and tools that are likely to be already
    being used for many other purposes and repurposes them in a way that is surprisingly
    well suited for them. Less retraining, fewer special case tools to manage, and
    easy access and usability by teams that may use the documentation less often.
  prefs: []
  type: TYPE_NORMAL
- en: Repos
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A new standard for documentation is to use online code repository systems. These
    systems generally work from a collection of text files that are loosely formatted
    but they get updated and version controlled centrally. This is a very different
    approach than what is taken with the examples given previously. This system does
    not address live collaboration between team members, but does allow for offline
    usage quite easily using standard tools used in the development space.
  prefs: []
  type: TYPE_NORMAL
- en: The real reason that the use of version-controlled code repositories has become
    an area of interest for documentation is that it is already being used heavily
    in the development and DevOps spaces and so is a natural system to adapt for use
    in IT documentation. The ease of using documentation offline using local reading
    and writing tools, and the ability to also have online copies makes it very flexible.
  prefs: []
  type: TYPE_NORMAL
- en: There are beginning to be ways to even use this type of documentation in a live,
    shared manner with some of the newer editing tools. Likely we will see this advance
    significantly in the near future as more focus is put on expanding the robustness
    of this process.
  prefs: []
  type: TYPE_NORMAL
- en: Ticketing systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Traditional documentation as we have been discussing is really state documentation:
    documenting the way that systems *are* or, at least, *should be*. There is much
    more to document. The other system that we should use is a ticketing system or,
    to think of it another way, *change documentation*.'
  prefs: []
  type: TYPE_NORMAL
- en: Tickets are a form of documentation just like your wiki might be. Unlike a wiki,
    tickets are focused on recording events in time. They track errors, problems,
    issues, requests, observations, reactions, changes, decisions, and so forth. Unlike
    traditional documentation that is a final document showing the results of all
    decisions and changes made until the current time, your ticket system should reflect
    the history of your systems and workloads to allow you to, theoretically, *play
    back* events as they happened to not only know what changes were made to a system
    but also who made them, who requested them, who approved them, and why.
  prefs: []
  type: TYPE_NORMAL
- en: Tickets, when used properly, play a huge role in the lives of a system administrator.
    While possible to function without a good ticketing system, this will add so much
    unnecessary work. Using tickets to track tasks as they get assigned, the process
    of completing the work, and the final disposition provides the missing half of
    the documentation puzzle.
  prefs: []
  type: TYPE_NORMAL
- en: If your business does not have or is unsupportive of getting a ticketing system,
    consider implementing a private one just for yourself. Ticket software comes in
    many shapes and forms and free software and services are available that work quite
    well if spending money on upgraded products or more extensive features is not
    an option. You can think of your ticket system as a personal work journaling mechanism
    if that makes more sense.
  prefs: []
  type: TYPE_NORMAL
- en: You do not have to go overboard attempting to integrate tickets into your company's
    greater workflow if you cannot get top level buy in or it does not make sense
    for how the organization should work, but it is hard to imagine any IT department
    that would not benefit dramatically for being able to track IT change events,
    including denied events, to be able to demonstrate the history and activity of
    the department and to be able to trace potential issues caused by changes in our
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: Like traditional documentation, ticketing systems come in all shapes and sizes.
    Play with a few, give them a try, do not be afraid to change to something else.
    Find something that works for you and allows you to effectively document the changes
    that you make, when you made them, how long it took you, why you did it in the
    first place; and all with a minimum of effort.
  prefs: []
  type: TYPE_NORMAL
- en: Approaching documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Chances are you have some amount of documentation in your job today. Chances
    are even better that what you have is incomplete, out of date, and essentially
    useless. It is okay, nearly all companies suffer from bad documentation. But this
    is a tremendous opportunity for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: If you have documentation like most businesses, the best thing is often to literally
    start over. Look over your options, think about how your company will need to
    approach documentation and collaboration and pick an approach. It does not even
    have to be the right one. Any documentation process is good, even if you risk
    having to do it again. Pick a system and try it out. See if it fits the style
    of the data that you need to store, if it is comfortable for you to use, and if
    it allows for the style of collaboration (if any) that your business needs.
  prefs: []
  type: TYPE_NORMAL
- en: Do not try to document absolutely everything right away. Take a single system
    or workload and try documenting that one item in a very good way. Format it to
    look really good. Organize the data to make the data that you need quickly be
    clearly visible and available near the top so that someone trying to address a
    problem does not have to search far to find what they need. Remove redundancy
    and ensure that data exists only one time, in a single, predictable place. Think
    of your documentation like a relational database that needs some normalization,
    and the first major step is organization and the second is removing redundancy.
    Documentation is always hard to maintain, and redundancy of data makes it all
    but impossible. Attempting to change unknown occurrences of the same information
    gives no clue to how to find it all and what needs to be updated.
  prefs: []
  type: TYPE_NORMAL
- en: When you find a system and process that works for you, stick with that. Start
    documenting everything. Make it a huge priority, do nothing without documentation.
    Add tickets and start making everything get tracked.
  prefs: []
  type: TYPE_NORMAL
- en: Maybe you work for a company where documentation is already good. Chances are,
    though, you do not. And if you do, chances are you will never work in a place
    like that again. Good documentation is a rarity even before we consider the importance
    of tickets in the overall documentation equation.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are no best practices as to what tools to use or in what format to put
    your documentation, but there are some high-level best practices to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: Use both state and change documentation systems to track all aspects of your
    systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid data redundancy in state documentation systems (it is fine in change systems.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep all documentation up to date and secure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not document data that can be recreated reliably from other data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is easy to say that we need to be religious about our documentation, and
    everyone agrees that it is of the utmost importance. Yet actually moving from
    saying it, to doing it, is understandably hard. Management rarely verifies documentation
    as we are working, but they do reward getting other work done and frown upon delays.
    It is unfortunate that often the most important aspects of our careers are not
    seen as important enough or interesting enough for those outside of our field
    and they get deprioritized by people with no knowledge of how they play into what
    we do.
  prefs: []
  type: TYPE_NORMAL
- en: In our next section, we will move on from purely manual system tracking to beginning
    to use tools on our systems to measure and track them in a more automated fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Tooling and impact
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the fundamental natures of physics, as well as a rule that you learn
    straight away in industrial engineering, is that you cannot observe or measure
    events without in some way impacting them. In computing, we face the same problem.
    If anything, we face it far more than in most other places.
  prefs: []
  type: TYPE_NORMAL
- en: The more that we measure, log, or put metrics on our systems the more of the
    system resources needed for our workloads is taken up by the measurement processes.
    As computers have gotten faster over the years the ability to measure without
    completely crippling our workloads has become more common and now, we often even
    track checkpoints inside of applications in addition to operating system metrics.
    But we always have to maintain an awareness of what this impact is.
  prefs: []
  type: TYPE_NORMAL
- en: At some point there is more value to just letting the systems that we have run
    as fast as they can rather than trying to measure them to see how fast they are
    going. A sprinter running flat out is faster than a sprinter running while carrying
    measurement devices to determine their speed. The measurement process works against
    them. However the sprinter getting more feedback might be able to improve with
    the additional knowledge over time. But you will never see someone attempting
    to outrun a charging hippopotamus (they are one of the fastest and most dangerous
    land mammals, you know) first stop to turn on measuring devices. They will just
    run as fast as they can. Knowing how to run faster is only useful if it gives
    you both potentially useful data that by using you can enact improvements and
    you get the chance to implement those improvements. If the hungry hippopotamus
    catches you, all those measurements will be for naught.
  prefs: []
  type: TYPE_NORMAL
- en: Different tools will have very different levels of impact. Some simple everyday
    tools that we use on our systems may have almost no impact at all, but will generally
    give us only an extremely high level view of what the computer is doing. Other
    tools, like log collection, can require a great many resources and can even put
    noticeable strains on networking and storage resources.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting data from a system is not the only activity that uses system resources.
    Collating that data and presenting it in a form useful for humans also requires
    resources, as would shipping that data off to an external system. Each step of
    the process requires that we use more and more resources. All of this is before
    we even consider how much human time may be involved in examining the data, as
    well. It is always tempting to simply opt for the most possible insight and monitoring
    into a system, but unless we can derive true value from that process it is actually
    a negative to do so.
  prefs: []
  type: TYPE_NORMAL
- en: In general, we will use a variety of tooling on our systems to provide some
    degree of regular measurement. There are both data collection tools, like the
    sysstat SAR utility, and immediate, *on the spot* observation tools like `top`,
    `htop`, and `glances` that allow us to watch a system's behavior in real time.
    Both kinds of tools deliver a lot of value.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there are a large variety of both free and paid, software and service
    tools that can take your monitoring to another level. Researching these will be
    very beneficial as even the open-source offerings have become amazingly powerful
    and robust. Performance tooling is typically handled locally as it is rarely used
    for alerting or security considerations and using it to perform postmortem investigations
    is often fruitless so incurring the cost of central data collection for performance
    data is not commonly worth it. Centralized tools do exist and can be quite useful.
    When used, these tend to be chosen for ease of use to humans rather than to serve
    a specific technical need. Decentralized tools that can optionally leverage a
    single pane of glass style interface to display data from many locations are quite
    popular for this specific need.
  prefs: []
  type: TYPE_NORMAL
- en: Netdata
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I typically do not want to delve into specific products, but I feel that **Netdata**
    makes for an exceptional use case as a way to demonstrate the variety and power
    of available tools on the market today for Linux system administrators.
  prefs: []
  type: TYPE_NORMAL
- en: First, Netdata is free and open source. So as a system administrator who may
    have to justify any software purchases, this is one that can be downloaded and
    implemented to enhance our monitoring abilities without needing any approvals
    or notifications. Installation is also very quick, and very easy.
  prefs: []
  type: TYPE_NORMAL
- en: Second, Netdata provides crazy gorgeous dashboards right out of the box. These
    make it just more fun to do our jobs, for one thing. If we need to show data to
    management or present it in a meeting, few things are going to look more impressive
    and polished than Netdata dashboards. This is a tool that makes it easier to sell
    the business on what we do.
  prefs: []
  type: TYPE_NORMAL
- en: Third, Netdata uses surprisingly few resources. For the amazing graphical output
    that it generates you would never expect such a light utility to be able to pull
    it off.
  prefs: []
  type: TYPE_NORMAL
- en: Fourth, Netdata is decentralized. It runs locally on each server and does not
    send its data off to a central location to be collected. You can make a combined
    view of many systems, but doing so is all handled in the web browser of the viewer
    actively pulling the individual dashboards from each system directly and simply
    displaying disparate systems on one screen. There is no central server used to
    aggregate before display.
  prefs: []
  type: TYPE_NORMAL
- en: I love Netdata as an example of truly useful, free, open source, groundbreaking
    software that makes our everyday experience in system administration better. And
    it shows a pattern that is potentially useable for a great many other products
    and product types to make decentralization more viable than it may first appear.
  prefs: []
  type: TYPE_NORMAL
- en: One of the more important things that you will do as a system administrator
    is learning what tools to use, when, and how to read them. One of the most valuable
    things that I have found over the years is becoming comfortable with what a healthy
    system will look like, both historically and in real time, and being able to look
    at a variety of tools and to get an innate sense of how the system is behaving.
    There is little way to teach this other than talking about the value of observing
    systems at idle, and at standard load and observing what they look like; and of
    course, the better you understand how system components, and software works, the
    more you are able to interpret what you are seeing in a meaningful way.
  prefs: []
  type: TYPE_NORMAL
- en: With enough practice and understanding it can be possible to essentially *sense*
    the behavior of a system and gain a confidence into why a system is behaving as
    it is. This is not something that can be learned from a book and requires putting
    in a lot of time working with systems and paying close attention to what you observe
    from monitoring tools and combining that with what you observe from the system's
    performance and a solid understanding of the interaction of the physical components.
  prefs: []
  type: TYPE_NORMAL
- en: I find that momentary tools, such as top which is included in nearly all systems
    by default, presents a perfect way to stare at running systems as they perform
    their duties and become accustomed to how CPU utilization will fluctuate under
    appropriate load, how processes will shift around, and how load will vary. Some
    of the most complicated system troubleshooting will sometimes be done with little
    more than staring at changing process lists over time (and performing really well-timed
    screenshots.)
  prefs: []
  type: TYPE_NORMAL
- en: This is an area that can do quite a lot to separate junior from senior system
    administrators. It is far less about knowing the basics as much as truly internalizing
    them and being able to intuitively apply that knowledge on the fly when a system
    is behaving badly or possibly being able to do so based solely on someone describing
    the problem! How drives perform under different conditions, how the CPU is behaving
    under different loads, how caches are hit, how memory is tuned, when is paging
    good or bad, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding all of these factors is an ever-changing target. Each system is
    unique and new CPU schedulers, NUMA technologies, drive technologies, and so forth
    regularly change how systems behave and what our expectations of them should be.
    There is really no substitute for experience, and only one way to get experience.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing tooling can be hard. I tend to stay very light unless I have a workload
    with a very specific need. You should play with many different measurement tools
    to have a good feel for what is available and be ready to choose the right tool
    for you and for the task at hand whenever needed. In many cases for me, the simplest
    tools like **free**, **top**, and the **sysstat suite** are more than adequate
    for almost everything that I do, and they are available on essentially every system
    that I have encountered for over a decade. But on my own systems in my own environment,
    you will often catch me using something a bit more graphical and fun like Netdata
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Best Practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Learn measurement tooling before you need it and learn to use it quickly and
    efficiently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limit your usage of measurement tools to only that which is truly useful. Do
    not impact performance without a good reason.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have talked about how we measure what our systems are doing, it
    our next section we start using these tools to plan for the future.
  prefs: []
  type: TYPE_NORMAL
- en: Capacity planning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we take our knowledge of system resource usage away from the being in the
    moment and begin to apply it over the long-term aspects of a system, we start
    to think about capacity planning. Capacity planning should be, at least in theory,
    a rather important aspect of system administration. Many organizations will treat
    capacity planning as a non-technical exercise, however, and take it out of system
    administration hands. It is amazing how often I am told by a system administrator
    that they have received hardware that they did not specify and now have to *make
    it work* even though it was designed by someone with no knowledge of how it would
    be used! So much training and knowledge of system design in system administration
    being ignored and critical purchasing being down with no rhyme or reason.
  prefs: []
  type: TYPE_NORMAL
- en: It Is already designed when purchased
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the strangest problems that I run into with great regularity is system
    administrators asking me how they should set up hardware which they have already
    specified, ordered, and received. Most critically, they ask how they should configure
    the RAID and division of logical disks or splitting physical arrays. I am always
    amazed by this.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, different configurations of the server change how it would need to
    be configured at the hardware level. The software to be run on the server, the
    amount of software, the needed performance of that software, the amount of storage
    that will be needed, how backups will work, and nearly everything about how a
    server will be used over its anticipated lifespan is needed to be well understood
    to be able to even begin the process of specifying hardware to be purchased. How
    did they know how much RAM to buy, or how many cores, how fast the CPUs should
    be, which CPU models to start with, even which brands would work? In many cases
    people overspend and overbuy by such a degree that things work out and no one
    notices because the mistakes are made in the form of lost money that no one investigates.
    A server budget was given, no one follows up to determine if the server that was
    purchased was a good value, only if it was in budget. So overbuying is often a
    way to cover for failing to do capacity planning, and one that can be costing
    companies a significant amount of money.
  prefs: []
  type: TYPE_NORMAL
- en: Most noticeable, though, is RAID configuration. When someone asks me what RAID
    level and configuration that I would recommend for hardware that was purposely
    purchased new for this project I have no idea how to respond. Any and all decisions
    about the RAID configuration surely had to have been made before the server was
    purchased. It is only by knowing the performance, reliability, and capacity artefacts
    of not only each RAID level but of different configuration options and applying
    that knowledge in combination with available physical drive and controller options
    that you could have even approached purchasing the storage portion of the server
    in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to decide on storage needs you have to know what you need, first.
    Then you have to know how the hardware that you will specify will meet those needs.
    Some questions that come to my mind when someone says that they have hardware
    and bought it without having specified any design yet include:'
  prefs: []
  type: TYPE_NORMAL
- en: How did you know which hardware RAID card to buy? Or even that you needed a
    hardware controller at all?
  prefs: []
  type: TYPE_NORMAL
- en: How did you determine how much cache to purchase?
  prefs: []
  type: TYPE_NORMAL
- en: How did you know which types of drives would most useful?
  prefs: []
  type: TYPE_NORMAL
- en: How did you know what speed of drives you would need in throughput and/or IOPS?
  prefs: []
  type: TYPE_NORMAL
- en: How did you know what size of drives to get?
  prefs: []
  type: TYPE_NORMAL
- en: How did you know the quantity of drives to get?
  prefs: []
  type: TYPE_NORMAL
- en: How did you determine caching capacity?
  prefs: []
  type: TYPE_NORMAL
- en: How did you determine tiering capacity?
  prefs: []
  type: TYPE_NORMAL
- en: How did you determine hot spare needs?
  prefs: []
  type: TYPE_NORMAL
- en: The decisions necessary to make any of these decisions require having made all
    of the decisions as a whole. The final outcome is a product of the whole and any
    change in RAID level, for example, would drastically change the usable capacity,
    the system performance, and the overall reliability. Every small change makes
    everything else change with it. No piece can be decided upon individually, let
    alone changed. The most innocuous change could result in a system that is not
    large enough in capacity, or fast enough for the workload to function; and more
    dangerously the reliability of the storage system could swing wildly between extremely
    safe and extremely dangerous.
  prefs: []
  type: TYPE_NORMAL
- en: It is really hard to describe just how crazy this process is; and even crazier
    to realize that this might even be normal for how people buy servers! The best
    analogy that I can muster is to say that it is like buying a transmission for
    a 1978 Ferrari and expecting it to just work when you do not even know if you
    are getting a car, boat, or small plane yet, let alone what year or model of Ferrari!
  prefs: []
  type: TYPE_NORMAL
- en: Capacity planning is about far more than saving money, at least indirectly.
    It is about ensuring that systems that we purchase can meet all of the *projected*
    needs of our business for the duration of time that makes sense to do so. This
    is obviously a difficult number to really nail down as what feels appropriate
    as a projection, what are the likely changes coming in the near future, and what
    is a reasonable time frame for your systems, are all rather fungible concepts.
  prefs: []
  type: TYPE_NORMAL
- en: It is a common trend in businesses to want to project astronomic growth using
    *pie in the sky* numbers as hardware investment bases as well as using the maximum
    reasonable lifespan of the hardware to calculate over. While we cannot control
    the political processes that drive our businesses from our positions within IT,
    except in the rarest of cases, what we can control is the quality of our own numbers
    being provided to those making the decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Buy late
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Good business logic says that, with rare exceptions, the cost of everything
    in IT goes down over time. It goes down a lot. The cost of memory, compute cycles,
    or storage is fractional today compared to just a few years ago and this trend
    has really never stopped nor reversed, nor is it likely to. Momentary issues due
    to scarcity during times of manufacturing or logistical crisis can happen, but
    these are extremely rare and short lived events. Given any amount of time to make
    a purchase, the cost of systems in a few months will be better than they are today.
    Either the money that we spend is less, or the amount that we get for that money
    is greater. In either case, we benefit by investing later.
  prefs: []
  type: TYPE_NORMAL
- en: A common example that we can use is what if we bought a server today with plans
    to use it for eight years and we have expected growth, so we buy a server that
    meets our eight-year projections. To acquire a server with that much power, maybe
    we will spend $20,000 today. Or to get a server that we project will last us for
    four years, we might spend $8,000 today. A big difference. Of course, this is
    a contrived example, but in the real world, these kinds of costs are typical in
    a lot of common scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we then assume that in four years we can buy another new server
    for an additional $8000 that meets our needs for four more years. Again, contrived,
    but often true. The cost tends to work out similarly to this.
  prefs: []
  type: TYPE_NORMAL
- en: The number of advantages to buying less to last an expected shorter amount of
    time is hard to overstate. First there is often hard cost savings because of the
    nature of server pricing means that buying less, more often simply costs less
    because of the price benefits that happen within the operational lifespan of a
    modern server. And then there is the time-value of money that says that spending
    the same amount of money, but delaying spending it, means that you have more money
    to make you money in the interim and that the same money that you spend in the
    future is worth less than that money today. Then there is newer technology - if
    we wait for years to buy a new server we potentially get a lot of newer technology
    in that server that can contribute not only to capacity advantages, but also lower
    power consumption, great durability, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: Then the advantage of having two servers. We assume that the second server is
    going to replace the first, and maybe it will. But we might also use the purchase
    to simply expand capacity, the first might remain in production service. If we
    are replacing the first server, it may be redeployed in another role within the
    organization or could be used as a backup server for the new one. Almost always
    you will be able to find a highly effective use for the original investment.
  prefs: []
  type: TYPE_NORMAL
- en: Most likely the biggest advantage is in delayed decision making. By holding
    off spending much of our initial budget by several years we get the flexibility
    to invest that money at any time, or never. Instead of doing an eight-year projection,
    which is wildly inaccurate to the point of being totally useless, we do two four-year
    projections, which are still pretty inaccurate, but the degree to which they are
    more accurate is pretty crazy. At our first four-year checkpoint we get to evaluate
    how good our last projection was and make a new one based on this new data and
    new starting point. We not only get to do a fresh evaluation of our own organization
    with four more years of insight, but also four more years of insight on the industry,
    and four more years of new technology. Very few businesses would make the same
    decisions in four years that they would make today. In business, delayed decision
    making of this nature can be astronomically beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: Sadly, for most businesses, projecting becomes an emotional exercise because
    there are political benefits to making people feel good and showing faith in the
    business or its leadership; and it just makes us feel good to think about all
    of the success that we are surely going to experience. And better projections
    normally means more clout, bigger budgets, more to work with for many years to
    come. Almost no business ever goes back and evaluates past projections to see
    if people did a good job, so there are rewards for being overly optimistic and
    generally zero risk of retribution if they are falsified for personal gain (emotional,
    financial, or political.) This system makes projections very dangerous and anything
    that we can do to reduce our dependency on them is important.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the day, delaying purchasing of server resources until they are
    actually needed is one of the best practice strategies that we can have in technology
    purchasing. It is the best approach from a purely financial viewpoint, the best
    approach from a decision making and planning perspective, and the best way to
    allow technological and manufacturing advancements to work in our favor.
  prefs: []
  type: TYPE_NORMAL
- en: There are three key numbers that will come from system administration during
    this process. The first is simply answering the question of *how many resources
    are we using currently?* The second question is *how many resources did we use
    in the past?* And third, *what resources do we think that we will use in the future?*
  prefs: []
  type: TYPE_NORMAL
- en: In reality, answering any of these questions is surprisingly hard. Just counting
    up the resources that we have purchased and own today tells us nothing. We need
    to really understand how our CPUs, RAM, and different aspects of storage are being
    used and how they affect workloads.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we are running a large database instance the database might
    happily cache outrageous amounts of storage into memory to improve database performance
    or reduce storage wear and tear. But reducing available memory may not have an
    impact on database performance. Because of this, just measuring memory utilization
    can be very tricky. How much *useful* memory are we using? Storage is easier,
    but similar challenges can exist. CPU is the easiest, but nothing is ever completely
    straightforward. Just because we use system resources at a certain level does
    not tell us how well they are needed.
  prefs: []
  type: TYPE_NORMAL
- en: With CPU we might have a system that is averaging fifty percent CPU utilization.
    For one company, or set of workloads, this might mean that we can put twice as
    many workloads on this system to get its utilization close to up to one hundred
    percent. For another company, or set of workloads, it might mean that we have
    overloaded the system and there is enough context switching and wait times that
    some applications are noticing latency. It is not uncommon for companies to target
    ninety percent utilization as a loose average, but for others targeting just ten
    percent can be required.
  prefs: []
  type: TYPE_NORMAL
- en: The tradeoff, in this case, is about waiting for throughput or latency. Available
    CPU cycles means that the CPU could be doing more tasks, but if a CPU is tied
    up doing tasks all of the time then it is not necessarily available if a new task
    is suddenly presented to it. If you are working with low latency systems, having
    available system resources at the ready to process that task at the time that
    it is first presented can be a requirement. In order to assess capacity use and
    needs for systems requires us to deeply understand not just how much of the system
    is being used, but what that ultimately means for our workloads.
  prefs: []
  type: TYPE_NORMAL
- en: As with so many aspects of system administration, the key is to understand our
    workloads inside and out. We have to know how they work, how they consume resources,
    how they will respond to more or fewer resources. Everything that we do in capacity
    planning depends on this.
  prefs: []
  type: TYPE_NORMAL
- en: Of course we have tools that we mentioned previously to help us with determining
    how well a system is performing, and with application measurement tools and/or
    human user observation we can reasonably determine what kind of resources are
    necessary for where our workloads are today.
  prefs: []
  type: TYPE_NORMAL
- en: Many of these tools that we use can also be used to collect historical records
    of system performance. Chances are that if we were to do this all of the time
    that we would produce a volume of data that we will never be prepared to utilize.
    Some organizations do collect this forever, but this is the exception, not the
    rule. More practical, in most circumstances, is to develop and track baselines
    over time. This generally means doing some sort of activity where you record measurements,
    as well as recording what you can about end user application performance, of the
    system so that you can look back and see what system utilization has been. This
    data should be collected over long periods of time. Weeks or months, at least
    sometimes, to find hot spots and cold spots. Common cold spots might be Sunday
    overnight when many applications are not used at all. A common hot spot is month-end
    financial processing times. Every organization has different utilization patterns.
    You need to learn yours.
  prefs: []
  type: TYPE_NORMAL
- en: With this collected data we can then analyze to see how utilization has changed
    over time. Changes will normally come from increases, or decreases, in application
    level utilization. But this is far from the only aspect that might change. It
    is important to be cognizant that application updates, operating system patches,
    changes in system configuration and so forth should be recorded and noted against
    data recording to make the data more meaningful in evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Long term data collection has to be considered against effort. Collecting data
    and collating that data on any scale can be extremely time consuming and potentially
    resource intensive. There is the possibility that after collecting all of that
    data that it will provide no useful insight or that the skills to read it back
    will be lacking. It is not unreasonable for a system administrator to track system
    performance data mentally if working with systems that are used constantly. In
    some cases, this will be more practical.
  prefs: []
  type: TYPE_NORMAL
- en: Risk of too much data overhead
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In pursuing capacity planning we risk creating a situation where we generate
    more overhead for ourselves, which will generally equate to more cost, than if
    we had not collected the data in the first place. We have to find an appropriate
    balance.
  prefs: []
  type: TYPE_NORMAL
- en: Large organizations will tend to find large value in using lots of data collection
    to save money on a large scale. At scale automating the data collection and analysis
    is often relatively simple. Small businesses will often find this impractical.
    To collect any reasonably thorough amount of system data for a single server could
    result in expenses as large as the cost of the systems themselves. Clearly that
    is unworkable. Common sense has to prevail.
  prefs: []
  type: TYPE_NORMAL
- en: Many small organizations will have just a single primary workload and will potentially
    never fully utilize the smallest of servers and will, from a capacity perspective,
    always experience overkill until moving away from running their own hardware,
    if that ever becomes practical. Large organizations are operating farms of servers
    and have many avenues to improve overall cost from playing with different software
    options, using many smaller servers or fewer large ones, using different processor
    models or even architectures, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: The effort to save money just has to be kept in check against the potential
    value in the data collection. This is true with all decision-making processes.
    Beware that data collection is part of the total that makes up the high cost of
    decision making and you always have to remember to keep that cost far below the
    expected value level of that decision.
  prefs: []
  type: TYPE_NORMAL
- en: When evaluating the cost of the data collection, we have to consider the time
    to collect the data, the cost of storage, and the cost of analyzing that data.
    We cannot forget, we have to consider the cost of considering all of this!
  prefs: []
  type: TYPE_NORMAL
- en: There are vendors that make tools specifically for tackling these difficult
    questions and they can be very good. Dell, famously, provides tools to customers
    that can be run over long periods of time and produce very detailed reports as
    to how systems are being used and, of course, also provide *recommendations*,
    which are actually sales pitches, to sell you more products. If used properly,
    these tools can be quite valuable.
  prefs: []
  type: TYPE_NORMAL
- en: Of course the natural question will also be *but what about cloud computing,
    does that not change all of this?* And yes, considering cloud computing is important
    and plays into this process.
  prefs: []
  type: TYPE_NORMAL
- en: As cloud computing enters into an organization's planning we have even more
    complexity to consider, in some ways. In other ways, cloud computing can make
    the process of capacity planning far simpler, if not moot.
  prefs: []
  type: TYPE_NORMAL
- en: In cloud computing, or at least in nearly all of it, we buy our capacity as
    needed or very nearly as needed. This is the beauty of cloud computing. Use only
    what you need and let the system decide what it needs in real time. This is great,
    in theory. But just allowing the system to do this still leaves us with a need
    to predict what this approach will cost in order to compare financially against
    alternatives, and to predict what this will cost in order to budget properly for
    it.
  prefs: []
  type: TYPE_NORMAL
- en: If your organization is using cloud computing currently, this can make our processes
    far easier. Generally your cloud platform itself will be able to tell you an awful
    lot about system utilization rates. Even if traditional reporting is not available,
    the billing for cloud computing can often tell you as much as you may need to
    know for many types of planning.
  prefs: []
  type: TYPE_NORMAL
- en: Our capacity planning best practices are purely mathematical. Use reasonable
    measurements and understanding of our systems and workloads and our best understanding
    of business expectations and input from other teams to plan for capacity needs
    for tomorrow and into the future. Study and understand the *cone of uncertainty*
    and use that sense of increasingly unforeseeable future combined with a good understanding
    of financial concepts such as the time value of money and the increased value
    of technological purchasing over time to provide best effort evaluations of future
    capacity investment needs for your organization.
  prefs: []
  type: TYPE_NORMAL
- en: Capacity planning is often boring and more political than technical, but it
    is a role that can rarely be handled by anyone except system administration so
    it is our lot in life (professional life, at least) to be integrally involved
    in system hardware purchasing projections. It is essentially the computing futures
    market on a tiny scale inside of our own business. In our next section we move
    from capacity and performance needs and look at tools used for security and troubleshooting
    starting with system and application logging.
  prefs: []
  type: TYPE_NORMAL
- en: Log management and security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you ask system administrators in casual conversation at the bar, you might
    believe that it is a major task for system administrators to collect all of their
    system logs and to spend hours each day manually and skillfully going through
    them line by line looking for system errors and malicious actors. Reality is very
    different. No one is doing this, no one was ever doing this, and no company is
    interested in paying for people to do this. Log reading is a serious skill and
    an activity that is excessively boring. It is also a type of task at which humans
    are extremely poor.
  prefs: []
  type: TYPE_NORMAL
- en: If you were to attempt to have humans doing your log management by actually
    reading logs when there is nothing known to be wrong with a system you would run
    into a few problems. First, realistically no human can read logs fast enough to
    be truly effective. Systems log a lot of data and attempting to keep up with that
    kind of flow of truly mindless information would make humans extremely error prone.
    And then there is the cost. Anyone skilled enough to be able to handle log reading
    like that would be at the top end of the pay scale, and that job being so painful
    would have to be a premium pay position, and since typically servers run around
    the clock you would likely need four or five full time people *per server* to
    even make the attempt. Costly beyond anyone's wildest imagination and completely
    impractical to the point of useless. And hence, no one does it.
  prefs: []
  type: TYPE_NORMAL
- en: That does not mean that logs are not valuable. The opposite is true. Logs are
    very valuable and we need to collect, protect, and know how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to logs we need to know how to read them. This might seem trivial,
    but when you have an emergency and need to read your logs is not the time to find
    out that you do not understand what is being logged or how to interpret it. The
    system logs on Linux are rather consistent. The challenges really begin when different
    applications are logging as well. These logs might be independent or consolidated
    into other logs. Each application is responsible for its own logging and so we
    can face quite a potential for log variety when we start running a number of disparate
    applications. Add to this mix any logging done by bespoke in-house applications
    and things can possibly get quite complicated.
  prefs: []
  type: TYPE_NORMAL
- en: There is no need to teach log reading here. This is an activity that anyone
    reading this book should be well acquainted with. The exercise that you should
    perform now, though, is to go through your logs and determine which logs are of
    a format that is unfamiliar to you and make sure that you are ready to read through
    any of your system logs at any time without needing to do additional research
    before doing so. Fast and efficient log reading will do much to make you a better
    system administrator.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing how to read your logs is not enough. You should also be familiar with
    your logs enough to recognize what normal activity will look like. You will be
    far better at recognizing when something is wrong if you first know what it looks
    like when it is right. So many companies bring in specialists to deal with problems
    after they have arisen and in doing so, there are so many more challenges created
    because there is no *logging baseline* to use as a basis for comparison against
    what things are doing now.
  prefs: []
  type: TYPE_NORMAL
- en: Without a solid baseline, errors that occur regularly can cause a lot of wasted
    time as diagnostic time is spent researching them to determine if they are normal
    log noise, a real problem, or an actual problem that is simply a component of
    the problem being diagnosed. When things are going wrong, we want to be extra
    efficient. That is the very last time when we want to be figuring out what good
    looks like.
  prefs: []
  type: TYPE_NORMAL
- en: It is always good to be prepared to hop directly onto a server and use traditional
    tools like vi, view, cat, head, tail, and grep to look at logs. You never know
    what situation you are going to be thrown into in the future.
  prefs: []
  type: TYPE_NORMAL
- en: With many modern systems today we expect to see extensive tooling around logs
    as there is much more that we can do with our logs than simply storing them on
    our local servers and poking around at them after something bad has happened.
  prefs: []
  type: TYPE_NORMAL
- en: Today, logging is one of the areas that has seen massive changes and advancements
    in server systems. We are leaps and bounds beyond where logging typically was
    just twenty years ago. There are some very simple advancements, such as high performance,
    graphical log viewers, that can be used to make the observation of logs faster
    and easier. There is advanced central logging to move logs away from the servers
    themselves and there is automated log processing.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of if logging is local or remote, modern log viewers have made a
    tremendous difference in how efficiently we can use our logs. Whether using local
    desktop GUIs, character-based sessions on the terminal, or a modern web interface,
    log viewing tools have been improving and for the last decade or more have made
    the act of reading logs pleasant and easy. Amazingly, very few organizations provide
    these kinds of tools or accommodate their usage and so it is far less common than
    it should be to find system administrators using them. If you talk to system administrators
    do not be surprised to find out that very few have actually had the pleasure of
    working in an environment with logging tools beyond the basic, included system
    log text files and the standard text file manipulation tools that are included
    in the operating system.
  prefs: []
  type: TYPE_NORMAL
- en: Good log viewers are an important starting point in a log management journey.
    Make logs accessible to view quickly and make their viewing a pleasurable and
    as simple as possible experience. When things are going wrong you do not want
    to be spending any more time than is absolutely necessary getting to your logs
    or to digging through them. You certainly do not want to be working to install
    a log viewing tool at a time when something is already broken.
  prefs: []
  type: TYPE_NORMAL
- en: Log viewing applications are only a starting point, we hope, for most organizations.
    The real leap in log management happens when we introduce central log collection.
    This is really where the logging revolution has taken place. Of course, even going
    back decades, the potential and tools for basic log aggregation existed. This
    can be as simple as using network copy commands or network mapped drives to store
    the same old text files on a central file server. So the fundamental idea of central
    logging is not new.
  prefs: []
  type: TYPE_NORMAL
- en: Originally the central logging constraint was that servers were not networked.
    Later it was performance and storage issues. Centralizing logs used a lot of network
    bandwidth and required a lot of storage capacity and, in some cases, was a performance
    nightmare for the log server as well. Those days are long since in the past. Today
    all of those things are trivialized simply by the natural leaps in capacity and
    performance of all aspects of our systems with far smaller growth in log size
    and complexity. Logs today are not all that much larger than they were decades
    ago.
  prefs: []
  type: TYPE_NORMAL
- en: Early log centralization systems were very basic and unable to scale gracefully.
    Large amounts of aggregated log data presents big challenges for most systems
    as they need to be able to continue to ingest large amounts of real time data
    from many sources while simultaneously being able to recall and display that data.
  prefs: []
  type: TYPE_NORMAL
- en: Modern central logging applications all use new, modern databases designed around
    this time of data flow and storage. No one single type of database is used for
    this, but many newer databases excel at handling these needs allowing data traditionally
    stored as large, unwieldy text files to be reduced to much smaller and more efficient
    database items with metadata, caching, collation, and other features that allow
    for the ingestion of massively larger amounts of data than ever before while being
    able to continue to display data effectively. This change, along with the general
    improvements in system power, has made for effective centralized logging not only
    on the LAN, but in many cases, even for and to servers running hosted, in the
    cloud, or otherwise not sitting on a traditional LAN.
  prefs: []
  type: TYPE_NORMAL
- en: By using this kind of system we have a few benefits. One is speed and efficiency
    in log reading. One (or at least fewer) places to go to read logs means that system
    administrators are looking at logs much faster than before and faster log reading
    means faster solutions. By having logs from many servers, systems, applications,
    and more all in a single place also means that we can correlate data between these
    systems without requiring humans to look at logs from multiple sources and make
    these connections manually.
  prefs: []
  type: TYPE_NORMAL
- en: New tools, like volume graphs, also allow us to see patterns that we may have
    been unable to detect before. If multiple computers suddenly show a spike in log
    traffic maybe applications have suddenly become busy, or maybe there is a failure
    or attack underway. Centralized logging tools make it easier not only for us to
    understand what a baseline looks like for a single system, but what a baseline
    will look like for all of our systems combined! More layers of system understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have these modern tools centralized the next logical step is using automation
    to read logs for us. **Security Information and Event Management** (**SIEM**)
    is the term generally applied for automatic log monitoring tools. Automation for
    logs is not new and even the United States government was putting rules in place
    for it by 2005\. But for many businesses, log automation is far beyond their current
    plans or capacity.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, like any automation, the degree to which we use it can vary greatly.
    Light automation might simply send alerts in case of certain triggering events
    occurring in the logs or alerting on uncharacteristic activity patterns. Complex
    automation might use artificial intelligence or threat pattern databases to scour
    logs across many systems at once to look for malicious activity.
  prefs: []
  type: TYPE_NORMAL
- en: Why central logging?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given that centralized logging carries so much network overhead and because
    it tends to be so costly to implement, it is easy to question the value to centralizing
    logging to a single server, or group of servers, rather than simply leaving logs
    on individual hosts and finding better methods of examining logs from them. This
    is a very valid question. Of course, central logging is not going to be right
    for every organization. It is right for a large number of them, though.
  prefs: []
  type: TYPE_NORMAL
- en: While many advancements have been made to make central logging more capable
    than ever before, there have also been many advancements in making decentralized
    logging better as well including on-device log viewers with reporting, alerting,
    and attractive user interfaces and aggregation tools that display the data from
    multiple sources in a single dashboard even though the data itself is disparately
    located.
  prefs: []
  type: TYPE_NORMAL
- en: Central logging offers unique advantages, though. The biggest advantage is simply
    that the data is not tied to the device. If a device dies, goes offline, or that
    device is compromised we have isolation for our logs. It is not uncommon to be
    stuck trying to get a server back online and running just so that we can look
    at the logs from that server.
  prefs: []
  type: TYPE_NORMAL
- en: If the server dies completely we may never want to bother bringing it back online.
    Or if the logs tells us that there is a catastrophic failure we might know from
    that, that we do not want to attempt to recover a failed device. Or perhaps we
    want one person to be working on getting a failed server back up and running simultaneously
    while another scours logs to determine what led up to the failure or possibly
    determine what is needed to restore services.
  prefs: []
  type: TYPE_NORMAL
- en: If a server or application is compromised there is a risk that the logging mechanisms
    or storage systems will be compromised along with it. In fact this is generally
    quite likely. Modifying logs to cover up a compromise is very common with sophisticated
    attacks and simply deleting logs common in simpler ones. In most cases logs are
    attacked because they are the most likely place to easily identify that a compromise
    has happened or is happening and what to do to mitigate it. If the logs never
    show any signs of an attack, you may easily never discover that one has happened.
  prefs: []
  type: TYPE_NORMAL
- en: If we instead send our logs, either in their entirety or at least a copy, directly
    to a remote logging server in real time then we have the logs stored separately
    from both the application and the server storage with an air gap so that, in order
    to modify those logs, a completely unrelated system has to also be compromised,
    without being detected. This is orders of magnitude more difficult to do, especially
    as the existence of and information about any external logging system will generally
    not be known until a compromise is already under way at which point it may already
    be too late to avoid detection.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the fact that logging is far more than just a way to look for bugs
    and primarily the key security recording system for auditing and tracking breaches,
    malicious activity, infiltration attempts, and others. it is critical that this
    data be kept safe from both accidental loss and intentional destruction.
  prefs: []
  type: TYPE_NORMAL
- en: Possibly the most important purpose of log separation, at least in larger organizations
    big enough to have multiple IT teams, is the separation of duties. If the logs
    are completely controlled by the same system administrator (presumably you) that
    controls the server then it is trivial to make major modifications and hide the
    evidence of those changes. If the logs are sent to an external system to which
    we are not the administrator then it is much harder for us to hide those changes
    as we must prevent them from being logged in the first place while not causing
    the logging itself to fail.
  prefs: []
  type: TYPE_NORMAL
- en: Having a strict separation of duties for this level of security may sound like
    something limited to large organizations, but even quite small companies, even
    those not large enough to have a single fill time system administrator, can take
    advantage of this aspect of a system like this by using an externally hosted logging
    platform rather than running their own. In this way all of the necessary system
    administration and security for the logging platform is encapsulated not only
    away from the individual system administrator but also away from the IT team and
    the entire corpus of the company itself!
  prefs: []
  type: TYPE_NORMAL
- en: Because every business is different, there is a place for different levels of
    logging and log management depending on your needs. Our constant IT mantra has
    to be that one size does not fit all.
  prefs: []
  type: TYPE_NORMAL
- en: So our best practice with logging is a difficult one. We need to evaluate logging
    needs. How can we use our logs efficiently to troubleshoot faster and better.
    How can we increase our security. Do we have factors that make local log storage
    outweigh the benefits of remote? Should we host our own log systems or use a third-party
    SaaS application that is managed for us? Will the security benefits of a SIEM
    or similar solution justify their cost and complexity?
  prefs: []
  type: TYPE_NORMAL
- en: Our only true best practices are to ensure that you are prepared to read logs
    before you need to, and to look at logs from time to time to understand what a
    healthy system looks like for you.
  prefs: []
  type: TYPE_NORMAL
- en: With logging we are forced to really look much more heavily at rules of thumb
    rather than best practices. In general, central log collection is a worthwhile
    endeavor for almost any environment with more than a single critical workload.
    This can mean a single company that has multiple workloads, or smaller firms should
    generally be using some form of external support vendor and that vendor would,
    in theory, have multiple customers and would generally benefit from a similar
    approach allowing them to centralize logs on behalf of their customers.
  prefs: []
  type: TYPE_NORMAL
- en: The smallest IT department
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a topic beyond the scope of the role of system administration, but one
    that everyone in IT should really understand because nearly every IT role will,
    at some point, be put in a position of being part of an organization that is simply,
    too small.
  prefs: []
  type: TYPE_NORMAL
- en: In most fields we can talk about a minimum size to any professional team. Doctors,
    lawyers, auto mechanics, veterinarians, software engineering, you name it. In
    all these examples we can talk about the staff and team necessary to make a position
    make sense. A doctor working with no nurses or assistants of any kind is going
    to be really inefficient and lack some vectors for healthcare training. Same with
    a veterinarian, if you are a lone vet and have no receptionist, cashier, vet tech,
    and so on, then you are forced to do roles at a fraction of your value. In software
    engineering it is more about the wide range of discrete tasks and roles that go
    into software design that cannot reasonably be done by a single person, even on
    a small project.
  prefs: []
  type: TYPE_NORMAL
- en: IT is one of the more dramatic fields for this because IT is so broad and covers
    so many totally different knowledge areas. And every company has the need for
    a large scope of that IT skill set. Some skills are unique to certain types of
    environments, but the large base of foundational skills apply to essentially any
    and every company.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most challenging aspects of this is that there is little room for
    underdeveloped skills. Because IT is the decision making and guidance around core
    business functions, infrastructure, support, efficiency, and security there is
    really no time that you do not want expert and mature guidance. A seemingly simple
    mistake, made nearly anywhere in the entire infrastructure, carries the risk of
    being a point of breach, an over expense, a decision that starts small but leads
    to a domino line of other decisions that will all be based on that one.
  prefs: []
  type: TYPE_NORMAL
- en: Most businesses do not need most, if indeed any, individual skill more than
    part time with some skills, like that of CIO, being needed potentially for just
    a few hours per year. Obviously if skills are not needed more than a few hours
    per year, or even if only a few per day, paying for the skill full time would
    not make sense.
  prefs: []
  type: TYPE_NORMAL
- en: Then there is the issue of coverage. Many businesses need to only have coverage
    for forty hours per week with strict office hours and all systems capable of being
    taken offline when the office is close. This is, however, not at all normal. Most
    businesses need to operate six or seven days per week, and long hours per day
    and running twenty four by seven is totally reasonable. To have full coverage
    just for someone to answer support tickets, let alone make decisions or solve
    real problems, would require at least five people just to have shift coverage,
    ignoring any skills needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you consider all of the discrete roles that exist in even the most minimal
    IT environment: systems, networking, CIO, helpdesk, desktop support, end user
    support, application support and then any specialty roles like cloud applications,
    backup, disaster recovery, project management, and on and on. What many companies
    attempt to do is to find a single person who can fill all of these roles, a generalist.
    This is a great theory, there is one person with tons of skills who can do a little
    bit of each one adding up to one whole person.'
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, this does not work, at all. First because the number of people
    who truly possess all those skills, keep them up to date, and are so good at all
    of them in the universe can probably be counted on one hand. Second, anyone with
    good CIO level skills or system administration skills has a huge per hour billable
    value from those skills alone. A worker is always worth the value of their maximum
    skill full time, not their minimum skill. And having additional skills raises
    your maximum. So a CIO with all these other skills would be, in theory, worth
    even more than if they only had the CIO skill. So even if you found such a person,
    either you would have to pay them an absorbent amount of money to do the job,
    or they would have to be willing to do the job for a tiny fraction of their value
    which from an employment standpoint makes no sense.
  prefs: []
  type: TYPE_NORMAL
- en: Second because of coverage. A single person can only work so many hours leaving
    a business without support most of the time. And even if you have a business that
    only exists eight hours a day and is happy to do all support and even proactive
    maintenance during that time you still have the issue that generally many of the
    roles that one person is called on to perform will need to happen simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Amazingly, tons of companies of all sizes attempt this approach and universally
    end up with bad results, although many never measure their results or even understand
    what good performance from an IT department should look like or even what that
    department should be accomplishing so often ignore or even praise the failures
    in this area.
  prefs: []
  type: TYPE_NORMAL
- en: Finding a theoretically useful lower limit to the size of an IT department is
    hard. As a rule of thumb, if you do not need at a minimum three full time IT staff
    who never do anything outside of IT, then you should not try to staff an IT department.
  prefs: []
  type: TYPE_NORMAL
- en: Entire ranges of IT businesses like Management Service Providers and IT Service
    Providers provide IT skills, management, oversight, and tooling in small portions
    for businesses who only need a little of many different resources. Smaller companies
    should never feel badly turning to these kinds of companies, they are necessary
    to provide the level of scale and division of that scale necessary to do IT well.
    That said, just like employees, the average firm is not going to be very good.
    So just as you want to make sure that you are hiring employees who are good, you
    want to hire a service provider who is good. Service providers are very much like
    employees, but employees that are more likely aligned with your business needs
    and generally with far more potential longevity - a good service provider relationship
    could easily outlast the career length of an individual employee.
  prefs: []
  type: TYPE_NORMAL
- en: Rethinking inappropriate IT departments from both sides can be a boost to the
    industry. So many employers are unhappy with IT results that are predictably bad
    based on the IT structures that they enforce. And so many IT practitioners are
    unhappy with their careers or at least their immediate jobs, because they feel
    that they have to, or are encouraged to, work in environments that simply do not
    make any sense.
  prefs: []
  type: TYPE_NORMAL
- en: Considering service providers as part of the in house IT team can make it possible
    to get the IT team that you need, at a price that is actually plausible. IT is
    not really outside of the budget of any company. If it seems like IT is going
    to be too expensive, something is wrong. The job of IT is to make the business
    money.
  prefs: []
  type: TYPE_NORMAL
- en: The most common mistakes that I see when companies engage service providers
    is either assuming many incorrect rules of engagement such as assuming that local
    resources are better or that the service provider has to match the technology
    that you plan to use - if you were doing this, how would you ever determine the
    service provider to hire as only they would have the expertise to determine the
    technology to be used! A Catch-22 for sure. And the other key mistake is confusing
    service providers (companies that provide IT services) with value added resellers
    (vendor sales representatives). The latter will often market themselves as the
    former, but it is easy to tell them apart. The first one's business is to provide
    IT as a service. The second one's business includes selling hardware, software,
    and third party services, potentially in addition to layering on some IT.
  prefs: []
  type: TYPE_NORMAL
- en: 'Best practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Avoid running IT departments that are too small to support the necessary roles
    and division of labour.
  prefs: []
  type: TYPE_NORMAL
- en: Never hire a reseller to do the job of an IT service provider.
  prefs: []
  type: TYPE_NORMAL
- en: Never allow your IT staff (internal or external) to have a conflict of interest
    and also sell the hardware, software, and services that it is their job to recommend
    and choose.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have a good idea as to why logging is so critical to our organization.
    Good use of and understanding of logs and putting in place a proper, well thought
    out infrastructure for logs is one of the areas in which we truly see a separation
    between struggling and truly excelling IT departments.
  prefs: []
  type: TYPE_NORMAL
- en: Not a heavily technical discussion at this point. It is really all about sitting
    down and putting in the effort to develop and roll out a logging plan. Making
    logging happen for your organization. Centralized, decentralized, automated, whatever
    works for you. Getting started with something, turn your logs into a robust tool
    that makes your life easier.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section we will continue on from logging to look at more general
    monitoring. Two highly related concepts that together really take our administration
    to another level.
  prefs: []
  type: TYPE_NORMAL
- en: Alerts and troubleshooting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having just discussed logs we now have to consider the highly related concept
    of system alerting. I have to mention that of course logging systems themselves
    are also a potential source of alerts. If we use automation in our logging systems,
    that automation will generally be expected to either send alerts directly, or
    add alerts to an alerting system.
  prefs: []
  type: TYPE_NORMAL
- en: Alerts are, fundamentally, a way for our monitoring systems to reach out and
    tell us humans that they are in trouble and it is time for us to step in and work
    our human-intelligence magic. While we hope that our systems will have automation
    and can repair many problems themselves, the reality is that for the foreseeable
    future nearly all companies will have to keep working in a reality where human
    intervention is needed on a regular basis in systems administration. Whether it
    is to log in and clear a full disk or stop a broken process or identify a corrupt
    file or even to trigger a failover to a different application or notify the business
    of expected impact humans have a large role to play in systems still.
  prefs: []
  type: TYPE_NORMAL
- en: Having good mechanisms for discovering serious issues and alerting humans is
    critical to quality support. In order to understand good alerting, we have to
    talk about both how we discover that something is wrong, and how we are notified
    of it.
  prefs: []
  type: TYPE_NORMAL
- en: On-device and centralized alerting systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can start by looking at on device and centralized alerts. Traditionally,
    going back more than a few years, it was common for systems to handle their own
    alerts individually. Systems were already set to log issues into a central log,
    it was a natural extension to have them also send out emails or similar notifications
    should something bad be detected. Alerting was very simple, and each system would
    handle its own detection and its own alerting individually. While centralized
    monitoring and alerting has long existed, the popularity of external monitoring
    really did not become highly mainstreamed until it was necessary to monitor hosted
    Internet resources, such as websites, where an outage would often be seen by customers
    first, rather than by employees. When outages are first noticed by internal staff,
    the decision to delay discovery can be more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: The simplicity of on-device alerting is enticing, and for smaller organizations
    or those that can risk slower error detection it can serve well. The key issues
    with on-device alerting are that many types of serious outages or attacks may
    disable alerting completely, or at least delay it. A simple example is the server
    that loses power or whose CPU melts, the system going offline is what we want
    to receive an alert about, but the system going offline suddenly precludes the
    possibility of the system telling anyone that something bad has happened. The
    same happens when there is a sudden loss of network connectivity. In the event
    of a system compromise, a hacker may take alerting capabilities offline before
    being detected leaving a system running, but unable to call out for help.
  prefs: []
  type: TYPE_NORMAL
- en: On-device alerting is generally inexpensive and simple. It is often built in
    and only needs a small amount of configuration. If using simple mechanisms such
    as email to send alerts, even simple scripts can add a lot of alerting functionality.
    This approach uses very few system resources and for small businesses or those
    that simply do not have to worry about potential downtime without employees reporting
    a loss of functionality, it can be adequate.
  prefs: []
  type: TYPE_NORMAL
- en: For the majority of businesses or workloads, the caveats of on-device alerting
    are too great. Whether a system is customer facing and you want to maximize customer
    confidence, or a system is internal and you want to move discovery of issues from
    employees to IT to improve performance, or a system has few, if any, end users
    that may every discover that it is not working and you want to make sure that
    work is continuing to be done (such as with a scanning security system or filter)
    then external monitoring is necessary.
  prefs: []
  type: TYPE_NORMAL
- en: External monitoring allows us to disseminate alerts even when the system in
    question has completely failed. Because total failure is quite common in alerting
    events, this can be pretty important. Complete failure might mean that hardware
    has failed, power has been lost, software has crashed, or networking has been
    lost, as examples. These are all common failure cases, and all either certainly
    or likely will cause on-device alerting to fail. External alerts give us a level
    of confidence that we will be alerted when something fails that is otherwise lacking.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, external systems can fail as well, leading to a lack of alerts, but
    there are ways that we can effectively hedge against this. One option, of course,
    is external alerting on the external alerting system. Essentially backup alerting.
    And of course, by having only a single alert source, it is easy for us to simply
    check that source as humans to verify that it is working. An external alert mechanism,
    if decoupled from the systems that it monitors, is extremely unlikely to fail
    at the same time that another system fails and while not perfect, this will easily
    eliminate 99.99% or more of missed alerts which, for most organizations, is plenty.
  prefs: []
  type: TYPE_NORMAL
- en: Out of band on-device alerts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There can be a little bit of a middle ground in alert management. If we think
    of our systems as a stack, each device lower in the stack is able to monitor,
    in a very minor way, the services running above it. For example, an application
    can tell us if a database connection is working, the operating system can tell
    us if an application is still running, a hypervisor can tell us if the operating
    system is still running, and, at the bottom of the stack, an out of band management
    hardware device can tell us if the core system components have failed.
  prefs: []
  type: TYPE_NORMAL
- en: This system is not foolproof and tends to be quite basic. An operating system
    knows very little about the workings of an application process and mostly can
    only tell us if the application has crashed completely causing an error code be
    returned to the operating system, or it can tell us if the application is using
    an inordinate amount of resources such as suddenly spiking in memory requests
    or using a large number of CPU cycles, but the operating system will have little
    idea if the application keeps running but is throwing errors or gibberish to end
    users.
  prefs: []
  type: TYPE_NORMAL
- en: For those unfamiliar, out of band management is actually an external *computer*
    that is housed inside of the chassis with the server hardware but has its own
    tiny CPU, RAM, and networking. Because it is a nearly completely separate computer
    from the server itself, the OOB (out of band) management system can report, either
    directly or to some monitoring system, if there are critical hardware failures
    on the server itself such as a failed motherboard, CPU, memory, storage, or other
    component that would normally make the server itself unable to send out its own
    alerts.
  prefs: []
  type: TYPE_NORMAL
- en: An OOB management system does share the chassis, location, and power with the
    server, though. This means that it still has limited ability to monitor a system
    for certain types of common failures. As with many things, for many businesses
    this might be adequate, for others it will not be enough.
  prefs: []
  type: TYPE_NORMAL
- en: Pushed and pulled alerts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Alerting systems also have two basic ways of interacting with us, as the actors
    being alerted by the system. What we tend to think of is pushed alerts. That is,
    alerts that are sent to us with the intention of grabbing our attention when we
    are not thinking about alerts.
  prefs: []
  type: TYPE_NORMAL
- en: Typically pushed alerts go out via email, text messages (SMS), telephone calls,
    WhatsApp, Telegram, Signal, RocketChat, Slack, Microsoft Teams, Zoho Cliq, MatterMost,
    or other, similar, real-time communications channel. Some alerting systems have
    their own applications that you install to desktops or smartphones so that they
    can push out alerts rapidly and reliably without having to integrate or depend
    on any additional infrastructure. You can easily imagine an organization running
    their own email and messaging platforms only to have those platforms be monitored
    by our alert system and also be the path by which we receive the alerts. Even
    if the alerting system itself does not fail, it is possible that it will be unable
    to tell us that something has failed because the systems that it monitors are
    also the systems that get the alerts to us. This is why having one fewer path
    to fail and one fewer dependency in alert delivery is sometimes approached.
  prefs: []
  type: TYPE_NORMAL
- en: Alerting is a surprisingly complex animal. If alerting was being handled by
    humans, rather than computers, we would quickly find that call centers have complex,
    multi-branch decision trees to follow for what to do when we cannot tell someone
    that something is wrong. With humans, though, we know that in an extreme emergency
    someone will start pulling out their personal cell phone and texting someone to
    call someone and knock on a door and wake someone up or whatever. Computers can
    do all of this, too, but they need access to those tools, algorithms to make those
    decisions, and knowledge of how to reach people. Easier said that done.
  prefs: []
  type: TYPE_NORMAL
- en: To solve this particular problem, many companies opt to include humans in the
    communications path. An expensive, but effective, tool. Sometimes human decision
    making, and flexibility wins out. Human call centers that are always staffed and
    receive alerts on behalf of technical teams and managers and then manage the contact
    path to whomever needs to receive the alert can be a great option. And, obviously,
    hybrid options where computer systems alert end recipients directly but humans
    are always involved in verifying that alerts go out, acknowledgements are received,
    or whatever is possible.
  prefs: []
  type: TYPE_NORMAL
- en: The alternative to pushed alerts is pulled alerts. Pulled alerting refers to
    systems that display the status of any open or logged alerts when the end user
    logs in to look at them. These systems are vastly more reliable because the end
    user is looking at the system and knows if there is an inability to view the alert
    status or not. If the system has failed, then they can start working on the issue
    right away. If it has not failed, they see the alerts and know if action is needed
    or not.
  prefs: []
  type: TYPE_NORMAL
- en: Silence as success
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The basic problem that arises with using purely pushed alerts is that we rely
    on silence to tell us that everything is okay. Rather than getting a confirmation
    that everything has been checked and that nothing is currently wrong, we depend
    on not having been reached to create an assumption of nothing being wrong. This
    is a dangerous approach.
  prefs: []
  type: TYPE_NORMAL
- en: We all know the feeling of waking up or having been on a long car ride or maybe
    being at a party and not actively watching our phones and mostly feeling good
    that the office has not reached out to us, no one has called, so everything must
    be fine. Then you look at your phone some hours later and realize that the battery
    has died, there was no service, or you had your phone on silence. Panic sets in.
    You plug in your phone, get service back, and turn on the ringer and find that
    you have been missing call after call, voicemail after voicemail, text after text
    telling you that there is a huge emergency, you left the office having changed
    a critical password and not telling anyone, the system is down, no one can get
    in except for you and you are not responding!
  prefs: []
  type: TYPE_NORMAL
- en: Trusting that no one was able to get my attention, therefore nothing can be
    wrong just does not work. But neither does staring at a console and never being
    offline. There has to be a balance. It is clear that simply hoping that you will
    be able to be reached is a recipe for disaster. Maybe a disaster that takes many,
    many years to finally happen, but a disaster that is almost certainly going to
    happen eventually. There are just too many variables that can go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Pull monitoring and alert systems are therefore important as a means of verifying
    that pushed alerts are working currently or to work around known disconnects.
    Or to run an active monitoring site.
  prefs: []
  type: TYPE_NORMAL
- en: Alerting's systems, too, struggle with defining a successful alert. Many mechanisms
    like email and SMS texting will confirm only that a message has been sent or possibly
    received by the recipient's infrastructure vendor, but they do not give any indication
    that the message has made it all of the way to the end user's device, or that
    the end user has been displayed the message. Even if a message does go end to
    end, does it get filtered into a spam folder and hidden? Unless we have a human
    actually acknowledge an alert there is very little, we can do to have confidence
    that an alert has truly been seen.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pulled alert systems, generally displayed as dashboards, are typically what
    we picture as a red light, green light system. It is common to display monitored
    systems or components graphically and to show systems believed to be healthy shown
    as green, those experiencing problems, but not yet indicating an outage as yellow,
    and those that have failed whatever sensor test we are performing as red. This
    does not just give the humans the ability to quickly eyeball the range of alerts,
    but also makes it trivial for the system to roll up large groups of alerts into
    single displays. As long as those are green, you know everything in the group
    is healthy. If it is red, you can dig in to see exactly what is wrong. At the
    highest level you can, in theory, even have a single big indicator that shows
    as green or red. Green if systems are one hundred percent good and red if any
    system has failed. Simply: is action needed or is it not. If you can be green
    most of the time, this might be exactly what you need to combine reliable monitoring
    with low overhead in verification.'
  prefs: []
  type: TYPE_NORMAL
- en: Most alert systems will offer both a dashboard to show pulled alerts along with
    push notifications to improve response times and reach people who are not actively
    checking alerts. Pulled alert systems are often used at the core of a call center
    where humans on shifts watch the pulled alerts around the clock and either enact
    the push alerts to the concerned parties or follow up to ensure delivery of automated
    alerts. It is less common for organizations to open pulled alerts to many staff
    which can be a mistake as it can lower stress and increase alert reliability.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the interaction between the monitoring system and the end points
    that are being monitored can work in either direction or both. The monitoring
    system may have remote access to the end points and actively reach out to them
    to request their status. Or an agent running on the end points may reach out to
    the monitoring server to push their status over to it.
  prefs: []
  type: TYPE_NORMAL
- en: In house and hosted monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monitoring and alerting are, in some ways, two separate pieces and there is
    software and services that do either, and those that do both. The monitoring component
    determines if a series of sensors detects something that is wrong in our workloads.
    The alerting component takes the results of the monitoring and attempts to notify
    the correct parties. It used to be that the two components were always merged
    into single products, but in more recent years with more and more types of systems
    needing to be monitored (more than IT systems, that is) and as alerting needs
    have increased and have needed to become more robust, different vendors have started
    to build each independently in some cases.
  prefs: []
  type: TYPE_NORMAL
- en: Today monitoring solutions come in a good variety of packages and styles. You
    easily may decide that you would benefit from using more than one. Choosing a
    good package might be the hardest part of your monitoring puzzle. Monitoring software
    is available commercial and free, closed and open source, and built to run on
    nearly any platform.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring is a function that you will generally want to host externally to
    your primary infrastructure as you want it be less quick and reliable, and more
    totally independent of your other systems compared to other workloads. You can
    host it yourself on your own equipment, go with third party cloud or VPS hosted
    infrastructure, or get a SaaS application from a provider. You can tackle this
    in any manner than makes sense for your organization. But rarely do you want your
    monitoring solution to sit on the same hardware, let alone the same datacenter,
    as your other workloads or you risk losing monitoring when you lose everything
    else.
  prefs: []
  type: TYPE_NORMAL
- en: Whether to run and maintain your own monitoring or to go with a hosted product
    will mostly be a question of cost and politics within your organization. Even
    free and open-source monitoring solutions can be robust enough for the most demanding
    of organizations. You will need to determine if the cost of building, maintaining,
    and *monitoring* a monitoring solution makes sense for your organization or if
    simply buying that functionality ready to go makes sense for you. In most cases
    this is determined by scale. If you monitor a very large number of workloads or
    your monitoring needs are highly unique you may benefit from building the expertise
    in house and having full time specialists dedicated to this project. Generally
    for a project like this to be cost effective to keep in house you will want to
    have either fully dedicated staff or heavily dedicated staff who have the time
    and resources to really learn the products and maintain them properly. Often monitoring
    and logging will be bundled together whether as a single product or under a single
    person or team as they overlap so heavily, and logging can be thought of as a
    specialty function of monitoring. The two may be operated separately or combined.
    Using both through the same alerting channels generally makes sense as they can
    leverage the same effort and infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Like most things in this chapter, the real struggle around best practices is
    finding what we can distill as being *best* as guidance here is very broad and
    mostly ambiguous. There is no one size fits all. It seems like cheating to say,
    but it is true that the real best practice here is to evaluate your business'
    needs based on cost, functionality, support, separation from your production environment
    and determine what monitoring and alerting mechanisms are right for you.
  prefs: []
  type: TYPE_NORMAL
- en: RMMs and monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you work in internal IT then the term RMM might be something that you have
    never heard of, but if you have worked in the service provider sector then RMMs
    are the core tools expected to be used for customer support in that area.
  prefs: []
  type: TYPE_NORMAL
- en: An RMM, which stands for Remote Monitoring and Management, is a tool category
    designed around the needs of service providers who almost always need to work
    remotely to their client sites and to be able to quickly monitor many disparate
    client systems at one time. This is generally quite different from internal IT
    needs where often they are not remote and even when they are, their systems are
    typically integrated.
  prefs: []
  type: TYPE_NORMAL
- en: A rare few non-service providers still lean on RMM tools as a monitoring mechanism.
    Typically RMMs are very light and inflexible but are, at their core, monitoring
    systems much like what we are discussing here. So you can certainly consider using
    an RMM that you purchase or run yourself, or if you have a service provider, this
    might be part of the service that you are already paying for. RMMs are even available
    as free, open-source products. So no company, of any size can say that they do
    not have the resources to at least do the most basic levels of monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, traditional monitoring tools designed for internal IT teams are
    so robust that they actually displace RMMs in service providers. Or the two could
    be used in tandem, as well.
  prefs: []
  type: TYPE_NORMAL
- en: The rule of thumb is that more monitoring is better than less, hosting outside
    of your environment is generally best, make sure that alerts have many channels
    to find a way to get to a human, make sure that pull monitoring is available to
    at least verify that push is working, and consider having your monitoring system
    create actionable tickets for your support team automatically to track follow
    ups.
  prefs: []
  type: TYPE_NORMAL
- en: 'Is there an actual best practice? Yes. The best practice here is simple and
    broad: if a workload has a purpose, then it should be monitored. Monitoring, because
    it does not directly stop production from running if it does not exist, can too
    easily be overlooked. Almost no one gets promoted for doing good monitoring or
    fired for lacking it, but implementing proper monitoring is effective in separating
    the good administrators from the run of the mill.'
  prefs: []
  type: TYPE_NORMAL
- en: Go set up some monitoring!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we have looked at the range of key non-systems components that
    surround the systems themselves. Documentation, system measurement, data collection
    and planning, log collection and management, and finally monitoring sensors and
    alerting based on them. These could almost be considered soft skills within the
    systems administration realm.
  prefs: []
  type: TYPE_NORMAL
- en: Consistently in environments that I have taken over we have found documentation
    to be practical non-existent, measuring systems to be all but unheard of, capacity
    planning being a process no one has ever so much as discussed, monitoring often
    minimal and unreliable at best, and log collection while well understood, simply
    a pipe dream when it comes to real world implementation. Yet a single system administrator
    with almost no resources could, with just some time, pull together some free,
    open-source software and tackle each of these projects on their own with little
    to no budgetary constraints and could often hide the workloads somewhere within
    the system if it was necessary to do so.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter has not been about how to make your systems run better; it has
    been about everything else. How do we know that they have been running better?
    How do we know that they are running right now? How do we know that we can pass
    the proverbial baton on to someone else should we win the lottery? How do we confidently
    say that we are doing what needs to be done to make a best effort against a malicious
    attack? The topics in this chapter have made us look at how to be better at all
    of the things that we do and not just the ones that are most visible.
  prefs: []
  type: TYPE_NORMAL
- en: Up your visibility
  prefs: []
  type: TYPE_NORMAL
- en: Too often what we do in IT is completely invisible to those on other teams,
    even those in management to whom we report. Maybe it is invisible because there
    is simply nothing to show. Or maybe what we do is too hard and complex for people
    outside of our realm to really understand. Or maybe we are invisible because we
    choose to accept being invisible.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the topics in this section provide perfect opportunities to step out
    of the IT dungeon or closet and get in management's face(s) to do a little IT
    team self-promotion. From monitoring dashboard to beautiful documentation, to
    capacity charts, to log drill down examples there is almost always something that
    we can print out or show on a big screen and look pretty impressive for having
    implemented.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the attention of management and showing that we are being proactive,
    that we are following best practices, this is where we can make a sales pitch
    for just how amazing our value is to the organization. Do not be afraid to do
    some self-promotion, you deserve it. Make some noise and show off how you are
    preparing the business for the greatest success.
  prefs: []
  type: TYPE_NORMAL
- en: Go out and make sure that all of these systems mentioned in this chapter are
    implemented in your environment. Keep it simple to get started, but do not skip
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: In our next chapter we are going to move on to scripting and system automation
    including DevOps, which I know that you have been waiting for.
  prefs: []
  type: TYPE_NORMAL
