<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer184">
			<h1 id="_idParaDest-135"><em class="italic"><a id="_idTextAnchor138"/>Chapter 6</em>: Shell-Based Software Management</h1>
			<p>Copying content over a network is usually done as a manual process – for example, we just use <strong class="source-inline">scp</strong> or <strong class="source-inline">FTP</strong> to transfer a file and that's that. But what happens if we need to make this process a permanent one? We then need to figure out a way to perform file/directory synchronization, which is what <strong class="source-inline">rsync</strong> is all about. That being said, with all of the security-related incidents in the past 5+ years, it's always a good idea to implement some kind of encryption, so using <strong class="source-inline">ssh</strong> and <strong class="source-inline">scp</strong> seems like a reasonable approach. And that's exactly what we are going to do.</p>
			<p>In this chapter, we are going to learn about the following topics:</p>
			<ul>
				<li>Using <strong class="source-inline">dnf</strong> and <strong class="source-inline">apt</strong> for package management</li>
				<li>Using additional repositories, streams, and profiles</li>
				<li>Creating custom repositories</li>
				<li>Compiling third-party software</li>
			</ul>
			<h1 id="_idParaDest-136"><a id="_idTextAnchor139"/>Technical requirements </h1>
			<p>For these recipes, we're going to use two Linux machines – we can use the <strong class="source-inline">cli1</strong> and <strong class="source-inline">cli2</strong> virtual machines from our previous recipes. These recipes are doable both on CentOS and/or Ubuntu, so there is no reason to use separate virtual machines for these scenarios.</p>
			<p>So, let's start our virtual machines, and let's get cracking!</p>
			<h1 id="_idParaDest-137"><a id="_idTextAnchor140"/>Using dnf and apt for package management</h1>
			<p>Packages and package<a id="_idIndexMarker417"/> groups are different ways<a id="_idIndexMarker418"/> of deploying software<a id="_idIndexMarker419"/> to our CentOS and Ubuntu<a id="_idIndexMarker420"/> virtual machines. A package is nothing more than a stack of files that can be installed on our machine in an automated fashion, without our manual input. Package groups are more of a RedHat/CentOS concept. Just like the term suggests, they are a way of grouping packages into larger groups so that we can use these groups to install multiple packages without manually specifying every single package from the group. Let's learn how to use them to our benefit, specifically, for deployment purposes.</p>
			<h2 id="_idParaDest-138"><a id="_idTextAnchor141"/>Getting ready</h2>
			<p>Let's continue using our <strong class="source-inline">cli1</strong> and <strong class="source-inline">cli2</strong> machines<a id="_idIndexMarker421"/> for this one, so make sure that they're powered<a id="_idIndexMarker422"/> on and ready to go. We<a id="_idIndexMarker423"/> are going to use <strong class="source-inline">cli1</strong> for the <strong class="source-inline">apt</strong> part<a id="_idIndexMarker424"/> of this recipe, and <strong class="source-inline">cli2</strong> for the <strong class="source-inline">yum/dnf</strong> part, as <strong class="source-inline">cli1</strong> is Ubuntu-based and <strong class="source-inline">cli2</strong> is CentOS-based.</p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor142"/>How to do it…</h2>
			<p>Let's start with the basics of <strong class="source-inline">yum</strong> and <strong class="source-inline">dnf</strong> for CentOS on cli2. Let's list all the available packages on the system:</p>
			<p class="source-code">yum list</p>
			<p>The output should look like this (abbreviated):</p>
			<div>
				<div id="_idContainer146" class="IMG---Figure">
					<img src="Images/Figure_6.1_B16269.jpg" alt="Figure 6.1 – Shortened yum list output&#13;&#10;" width="1047" height="935"/>
				</div>
			</div>
			<p class="figure-caption">Figu<a id="_idTextAnchor143"/>re 6.1 – Shortened yum list output</p>
			<p>We've shortened this screenshot in <em class="italic">Figure 6.1</em> as it contains thousands of packages. There are three columns<a id="_idIndexMarker425"/> in this output. Going from left to right, the first<a id="_idIndexMarker426"/> column is the package name, the second column<a id="_idIndexMarker427"/> is the package version, and the third<a id="_idIndexMarker428"/> one is the package repository where that specific package is located. </p>
			<p>If we want to find out more details about a package, we can use <strong class="source-inline">yum info</strong> (or <strong class="source-inline">dnf info</strong>), for example:</p>
			<div>
				<div id="_idContainer147" class="IMG---Figure">
					<img src="Images/Figure_6.2_B16269.jpg" alt="Figure 6.2 – Getting information regarding a package&#13;&#10;" width="1131" height="518"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.2 – Getting information regarding a package</p>
			<p>By using this command, we get much more information<a id="_idIndexMarker429"/> about the package. Also, please<a id="_idIndexMarker430"/> note that<a id="_idIndexMarker431"/> we didn't use <strong class="source-inline">x86_64</strong> in the package<a id="_idIndexMarker432"/> name, as it's not necessary. Bearing in mind the fact that we're using a 64-bit distribution, it becomes understandable that using <em class="italic">architecture</em> in the package name is almost always unnecessary.</p>
			<p>Let's now install a package, for example, <strong class="source-inline">mc</strong> (Midnight Commander):</p>
			<div>
				<div id="_idContainer148" class="IMG---Figure">
					<img src="Images/Figure_6.3_B16269.jpg" alt="Figure 6.3 – Installing a package&#13;&#10;" width="1058" height="851"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.3 – Installing a package</p>
			<p>The beauty of Linux package<a id="_idIndexMarker433"/> systems is evident here. It's not only about<a id="_idIndexMarker434"/> the fact that a package gets installed<a id="_idIndexMarker435"/> without hassle – dependencies<a id="_idIndexMarker436"/> get installed by default, as well, and that's really useful. Back in the days when we only had the <strong class="source-inline">rpm</strong> command to install packages in CentOS, it was much more difficult to resolve dependencies. We had to deploy them before deploying the package that we wanted to deploy, and in a specific order, which complicated the deployment process.</p>
			<p>We can remove that package by using the following command:</p>
			<p class="source-code">dnf -y remove mc</p>
			<p>If we want to find which package installed a specific file, we can use the <strong class="source-inline">yum provides</strong> or <strong class="source-inline">dnf provides</strong> command:</p>
			<div>
				<div id="_idContainer149" class="IMG---Figure">
					<img src="Images/Figure_6.4_B16269.jpg" alt="Figure 6.4 – Checking which package installed a specific file&#13;&#10;" width="1213" height="427"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.4 – Checking which package installed a specific file</p>
			<p>If we need<a id="_idIndexMarker437"/> to find package<a id="_idIndexMarker438"/> dependencies (which package<a id="_idIndexMarker439"/> depends on which package), we can<a id="_idIndexMarker440"/> use the following command:</p>
			<div>
				<div id="_idContainer150" class="IMG---Figure">
					<img src="Images/Figure_6.5_B16269.jpg" alt="Figure 6.5 – Checking package dependencies&#13;&#10;" width="1025" height="448"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.5 – Checking package dependencies</p>
			<p>We used <strong class="source-inline">bash</strong> in this example, but we could have used any package name for this query.</p>
			<p>We can also use <strong class="source-inline">dnf</strong> and <strong class="source-inline">yum</strong> to download and install<a id="_idIndexMarker441"/> packages locally. Let's say that we want<a id="_idIndexMarker442"/> to download and<a id="_idIndexMarker443"/> install the <strong class="source-inline">joe</strong> editor<a id="_idIndexMarker444"/> locally. This is how we'd do it:</p>
			<div>
				<div id="_idContainer151" class="IMG---Figure">
					<img src="Images/Figure_6.6_B16269.jpg" alt="Figure 6.6 – Downloading and installing a package manually from a local disk&#13;&#10;" width="1319" height="862"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.6 – Downloading and installing a package manually from a local disk</p>
			<p>We can, of course, search for packages by using the <strong class="source-inline">yum search</strong> or <strong class="source-inline">dnf search</strong> command:</p>
			<div>
				<div id="_idContainer152" class="IMG---Figure">
					<img src="Images/Figure_6.7_B16269.jpg" alt="Figure 6.7 – Using the yum/dnf search command&#13;&#10;" width="1294" height="911"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.7 – Using the yum/dnf search command</p>
			<p>Sometimes, the list<a id="_idIndexMarker445"/> of these packages<a id="_idIndexMarker446"/> is going to be quite<a id="_idIndexMarker447"/> long, so additional filtering<a id="_idIndexMarker448"/> might be required.</p>
			<p>Let's now talk a bit about package groups, starting with the <strong class="source-inline">dnf grouplist</strong> command:</p>
			<div>
				<div id="_idContainer153" class="IMG---Figure">
					<img src="Images/Figure_6.8_B16269.jpg" alt="Figure 6.8 – Using dnf group list commands gives us a list of package groups&#13;&#10;" width="875" height="532"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.8 – Using dnf group list commands gives us a list of package groups</p>
			<p>The output<a id="_idIndexMarker449"/> of that command<a id="_idIndexMarker450"/> is going to give us<a id="_idIndexMarker451"/> the names of <strong class="bold">package groups</strong> that we can<a id="_idIndexMarker452"/> use for much <em class="italic">larger</em> package deployments. For example, let's check what's going<a id="_idIndexMarker453"/> to happen if we install the <strong class="bold">Development Tools</strong> package group by issuing the following command:</p>
			<p class="source-code">dnf groupinstall "Development Tools"</p>
			<p>This command will ask us whether we want to download and deploy more than 100 packages. If we answer <em class="italic">yes</em>, that's exactly what's going to happen (the screenshot is rendered smaller on purpose, just to show the end of the command output):</p>
			<div>
				<div id="_idContainer154" class="IMG---Figure">
					<img src="Images/Figure_6.9_B16269.jpg" alt="Figure 6.9 – Installing a package group&#13;&#10;" width="1048" height="465"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.9 – Installing a package group</p>
			<p>As we can see, having the ability<a id="_idIndexMarker454"/> to deploy package groups<a id="_idIndexMarker455"/> greatly increases the speed<a id="_idIndexMarker456"/> of package<a id="_idIndexMarker457"/> deployment. </p>
			<p>The next step in our process is to cover everything that we've covered in this recipe, but to deliver it on Ubuntu. So, let's switch to our <strong class="source-inline">cli1</strong> machine and start from scratch. First, let's describe a couple of commands that we're interested in:</p>
			<ul>
				<li><strong class="source-inline">apt-get</strong> or <strong class="source-inline">apt</strong>: Commands used to install, remove, upgrade, and update packages</li>
				<li><strong class="source-inline">apt-cache</strong>: Mostly used to search and find information about packages</li>
			</ul>
			<p>Let's now learn to use them. First, we are going to discuss regular operations – installing, removing, purging, updating, and upgrading. Let's install a package, for example, <strong class="source-inline">mc</strong>:</p>
			<div>
				<div id="_idContainer155" class="IMG---Figure">
					<img src="Images/Figure_6.10_B16269.jpg" alt="Figure 6.10 – Using apt-get to install a package&#13;&#10;" width="1136" height="510"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.10 – Using apt-get to install a package</p>
			<p>Now, let's<a id="_idIndexMarker458"/> remove<a id="_idIndexMarker459"/> it:</p>
			<div>
				<div id="_idContainer156" class="IMG---Figure">
					<img src="Images/Figure_6.11_B16269.jpg" alt="Figure 6.11 – Using apt-get to remove a package&#13;&#10;" width="1002" height="385"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.11 – Using apt-get to remove a package</p>
			<p>We can see that we have<a id="_idIndexMarker460"/> a standard situation – the package <em class="italic">was</em> removed, but<a id="_idIndexMarker461"/> some of its dependencies weren't. We can do that, as well, by using the <strong class="source-inline">apt-get autoremove</strong> command:</p>
			<div>
				<div id="_idContainer157" class="IMG---Figure">
					<img src="Images/Figure_6.12_B16269.jpg" alt="Figure 6.12 – Removing packages that are no longer needed&#13;&#10;" width="914" height="462"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.12 – Removing packages that are no longer needed</p>
			<p>This is very<a id="_idIndexMarker462"/> useful as we're reducing<a id="_idIndexMarker463"/> the attack surface<a id="_idIndexMarker464"/> of our server (for security breaches) by removing<a id="_idIndexMarker465"/> unnecessary software packages.</p>
			<p>Now let's check what happens if we use the <strong class="source-inline">update</strong> option:</p>
			<div>
				<div id="_idContainer158" class="IMG---Figure">
					<img src="Images/Figure_6.13_B16269.jpg" alt="Figure 6.13 – Updating repository and package info&#13;&#10;" width="865" height="184"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.13 – Updating repository and package info</p>
			<p>As we can see, <strong class="source-inline">apt</strong> refreshed its package list before the upgrade process could happen – these steps are mostly used in sequence – <strong class="source-inline">update</strong> followed by <strong class="source-inline">upgrade</strong>:</p>
			<div>
				<div id="_idContainer159" class="IMG---Figure">
					<img src="Images/Figure_6.14_B16269.jpg" alt="Figure 6.14 – Upgrading available packages – this time, no upgrades are necessary&#13;&#10;" width="788" height="236"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.14 – Upgrading available packages – this time, no upgrades are necessary</p>
			<p>Interestingly enough, no packages<a id="_idIndexMarker466"/> were installed, which is a very<a id="_idIndexMarker467"/> rare situation, to be honest. Usually, we'd have<a id="_idIndexMarker468"/> at least a few packages<a id="_idIndexMarker469"/> to be upgraded. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">Before we get into the topic of doing dist-upgrade, we are absolutely <em class="italic">NOT</em> recommending this for a production server. Using <strong class="source-inline">dist-upgrade</strong> and <strong class="source-inline">do-release-upgrade</strong> is something that we <em class="italic">can</em> do, but shouldn't. Migration is always a better idea, however much time it might take.</p>
			<p>Let's now push this situation to the extreme by trying to do <strong class="source-inline">dist-upgrade</strong>, followed by <strong class="source-inline">do-release-upgrade</strong>. What the <strong class="source-inline">dist-upgrade apt</strong> option does is simple in theory – it tries to prepare our current distribution so that it's possible to upgrade it to the latest one in the branch. At first, it might just be getting a couple of new packages. Usually, these packages contain new repositories and information about locations, from which <strong class="source-inline">apt</strong> will upgrade our distribution to the latest one. Here's an example:</p>
			<div>
				<div id="_idContainer160" class="IMG---Figure">
					<img src="Images/Figure_6.15_B16269.jpg" alt="Figure 6.15 – Using dist-upgrade to get information about new distribution versions&#13;&#10;" width="878" height="339"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.15 – Using dist-upgrade to get information about new distribution versions</p>
			<p>The next step after<a id="_idIndexMarker470"/> that one is to use <strong class="source-inline">do-release-upgrade</strong>, a standalone<a id="_idIndexMarker471"/> command that's not an <strong class="source-inline">apt</strong> subcommand. We need to remember<a id="_idIndexMarker472"/> that this is not<a id="_idIndexMarker473"/> an <strong class="source-inline">apt</strong> option (there's no <strong class="source-inline">apt do-release-upgrade</strong>, it's just <strong class="source-inline">do-release-upgrade</strong>). After executing it, our system is going to ask us whether we want to continue with the distribution release upgrade:</p>
			<div>
				<div id="_idContainer161" class="IMG---Figure">
					<img src="Images/Figure_6.16_B16269.jpg" alt="Figure 6.16 – Using do-release-upgrade, not to be recommended in production environments&#13;&#10;" width="903" height="569"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.16 – Using do-release-upgrade, not to be recommended in production environments</p>
			<p>If we confirm, the process<a id="_idIndexMarker474"/> is going to start, and it's going<a id="_idIndexMarker475"/> to take a while. The end result<a id="_idIndexMarker476"/> should be an Ubuntu<a id="_idIndexMarker477"/> machine that's fully updated to the latest version, with all of the latest package versions. Remember, we specifically mentioned that this shouldn't be done in production – it's just an extreme example of using <strong class="source-inline">apt</strong> capabilities to do a system-wide package upgrade. Hundreds, perhaps thousands of packages, will get updated if we do something like that, and the process isn't reversible, so it carries a lot of risk. Try it out on some test virtual machine just for practice. If successful, this procedure will upgrade to the latest Ubuntu version. The end result, at the time of writing, looks like this:</p>
			<div>
				<div id="_idContainer162" class="IMG---Figure">
					<img src="Images/Figure_6.17_B16269.jpg" alt="Figure 6.17 – The end result of do-release-upgrade, and in our experience, we got lucky this time!&#13;&#10;" width="901" height="696"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.17 – The end result of do-release-upgrade, and in our experience, we got lucky this time!</p>
			<p>Notice that<a id="_idIndexMarker478"/> our Ubuntu<a id="_idIndexMarker479"/> machine was<a id="_idIndexMarker480"/> upgraded to the<a id="_idIndexMarker481"/> latest (21.04) version.</p>
			<p>There are a few more important <strong class="source-inline">apt</strong> commands – for example, for a package search, we can use the <strong class="source-inline">apt-cache showpkg package_name</strong> command. Let's use it, for example, on <strong class="source-inline">mc</strong>, a package we installed previously:</p>
			<div>
				<div id="_idContainer163" class="IMG---Figure">
					<img src="Images/Figure_6.18_B16269.jpg" alt="Figure 6.18 – Using apt-get to get package info&#13;&#10;" width="1258" height="747"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.18 – Using apt-get to get package info</p>
			<p>There is a somewhat<a id="_idIndexMarker482"/> shorter version<a id="_idIndexMarker483"/> of the same<a id="_idIndexMarker484"/> thing if we use<a id="_idIndexMarker485"/> the <strong class="source-inline">apt</strong> command:</p>
			<div>
				<div id="_idContainer164" class="IMG---Figure">
					<img src="Images/Figure_6.19_B16269.jpg" alt="Figure 6.19 – Using apt to get package info – somewhat shorter and more concise&#13;&#10;" width="1266" height="737"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.19 – Using apt to get package info – somewhat shorter and more concise</p>
			<p>If we need to add<a id="_idIndexMarker486"/> repositories, we can use the <strong class="source-inline">add-apt-repository</strong> command. Let's say that<a id="_idIndexMarker487"/> we want to add an<a id="_idIndexMarker488"/> unofficial repository, such as <strong class="bold">Personal Package Archives</strong> (<strong class="bold">PPA</strong>), that is hosted on Launchpad. Generally<a id="_idIndexMarker489"/> speaking, we should<a id="_idIndexMarker490"/> only add <em class="italic">reputable</em> repositories, and not just <em class="italic">any</em> repository just because it has a certain package that we might need. We are going to use an example here – let's say that we need to install the latest PHP 7.4 version on our Ubuntu machine. We can do it like this:</p>
			<p class="source-code">apt-get install software-properties-common</p>
			<p class="source-code">add-apt-repository ppa:ondrej/php</p>
			<p class="source-code">apt-get update</p>
			<p class="source-code">apt-get install -y php7.4</p>
			<p>This should be the result if we started <strong class="source-inline">php</strong> from the shell:</p>
			<div>
				<div id="_idContainer165" class="IMG---Figure">
					<img src="Images/Figure_6.20_B16269.jpg" alt="Figure 6.20 – The end result of us using the ppa repository to deploy the latest release of PHP 7.4&#13;&#10;" width="836" height="162"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.20 – The end result of us using the ppa repository to deploy the latest release of PHP 7.4</p>
			<p>This covers all the necessary<a id="_idIndexMarker491"/> commands we need for both Ubuntu<a id="_idIndexMarker492"/> and CentOS. Let's now explain some background<a id="_idIndexMarker493"/> information about where some<a id="_idIndexMarker494"/> of the more important information is stored – for both CentOS (<strong class="source-inline">dnf</strong>/<strong class="source-inline">yum</strong>) and Ubuntu (<strong class="source-inline">apt</strong>/<strong class="source-inline">apt-get</strong>).</p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor144"/>How it works…</h2>
			<p><strong class="source-inline">yum</strong> and <strong class="source-inline">dnf</strong> work in tandem with files located in <strong class="source-inline">/etc/yum.repos.d</strong> repository files, as well as the <strong class="source-inline">/etc/yum.conf</strong> configuration file. We covered repository files, so let's now discuss <strong class="source-inline">/etc/yum.conf</strong> and a couple of important configuration options that we can use from it. This is a global configuration file for <strong class="source-inline">dnf</strong> and <strong class="source-inline">yum</strong> commands.</p>
			<p>There are a couple of really useful configuration items that we can manage in it. Let's just illustrate that point by using two commonly used examples. Let's add these two options to it:</p>
			<p class="source-code">exclude: kernel* open-vm*</p>
			<p class="source-code">gpgcheck=0</p>
			<p>By using these two commands, we instructed <strong class="source-inline">yum</strong>/<strong class="source-inline">dnf</strong> to exclude all <strong class="source-inline">kernel</strong> and <strong class="source-inline">open-vm</strong> packages (by name) in any kind of operation, such as a <strong class="source-inline">yum</strong> update (which updates all packages on the machine). <strong class="source-inline">gpgcheck=0</strong> sets a global policy that tells <strong class="source-inline">yum</strong> and <strong class="source-inline">dnf</strong> <em class="italic">not</em> to use GPG key checking when working with packages. This can also be managed in <strong class="source-inline">/etc/yum.repos.d</strong>, as discussed in our recipe.</p>
			<p>Ubuntu has a very similar principle; it's just that directories are different as well as the file structure, somewhat. The most important information regarding the software repository location is kept in the /<strong class="source-inline">etc/apt</strong> directory, specifically, in the <strong class="source-inline">/etc/apt/sources.list</strong> file. Here's an excerpt:</p>
			<div>
				<div id="_idContainer166" class="IMG---Figure">
					<img src="Images/Figure_6.21_B16269.jpg" alt="Figure 6.21 – Main apt configuration file called sources.list&#13;&#10;" width="1259" height="563"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.21 – Main apt configuration file called sources.list</p>
			<p>The general structure<a id="_idIndexMarker495"/> is simple enough. The second<a id="_idIndexMarker496"/> part of our <strong class="source-inline">apt</strong> equation<a id="_idIndexMarker497"/> is located in the <strong class="source-inline">/etc/apt/sources.list.d</strong> directory. A couple<a id="_idIndexMarker498"/> of steps ago, we added the PPA repository, and, sure enough, we have a configuration file for that repository configuration file there, called <strong class="source-inline">ondrej-ubuntu-php-groovy.list</strong>:</p>
			<div>
				<div id="_idContainer167" class="IMG---Figure">
					<img src="Images/Figure_6.22_B16269.jpg" alt="Figure 6.22 – Additional apt configuration file located at /etc/apt/sources.list.d&#13;&#10;" width="862" height="111"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.22 – Additional apt configuration file located at /etc/apt/sources.list.d</p>
			<p>That covers our package and package groups recipe. Let's now move on to the next recipe, which is about using modules and module streams.</p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor145"/>There's more…</h2>
			<p>If you need more information<a id="_idIndexMarker499"/> about networking in CentOS and Ubuntu, make<a id="_idIndexMarker500"/> sure that you check<a id="_idIndexMarker501"/> out the following resources:</p>
			<ul>
				<li><strong class="bold">Yum cheat sheet</strong>: <strong class="source-inline">https://access.redhat.com/sites/default/files/attachments/rh_yum_cheatsheet_1214_jcs_print-1.pdf</strong></li>
				<li><strong class="bold">Yum to DNF cheat sheet</strong>: <strong class="source-inline">https://fedoraproject.org/wiki/Yum_to_DNF_Cheatsheet</strong></li>
				<li><strong class="bold">Apt cheat sheet</strong>: <strong class="source-inline">https://packagecloud.io/blog/apt-cheat-sheet/</strong></li>
			</ul>
			<h1 id="_idParaDest-142"><a id="_idTextAnchor146"/>Using additional repositories, streams, and profiles</h1>
			<p>Repositories are the most<a id="_idIndexMarker502"/> important objects/locations to manage as they provide us with packages<a id="_idIndexMarker503"/> and package groups that we can install on our CentOS machine. Let's now<a id="_idIndexMarker504"/> learn how to manage repositories by using <strong class="source-inline">yum-config-manager</strong> and <strong class="source-inline">dnf</strong>. Also, let's get to know some configuration files that are key for this process.</p>
			<p>Adding to the idea of package groups, which group packages into larger groups, <strong class="source-inline">dnf</strong> introduced the idea of additional modularity. It's all about package organization – we want to have simple ways of deploying software – runtimes, applications, bits and pieces of software. These concepts also enable us to have control over <em class="italic">versions of software</em> that we want to install, which is really handy. For example, let's say that you need to deploy PHP 7.2 and 7.3 on the machine. Doing that manually isn't going to be much fun. As we're going to demonstrate by using an example, this is much more easily done if we use a module stream.</p>
			<p>Profiles act as quasi-repositories, without actually being repositories, within the <strong class="bold">AppStream</strong> repository. This concept enables<a id="_idIndexMarker505"/> us to additionally filter what we install. Just as an example, the <strong class="source-inline">httpd</strong> module has a couple of profiles (<strong class="source-inline">minimal</strong>, <strong class="source-inline">devel</strong>, <strong class="source-inline">common</strong>). The minimal profile means just the minimum number of packages that need to be installed for <strong class="source-inline">httpd</strong> to work. Unlike that, common is a default profile that's ready for production and additionally treated in terms of security (hardened).</p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor147"/>Getting ready</h2>
			<p>Start the <strong class="source-inline">cli2</strong> virtual machine created in the previous recipes. We're going to use it to work with streams and profiles on our CentOS machine.</p>
			<h2 id="_idParaDest-144"><a id="_idTextAnchor148"/>How to do it…</h2>
			<p>To manage repositories, we<a id="_idIndexMarker506"/> have to learn to use<a id="_idIndexMarker507"/> two commands – <strong class="source-inline">yum-config-manager</strong> and <strong class="source-inline">dnf</strong>. Also, we need<a id="_idIndexMarker508"/> to look into the <strong class="source-inline">/etc/yum.conf</strong> file, as well as the <strong class="source-inline">/etc/yum.repos.d</strong> directory. <strong class="source-inline">Yum.conf</strong> gives us global <strong class="source-inline">yum</strong> command configuration options, and the <strong class="source-inline">/etc/yum.repos.d</strong> directory contains configuration files with repository locations. </p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor149"/>How it works…</h2>
			<p>Let's look at <strong class="source-inline">yum-config-manager</strong> first. This command was introduced in Red Hat Enterprise Linux/CentOS 7 to easily add additional repositories to your Red Hat Enterprise Linux or CentOS machine. And it does just that – it lets us skip the whole manual repository configuration and get straight to business. If we didn't have this command, we would need to learn the configuration file options for <strong class="source-inline">/etc/yum.repos.d</strong> directory files. </p>
			<p>If we go to the first virtual machine that we installed (source), and list the content of the <strong class="source-inline">/etc/yum.repos.d</strong> directory, this is what we'll get:</p>
			<div>
				<div id="_idContainer168" class="IMG---Figure">
					<img src="Images/Figure_6.23_B16269.jpg" alt="Figure 6.23 – /etc/yum.repos.d directory content&#13;&#10;" width="848" height="446"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.23 – /etc/yum.repos.d directory content</p>
			<p>Let's say that we want to add a custom repository, <strong class="source-inline">url</strong>, to our machine. We can do this in three different ways. The first approach involves using <strong class="source-inline">yum-package-manager</strong>, and that tool requires the <strong class="source-inline">yum-utils</strong> package (<strong class="source-inline">url</strong> is the location of the repository that we want to use):</p>
			<p class="source-code">yum -y install yum-utils</p>
			<p class="source-code">yum-config-manager --add-repo url </p>
			<p class="source-code">yum-config-manager --enable repo</p>
			<p>We can also check<a id="_idIndexMarker509"/> the list of currently<a id="_idIndexMarker510"/> configured repositories<a id="_idIndexMarker511"/> by using the following command:</p>
			<p class="source-code">yum repolist all</p>
			<p>If we need to find the list of currently disabled (unused) repositories, we can use the following command:</p>
			<p class="source-code">yum repolist enabled</p>
			<p>If we need to enable a disabled repository, we can use the following (<strong class="source-inline">repository_id</strong> is a parameter that you can get from the <strong class="source-inline">yum repolist all</strong> command):</p>
			<p class="source-code">yum-config-manager --enable repository_id</p>
			<p>The most obvious problem with using <strong class="source-inline">yum-config-manager</strong> is the fact that there are some parameters that we can't assign via that command itself. This is where the manual editing of <strong class="source-inline">/etc/yum.repos.d</strong> configuration files comes in handy.</p>
			<p>This command is being phased out little by little and redirected to its new <strong class="source-inline">dnf</strong> counterparts (<strong class="source-inline">dnf config-manager</strong>), just like <strong class="source-inline">yum</strong> is being used in parallel with the <strong class="source-inline">dnf</strong> command. If we want to do the same job by using <strong class="source-inline">dnf</strong> tools, we can do this:</p>
			<p class="source-code">dnf config-manager --add-repo url</p>
			<p>That will create a new configuration file in the <strong class="source-inline">/etc/yum.repos.d</strong> directory with the repository definition and enable it by default.</p>
			<p>Our next step is going to be to learn a bit about these configuration files, as they're really not all that difficult to understand. Let's use a repository configuration file to explain their concept, for example, <strong class="source-inline">/etc/yum.repos.d/CentOS-Sources.repo</strong>:</p>
			<div>
				<div id="_idContainer169" class="IMG---Figure">
					<img src="Images/Figure_6.24_B16269.jpg" alt="Figure 6.24 – Part of the /etc/yum.repos.d/CentOS-Sources.repo file&#13;&#10;" width="875" height="156"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.24 – Part of the /etc/yum.repos.d/CentOS-Sources.repo file</p>
			<p>Let's explain<a id="_idIndexMarker512"/> these configuration<a id="_idIndexMarker513"/> parameters: </p>
			<ul>
				<li><strong class="source-inline">[BaseOS-Source]</strong>is the<a id="_idIndexMarker514"/> repository ID. This is what we use in <strong class="source-inline">yum-config-manager</strong> or <strong class="source-inline">dnf </strong>to reference repositories.</li>
				<li>The <strong class="source-inline">name</strong> parameter is a description of that repository.</li>
				<li>The <strong class="source-inline">baseurl</strong> parameter describes <em class="italic">where</em> the location of this repository is, and it can use a variety of different options – <strong class="source-inline">http</strong>, <strong class="source-inline">https</strong>, <strong class="source-inline">ftp</strong>, or <strong class="source-inline">file</strong>. If we create a <em class="italic">local</em> repository (mount it somewhere on our CentOS machine), then the <strong class="source-inline">file</strong> statement will be used to access it. </li>
				<li>The <strong class="source-inline">gpgcheck</strong> parameter tells <strong class="source-inline">yum/dnf</strong> whether or not to check the <strong class="source-inline">gpg</strong> key against the package signatures. If it's <strong class="source-inline">1</strong>, that means that checking is mandatory. </li>
				<li>The <strong class="source-inline">enabled</strong> parameter tells <strong class="source-inline">yum/dnf</strong> whether this repository is enabled, which means whether <strong class="source-inline">dnf/yum</strong> can use it to get packages. We can also use <strong class="source-inline">yum --enablerepo</strong> to enable a certain defined repository by name, or <strong class="source-inline">yum --disablerepo</strong> to do the opposite.</li>
				<li>The <strong class="source-inline">gpgkey</strong> parameter tells <strong class="source-inline">yum/dnf</strong> where the <strong class="source-inline">gpg</strong> key for <strong class="source-inline">gpgcheck</strong> is located.</li>
			</ul>
			<p>Let's now move on to the idea of streams and profiles, the logical next step in our recipe.</p>
			<p>After we log in to the source machine, let's use an example to describe what streams and profiles are all about. So, let's use a module stream and profile to remove and re-deploy <strong class="source-inline">httpd</strong>. In the first step, we're going to use the following command:</p>
			<p class="source-code">dnf -y remove @httpd</p>
			<p>After<a id="_idIndexMarker515"/> the process<a id="_idIndexMarker516"/> is complete, let's do<a id="_idIndexMarker517"/> the opposite:</p>
			<p class="source-code">dnf -y install @httpd</p>
			<p>Let's now check the output of the second command:</p>
			<div>
				<div id="_idContainer170" class="IMG---Figure">
					<img src="Images/Figure_6.25_B16269.jpg" alt="Figure 6.25 – Using streams and profiles&#13;&#10;" width="1114" height="1068"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.25 – Using streams and profiles</p>
			<p>We can see<a id="_idIndexMarker518"/> that the deployment<a id="_idIndexMarker519"/> process automatically<a id="_idIndexMarker520"/> defaulted to using the <strong class="source-inline">httpd/common</strong> profile<a id="_idIndexMarker521"/> and the default stream (<strong class="bold">AppStream</strong>) repository. </p>
			<p>Let's do another<a id="_idIndexMarker522"/> example. We can check<a id="_idIndexMarker523"/> the list of all available modules<a id="_idIndexMarker524"/> by using the following command:</p>
			<p class="source-code">dnf module list</p>
			<p>This will give us the following result:</p>
			<div>
				<div id="_idContainer171" class="IMG---Figure">
					<img src="Images/Figure_6.26_B16269.jpg" alt="Figure 6.26 – dnf module list, with versions and profiles; abridged output&#13;&#10;" width="1299" height="776"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.26 – dnf module list, with versions and profiles; abridged output</p>
			<p>Let's say that we want to install <strong class="source-inline">container-tools</strong> version 2.0. We can do it this way:</p>
			<div>
				<div id="_idContainer172" class="IMG---Figure">
					<img src="Images/Figure_6.27_B16269.jpg" alt="Figure 6.27 – Deploying a specific module version by using the dnf command&#13;&#10;" width="1385" height="774"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.27 – Deploying a specific module version by using the dnf command</p>
			<p>As you can see, the result of this action<a id="_idIndexMarker525"/> is going to be quite extensive. Sometimes, when we deploy<a id="_idIndexMarker526"/> a set of packages from modules and streams, our machine<a id="_idIndexMarker527"/> is going to deploy hundreds of packages. So, be prepared to wait for a bit of time to see whether it happens.</p>
			<p>In one of our examples, we deployed the <strong class="source-inline">httpd</strong> package by using the default profile and stream. Every one of these streams can have multiple profiles for our convenience. If the stream has multiple profiles, one of them can be used as the default one (and marked as such). This is not mandatory, but it's a good practice. </p>
			<p>In terms of modules, there are 60+ modules available already, with various versions of Python, PHP, PostgreSQL, nginx, and so on, to name a few commonly used services. We can use a module from that list to deploy it. Also, the output of the command gives us details about profiles, which we can then use to deploy a specific module profile.</p>
			<p>By using these capabilities, we can modularize our approach to deploy specific packages. The overall idea of modularization via streams and profiles is a good one, although it's a bit clunky and unfinished in terms of upgrades. That being said, it's something that is going to be around in the future, so it's a worthwhile investment of our time to learn about it.</p>
			<p>We're done with advanced<a id="_idIndexMarker528"/> repository management<a id="_idIndexMarker529"/> for the time being. Let's now learn<a id="_idIndexMarker530"/> how to create custom repositories.</p>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor150"/>Creating custom repositories</h1>
			<p>Sometimes, it's necessary to create<a id="_idIndexMarker531"/> your own private repository of packages. Whatever the reason might be – no internet access, low deployment speed – it's a completely normal usage model that's often used all over the world. We are going to show examples for both CentOS and Ubuntu so that we cover everything necessary for most Linux administrators. Let's roll up our sleeves and start!</p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor151"/>Getting ready</h2>
			<p>Keep the <strong class="source-inline">cli1</strong> virtual machine powered on and let's continue using our shell. Let's make sure that the necessary packages are installed by using our standard commands. So, let's use this command:</p>
			<p class="source-code">dnf -y install vsftpd createrepo lftp</p>
			<p>That should be all in terms of preparation, so let's do it. </p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor152"/>How to do it…</h2>
			<p>Setting up a custom CentOS repository is actually quite a simple affair. The first step involves downloading some packages. We are going to download a few of them and place them in the same directory. Then, we are going to make that directory available via the network by using <strong class="source-inline">vsftpd</strong>. A more detailed explanation of <strong class="source-inline">vsftpd</strong> can be found in the next chapter of this book, which is about network-based file synchronization. Here, we are just going to do a <em class="italic">Formula 1</em> qualifying lap through <strong class="source-inline">vsftpd</strong> to create a repository. </p>
			<p>Let's say that we want to create a local repository (hosted on our <strong class="source-inline">cli2</strong> machine) that's going to have two packages in it – the <strong class="source-inline">joe</strong> editor and <strong class="source-inline">desktop-backgrounds-basic</strong>. We need to put them in a directory, <strong class="source-inline">/var/ftp/pub/repository</strong>, so that they're nice and handy inside the <strong class="source-inline">vsftpd</strong> folder structure. We could do it like this:</p>
			<div>
				<div id="_idContainer173" class="IMG---Figure">
					<img src="Images/Figure_6.28_B16269.jpg" alt="Figure 6.28 – Downloading a few packages and getting ready for repository configuration&#13;&#10;" width="1650" height="742"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.28 – Downloading a few packages and getting ready for repository configuration</p>
			<p>Since we already installed the <strong class="source-inline">createrepo</strong> package in the introduction<a id="_idIndexMarker532"/> to this recipe, we just need to use the <strong class="source-inline">createrepo</strong> command to create the necessary inventory information:</p>
			<div>
				<div id="_idContainer174" class="IMG---Figure">
					<img src="Images/Figure_6.29_B16269.jpg" alt="Figure 6.29 – Creating a repository out of a directory with RPM packages&#13;&#10;" width="1650" height="680"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.29 – Creating a repository out of a directory with RPM packages</p>
			<p>The next step is to allow this directory to be used via <strong class="source-inline">vsftpd</strong>. Again, we have already installed <strong class="source-inline">vsftpd</strong> and, by default, we just need<a id="_idIndexMarker533"/> to change one option in its configuration file to allow anonymous FTP. Let's open the configuration file, <strong class="source-inline">/etc/vsftpd/vsftpd.conf</strong>, and locate the offending option:</p>
			<p class="source-code">anonymous_enable=NO</p>
			<p>And change it to the following:</p>
			<p class="source-code">anonymous_enable=YES</p>
			<p>We can now start and enable the service:</p>
			<p class="source-code">systemctl restart vsftpd</p>
			<p class="source-code">systemctl enable vsftpd</p>
			<p>Then, let's try to log in to it to verify whether everything is ready:</p>
			<div>
				<div id="_idContainer175" class="IMG---Figure">
					<img src="Images/Figure_6.30_B16269.jpg" alt="Figure 6.30 – Checking whether the vsftpd configuration works&#13;&#10;" width="1367" height="263"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.30 – Checking whether the vsftpd configuration works</p>
			<p>Everything is now ready from the service perspective. Now we just need to explain to <strong class="source-inline">yum/dnf</strong> that they need to use this as a repository. So, let's head to the <strong class="source-inline">/etc/yum.repos.d</strong> directory and create a repository configuration file there. Let's say we'll call it <strong class="source-inline">localrepo.repo</strong>. The name is irrelevant, it's just that it needs to have the <strong class="source-inline">.repo</strong> extension. Let's add the following options to it and save it:</p>
			<p class="source-code">[MyLocalRepo]</p>
			<p class="source-code">name=My Local Package Repository</p>
			<p class="source-code">baseurl=ftp://localhost/pub/repository</p>
			<p class="source-code">enabled=yes</p>
			<p class="source-code">gpgcheck=no</p>
			<p>Let's verify whether this repository definition<a id="_idIndexMarker534"/> now works. We need to use <strong class="source-inline">yum</strong> or <strong class="source-inline">dnf</strong> for that, with the <strong class="source-inline">repolist</strong> keyword:</p>
			<div>
				<div id="_idContainer176" class="IMG---Figure">
					<img src="Images/Figure_6.31_B16269.jpg" alt="Figure 6.31 – Checking whether our repository is correctly configured via its repo config file&#13;&#10;" width="970" height="178"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.31 – Checking whether our repository is correctly configured via its repo config file</p>
			<p>As we can see, <strong class="source-inline">MyLocalRepo</strong> is defined and ready to be used. Let's test it by trying to install the <strong class="source-inline">desktop-backgrounds-basic</strong> package:</p>
			<p class="source-code">yum -y install desktop-backgrounds-basic</p>
			<p>This should be the result:</p>
			<div>
				<div id="_idContainer177" class="IMG---Figure">
					<img src="Images/Figure_6.32_B16269.jpg" alt="Figure 6.32 – Installing a package from our custom repository&#13;&#10;" width="1376" height="697"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.32 – Installing a package from our custom repository</p>
			<p>We can clearly see the relevant information here – the repository used was called <strong class="source-inline">MyLocalRepo</strong>, so both <strong class="source-inline">vsftpd</strong> and our repository<a id="_idIndexMarker535"/> configuration file work without any problems.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Ubuntu tends to be much, much richer in terms of custom repositories; for example, repositories that are hosted on launchpad.net, and so on. It also tends to be a bit more internet-reliant than CentOS, but, that being said, it's easy enough to create repositories on either one of these distributions.</p>
			<p>Let's dive into a short explanation about how this all works in CentOS, and then it's time for another recipe!</p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor153"/>How it works…</h2>
			<p>There are two aspects to this recipe:</p>
			<ul>
				<li>Understanding how creating a repository works</li>
				<li>Understanding how using a <em class="italic">custom-created</em> repository works from the service and <strong class="source-inline">yum/dnf</strong> perspective</li>
			</ul>
			<p>As always, we need to understand both of these concepts so that we can make them work for us. Let's start with the repository creation part.</p>
			<p>Obviously, when creating a repository, we have to have some packages for that repository. So, a logical first step would always be to either create some packages or download them. There's just one key point to be made here – there <em class="italic">might</em> be problems if you download some packages <em class="italic">without</em> their dependencies. We deliberately chose two packages that don't have any dependencies so that we can have something to start our work with. That problem can be solved in either of the following two ways:</p>
			<ul>
				<li>We download all of the necessary dependencies for the packages that we're creating a repository for.</li>
				<li>We set up our repositories so that some other repository has all of the necessary dependencies for the packages we're creating our repository for.</li>
			</ul>
			<p>Generally speaking, we'll go a long way in solving this problem by just enabling the EPEL repository for our CentOS version, so, generally speaking, we should install the EPEL <strong class="source-inline">rpm</strong> as it's going to help us with dependencies for almost anything:</p>
			<p class="source-code">yum -y install epel-release</p>
			<p>Then, it all just becomes a matter of creating a directory, placing packages there, and using <strong class="source-inline">createrepo</strong> to create the necessary XML files so that the directory with packages can be used as a repository. Without <strong class="source-inline">createrepo</strong>, we are going to get an error, so we should always install it and use it prior to using our custom repository.</p>
			<p>The second aspect is related to a wider picture – that is, how to make this repository available to other machines on the network and how to configure those machines to use it. That's why we strategically selected <strong class="source-inline">vsftpd</strong> as a delivery service, as its configuration for this scenario is really easy. We could have used the Apache web server as well, but seeing that our next chapter is related to <strong class="source-inline">vsftpd</strong>, we thought it would be a fun way to get an introduction to <strong class="source-inline">vsftpd</strong> out of the way by seeing it in action. </p>
			<p>A part of this process is to work on <strong class="source-inline">repo</strong> files from the repository client perspective – that is, all of the machines that are going to be using our custom repository. It's just a couple of configuration lines that cover the repository's unique name and description, location, and some general settings, such as whether that repository is enabled on a client and if we're using signed packages and verifying their signature. Usually, people tend to skip over this, although it's quite important. If we enable the <strong class="source-inline">gpgcheck</strong> option, we need to install a <strong class="source-inline">gpg</strong> key that a repository is using to sign its packages, as well. We can do that with the <strong class="source-inline">gpg --import file_name.gpg</strong> command, after we download the <strong class="source-inline">gpg</strong> file.</p>
			<p>Let's now get ready for the last part<a id="_idIndexMarker536"/> of this chapter, which is all about compiling software from the source code. We're going to use some familiar, usual suspects to do that and learn how to do it along the way. </p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor154"/>There's more…</h2>
			<p>If we need to learn<a id="_idIndexMarker537"/> more about <strong class="source-inline">vsftpd</strong>, make sure<a id="_idIndexMarker538"/> that you check<a id="_idIndexMarker539"/> the following<a id="_idIndexMarker540"/> links:</p>
			<ul>
				<li><strong class="bold">yum:</strong> <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/deployment_guide/ch-yum%0D">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/deployment_guide/ch-yum</a></li>
				<li><strong class="bold">Install Anonymous FTP server on CentOS 8</strong>: <a href="https://www.centlinux.com/2020/02/install-anonymous-ftp-server-on-centos-8.html%0D">https://www.centlinux.com/2020/02/install-anonymous-ftp-server-on-centos-8.html</a></li>
				<li><strong class="bold">Create Local Repos</strong>: <a href="https://wiki.centos.org/HowTos/CreateLocalRepos%0D">https://wiki.centos.org/HowTos/CreateLocalRepos</a></li>
				<li><strong class="bold">Configuring yum and yum repositories</strong>: <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/deployment_guide/sec-configuring_yum_and_yum_repositories%0D">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/deployment_guide/sec-configuring_yum_and_yum_repositories</a></li>
			</ul>
			<h1 id="_idParaDest-151"><a id="_idTextAnchor155"/>Compiling third-party software</h1>
			<p>Sometimes, a package for a certain application is just not available – either nobody bothered to create it, or that application is so old that it's obsolete and nobody wants to do it. Either way, if an application is useful to us, there's no reason why we shouldn't try to find its source code and compile it. </p>
			<p>Compiling software from source code<a id="_idIndexMarker541"/> can sometimes be like dark magic, and we have a good example coming up very soon. Sometimes it works without any real effort, and we are going to show you an example of that, too. The main distinction between those two scenarios seems to be the all-important dependencies and their version. Also, there's a lot of software for Linux that needs to be compiled in a specific sequence. A perfect example of that is the LAMP stack. After installing Linux, if you want to compile Apache, MySQL, and PHP, you had better do it in the correct order. Otherwise, your keyboard might find its way to the garbage can sooner than you planned. Let's see what we can do about this so that it doesn't happen.</p>
			<h2 id="_idParaDest-152"><a id="_idTextAnchor156"/>Getting ready</h2>
			<p>We can use any machine for this recipe, but the most common scenario is a default installation of some Linux distribution with a lot of packages missing. So, let's install a fresh Ubuntu machine, and let's call it <strong class="source-inline">compile1</strong>, just for fun. So, this one is going to be just a Vanilla Ubuntu installation that will need all of the configurations in order for the compilation process to work. </p>
			<h2 id="_idParaDest-153"><a id="_idTextAnchor157"/>How to do it…</h2>
			<p>We'll start with an easy example<a id="_idIndexMarker542"/> of a package that's very easy to compile and won't give us a massive headache. Let's compile the <strong class="source-inline">joe</strong> editor and show you what we're talking about. We'll start with the usual procedure:</p>
			<p class="source-code">apt-get -y update</p>
			<p class="source-code">apt-get -y upgrade</p>
			<p>Just to be on the safe side, to get our machine ready for the compilation process, let's use this command to install a large selection of packages:</p>
			<p class="source-code">apt-get -y install autoconf g++ subversion linux-source linux-headers-'uname -r' build-essential tofrodos git-core subversion dos2unix make gcc automake cmake checkinstall git-core dpkg-dev fakeroot pbuilder dh-make debhelper devscripts patchutils quilt git-buildpackage pristine-tar git yasm checkinstall cvs mercurial</p>
			<p>As a result, our Ubuntu machine should now be ready for any compilation effort. Let's now download <strong class="source-inline">joe</strong> source:</p>
			<p class="source-code">wget https://kumisystems.dl.sourceforge.net/project/joe-editor/JOE%20sources/joe-4.6/joe-4.6.tar.gz</p>
			<p>We prefer to keep things tidy in the root's home directory, so let's just create a folder for compilation purposes. Let's call it <strong class="source-inline">source</strong> and move <strong class="source-inline">joe</strong> source there, and then open its <strong class="source-inline">tar.gz</strong> file with the source code:</p>
			<p class="source-code">mkdir source</p>
			<p class="source-code">mv joe-4.6.tar.gz source</p>
			<p class="source-code">cd source</p>
			<p class="source-code">tar zfpx joe-4.6.tar.gz </p>
			<p>The last command (<strong class="source-inline">tar</strong>) is going to open another subfolder (<strong class="source-inline">joe-4.6</strong>) with all the necessary files for the compilation process located there. So, let's change the directory to <strong class="source-inline">joe-4.6</strong> and start the configuration process:</p>
			<p class="source-code">cd joe-4.6</p>
			<p class="source-code">./configure</p>
			<p>If everything goes well, we should have something<a id="_idIndexMarker543"/> like this as a result (shortened for formatting reasons):</p>
			<div>
				<div id="_idContainer178" class="IMG---Figure">
					<img src="Images/Figure_6.33_B16269.jpg" alt="Figure 6.33 – Configuration step concluded successfully&#13;&#10;" width="802" height="438"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.33 – Configuration step concluded successfully</p>
			<p>The configuration process has finished successfully. Let's now continue with the actual compilation process, for which we need the <strong class="source-inline">make</strong> command (hence the reason why we installed all of those packages, <strong class="source-inline">make</strong> being one of them), and we can use some additional options to speed the process up. My Ubuntu machine has four processors, so we can use <strong class="source-inline">make -j4</strong> to speed the process up (so that the compilation process takes all of the available cores, not just one). After a couple<a id="_idIndexMarker544"/> of seconds, the compilation process should finish similar to this:</p>
			<div>
				<div id="_idContainer179" class="IMG---Figure">
					<img src="Images/Figure_6.34_B16269.jpg" alt="Figure 6.34 – Compilation process also concluded successfully&#13;&#10;" width="1266" height="663"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.34 – Compilation process also concluded successfully</p>
			<p>The final step in this process is to install our compiled application. We do that by using the following command:</p>
			<p class="source-code">make install</p>
			<p>After this command finishes its job and installs <strong class="source-inline">joe</strong> system-wide, we should be able to start <strong class="source-inline">joe</strong> from the command line and edit our files. We can also create a <strong class="source-inline">deb</strong> package out of this installation by using the <strong class="source-inline">checkinstall</strong> package. When we run it, it's going to ask us for a package description. We can type in something like <strong class="source-inline">Joe editor v4.6</strong> and be done with it. At the end of this process, we're going to get a <strong class="source-inline">deb</strong> package with installation files that are required to deploy <strong class="source-inline">joe</strong> on other Ubuntu servers. </p>
			<p>That wasn't so bad, was it? Yes, we had a couple of steps to do, but overall, it was a very simple process.</p>
			<p>Now let's do another example that's the complete opposite of what we'd call a <em class="italic">very simple process</em>. Let's try to compile the Apache web server. We're going to use the latest version at the time of writing (2.4.49), located at <strong class="source-inline">https://dlcdn.apache.org//httpd/httpd-2.4.49.tar.gz</strong>, by using the same procedure – download the source<a id="_idIndexMarker545"/> to our source directory, open the source archive, and start with the configuration process. Let's see what happens:</p>
			<div>
				<div id="_idContainer180" class="IMG---Figure">
					<img src="Images/Figure_6.35_B16269.jpg" alt="Figure 6.35 – configure script in action – Missing dependencies – Example 1&#13;&#10;" width="828" height="357"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.35 – configure script in action – Missing dependencies – Example 1</p>
			<p>Oops! Not going to happen. So then, we go to Dr. Google and check what to do if the message received is <em class="italic">APR is not found</em>. We'll end up finding some articles that state that we should install some additional packages, so let's do that:</p>
			<p class="source-code">apt-get -y install libapr1-dev libaprutil1-dev</p>
			<p>Try to run the <strong class="source-inline">configure</strong> script again, and check<a id="_idIndexMarker546"/> the results:</p>
			<div>
				<div id="_idContainer181" class="IMG---Figure">
					<img src="Images/Figure_6.36_B16269.jpg" alt="Figure 6.36 – configure script in action – Missing dependencies – Example 2&#13;&#10;" width="1258" height="458"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.36 – configure script in action – Missing dependencies – Example 2</p>
			<p>Another package seems to be missing. And when we – just as an example – try to find a package such as <strong class="source-inline">libpcre</strong> in the <strong class="source-inline">apt</strong> cache, this is what we're going to get:</p>
			<div>
				<div id="_idContainer182" class="IMG---Figure">
					<img src="Images/Figure_6.37_B16269.jpg" alt="Figure 6.37 – Trying to figure out which package is missing&#13;&#10;" width="1231" height="535"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.37 – Trying to figure out which package is missing</p>
			<p>Now the question becomes how to know which packages to install from this list? What usually happens is that people lose patience and write a command such as this:</p>
			<p class="source-code">apt-get -y install *pcre* </p>
			<p>And that's going to install <a id="_idIndexMarker547"/>more than 200 packages on our machine. If we're security-conscious, that's really not the way to go. It's easy for people like us as we've done this a thousand times, but for normal people, this gets really frustrating really quick. So, let's now install the required package and its dependencies:</p>
			<p class="source-code">apt-get -y install libpcre3-dev</p>
			<p>Before we do the actual configuration/compiling, we do have to mention one thing. Nowadays, a lot of the app code is shared via concepts such as Git. Most of these repositories are hosted by app coders, and usually have additional instructions for dependencies and how to deploy them. However, if we download a source code from a non-Git-like resource, we usually get more information about compiling that source code in files such as <strong class="source-inline">INSTALL</strong> after we extract the source archive. So, we need to make sure that we check these resources prior to trying to compile an app from some source code.</p>
			<p>Run the rest of our procedure in a serial fashion:</p>
			<p class="source-code">./configure; make; make install</p>
			<p>Luckily, there will be no more<a id="_idIndexMarker548"/> questions, as we can see in the following screenshot:</p>
			<div>
				<div id="_idContainer183" class="IMG---Figure">
					<img src="Images/Figure_6.38_B16269.jpg" alt="Figure 6.38 – Compilation and installation completed successfully&#13;&#10;" width="714" height="641"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.38 – Compilation and installation completed successfully</p>
			<p>We deliberately chose a package that's <em class="italic">a bit</em> annoying, but not <em class="italic">over-the-top</em> annoying. There are applications out there that can make us spend hours and hours figuring out all of the dependencies so that we can compile a single package. </p>
			<h2 id="_idParaDest-154"><a id="_idTextAnchor158"/>How it works…</h2>
			<p>Now that we have got the step-by-step process out of the way, let's discuss the specifics of how all of this works and fits together. It's pretty obvious that there are multiple steps to the process and that each and every one of them is significant. And it is – one can't be done without the other. So, let's now discuss all of the commands that we used and describe how they work.</p>
			<p>The first phase in our compilation process starts with the <strong class="source-inline">./configure</strong> command. It's actually not a command <em class="italic">per se</em>; it's a <strong class="source-inline">shell</strong> script that almost all source code packages have. This script is there<a id="_idIndexMarker549"/> to make sure that the environment is ready for the compilation process – check included files, libraries, dependencies, everything needed for the source code compilation process. It checks for the necessary compiler and its libraries to make sure that the stage is set up for the next part of the process. It also writes down some configuration files that are going to be used by <strong class="source-inline">make</strong> when the build process starts.</p>
			<p>The next part of the process involves using the <strong class="source-inline">make</strong> command. By using the configuration files created by the <strong class="source-inline">configure</strong> script and other files, it starts compiling source code. One of these files is called <strong class="source-inline">Makefile</strong>, and it contains a lot of information about what <strong class="source-inline">make</strong> needs to do – which files to compile and how, which compiler flags to use, how to link all of the compiled code into the resulting binaries, and more besides. </p>
			<p>The last part of the process is not compiling a source code <em class="italic">per se</em> – it's about installing the compiled code on our Linux machine. By using relevant information in the configuration files, <strong class="source-inline">make install</strong> installs all of the files necessary for our command to work – libraries, binaries, man pages, documentation, and so on. If the compilation process from the previous part concludes successfully, installation is just about making sure that the compiled application is available to be used.</p>
			<p>That was the last recipe in this chapter. The next chapter is about network-based file synchronization, and as part of those recipes, we are going to go much deeper into the inner workings of <strong class="source-inline">vsftpd</strong>, which we just kind of touched on in this chapter without giving it much time or space. Also, we are going to discuss <strong class="source-inline">ssh</strong> and <strong class="source-inline">scp</strong>, two ways of securely connecting to servers and transferring files between servers, and <strong class="source-inline">rsync</strong>, a file synchronization methodology. Stay tuned for the next chapter.</p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor159"/>There's more…</h2>
			<p>If you need to learn<a id="_idIndexMarker550"/> more about <strong class="source-inline">vsftpd</strong>, make<a id="_idIndexMarker551"/> sure that you check out the following links:</p>
			<ul>
				<li><strong class="bold">How to compile and run C/C++ code in Linux</strong>: <a href="https://www.cyberciti.biz/faq/howto-compile-and-run-c-cplusplus-code-in-linux/%0D">https://www.cyberciti.biz/faq/howto-compile-and-run-c-cplusplus-code-in-linux/</a></li>
				<li><strong class="bold">Compiling things on Ubuntu the easy way</strong>: <a href="https://help.ubuntu.com/community/CompilingEasyHowTo%0D">https://help.ubuntu.com/community/CompilingEasyHowTo</a></li>
			</ul>
		</div>
	</div></body></html>