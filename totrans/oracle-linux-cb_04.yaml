- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Creating and Managing Single-Instance Filesystems
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和管理单实例文件系统
- en: 'Without data, there is no reason for a system to exist, and with that thought,
    the data has to live somewhere. In this chapter, we will cover the two most popular
    filesystems used to manage data that is local to the server: **B-Tree File System**
    (**Btrfs**, pronounced *Butter F S*) and **eXtended File System** (**XFS**, pronounced
    *X* *F S*).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 没有数据，系统就没有存在的意义，基于这一点，数据必须存储在某个地方。在本章中，我们将讨论两种最流行的文件系统，它们用于管理本地服务器上的数据：**B树文件系统**（**Btrfs**，发音为*Butter
    F S*）和**扩展文件系统**（**XFS**，发音为*X* *F S*）。
- en: These are single-instance filesystems, which are basically filesystems that
    are only mounted on a single server at any one time. There are also multi-instance
    filesystems that are mounted on multiple systems at the same time. Common examples
    are **Oracle Clustered File System version 2** (**OCFS2**) and **Global File System
    2** (**GFS2**). All of these examples use shared block storage for the underlying
    storage.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是单实例文件系统，基本上是只在某一时刻挂载在单个服务器上的文件系统。也有多实例文件系统，可以同时挂载在多个系统上。常见的例子有**Oracle集群文件系统版本2**（**OCFS2**）和**全局文件系统2**（**GFS2**）。所有这些例子都使用共享块存储作为底层存储。
- en: Additionally, there is **Ceph**, which is not an acronym, but instead a reference
    to **cephalopod**. This is because Ceph is a distributed architecture that stores
    data on all nodes of a Ceph cluster. This allows Ceph to offer scalable storage
    with some additional complexity. **Gluster** is another example of a distributed
    filesystem.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有**Ceph**，它不是一个首字母缩略词，而是指**头足类动物**。这是因为Ceph是一种分布式架构，能够将数据存储在Ceph集群的所有节点上。这使得Ceph能够提供可扩展的存储，尽管它有一些额外的复杂性。**Gluster**是另一种分布式文件系统的例子。
- en: Note
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Why not **ZFS**? Because Btrfs and XFS are built into the Oracle Linux **Unbreakable
    Enterprise Kernel** (**UEK**), and ZFS is not available outside of third-party
    repositories.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不使用**ZFS**？因为Btrfs和XFS是内置在Oracle Linux的**不可破坏企业内核**（**UEK**）中的，而ZFS在第三方仓库之外无法使用。
- en: 'We will cover the following recipes that will help you understand and manage
    local filesystems:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下食谱，帮助你理解和管理本地文件系统：
- en: What you need to know about local filesystems
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于本地文件系统，你需要知道的
- en: Btrfs – creating, resizing, and monitoring
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Btrfs – 创建、调整大小和监控
- en: Btrfs – subvolumes, snapshots, quotas, and more
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Btrfs – 子卷、快照、配额等
- en: Protecting data with mdadm – a software RAID solution
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用mdadm保护数据 – 一种软件RAID解决方案
- en: Playing with logical volume management
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作逻辑卷管理
- en: XFS – creating, modifying, and more
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XFS – 创建、修改等
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this recipe, you will need an **Oracle Linux 8** system. As with most of
    these recipes, a VM on your desktop using a desktop virtualization product such
    as **Oracle VirtualBox** is recommended. A small VM with two cores, 2 GB RAM,
    and a few free gigabytes of disk space is fine. You will also need some additional
    disks assigned to the VM, ideally at least five equally sized disks. Ideally,
    before you start, patch your system to the latest packages available. This only
    takes a few minutes and can save a ton of time when troubleshooting issues caused
    by a bug.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本篇，你需要一个**Oracle Linux 8**系统。像大多数这些食谱一样，推荐在桌面上使用如**Oracle VirtualBox**等桌面虚拟化产品的虚拟机。一个小型虚拟机，具有两个核心、2
    GB内存和几个空闲的磁盘空间就足够了。你还需要为虚拟机分配一些额外的磁盘，理想情况下至少五个大小相等的磁盘。理想情况下，在开始之前，先将系统补丁更新到最新版本。这个过程只需要几分钟，并且在解决由错误引起的问题时能节省大量时间。
- en: Many of the recipes in this book have their related configuration files available
    on GitHub, located at [https://github.com/PacktPublishing/Oracle-Linux-Cookbook](https://github.com/PacktPublishing/Oracle-Linux-Cookbook).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的许多食谱都提供了相关的配置文件，可以在GitHub上找到，地址为[https://github.com/PacktPublishing/Oracle-Linux-Cookbook](https://github.com/PacktPublishing/Oracle-Linux-Cookbook)。
- en: What you need to know about local filesystems
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于本地文件系统，你需要知道的
- en: This recipe will discuss the differences between local and remote filesystems,
    as well as the core differences between Btrfs and ZFS.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本篇将讨论本地文件系统与远程文件系统之间的区别，以及Btrfs和ZFS之间的核心差异。
- en: The backbone of an **operating system** (**OS**) is the local filesystem. It
    enables efficient storage and management of files and directories on a computer
    or server using a hierarchical structure. This structure allows users and programs
    to easily create, modify, and access files on local storage devices such as hard
    disks, solid-state drives, and storage **logical unit numbers** (**LUNs**) from
    a local **storage area network** (**SAN**) or cloud provider. These filesystems
    are designed specifically for file and folder management efficiency, protecting
    files from accidental deletion or corruption. They come equipped with features
    such as file permissions, ownership, and access control, which provide users with
    utmost security and privacy. In comparison to remote filesystems, local filesystems
    offer superior performance, though files are not available on other systems unless
    paired with a remote filesystem technology. Notable examples of local Linux filesystems
    include Btrfs, XFS, ext4, fat32, and even ZFS.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作系统**（**OS**）的骨干是本地文件系统。它通过分层结构实现了计算机或服务器上文件和目录的高效存储和管理。这种结构使用户和程序可以轻松地在本地存储设备（如硬盘、固态硬盘以及来自本地**存储区域网络**（**SAN**）或云服务提供商的**逻辑单元号**（**LUNs**））上创建、修改和访问文件。这些文件系统专门设计用于文件和文件夹管理的高效性，能够保护文件免受意外删除或损坏。它们配备了文件权限、所有权和访问控制等功能，提供用户最高的安全性和隐私性。与远程文件系统相比，本地文件系统提供了更优的性能，尽管文件除非与远程文件系统技术配对，否则无法在其他系统上访问。Linux本地文件系统的典型例子包括Btrfs、XFS、ext4、fat32，甚至ZFS。'
- en: Note
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: While ZFS is a local filesystem, it is not included in the kernel and needs
    to be added using software from [https://zfsonlinux.org](https://zfsonlinux.org).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ZFS是一个本地文件系统，但它没有包含在内核中，需要通过[https://zfsonlinux.org](https://zfsonlinux.org)提供的软件来添加。
- en: A remote filesystem allows you to access files and directories on a remote server
    through a network. This system provides the convenience of accessing and manipulating
    files on a remote machine as if they were stored locally, eliminating the need
    to transfer them physically. Remote filesystems are widely used in distributed
    computing environments where multiple computers or servers need to share data
    and resources. They are also valuable in cloud computing and web hosting environments
    where data is stored remotely and accessed over the internet. However, it’s important
    to note that using remote filesystems can impact performance when sharing files
    between multiple servers over a network.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 远程文件系统使你能够通过网络访问远程服务器上的文件和目录。这个系统提供了便捷的方式，可以像本地存储一样访问和操作远程机器上的文件，从而消除了物理传输文件的需求。远程文件系统在分布式计算环境中被广泛使用，在这些环境中，多台计算机或服务器需要共享数据和资源。它们在云计算和网站托管环境中也非常有价值，因为数据存储在远程并通过互联网访问。然而，需要注意的是，在通过网络共享文件时，使用远程文件系统可能会影响性能，尤其是在多个服务器之间共享文件时。
- en: Examples of remote filesystems include **Network File System** (**NFS**), **Server
    Message Block** (**SMB**), and **Common Internet File System** (**CIFS**), which
    are widely used in Unix, Linux, and Windows environments, respectively. Other
    popular remote filesystems include **s3fs**, which allows users to access files
    securely over cloud-based object storage.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 远程文件系统的例子包括**网络文件系统**（**NFS**）、**服务器消息块**（**SMB**）和**公共互联网文件系统**（**CIFS**），这些在Unix、Linux和Windows环境中广泛使用。其他流行的远程文件系统还包括**s3fs**，它允许用户通过基于云的对象存储安全地访问文件。
- en: For optimal performance when managing MySQL, Postgres, and Oracle databases,
    it’s highly recommended to utilize local filesystems instead of network filesystems.
    This strategy can also be effectively applied to the OS.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在管理MySQL、Postgres和Oracle数据库时，建议使用本地文件系统而非网络文件系统，以确保最佳性能。这个策略也可以有效地应用于操作系统。
- en: Getting ready
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You need to understand the core differences between the two filesystems. The
    XFS filesystem is surprisingly much older than many admins realize. It started
    back in 1993, as the filesystem for the **Silicon Graphics IRIX** OS, and was
    ported over to Linux in 2001\. Btrfs is much newer, being developed in 2007 by
    Oracle (as an open source project) for Linux. Btrfs is also more than a filesystem,
    as it includes the volume manager, data redundancy, and filesystem functionality
    in one technology.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要理解这两种文件系统的核心差异。XFS文件系统比许多管理员意识到的要老得多。它最早起始于1993年，作为**硅图形IRIX**操作系统的文件系统，并于2001年移植到Linux。Btrfs则要新得多，2007年由Oracle（作为开源项目）为Linux开发。Btrfs不仅仅是一个文件系统，它还集成了卷管理器、数据冗余和文件系统功能于一体。
- en: With XFS, you need to combine it with a logical volume manager for dynamic volumes
    and also `mdadm` command) to provide for fault tolerance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 XFS 时，您需要将其与逻辑卷管理器结合使用，以便动态管理卷，还需要使用 `mdadm` 命令来提供容错能力。
- en: 'With Btrfs, you have the choice of five types of RAID volumes. What you pick
    is based on your use case as it’s a balance between performance, disk space required,
    and the usable capacity of the volume. The details are in the following table:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Btrfs，您可以选择五种类型的 RAID 卷。选择哪种取决于您的使用案例，因为它是性能、所需磁盘空间和卷的可用容量之间的平衡。详细信息见下表：
- en: '| **Type** | **Description** | **Performance** | **Redundance** | **Capacity**
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **类型** | **描述** | **性能** | **冗余性** | **容量** |'
- en: '| RAID 0 | Striping across disks | Best | None | 100% |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| RAID 0 | 跨磁盘条带化 | 最佳 | 无 | 100% |'
- en: '| RAID 1 | Mirror two disks | Good | 1 drive failure | 50% |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| RAID 1 | 镜像两个磁盘 | 良好 | 1 个驱动器故障 | 50% |'
- en: '| RAID 10 | Mirrored then striped, min of 4 disks | Almost the best | 1 drive
    failure | 50% |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| RAID 10 | 先镜像再条带化，最少 4 个磁盘 | 几乎最好 | 1 个驱动器故障 | 50% |'
- en: '| RAID1C3 | 3 copies of the metadata, min of 3 disks | Average | 2 drive failures
    | 66% |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| RAID1C3 | 3 份元数据，最少 3 个磁盘 | 一般 | 2 个驱动器故障 | 66% |'
- en: '| RAID1C4 | 4 copies of the metadata, min of 4 disks | Lowest | 3 drive failures
    | 75% |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| RAID1C4 | 4 份元数据，最少 4 个磁盘 | 最低 | 3 个驱动器故障 | 75% |'
- en: Table 4.1 – Btrfs RAID options
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1 – Btrfs RAID 选项
- en: Both systems have the same limitation for the maximum filesystem size of 8 exabytes!
    But Btrfs also adds features such as snapshots, transparent compression, integrated
    checksum-based data integrity, and rollback capabilities. XFS is not left out
    though, with higher performance through I/O threads and more bandwidth, though
    these advantages may not be realized once you integrate XFS with an LVM and RAID
    technology. One other major difference is that Btrfs requires that you use the
    UEK, though XFS works well with both UEKs and **Red Hat Compatible** **Kernels**
    (**RHCKs**).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 两种系统的最大文件系统大小限制相同，都是 8 exabytes！但是，Btrfs 还增加了快照、透明压缩、基于校验和的数据完整性和回滚能力等功能。而 XFS
    也不逊色，通过 I/O 线程和更高的带宽提供更高的性能，尽管在将 XFS 与 LVM 和 RAID 技术集成后，这些优势可能无法得到充分体现。另一个主要区别是
    Btrfs 要求使用 UEK，而 XFS 则在 UEK 和**红帽兼容内核**（**RHCK**）下均能良好工作。
- en: How to do it…
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: Oracle Linux by default uses the XFS filesystem, but when doing the installation,
    you can use Btrfs as the root filesystem. If you want to use XFS as the boot filesystem,
    install it as you normally would. If you want to use Btrfs, then you should continue.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle Linux 默认使用 XFS 文件系统，但在安装时，您可以选择使用 Btrfs 作为根文件系统。如果您想使用 XFS 作为启动文件系统，按常规方式安装即可。如果您想使用
    Btrfs，则应继续进行。
- en: Note
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Your boot filesystem can be different from the data filesystems on the server.
    You can easily have the root use XFS and the data filesystem use Btrfs, or vice
    versa.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您的启动文件系统可以与服务器上的数据文件系统不同。您可以轻松地让根文件系统使用 XFS，而数据文件系统使用 Btrfs，或反之亦然。
- en: 'The easiest way to run Btrfs is to pick it when doing an installation using
    the UEK boot disk. This will let you choose Btrfs as the destination filesystem.
    When running the install, select **Install Destination**, and then select a custom
    storage configuration. This will then give you the manual partitioning option
    where you can use the dropdown and select **Btrfs**, as seen in the following
    screenshot:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 Btrfs 最简单的方法是在使用 UEK 启动盘进行安装时选择它。这样，您可以选择 Btrfs 作为目标文件系统。安装时，选择 **安装目标**，然后选择自定义存储配置。这时，您将获得手动分区选项，可以通过下拉菜单选择
    **Btrfs**，如下面的截图所示：
- en: '![Figure 4.1 – Btrfs selection](img/B18349_04_01.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – Btrfs 选择](img/B18349_04_01.jpg)'
- en: Figure 4.1 – Btrfs selection
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – Btrfs 选择
- en: 'When setting up the custom configuration, you can add additional directories
    for `/var` or `/var/tmp` (a **secure technical implementation guide** (**STIG**)
    requirement). These are actually not just directories, but subvolumes of the main
    volume. This is why they show the same available space:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置自定义配置时，可以为 `/var` 或 `/var/tmp` 添加额外的目录（这是**安全技术实施指南**（**STIG**）的要求）。这些实际上不仅仅是目录，而是主卷的子卷。因此，它们显示的可用空间相同：
- en: '![Figure 4.2 – Btrfs mountpoints](img/B18349_04_02.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – Btrfs 挂载点](img/B18349_04_02.jpg)'
- en: Figure 4.2 – Btrfs mountpoints
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – Btrfs 挂载点
- en: This is because with Btrfs, they all use the same volume and have the same usable
    disk space. We can limit this later using quotas.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为使用 Btrfs 时，它们都使用相同的卷并具有相同的可用磁盘空间。我们可以稍后通过配额来限制这一点。
- en: Finish the install using your normal settings for network and software source,
    though as a note, you will likely need to set **Installation Source** as a URL
    or local network share. You will also need to add the UEK repository if running
    8.7 or earlier.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用常规的网络和软件源设置完成安装，但需要注意的是，你可能需要将 **安装源** 设置为 URL 或本地网络共享。如果你使用的是 8.7 或更早版本，还需要添加
    UEK 仓库。
- en: Once the system is booted, you will see that it is now using Btrfs. This can
    be checked once the system is up.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 系统启动后，你将看到它现在正在使用 Btrfs。系统启动后可以检查这一点。
- en: How it works…
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'You can check the filesystem in several ways, the easiest being by checking
    `/etc/fstab` to see how the filesystem was mounted. This is seen in the following
    screenshot:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过几种方式检查文件系统，最简单的是检查 `/etc/fstab` 以查看文件系统是如何挂载的。如下图所示：
- en: '![Figure 4.3 – Btrfs fstab example](img/B18349_04_03.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – Btrfs fstab 示例](img/B18349_04_03.jpg)'
- en: Figure 4.3 – Btrfs fstab example
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – Btrfs fstab 示例
- en: 'You can also use the `df` command with the `T` option to show the filesystem
    type. Running the following command will show you this info:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用带 `T` 选项的 `df` 命令来显示文件系统类型。运行以下命令将显示这些信息：
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will show the filesystem type for each mounted file, as seen in the following
    figure:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示每个挂载文件的文件系统类型，如下图所示：
- en: '![Figure 4.4 – df -T with Btrfs filesystems](img/B18349_04_04.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 使用 Btrfs 文件系统的 df -T 输出](img/B18349_04_04.jpg)'
- en: Figure 4.4 – df -T with Btrfs filesystems
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 使用 Btrfs 文件系统的 df -T 输出
- en: Btrfs – creating, resizing, and monitoring
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Btrfs – 创建、调整大小和监控
- en: In this recipe, we will create a new RAIDed Btrfs volume and filesystem, using
    multiple disks for fault-tolerant storage. We will then add a new LUN, growing
    the filesystem. We will wrap up by modifying the filesystem to compress the data!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本步骤中，我们将创建一个新的 RAID 磁盘阵列 Btrfs 卷和文件系统，使用多个磁盘实现容错存储。然后我们将添加新的 LUN，扩展文件系统。最后，我们将修改文件系统以压缩数据！
- en: Getting ready
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To get started, I added five 10 GB drives to the OS. These will be used to
    build a new RAID1C4 volume. I can see these new devices by using the `fdisk -l`
    command, grepping for `GiB` using the following command:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我向操作系统添加了五个 10 GB 的硬盘。它们将用于构建一个新的 RAID1C4 卷。可以通过使用 `fdisk -l` 命令并结合 `grep`
    查找 `GiB`，使用以下命令来查看这些新设备：
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is seen in the following figure:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如图所示：
- en: '![Figure 4.5 – fdisk output](img/B18349_04_05.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5 – fdisk 输出](img/B18349_04_05.jpg)'
- en: Figure 4.5 – fdisk output
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – fdisk 输出
- en: Here, we can see that the 10 GB devices are `sdb`, `sdc`, `sbd`, `sbe`, and
    `sbf`. We will need this info to make the Btrfs volume.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到这五个 10 GB 的设备分别是 `sdb`、`sdc`、`sbd`、`sbe` 和 `sbf`。我们将在创建 Btrfs 卷时使用这些信息。
- en: How to do it…
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: Now that we know the devices, let’s manually create a RAID1C3 volume. We will
    use all five devices in a RAID1C3 configuration and name the volume `data`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了设备信息，接下来手动创建一个 RAID1C3 卷。我们将使用所有五个设备以 RAID1C3 配置，并将该卷命名为 `data`。
- en: 'We will then use the following command to make the volume:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用以下命令来创建该卷：
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Please refer to the following figure to view the output:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下图示查看输出：
- en: '![Figure 4.6 – mkfs.btrfs output](img/B18349_04_06.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – mkfs.btrfs 输出](img/B18349_04_06.jpg)'
- en: Figure 4.6 – mkfs.btrfs output
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – mkfs.btrfs 输出
- en: Note
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When mounting a Btrfs volume, you normally use the first device in the volume
    or the UUID. The UUID is reported by `mkfs.btrfs` when the volume is created.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在挂载 Btrfs 卷时，通常使用卷中的第一个设备或 UUID。UUID 是在创建卷时由 `mkfs.btrfs` 报告的。
- en: 'Next, let’s mount this in `/data`. Make the `/data` directory, then mount it
    with the following commands:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将它挂载到 `/data` 目录。首先创建 `/data` 目录，然后使用以下命令进行挂载：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Optional, though highly recommended, is to add this to the `fstab` file. With
    this example, we are using the UUID of the volume, and since data has no subvolume,
    the `subvol` parameter is defined but left blank:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 可选，但强烈推荐的是将其添加到 `fstab` 文件中。此示例中，我们使用的是卷的 UUID，并且由于数据没有子卷，`subvol` 参数已定义但留空：
- en: '![Figure 4.7 – Sample fstab using UUID](img/B18349_04_07.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 使用 UUID 的 fstab 示例](img/B18349_04_07.jpg)'
- en: Figure 4.7 – Sample fstab using UUID
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 使用 UUID 的 fstab 示例
- en: How it works…
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'Now that we have a mounted volume, let’s do a few things with it! First, we
    can use the `btrfs` command to check several things. The first is to check the
    device’s health, which is useful to see whether the RAID has any failing devices.
    The `btrfs stats /$DEVICE` command is used to show the status. Don’t forget to
    replace `$DEVICE` with the actual Btrfs device you are checking:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个已挂载的卷，让我们对其进行一些操作！首先，我们可以使用 `btrfs` 命令来检查几件事情。首先是检查设备的健康状况，这对于查看RAID是否有任何失败设备非常有用。使用
    `btrfs stats /$DEVICE` 命令来显示状态。不要忘记将 `$DEVICE` 替换为您正在检查的实际 Btrfs 设备：
- en: '![Figure 4.8 – Healthy devices](img/B18349_04_08.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 健康设备](img/B18349_04_08.jpg)'
- en: Figure 4.8 – Healthy devices
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 健康设备
- en: When a device starts to fail, you should start to see errors in this report.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当设备开始故障时，您应该在此报告中看到错误。
- en: 'Next up, we will add a few more devices to the volume. Four more 10 GB disks
    were added: `sdg`, `sdh`, `sdi`, and `sdj`.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将向卷中添加几个设备。又添加了四个 10 GB 的磁盘：`sdg`、`sdh`、`sdi` 和 `sdj`。
- en: 'Before we add the device, we can see that `/data` has 50 GB of usable raw space.
    This is seen using the following command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加设备之前，我们可以看到 `/data` 有 50 GB 可用的原始空间。使用以下命令可以看到：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output from the command is shown in the following screenshot:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 命令的输出显示在以下截图中：
- en: '![Figure 4.9 – Btrfs filesystem usage](img/B18349_04_09.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9 – Btrfs 文件系统使用情况](img/B18349_04_09.jpg)'
- en: Figure 4.9 – Btrfs filesystem usage
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – Btrfs 文件系统使用情况
- en: Here we can see the stats, mainly the 50 GB of free raw space, as well as the
    other metrics, including the space allocated to each device in the volume and
    which devices have the metadata.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们可以看到统计数据，主要是 50 GB 的免费原始空间，以及其他指标，包括卷中每个设备分配的空间以及哪些设备具有元数据。
- en: 'Next, let’s add the four new devices. This is done with the `btrfs device`
    `add` command:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们添加四个新设备。这可以通过 `btrfs device add` 命令完成：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Do this for each device being added to the volume, or bulk add them with `/dev/sd[a-z]`,
    replacing `a` and `z` with the appropriate range. When done, you can check using
    the usage option, as seen in the following sample:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个要添加到卷中的设备都要执行此操作，或者使用 `/dev/sd[a-z]` 批量添加它们，替换 `a` 和 `z` 为适当的范围。完成后，您可以使用使用选项检查使用情况，如以下示例所示：
- en: '![Figure 4.10 – Btrfs devices added](img/B18349_04_10.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.10 – 添加的 Btrfs 设备](img/B18349_04_10.jpg)'
- en: Figure 4.10 – Btrfs devices added
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 添加的 Btrfs 设备
- en: 'You will now see the device at 90 GB. Now, as space in `/data` gets consumed,
    you should start to see the available space go down, as well as the distribution
    of data against the individual disks:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您将看到设备达到了 90 GB。现在，随着 `/data` 中的空间被消耗，您应该开始看到可用空间减少，以及数据分布在各个磁盘上的情况：
- en: '![Figure 4.11 – Btrfs space used](img/B18349_04_11.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.11 – Btrfs 使用空间](img/B18349_04_11.jpg)'
- en: Figure 4.11 – Btrfs space used
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – Btrfs 使用空间
- en: 'For the last example, we will be removing a device to free up space, and then
    rebalancing the data. To delete a physical device, use the `btrfs device delete`
    command, passing the device mountpoint:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最后一个示例，我们将删除一个设备以释放空间，然后重新平衡数据。要删除物理设备，请使用 `btrfs device delete` 命令，并传递设备挂载点：
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will remove the device:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这将移除设备：
- en: '![Figure 4.12 – Device removal](img/B18349_04_12.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.12 – 设备移除](img/B18349_04_12.jpg)'
- en: Figure 4.12 – Device removal
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12 – 设备移除
- en: 'Once the device is removed, rerun the usage report. What you will now see is
    the remaining devices, and which data is on which device:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 设备移除后，重新运行使用情况报告。现在您将看到剩余的设备以及哪些数据在哪个设备上：
- en: '![Figure 4.13 – Unbalanced usage](img/B18349_04_13.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.13 – 不平衡使用情况](img/B18349_04_13.jpg)'
- en: Figure 4.13 – Unbalanced usage
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – 不平衡使用情况
- en: 'While it may appear to be a minor issue, it has the potential to cause complications
    down the line. Fortunately, the solution is simple – a system rebalance. This
    is done using the `balance` option in the `btrfs` command. The following command
    will be used to balance the `/``data` filesystem:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这可能看起来是个小问题，但它有可能引起后续的复杂问题。幸运的是，解决方案很简单 – 系统重新平衡。这可以通过 `btrfs` 命令中的 `balance`
    选项完成。以下命令将用于平衡 `/data` 文件系统：
- en: '[PRE7]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This command will then rebalance the data chunks, and when done, the usage
    will show the data balanced across the disks:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然后这个命令会重新平衡数据块，完成后，使用情况将显示数据均衡分布在各个磁盘上：
- en: '![Figure 4.14 – Balanced usage](img/B18349_04_14.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.14 – 平衡使用情况](img/B18349_04_14.jpg)'
- en: Figure 4.14 – Balanced usage
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.14 – 平衡使用情况
- en: Note
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To ensure a well-balanced distribution of data, it is recommended to always
    balance your system when adding or removing devices, even though there may be
    slight variations. This practice is essential for maintaining an optimally performing
    filesystem. The `btrfsmaintenance` package in the `ol8_developer` repo is a great
    tool for automating all the required Btrfs maintenance tasks.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保数据分布均衡，建议在添加或移除设备时始终对系统进行平衡操作，尽管可能会有轻微的变化。这一做法对于维持最佳性能的文件系统至关重要。`ol8_developer`
    仓库中的 `btrfsmaintenance` 包是一个很好的工具，可以自动化所有必要的 Btrfs 维护任务。
- en: Btrfs – subvolumes, snapshots, quotas, and more
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Btrfs – 子卷、快照、配额及更多
- en: Btrfs can do so much more than the older XFS technology. This includes subvolumes,
    snapshots, and quotas. Btrfs subvolumes are an exceptional tool that allows users
    to create multiple snapshots or subfilesystems within a single Btrfs filesystem.
    These subvolumes are displayed as distinct directories in the filesystem hierarchy,
    but they utilize the same storage space and can be managed independently.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Btrfs 比较旧的 XFS 技术能做的更多。这包括子卷、快照和配额。Btrfs 子卷是一种卓越的工具，允许用户在单一 Btrfs 文件系统内创建多个快照或子文件系统。这些子卷作为文件系统层次结构中的独立目录显示，但它们使用相同的存储空间，并且可以独立管理。
- en: The flexibility and versatility of subvolumes make them ideal for various purposes,
    such as creating backups or isolating different parts of the filesystem for easier
    management. Snapshots are particularly useful since they offer read-only copies
    of the filesystem at a specific point in time. With snapshots, users can restore
    files or entire subvolumes to a previous state or easily create replicable backups
    that can be moved to another system.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 子卷的灵活性和多功能性使它们非常适合各种用途，例如创建备份或隔离文件系统的不同部分，以便更轻松地进行管理。快照特别有用，因为它们提供了在特定时间点的文件系统只读副本。通过快照，用户可以将文件或整个子卷恢复到以前的状态，或轻松创建可复制的备份，这些备份可以移动到另一台系统。
- en: Subvolumes also enable users to manage disk space more efficiently. For example,
    users can create a subvolume for a specific application or project and restrict
    its disk usage to a certain amount to prevent it from using up too much space
    on the filesystem. Additionally, subvolumes can be used to implement access controls
    by assigning different permissions to different subvolumes or creating separate
    subvolumes for different users or groups. This recipe will go over how to do all
    of this.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 子卷还使用户能够更有效地管理磁盘空间。例如，用户可以为特定的应用程序或项目创建一个子卷，并将其磁盘使用量限制在一定范围内，以防止它占用过多的文件系统空间。此外，子卷还可以通过为不同的子卷分配不同的权限，或为不同的用户或组创建独立的子卷来实施访问控制。本教程将介绍如何做到这一点。
- en: Getting ready
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: This recipe will require a Btrfs filesystem, and will use the data filesystem
    created in the previous recipe for the examples.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程需要一个 Btrfs 文件系统，并将使用上一教程中创建的数据文件系统作为示例。
- en: How to do it…
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'In this recipe, we will do the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中，我们将进行以下操作：
- en: Create a subvolume in `/data` and mount it.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `/data` 中创建子卷并挂载它。
- en: Set a quota on the subvolume.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置子卷的配额。
- en: Create a snapshot.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建快照。
- en: Enable compression.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用压缩。
- en: 'Creating a subvolume is straightforward and is done by using the `btrfs` command
    and specifying the full path to the subvolume:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 创建子卷很简单，只需使用 `btrfs` 命令并指定子卷的完整路径即可：
- en: '[PRE8]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once created, simply add it to `fstab`, this time declaring the subvolume name
    in the fourth column. This is seen in the following screenshot, where `/data/vol1`
    is mounted using subvolume `vol1`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 创建完成后，直接将其添加到 `fstab` 中，此时需要在第四列中声明子卷名称。以下截图显示了如何使用子卷 `vol1` 挂载 `/data/vol1`：
- en: '![Figure 4.15 – Subvolume in fstab](img/B18349_04_15.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.15 – fstab 中的子卷](img/B18349_04_15.jpg)'
- en: Figure 4.15 – Subvolume in fstab
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15 – fstab 中的子卷
- en: 'Now that we have the subvolume mounted, let’s add a quota to limit it to 5
    GB. To do this, we first need to enable quotas for the volume. This is done with
    the following command:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经挂载了子卷，让我们为其添加一个配额，将其限制为 5 GB。为此，首先需要启用该卷的配额。这可以通过以下命令完成：
- en: '[PRE9]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we need to assign a quota-group limit to the subvolume. This will restrict
    the subvolume to the size defined. This is done using the `limit` option, as seen
    in the following command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要为子卷分配配额组限制。这将限制子卷的大小。可以使用 `limit` 选项来完成此操作，如下所示的命令所示：
- en: '[PRE10]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can see what quotas are defined in a volume using the `btrfs qgroup show`
    command with the `-``reF` option:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `btrfs qgroup show` 命令和 `-reF` 选项，可以查看卷中定义的配额：
- en: '[PRE11]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The command and its output are shown in the following screenshot:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 命令及其输出显示在以下屏幕截图中：
- en: '![Figure 4.16 – Set quotas](img/B18349_04_16.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.16 – 设置配额](img/B18349_04_16.jpg)'
- en: Figure 4.16 – Set quotas
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.16 – 设置配额
- en: 'Now that we have a quota set, let’s create a snapshot for backups. We do need
    a place for the backups, so let’s create a subvolume for the backups with the
    following command:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了配额，让我们创建一个备份的快照。我们需要一个存放备份的位置，所以我们先创建一个子卷用来存放备份，使用以下命令：
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Btrfs snapshots are highly useful copies of a Btrfs filesystem, capturing a
    specific point in time. Through a seamless copy-on-write process, these snapshots
    separate any changes made to the filesystem from the snapshot itself. This makes
    them ideal for different purposes, such as creating backups, testing software
    configurations, and providing an effortless way to undo system updates. Additionally,
    backups can be created rapidly and with minimal storage space, as the snapshots
    only store the differences between the current state of the filesystem and the
    state at the moment the snapshot was taken. To create a Btrfs snapshot, you can
    use the `btrfs subvolume snapshot` command, specifying the subvolume you want
    to snapshot and the name and location of the snapshot:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Btrfs 快照是非常有用的 Btrfs 文件系统副本，用于捕捉某一特定时间点。通过无缝的写时复制过程，这些快照将对文件系统所做的任何更改与快照本身分离开来。这使得它们非常适合用于不同的用途，例如创建备份、测试软件配置和提供一种轻松的方式来撤销系统更新。此外，备份可以快速创建且占用最小的存储空间，因为快照仅存储文件系统当前状态与快照拍摄时的状态之间的差异。要创建
    Btrfs 快照，可以使用 `btrfs subvolume snapshot` 命令，指定要快照的子卷以及快照的名称和位置：
- en: '[PRE13]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This command creates a read-only snapshot of the `/data/vol1` subvolume and
    saves it as a separate subvolume in the `/``data/backup` directory.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令创建了 `/data/vol1` 子卷的只读快照，并将其作为一个单独的子卷保存在 `/data/backup` 目录下。
- en: Don’t worry if you’ve already taken a snapshot – you can easily revert the filesystem
    to its exact state at that time using the powerful Btrfs rollback feature. With
    Btrfs snapshot rollback, you can restore your Btrfs filesystem to a previous state
    by simply selecting a snapshot. Rolling back to a snapshot discards all changes
    made to the filesystem since the snapshot was taken and restores the filesystem
    to the exact state it was in when the snapshot was created.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经创建了一个快照，不用担心——你可以通过强大的 Btrfs 回滚功能轻松地将文件系统恢复到当时的精确状态。通过 Btrfs 快照回滚，你只需选择一个快照，就可以将
    Btrfs 文件系统恢复到先前的状态。回滚到快照会丢弃自快照创建以来对文件系统所做的所有更改，并将文件系统恢复到快照创建时的精确状态。
- en: 'To roll back a Btrfs snapshot, you can use the `btrfs subvolume snapshot` command
    with the `-r` option, which specifies that the snapshot should be used for a rollback:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 要回滚 Btrfs 快照，可以使用 `btrfs subvolume snapshot` 命令并加上 `-r` 选项，指定使用该快照进行回滚：
- en: '[PRE14]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This command rolls back `/data/vol1` to the state it was in when the `/data/backup/vol1_backlup1`
    snapshot was created.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将 `/data/vol1` 回滚到 `/data/backup/vol1_backlup1` 快照创建时的状态。
- en: It is important to note that rolling back a snapshot will discard any changes
    made to the filesystem since the snapshot was taken. However, this feature is
    extremely useful when you want to fully revert the filesystem to a previous state.
    Btrfs snapshots provide a simple and effective solution for data management and
    protection, allowing for effortless backup creation and easy restoration of prior
    filesystem versions.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，回滚快照会丢弃自快照创建以来对文件系统所做的任何更改。然而，当你想将文件系统完全恢复到先前的状态时，这一功能非常有用。Btrfs 快照提供了一个简单有效的数据管理和保护解决方案，使得备份创建变得轻松，并能够方便地恢复先前的文件系统版本。
- en: Note
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Automatic snapshots can be enabled so a `dnf` transaction will create a snapshot.
    This is done by the `dnf-plugin-snapper` tool. More information can be found here:
    [https://docs.oracle.com/en/operating-systems/oracle-linux/8/fsadmin/fsadmin-ManagingtheBtrfsFileSystem.html#snapper-btrfs](https://docs.oracle.com/en/operating-systems/oracle-linux/8/fsadmin/fsadmin-ManagingtheBtrfsFileSystem.html#snapper-btrfs).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 可以启用自动快照，使得 `dnf` 事务会创建一个快照。此操作由 `dnf-plugin-snapper` 工具完成。更多信息可以参见：[https://docs.oracle.com/en/operating-systems/oracle-linux/8/fsadmin/fsadmin-ManagingtheBtrfsFileSystem.html#snapper-btrfs](https://docs.oracle.com/en/operating-systems/oracle-linux/8/fsadmin/fsadmin-ManagingtheBtrfsFileSystem.html#snapper-btrfs)。
- en: This section will cover how to enable compression using the Btrfs filesystem.
    Btrfs compression is a powerful feature that allows you to compress data in real
    time while writing it to the filesystem. This feature can significantly reduce
    storage space, making it ideal for filesystems that store vast amounts of data,
    such as media archives and backup systems. Additionally, it’s beneficial for systems
    with limited storage space, such as mobile devices and embedded systems.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何使用Btrfs文件系统启用压缩。Btrfs压缩是一项强大的功能，可以在将数据写入文件系统的同时实时压缩数据。此功能可以显著减少存储空间，特别适合存储大量数据的文件系统，如媒体归档和备份系统。此外，它对于存储空间有限的系统（如移动设备和嵌入式系统）也很有帮助。
- en: 'Btrfs compression uses various compression algorithms to compress data while
    writing it to the filesystem. The compressed data is then stored on the disk and
    automatically decompressed on the fly when accessed. This process is seamless
    to the applications accessing the data, so there’s no need for them to be aware
    of the compression process as Btrfs handles it. Btrfs supports three compression
    algorithms, `zlib`, `lzo`, and `zstd`, each with its own strengths and weaknesses:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Btrfs压缩在将数据写入文件系统时使用各种压缩算法。这些压缩数据会存储在磁盘上，并在访问时自动解压。这个过程对访问数据的应用程序是透明的，因此它们不需要关注压缩过程，Btrfs会自动处理。Btrfs支持三种压缩算法：`zlib`、`lzo`和`zstd`，每种算法都有其优缺点：
- en: '`zlib`: This is a widely used general-purpose compression algorithm that provides
    good compression ratios but can be relatively slow, especially at higher compression
    levels. It is suitable for compressing general-purpose data and text files.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zlib`：这是一种广泛使用的通用压缩算法，提供良好的压缩比，但在较高压缩级别下可能相对较慢。它适用于压缩通用数据和文本文件。'
- en: '`lzo`: This is a lightweight compression algorithm that provides good compression
    ratios and is relatively fast. It is suitable for compressing data that is already
    compressed, such as media files and archives.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lzo`：这是一种轻量级压缩算法，提供良好的压缩比，并且相对较快。它适用于压缩已经压缩过的数据，如媒体文件和归档文件。'
- en: '`zstd`: This is a newer compression algorithm that provides a good balance
    between compression ratio and speed. It is suitable for compressing a wide range
    of data types, including text, media files, and archives.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zstd`：这是一种较新的压缩算法，它在压缩比和速度之间提供了良好的平衡。它适用于压缩各种类型的数据，包括文本、媒体文件和归档文件。'
- en: The choice of compression algorithm depends on the specific use case and performance
    requirements.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 压缩算法的选择取决于特定的使用场景和性能要求。
- en: 'To enable compression on a filesystem, you can use the `btrfs property` command
    to set the compression for the filesystem:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要在文件系统上启用压缩，可以使用`btrfs property`命令来设置文件系统的压缩：
- en: '[PRE15]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'When compression is enabled, only new data being written to the filesystem
    is compressed. However, you can also use the `defragment` command to compress
    the data that was on the filesystem before compression was enabled. To do this
    on a subvolume, you will also need to recursively run the command using the `-r`
    option along with the `-c` option to compress data:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用压缩时，只有写入到文件系统的新增数据会被压缩。不过，你也可以使用`defragment`命令来压缩在启用压缩之前已经存在于文件系统中的数据。要在子卷上执行此操作，还需要使用`-r`选项递归运行命令，并配合`-c`选项来压缩数据：
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: There’s more…
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: 'Compression efficiency will vary, depending on the data and algorithm used.
    Let’s first check how much space we have, using the following command:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 压缩效率会有所不同，取决于所使用的数据和算法。让我们首先使用以下命令检查剩余空间：
- en: '[PRE17]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, let’s create a 2 GB file with random data:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个包含随机数据的2 GB文件：
- en: '[PRE18]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, we can use the `df` and `du` commands to compare the space consumed and
    the space used:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用`df`和`du`命令来比较已消耗的空间和已使用的空间：
- en: '[PRE19]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The sample outputs for these commands are as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令的示例输出如下：
- en: '[PRE20]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here, we can see 2 GB is used (via the `du` command), and also 2 GB (via the
    `df` command) is actually consumed. So, for this random data file, we can see
    no benefit from the compression.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到2 GB的空间已经被使用（通过`du`命令），而且实际上2 GB空间已经被消耗（通过`df`命令）。因此，对于这个随机数据文件，我们看到压缩并未带来任何好处。
- en: 'Let’s delete the `test1` file now:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们删除`test1`文件：
- en: '[PRE21]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To speed things up, let’s defrag and rebalance the volume. This is needed to
    actually free up the space from the deleted file now, instead of waiting:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加速，我们来进行碎片整理和重新平衡。这是现在就释放已删除文件的空间所需要的，而不是等待：
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, with a file with lots of repeating data, we will see more compression.
    To create a 2 GB file with repeating data, run the following command:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, we repeat the same `du` and `df` commands as before, but we will see very
    different results:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, we see 4 GB is allocated, but only 62 MB is actually used! That’s a huge
    benefit from the compression.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Protecting data with mdadm – a software RAID solution
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modern computing systems rely on RAID technology to ensure data integrity, availability,
    and performance. By distributing data across multiple disks in various configurations,
    RAID provides fault tolerance, allowing systems to continue functioning even if
    one or more disks fail. This redundancy is critical to prevent data loss and minimize
    downtime.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, RAID configurations such as striping and mirroring can significantly
    improve read and write performance by allowing data to be accessed in parallel
    from multiple disks. As data volume and importance continue to increase in today’s
    digital world, RAID plays a vital role in protecting, optimizing, and maintaining
    storage system reliability. The easiest way to do this when not using Btrfs with
    Oracle Linux 8 is to use a tool called **mdadm**.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'mdadm is a software utility for managing and configuring software RAID arrays
    in Linux systems. It stands for **multiple device administration** and is commonly
    used to create, manage, monitor, and maintain RAID arrays. These arrays leverage
    a kernel driver called **multiple device** (**MD**). mdadm allows users to create
    various RAID levels, including RAID, RAID 0, RAID 1, RAID 5, RAID 6, RAID 0+1,
    and RAID 10, using a combination of multiple physical disks:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '| **Type** | **Description** | **Notes** |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
- en: '| RAID | Spanning | No redundancy or performance advantages. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
- en: '| RAID-0 | Striping | No redundancy, but better performance versus RAID. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
- en: '| RAID-1 | Mirroring | Mirrored redundancy, but no performance advantage in
    write workloads. Read workloads may improve. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
- en: '| RAID-5 | Striping with double parity | Redundancy and good performance. Can
    lose one disk without data loss. Recommended to use at least four disks. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
- en: '| RAID-6 | Striping with tripple parity | Redundancy and good performance.
    Can lose two disks without data loss. Recommended to use at least five disks.
    |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '| RAID 0+1 | Mirroring of striped disks | Great performance, but recovering
    a lost disk takes a long time. This requires at least four disks. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
- en: '| RAID 10 | Striping of mirrored disks | Most expensive option, but generally
    considered the best for redundancy, performance, and rebuild time. This requires
    at least four disks. |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
- en: Table 4.2 – MD RAID options
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: It’s not uncommon to confuse a **JBOD** (**just a box of disks**) enclosure
    with a RAID enclosure. JBOD is a simple disk enclosure with no hardware RAID.
    A RAID disk enclosure has a hardware controller that offloads all the RAID logic
    for the disks within the enclosure. For this example, hardware RAID is not being
    used, only JBOD. All the RAID logic is being performed by Oracle Linux.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: mdadm is an essential tool for administrators to create, modify, and monitor
    RAID arrays. It allows users to add or remove disks from an existing array, perform
    data recovery operations, and configure various parameters such as RAID level
    and spare disks. With its command-line interface, mdadm provides flexibility in
    managing and maintaining disk redundancy and performance. It is a reliable and
    robust solution that optimizes storage performance, ensures data redundancy, and
    maintains high availability of data. mdadm is normally installed when Oracle Linux
    is installed.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating an MD device is fairly simple. But before you create the device, you
    need to plan a few things in advance:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: What type of RAID will you be using? As mentioned previously, the MD kernel
    driver supports many types of RAID algorithms. You need to pick one before running
    the command. This maps to the `–``level` option.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many drives will you be using in the device? Most RAID types use even numbers
    of disks, but you still need to know how many disks will be used for data. This
    maps to the `–``raid-devices` option.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will you configure a hot spare device? Hot spares are a great option when systems
    need to automatically rebuild the data if a device fails. It’s not uncommon in
    remote locations to have many hot spares. When picking hot spares, balance the
    required space versus how long it will take for a replacement to be installed.
    This maps to the `–``spare-devices` option.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the number of the MD device? Traditionally, you start with 0 and work
    your way up, but track the numbers so you do not accidentally use the wrong device.
    This maps to `/dev/md#`.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the paths to the drives that you are going to use? They are normally
    `/dev/sd#`, `/dev/nvme#`, or even `/dev/vd#`.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following example, we will create a RAID-5 array with one hot spare.
    The device being used is `/dev/sd[bcdef]` and this will be the `/``dev/md0` device:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You can quickly check the status by cating the `/``proc/mdstat` file:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.17 – /proc/mdstat](img/B18349_04_17.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
- en: Figure 4.17 – /proc/mdstat
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'The last step, while optional, is highly recommended. This will save the current
    config to the mdadm configuration file. This helps the kernel assemble the array
    at boot. This is done with the following command:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works…
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s look at a few things about the MD device. First, if we use the `lsblk`
    command, we will see that the disks used by `md0` are now identified as having
    `md0` as children. This is because `md0` is a child of the actual disk:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.18 – lsblk command output](img/B18349_04_18.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
- en: Figure 4.18 – lsblk command output
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also check the device with the `-Q` option to the `mdamd` command. Simply
    pass the device as a parameter, and the command will give you a short summary:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.19 – mdadm -Q](img/B18349_04_19.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
- en: Figure 4.19 – mdadm -Q
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, you can pass the `–-detail` option to get significantly more information
    about the array:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.20 – mdadm --detail](img/B18349_04_20.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
- en: Figure 4.20 – mdadm --detail
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see not only the health of the array but also its creation date
    and lower-level metrics such as block size and layout.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Once the volume is created, you can now use it for filesystems or as storage
    for a logical volume manager.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Playing with logical volume management
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to filesystems, one of the biggest issues is their inflexibility
    when it comes to storage. Creating a volume on a disk means the space is locked
    in for the volume, which also locks in the size of the filesystem. However, **Logical
    Volume Manager** (**LVM**) provides a solution to this problem. LVM is a widely
    used tool in the field of computer storage management that acts as a layer of
    abstraction between physical storage devices, such as hard drives or SSDs, and
    the OS. This enables the flexible and efficient management of storage resources.
    LVM is especially valuable for Linux systems, as it offers a flexible and scalable
    storage management solution.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: With LVM, administrators can dynamically allocate and resize storage volumes
    without the need to repartition disks or disrupt the system. This flexibility
    is particularly useful in environments where storage requirements change frequently
    or where efficient resource allocation is needed. Additionally, LVM introduces
    the concept of volume groups, which act as logical containers for physical storage
    devices. By creating logical volumes within volume groups, administrators can
    easily allocate and manage storage space, simplifying the management of storage
    resources in Linux systems and making it easier to organize and utilize storage
    resources effectively.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'With LVM, there are three core components of the storage:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '**Physical volumes** (**PVs**): These are the block-level disk devices that
    are used for storage. They can be physical disks, virtual disks (such as the MD
    devices created in the mdadm recipe), or other block-level devices.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volume groups** (**VGs**): These are groups of PVs that are combined into
    a single logical device. They can be a single device to start with, with new devices
    added later to add capacity.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logical volumes** (**LVs**): These are logical disks built into the VG. They
    are used to create filesystems and can be dynamically resized as needed.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LVM, a VG, is a central component that acts as a logical container for one or
    more PVs. A VG is created by combining physical storage devices, such as hard
    drives or SSDs, into a single storage pool.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will show you how to initialize PVs, create a VG, and then
    add LVs for future use by a filesystem. We will also show some of the basic management
    commands.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The examples in this recipe will use the `/dev/md0` virtual disk created in
    the mdadm recipe, in addition to a few extra LUNs. The LVM RPMs are normally installed
    by default with a normal installation.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step is to identify what disks we can use. This is done with the
    `lvmdiskscan` command:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.21 – lvmdiskscan](img/B18349_04_21.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: Figure 4.21 – lvmdiskscan
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see three devices, `md0`, `sda1`, and `sda2`. We can also see
    that `sda2` is already initialized as a PV. We can use the `pvs` command to display
    the PVs on the system:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.22 – pvs](img/B18349_04_22.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
- en: Figure 4.22 – pvs
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that the `/dev/sda2` device is used by the `ol` VG. Let’s
    go ahead and use `pvcreat` to initialize `/dev/md0`. This is done with the following
    command:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now that the device is initialized, we can create a VG. This is done with the
    `vgcreate` command. The command uses the first parameter as the name of the VG
    and then a list of devices. In this case, we will only use `/dev/md0` to create
    the `DATA` VG:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: How it works…
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can see the list of VGs on a system using the `vgs` command:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.23 – vgs](img/B18349_04_23.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
- en: Figure 4.23 – vgs
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see two VGs: the freshly created `DATA` VG and the existing `ol`
    VG where the OS is installed. We will then use the VG to create an LV. This is
    done with the `lvcreate` command. The `lvcreate` command takes a few parameters:
    `-L` to set the size of the volume, `-n` for the name, and then at the end, the
    VG where the volume will exist. Let’s create a 3 GB volume named `xfs1` in the
    `DATA` VG:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can also tell `lvcreate` to use all available space. This is done using
    a lowercase `l` and the special `100%FREE` option:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `lvs` command will show all the LVs on a server:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.24 – lvs](img/B18349_04_24.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
- en: Figure 4.24 – lvs
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see the `xfs1` and `xfs2` volumes and their size. Additionally,
    we can see all the volumes in `ol`, where Linux was installed.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go ahead and free up some space by deleting the `xfs2` LV. This is done
    with the `lvremove` command. When using `lvremove`, use the VG/LV to identify
    the LV being deleted. The following command will remove the `xfs2` LV:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You will also need to acknowledge the removal:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.25 – lvremove](img/B18349_04_25.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
- en: Figure 4.25 – lvremove
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: 'The last trick is to see the details of a specific LV. This is done with the
    `lvdisplay` command. You can run the command by itself, and this will show the
    details for all LVs on the server. Optionally, you can use the command to report
    on a single LV, in this case the `xfs1` LV:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output is as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.26 – lvdisplay](img/B18349_04_26.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
- en: Figure 4.26 – lvdisplay
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: Here, you can see the volume creation date, the UUID, and the size of the volume.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Once created, there are various ways to access LVs, but the most common method
    is by using their mapper addresses. In Linux, the `/dev/mapper` directory is utilized
    to access device mapper devices, which is a kernel-level framework that allows
    for the creation and management of virtual block devices. With a device mapper,
    advanced storage functionalities such as software RAID, encryption, and LVM can
    be achieved. By using LVM, a device mapper creates virtual devices that are represented
    as device mapper devices under the `/dev/mapper` directory, which act as abstractions
    and provide an interface for accessing and managing the underlying storage features.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, logical volumes set up using LVM are mapped to device mapper
    devices located in the `/dev/mapper` directory. Each logical volume has a corresponding
    device mapper device entry that can be used to interact with the logical volume
    as if it were a regular block device. The path for accessing it is `/dev/mapper`
    followed by the `VG-LV` name. Thus, `DATA/xfs1` would be `/dev/mapper/DATA-xfs1`.
    You can use the `dmsetup ls` command to show all of the mapped devices:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.27 – dmsetup ls](img/B18349_04_27.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
- en: Figure 4.27 – dmsetup ls
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: XFS – creating, modifying, and more
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: XFS is a highly advanced and established filesystem that boasts an array of
    benefits and features, making it an ideal option for a wide range of use cases.
    XFS is designed to handle vast storage capacities, making it suitable for environments
    with heavy data demands. It can support filesystems and files up to 8 exabytes
    in size, allowing for the management of vast amounts of data. This scalability
    makes XFS highly suitable for big data applications, enterprise storage systems,
    and large-scale storage deployments. XFS has exceptional performance capabilities.
    It employs advanced techniques such as allocation-group-based block mapping, delayed
    allocation, and asynchronous I/O, which optimize disk I/O operations and improve
    overall throughput. XFS is particularly effective at handling large files and
    performing tasks that involve intensive read and write operations.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: XFS incorporates data protection features to safeguard against data corruption.
    It employs checksumming for both metadata and data, allowing the filesystem to
    detect and address potential data integrity issues. Additionally, XFS supports
    **copy-on-write** (**COW**) snapshots, enabling efficient point-in-time backups
    and data recovery options. XFS also uses a journaling mechanism that provides
    fast recovery in case of system crashes or power failures. The journaling feature
    records modifications to the filesystem metadata, ensuring the consistency and
    integrity of data. This results in faster boot times and improved reliability,
    as well as the reduction of time required for filesystem checks during system
    startup.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Oracle actively contributes to many Linux technologies. The COW XFS feature
    was one example of an Oracle contribution to the community, keeping Linux free
    and open source. For more info, refer to [https://blogs.oracle.com/linux/post/xfs-data-block-sharing-reflink](https://blogs.oracle.com/linux/post/xfs-data-block-sharing-reflink).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: With XFS, administrators can perform a broad range of filesystem operations
    while the filesystem is mounted and in use. This includes online resizing, enabling
    seamless expansion or contraction of filesystems without requiring unmounting
    or disruption of services. These online administration capabilities make XFS highly
    suitable for environments that demand continuous availability and minimal downtime.
    XFS also offers extensive support for extended attributes, **access-control lists**
    (**ACLs**), and timestamps with nanosecond precision. These features provide flexibility
    in managing file metadata and enable the implementation of complex permission
    structures and custom metadata schemes.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: XFS is natively supported by the Linux kernel, making it a well-integrated and
    widely adopted choice for Linux distributions. It is the default filesystem in
    Oracle Linux and continues to benefit from ongoing development and improvement
    by Oracle and the Linux community. Additionally, XFS comes with a comprehensive
    set of tools for filesystem management and administration, making it an all-around
    top-notch option.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The examples in this recipe will use the previously created `xfs1` LV. XFS filesystems
    can be created on any block device.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The most common way to create an XFS filesystem is to use the `mkfs.xfs` command
    with a single block device. This will place both the data and the journal on the
    same device:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Additionally, you can get more control using additional parameters:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** | **Samples** |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
- en: '| `-L` | This adds a label to the filesystem. | `-``L Test` |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
- en: '| `-b` | This sets the block size. | `-``b 8192` |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
- en: '| `-f` | This is the force option. | `-f` |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
- en: '| `-l` | This sets the location and size for the journal. This is commonly
    used to tune the performance by enabling the journal to be on a fast device while
    the data is on a slower device.`Size=20m /dev/$DEVICE` | `-l` `20m /dev/mapper/journal1`
    |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
- en: Table 4.3 – XFS options
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, add in the `/etc/fstab` entry info. Make sure to verify whether the mountpoint
    exists, and that you’re using the correct `/dev/mapper` path. The updated files
    are seen in the following screenshot:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.28 – /etc/fstab](img/B18349_04_28.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
- en: Figure 4.28 – /etc/fstab
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now mount the filesystem with the following `mount` command:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can clearly see the filesystem is mounted now, as seen in the output from
    the `df` command:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.29 – df -h](img/B18349_04_29.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
- en: Figure 4.29 – df -h
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that the filesystem is mounted, we can do a few things to it. The first
    task is to grow the filesystem as 2 GB was a tad small for the application. This
    is done in a few steps. First, we grow the LV that holds the filesystem, and then
    we can grow the filesystem. Let’s grow this to 10 GB.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: 'To grow the volume, we will use the `lvextend` command, passing to it the `+`
    option to add an additional 8 GB:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is seen in the following screenshot:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.30 – lvextend](img/B18349_04_30.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
- en: Figure 4.30 – lvextend
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the LV is grown, we need to extend the actual filesystem. This is done
    with the `xfs_growfs` command, passing the mapper path:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Depending on how much activity is on the filesystem, the growth can take a
    few minutes. The output from the `xfs_growfs` command will show the details of
    the filesystem when it completes:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.31 – xfs_growfs](img/B18349_04_31.jpg)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
- en: Figure 4.31 – xfs_growfs
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: You can also see these details by using the `xfs_info` command, passing the
    mountpoint of the filesystem or the mapper path.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'If you encounter problems mounting an `xfs` filesystem, you can use the `xfs_repair`
    command-line utility to repair and recover it. However, keep in mind that the
    command must be run on an unmounted filesystem. The main purpose of `xfs_repair`
    is to fix inconsistencies and repair filesystem corruption in XFS partitions caused
    by power failures, system crashes, or hardware issues. You can also use the `-n`
    option to check a filesystem without repairing it. For example, you can check
    the `xfs1` filesystem without repairing it by using the following command:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
